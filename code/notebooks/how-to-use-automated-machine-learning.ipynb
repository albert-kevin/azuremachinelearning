{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Kevin ALBERT  \n",
    "\n",
    "Created: April 2020  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Machine Learning\n",
    "_**Classification project with data residing on a data lake gen2 using remote compute with autoML and model registration**_\n",
    "\n",
    "## Contents\n",
    "1. [AutoML](#AutoML)\n",
    "1. [Setup](#Setup)\n",
    "1. [Train](#Train)\n",
    "1. [Results](#Results)\n",
    "1. [Register](#Register)\n",
    "1. [Deploy](#Deploy)\n",
    "1. [Test](#Test)\n",
    "1. [CustomML](#CustomML)\n",
    "1. [Finetuning](#Finetuning)\n",
    "1. [ONNX](#ONNX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Cleaned datasets created in datafactory onto a delta lake Gen2.  \n",
    "This notebook is using delta lake data and remote compute to autoML train a classification model.  \n",
    "We use example data to detect diabetic or non-diabetic based on 8 features.  \n",
    "\n",
    "This notebook show how to:\n",
    "1. Setup packages\n",
    "1. Setup workspace\n",
    "1. Create an experiment\n",
    "1. Load data\n",
    "1. Setup compute\n",
    "1. Configure autoML\n",
    "1. Train pipelines\n",
    "1. Explore the best pipeline\n",
    "1. Inspect model properties\n",
    "1. Register the model\n",
    "1. Deploy model as webservice\n",
    "1. Webservice inference test\n",
    "1. customML inline method\n",
    "1. customML script method\n",
    "1. HyperParametertuning\n",
    "1. ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* required\n",
    "  * disable shield on Brave webbrowser for the widgets to work\n",
    "  * download **config.json** from the machine learning workspace portal\n",
    "  * install extra azureml packages on **py37_default** when using **'local'** compute  \n",
    "  * split the data up in train and test dataset on data lake, validation dataset is not needed due to cross_validation\n",
    "* optional\n",
    "  * register datastore(s) manually\n",
    "  * register dataset(s) manually\n",
    "  * register compute cluster(s) manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! /anaconda/envs/py37_default/bin/python -m pip install -U azureml-sdk[explain,automl] azureml-widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import open-source packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import azure machine learning SDK packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml.core version: 1.2.0\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Dataset, Datastore, Run\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, AksCompute\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.webservice import Webservice, AciWebservice, AksWebservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling, GridParameterSampling\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice\n",
    "import azureml.core\n",
    "print(\"azureml.core version:\", azureml.core.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "# load the workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose an experiment name\n",
    "experiment = Experiment(ws, 'automl-classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Factory has prepped data from /bronze to /silver to /gold and /platinum for model training  \n",
    "**note:** this demonstration had files in the Data Lake Gen2 datalake container /platinum folder  \n",
    "  * /datalake/platinum/diabetes.csv\n",
    "  * /datalake/platinum/diabetes.parquet\n",
    "  * copy from ../data/platinum/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the datastore 'data lake gen2' as a **blob container**  \n",
    "**optional:** manually register in ML workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datalakestoragegen2': {\n",
       "   \"name\": \"datalakestoragegen2\",\n",
       "   \"container_name\": \"datalake\",\n",
       "   \"account_name\": \"datalake21032020\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " },\n",
       " 'workspaceblobstore': {\n",
       "   \"name\": \"workspaceblobstore\",\n",
       "   \"container_name\": \"azureml-blobstore-de4d27fa-16a7-42c6-acc9-62fb5ff16179\",\n",
       "   \"account_name\": \"mlworkspace5331841681\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " },\n",
       " 'workspacefilestore': {\n",
       "   \"name\": \"workspacefilestore\",\n",
       "   \"container_name\": \"azureml-filestore-de4d27fa-16a7-42c6-acc9-62fb5ff16179\",\n",
       "   \"account_name\": \"mlworkspace5331841681\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " }}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Datastore.register_azure_blob_container(\n",
    "    workspace=ws,\n",
    "    datastore_name=\"datalakestoragegen2\",\n",
    "    container_name=\"datalake\",\n",
    "    account_name=\"datalake21032020\",\n",
    "    account_key=\"Ck/4hMq3Zrzq5toZ96zE6cDncjbw2VdkR9ny1xXA3GLBwQXIv7V1ycSc/KpqyNRcoPWKtzKljjpcZVqjWOu+3Q==\",\n",
    "    create_if_not_exists=False)\n",
    "# list available datastores\n",
    "ws.datastores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register file(s) into a tabular dataset  \n",
    "**Note:** do not import Delta lake parquet file(s)  \n",
    "**Fix:** you can import pandas single gold/*.csv or gold/*.parquet file(s)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"name\": \"datalakestoragegen2\",\n",
       "  \"container_name\": \"datalake\",\n",
       "  \"account_name\": \"datalake21032020\",\n",
       "  \"protocol\": \"https\",\n",
       "  \"endpoint\": \"core.windows.net\"\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load datastore\n",
    "ds = Datastore.get(ws, 'datalakestoragegen2')\n",
    "# show datastore settings\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1 Tabular:** loading *.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('datalakestoragegen2', 'platinum/diabetes.parquet')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ReadParquetFile\",\n",
       "    \"DropColumns\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup parquet file(s) into a tabular dataset\n",
    "ds_path = [DataPath(ds, 'platinum/diabetes.parquet')] # {path/*.parquet}\n",
    "dataset = Dataset.Tabular.from_parquet_files(path=ds_path)\n",
    "# show dataset settings\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2 Tabular:** loading *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup csv file(s) into a tabular dataset\n",
    "ds_path = [DataPath(ds, 'platinum/diabetes.csv')]\n",
    "dataset = Dataset.Tabular.from_delimited_files(path=ds_path)\n",
    "# show dataset settings\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 3 Registered:** loading a registered dataset (manually register in ML workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list available datasets\n",
    "ws.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a registered dataset\n",
    "dataset = Dataset.get_by_name(ws, 'diabetes_parquet_from_datastore_datalakegen2')\n",
    "# show dataset settings\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check possible compute type **names** to create auto-scaling cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpus</th>\n",
       "      <th>maxResourceVolumeMB</th>\n",
       "      <th>memoryGB</th>\n",
       "      <th>name</th>\n",
       "      <th>vCPUs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>51200</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Standard_D1_v2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>7168</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Standard_DS1_v2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>51200</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Standard_D1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gpus  maxResourceVolumeMB  memoryGB             name  vCPUs\n",
       "0      0                51200      3.50   Standard_D1_v2      1\n",
       "8      0                 7168      3.50  Standard_DS1_v2      1\n",
       "18     0                51200      3.50      Standard_D1      1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example: list all with 1=vCPUs 2>GB and no-GPU\n",
    "vm_df = pd.DataFrame(AmlCompute.supported_vmsizes(ws))\n",
    "vm_df[(vm_df.vCPUs == 1) & (vm_df.memoryGB >= 2) & (vm_df.gpus == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option 1: Create training cluster  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# Specify a name for the compute (unique within the workspace)\n",
    "compute_name = 'aml-cluster'\n",
    "# Define compute configuration\n",
    "compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_D1_v2',\n",
    "                                                       min_nodes=0, # you are not paying if not using\n",
    "                                                       max_nodes=10, # depending quota limits\n",
    "                                                       vm_priority='dedicated', # {lowpriority, dedicated}\n",
    "                                                       admin_username='ubuntu',\n",
    "                                                       admin_user_password='ABCD1234abcd',\n",
    "                                                       idle_seconds_before_scaledown=120, # {default: 120}\n",
    "                                                      )\n",
    "# Create the compute\n",
    "training_cluster = ComputeTarget.create(ws, compute_name, compute_config)\n",
    "training_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option 2: Load already known training cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aml-cluster\n"
     ]
    }
   ],
   "source": [
    "# list all available training cluster(s):\n",
    "for cluster in ws.compute_targets:\n",
    "    print(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training cluster\n",
    "compute_name = 'aml-cluster'\n",
    "training_cluster = ComputeTarget(ws, name=compute_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure autoML\n",
    "Define settings to run the experiment.\n",
    "\n",
    "|Property|Description|Options|\n",
    "|-|-|-|\n",
    "|**task**||<i>classification</i><br><i>regression</i><br><i>forecasting</i>|\n",
    "|**compute_target**|execution on local DSVM serialized<br>execution on remote AML or AKS parallel|<i>local</i><br><i>training_cluster</i>|\n",
    "|**primary_metric**|the metric you want to optimize<br>[metrics](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml)|**classification:**<br><i>accuracy</i><br><i>AUC_weighted</i><br><i>average_precision_score_weighted</i><br><i>norm_macro_recall</i><br><i>precision_score_weighted</i><br><br>**regression:**<br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>|\n",
    "|**training_data**|input dataset, containing both X_train and y_train|<i>DataFrame</i><br><i>Dataset</i><br><i>DatasetDefinition</i><br><i>TabularDataset</i>|\n",
    "|**validation_data**|input dataset, covered with cross validation|N/A|\n",
    "|**label_column_name**|the name of the 'target' or 'label' column||\n",
    "|**enable_early_stopping**|stop the run if metric score is not improving|<i>True</i><br><i>False</i>|\n",
    "|**n_cross_validations**|number of cross validation splits|5|\n",
    "|**experiment_timeout_hours**|max time in hours the experiment terminates (+15min)|<i>0.25</i>|\n",
    "|**max_concurrent_iterations**|less or equal to the number of cores per node|2|\n",
    "\n",
    "\n",
    "\n",
    "**_You can find more information_** [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"enable_early_stopping\":True,\n",
    "    \"experiment_timeout_hours\":0.25,\n",
    "    \"iterations\":10, # number of runs\n",
    "    \"iteration_timeout_minutes\":5,\n",
    "    \"max_concurrent_iterations\":1,\n",
    "    \"max_cores_per_iteration\":-1,\n",
    "    #\"experiment_exit_score\":0.9920,\n",
    "    \"model_explainability\":True,\n",
    "    \"n_cross_validations\":5,\n",
    "    \"primary_metric\":'AUC_weighted',\n",
    "    \"featurization\":'auto',\n",
    "    \"verbosity\":logging.INFO, # {INFO, DEBUG, CRITICAL, ERROR, WARNING} -- debug_log=<*.log>\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task='classification',\n",
    "                             debug_log='automl_errors.log',\n",
    "                             compute_target='local', # {training_cluster or 'local'}\n",
    "                             #blacklist_models=['KNN','LinearSVM'],\n",
    "                             enable_onnx_compatible_models=True,\n",
    "                             training_data=dataset,\n",
    "                             label_column_name=\"Diabetic\",\n",
    "                             **automl_settings\n",
    "                            )\n",
    "# ouputs \"model.pkl\" and \"automl_errors.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819\n",
      "\n",
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Classes are balanced in the training data.\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:00:19       0.9904    0.9904\n",
      "         1   MaxAbsScaler XGBoostClassifier                 0:00:22       0.9901    0.9904\n",
      "         2   MaxAbsScaler LightGBM                          0:00:15       0.9800    0.9904\n",
      "         3   StandardScalerWrapper XGBoostClassifier        0:00:19       0.9729    0.9904\n",
      "         4   MaxAbsScaler SGD                               0:00:16       0.9320    0.9904\n",
      "         5   StandardScalerWrapper LightGBM                 0:00:17       0.9799    0.9904\n",
      "         6   SparseNormalizer XGBoostClassifier             0:00:18       0.9383    0.9904\n",
      "         7   MaxAbsScaler RandomForest                      0:00:19       0.9654    0.9904\n",
      "         8   MaxAbsScaler SGD                               0:00:17       0.9337    0.9904\n",
      "         9   VotingEnsemble                                 0:00:22       0.9901    0.9904\n",
      "****************************************************************************************************\n",
      "Current status: BestRunExplainModel. Best run model explanations started\n",
      "Current status: ModelExplanationDataSetSetup. Model explanations data setup completed\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features started\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features completed\n",
      "Current status: BestRunExplainModel. Best run model explanations completed\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "automl_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: retrieve a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "runId = 'AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819'\n",
    "automl_run = AutoMLRun(experiment, run_id=runId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the best pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41374cf0ce544dc4968a7bdf98025aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/automl-classification/runs/AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/ml_workspace\", \"run_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819\", \"run_properties\": {\"run_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819\", \"created_utc\": \"2020-04-13T09:33:32.202221Z\", \"properties\": {\"num_iterations\": \"10\", \"training_type\": \"TrainFull\", \"acquisition_function\": \"EI\", \"primary_metric\": \"AUC_weighted\", \"train_split\": \"0\", \"acquisition_parameter\": \"0\", \"num_cross_validation\": \"5\", \"target\": \"local\", \"RawAMLSettingsString\": \"{'name': 'automl-classification', 'path': '.', 'subscription_id': '43c1f93a-903d-4b23-a4bf-92bd7a150627', 'resource_group': 'myResourceGroup', 'workspace_name': 'ml_workspace', 'region': 'northeurope', 'compute_target': 'local', 'spark_service': None, 'azure_service': 'local', 'iterations': 10, 'primary_metric': 'AUC_weighted', 'task_type': 'classification', 'data_script': None, 'validation_size': 0.0, 'n_cross_validations': 5, 'y_min': None, 'y_max': None, 'num_classes': 2, 'featurization': 'auto', 'lag_length': 0, 'is_timeseries': False, 'max_cores_per_iteration': -1, 'max_concurrent_iterations': 1, 'iteration_timeout_minutes': 5, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'experiment_timeout_minutes': 15, 'experiment_exit_score': None, 'whitelist_models': None, 'blacklist_algos': ['KNN', 'KNN', 'SVM'], 'supported_models': ['ExtremeRandomTrees', 'KNN', 'BernoulliNaiveBayes', 'AveragedPerceptronClassifier', 'MultinomialNaiveBayes', 'SGD', 'LightGBM', 'TensorFlowDNN', 'DecisionTree', 'GradientBoosting', 'SVM', 'LogisticRegression', 'XGBoostClassifier', 'LinearSVM', 'RandomForest', 'TensorFlowLinearClassifier'], 'auto_blacklist': True, 'blacklist_samples_reached': True, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'automl_errors.log', 'show_warnings': False, 'model_explainability': True, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'enable_onnx_compatible_models': True, 'enable_split_onnx_featurizer_estimator_models': False, 'vm_type': None, 'telemetry_verbosity': 'INFO', 'send_telemetry': True, 'enable_dnn': False, 'force_text_dnn': False, 'enable_feature_sweeping': False, 'enable_early_stopping': True, 'early_stopping_n_iters': 10, 'metrics': None, 'enable_ensembling': True, 'enable_stack_ensembling': False, 'ensemble_iterations': 10, 'enable_tf': False, 'enable_cache': True, 'enable_subsampling': False, 'subsample_seed': None, 'enable_nimbusml': False, 'enable_streaming': False, 'force_streaming': False, 'label_column_name': 'Diabetic', 'weight_column_name': None, 'cost_mode': 1, 'metric_operation': 'maximize', 'preprocess': True, 'scenario': 'SDK'}\", \"AMLSettingsJsonString\": \"{\\\"name\\\": \\\"automl-classification\\\", \\\"path\\\": \\\".\\\", \\\"subscription_id\\\": \\\"43c1f93a-903d-4b23-a4bf-92bd7a150627\\\", \\\"resource_group\\\": \\\"myResourceGroup\\\", \\\"workspace_name\\\": \\\"ml_workspace\\\", \\\"region\\\": \\\"northeurope\\\", \\\"compute_target\\\": \\\"local\\\", \\\"spark_service\\\": null, \\\"azure_service\\\": \\\"local\\\", \\\"iterations\\\": 10, \\\"primary_metric\\\": \\\"AUC_weighted\\\", \\\"task_type\\\": \\\"classification\\\", \\\"data_script\\\": null, \\\"validation_size\\\": 0.0, \\\"n_cross_validations\\\": 5, \\\"y_min\\\": null, \\\"y_max\\\": null, \\\"num_classes\\\": 2, \\\"featurization\\\": \\\"auto\\\", \\\"lag_length\\\": 0, \\\"is_timeseries\\\": false, \\\"max_cores_per_iteration\\\": -1, \\\"max_concurrent_iterations\\\": 1, \\\"iteration_timeout_minutes\\\": 5, \\\"mem_in_mb\\\": null, \\\"enforce_time_on_windows\\\": false, \\\"experiment_timeout_minutes\\\": 15, \\\"experiment_exit_score\\\": null, \\\"whitelist_models\\\": null, \\\"blacklist_algos\\\": [\\\"KNN\\\", \\\"KNN\\\", \\\"SVM\\\"], \\\"supported_models\\\": [\\\"ExtremeRandomTrees\\\", \\\"KNN\\\", \\\"BernoulliNaiveBayes\\\", \\\"AveragedPerceptronClassifier\\\", \\\"MultinomialNaiveBayes\\\", \\\"SGD\\\", \\\"LightGBM\\\", \\\"TensorFlowDNN\\\", \\\"DecisionTree\\\", \\\"GradientBoosting\\\", \\\"SVM\\\", \\\"LogisticRegression\\\", \\\"XGBoostClassifier\\\", \\\"LinearSVM\\\", \\\"RandomForest\\\", \\\"TensorFlowLinearClassifier\\\"], \\\"auto_blacklist\\\": true, \\\"blacklist_samples_reached\\\": true, \\\"exclude_nan_labels\\\": true, \\\"verbosity\\\": 20, \\\"debug_log\\\": \\\"automl_errors.log\\\", \\\"show_warnings\\\": false, \\\"model_explainability\\\": true, \\\"service_url\\\": null, \\\"sdk_url\\\": null, \\\"sdk_packages\\\": null, \\\"enable_onnx_compatible_models\\\": true, \\\"enable_split_onnx_featurizer_estimator_models\\\": false, \\\"vm_type\\\": null, \\\"telemetry_verbosity\\\": \\\"INFO\\\", \\\"send_telemetry\\\": true, \\\"enable_dnn\\\": false, \\\"force_text_dnn\\\": false, \\\"enable_feature_sweeping\\\": false, \\\"enable_early_stopping\\\": true, \\\"early_stopping_n_iters\\\": 10, \\\"metrics\\\": null, \\\"enable_ensembling\\\": true, \\\"enable_stack_ensembling\\\": false, \\\"ensemble_iterations\\\": 10, \\\"enable_tf\\\": false, \\\"enable_cache\\\": true, \\\"enable_subsampling\\\": false, \\\"subsample_seed\\\": null, \\\"enable_nimbusml\\\": false, \\\"enable_streaming\\\": false, \\\"force_streaming\\\": false, \\\"label_column_name\\\": \\\"Diabetic\\\", \\\"weight_column_name\\\": null, \\\"cost_mode\\\": 1, \\\"metric_operation\\\": \\\"maximize\\\", \\\"preprocess\\\": true, \\\"scenario\\\": \\\"SDK\\\"}\", \"DataPrepJsonString\": null, \"EnableSubsampling\": \"False\", \"runTemplate\": \"AutoML\", \"azureml.runsource\": \"automl\", \"display_task_type\": \"classification\", \"dependencies_versions\": \"{\\\"azureml-widgets\\\": \\\"1.2.0\\\", \\\"azureml-train\\\": \\\"1.2.0\\\", \\\"azureml-train-restclients-hyperdrive\\\": \\\"1.2.0\\\", \\\"azureml-train-core\\\": \\\"1.2.0\\\", \\\"azureml-train-automl\\\": \\\"1.2.0\\\", \\\"azureml-train-automl-runtime\\\": \\\"1.2.0\\\", \\\"azureml-train-automl-client\\\": \\\"1.2.0\\\", \\\"azureml-tensorboard\\\": \\\"1.0.85\\\", \\\"azureml-telemetry\\\": \\\"1.2.0\\\", \\\"azureml-sdk\\\": \\\"1.2.0\\\", \\\"azureml-pipeline\\\": \\\"1.2.0\\\", \\\"azureml-pipeline-steps\\\": \\\"1.2.0\\\", \\\"azureml-pipeline-core\\\": \\\"1.2.0\\\", \\\"azureml-opendatasets\\\": \\\"1.0.85\\\", \\\"azureml-model-management-sdk\\\": \\\"1.0.1b6.post1\\\", \\\"azureml-interpret\\\": \\\"1.2.0\\\", \\\"azureml-explain-model\\\": \\\"1.2.0\\\", \\\"azureml-defaults\\\": \\\"1.2.0\\\", \\\"azureml-dataprep\\\": \\\"1.3.5\\\", \\\"azureml-dataprep-native\\\": \\\"14.1.0\\\", \\\"azureml-datadrift\\\": \\\"1.0.85\\\", \\\"azureml-core\\\": \\\"1.2.0.post1\\\", \\\"azureml-contrib-reinforcementlearning\\\": \\\"0.1.0.5919674\\\", \\\"azureml-contrib-notebook\\\": \\\"1.0.85\\\", \\\"azureml-contrib-interpret\\\": \\\"1.0.85\\\", \\\"azureml-contrib-functions\\\": \\\"1.2.0\\\", \\\"azureml-automl-runtime\\\": \\\"1.2.0\\\", \\\"azureml-automl-core\\\": \\\"1.2.0\\\"}\", \"ClientType\": \"SDK\", \"ClientSdkVersion\": \"1.2.0\", \"environment_cpu_name\": \"\", \"environment_cpu_version\": \"\", \"environment_gpu_name\": \"\", \"environment_gpu_version\": \"\", \"ProblemInfoJsonString\": \"{\\\"dataset_num_categorical\\\": 0, \\\"is_sparse\\\": true, \\\"subsampling\\\": false, \\\"dataset_classes\\\": 2, \\\"dataset_features\\\": 23, \\\"dataset_samples\\\": 10000, \\\"single_frequency_class_detected\\\": false}\", \"feature_skus\": \"automatedml_sdk_guardrails\", \"azureml.git.repository_uri\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"mlflow.source.git.repoURL\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"f834abad85fa91c96a624045592b837ae8834960\", \"mlflow.source.git.commit\": \"f834abad85fa91c96a624045592b837ae8834960\", \"azureml.git.dirty\": \"True\"}, \"tags\": {\"model_explain_run\": \"best_run\", \"model_explain_best_run_child_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819_0\", \"best_score\": \"0.9904426831775627\", \"best_pipeline\": \"LightGBM\"}, \"end_time_utc\": \"2020-04-13T09:37:01.647311Z\", \"status\": \"Completed\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:03:29\"}, \"child_runs\": [{\"run_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819_0\", \"run_number\": 2, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-13T09:33:37.078174Z\", \"end_time\": \"2020-04-13T09:33:55.091877Z\", \"created_time\": \"2020-04-13T09:33:36.904277Z\", \"created_time_dt\": \"2020-04-13T09:33:36.904277Z\", \"duration\": \"0:00:18\", \"iteration\": \"0\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, LightGBM\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.99044268, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819_1\", \"run_number\": 3, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-13T09:33:56.573069Z\", \"end_time\": \"2020-04-13T09:34:16.402439Z\", \"created_time\": \"2020-04-13T09:33:56.410604Z\", \"created_time_dt\": \"2020-04-13T09:33:56.410604Z\", \"duration\": \"0:00:19\", \"iteration\": \"1\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, XGBoostClassifier\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.99013634, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819_2\", \"run_number\": 4, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-13T09:34:19.666387Z\", \"end_time\": \"2020-04-13T09:34:34.261414Z\", \"created_time\": \"2020-04-13T09:34:19.504304Z\", \"created_time_dt\": \"2020-04-13T09:34:19.504304Z\", \"duration\": \"0:00:14\", \"iteration\": \"2\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, LightGBM\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.97998756, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819_3\", \"run_number\": 5, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-13T09:34:36.455294Z\", \"end_time\": \"2020-04-13T09:34:53.432331Z\", \"created_time\": \"2020-04-13T09:34:36.063454Z\", \"created_time_dt\": \"2020-04-13T09:34:36.063454Z\", \"duration\": \"0:00:17\", \"iteration\": \"3\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"StandardScalerWrapper, XGBoostClassifier\", \"run_properties\": \"<azureml.automl.runtime.shared.model_wrappers.StandardScalerWrapper object at 0x7f75d4371b00\", \"primary_metric\": 0.97287654, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819_4\", \"run_number\": 6, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-13T09:34:55.722542Z\", \"end_time\": \"2020-04-13T09:35:10.102181Z\", \"created_time\": \"2020-04-13T09:34:55.544427Z\", \"created_time_dt\": \"2020-04-13T09:34:55.544427Z\", \"duration\": \"0:00:14\", \"iteration\": \"4\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, SGD\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.93203224, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819_5\", \"run_number\": 7, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-13T09:35:12.294453Z\", \"end_time\": \"2020-04-13T09:35:27.447097Z\", \"created_time\": \"2020-04-13T09:35:12.119392Z\", \"created_time_dt\": \"2020-04-13T09:35:12.119392Z\", \"duration\": \"0:00:15\", \"iteration\": \"5\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"StandardScalerWrapper, LightGBM\", \"run_properties\": \"<azureml.automl.runtime.shared.model_wrappers.StandardScalerWrapper object at 0x7f75d435e550\", \"primary_metric\": 0.97985121, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819_6\", \"run_number\": 8, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-13T09:35:29.83185Z\", \"end_time\": \"2020-04-13T09:35:45.432951Z\", \"created_time\": \"2020-04-13T09:35:29.673041Z\", \"created_time_dt\": \"2020-04-13T09:35:29.673041Z\", \"duration\": \"0:00:15\", \"iteration\": \"6\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"SparseNormalizer, XGBoostClassifier\", \"run_properties\": \"<azureml.automl.runtime.shared.model_wrappers.SparseNormalizer object at 0x7f75d42e7668\", \"primary_metric\": 0.93834785, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819_7\", \"run_number\": 9, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-13T09:35:48.833503Z\", \"end_time\": \"2020-04-13T09:36:05.55431Z\", \"created_time\": \"2020-04-13T09:35:48.673079Z\", \"created_time_dt\": \"2020-04-13T09:35:48.673079Z\", \"duration\": \"0:00:16\", \"iteration\": \"7\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, RandomForest\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.9654148, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819_8\", \"run_number\": 10, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-13T09:36:08.123989Z\", \"end_time\": \"2020-04-13T09:36:23.20826Z\", \"created_time\": \"2020-04-13T09:36:07.935556Z\", \"created_time_dt\": \"2020-04-13T09:36:07.935556Z\", \"duration\": \"0:00:15\", \"iteration\": \"8\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, SGD\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.9336928, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819_9\", \"run_number\": 11, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-13T09:36:25.289643Z\", \"end_time\": \"2020-04-13T09:36:45.540758Z\", \"created_time\": \"2020-04-13T09:36:24.986698Z\", \"created_time_dt\": \"2020-04-13T09:36:24.986698Z\", \"duration\": \"0:00:20\", \"iteration\": \"9\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"VotingEnsemble\", \"run_properties\": \"classification_labels=None,\\n               estimators=[('0', Pipeline(memory=None,\\n     steps=[('maxabsscaler', MaxAbsScaler(copy=True\", \"primary_metric\": 0.99013875, \"best_metric\": 0.99044268}], \"children_metrics\": {\"categories\": [0], \"series\": {\"average_precision_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"average_precision_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9916787674263302, 0.9914207655503823, 0.9824355147560763, 0.971443166105584, 0.9304113537910306, 0.9821738696776879, 0.9455192723189926, 0.9619562954783841, 0.9383075975980069, 0.9913005215775158]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"average_precision_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9916787674263302, 0.9916787674263302, 0.9916787674263302, 0.9916787674263302, 0.9916787674263302, 0.9916787674263302, 0.9916787674263302, 0.9916787674263302, 0.9916787674263302, 0.9916787674263302]}], \"balanced_accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"balanced_accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9440819974618796, 0.946639302103166, 0.9194062242836161, 0.880773115188215, 0.8541634582326182, 0.9157448243762556, 0.8605164184930784, 0.898441321646219, 0.8513244412557588, 0.9449822771563096]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"balanced_accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9440819974618796, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166]}], \"precision_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"precision_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9468968210340906, 0.9478551551034957, 0.9247363415195327, 0.9185584651821628, 0.8257148535973157, 0.9222938365489398, 0.853269753017879, 0.8733833469860157, 0.840472742316086, 0.9475619059933074]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"precision_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9468968210340906, 0.9478551551034957, 0.9478551551034957, 0.9478551551034957, 0.9478551551034957, 0.9478551551034957, 0.9478551551034957, 0.9478551551034957, 0.9478551551034957, 0.9478551551034957]}], \"average_precision_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"average_precision_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9885533270268901, 0.9881262999794401, 0.9755397381214033, 0.9671138262930693, 0.9156473511228315, 0.9757088226944444, 0.9211101585594055, 0.9590567197665074, 0.9203422565818851, 0.9879551118771186]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"average_precision_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9885533270268901, 0.9885533270268901, 0.9885533270268901, 0.9885533270268901, 0.9885533270268901, 0.9885533270268901, 0.9885533270268901, 0.9885533270268901, 0.9885533270268901, 0.9885533270268901]}], \"precision_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"precision_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9309999999999998, 0.9112, 0.8445, 0.9284000000000001, 0.8711, 0.8917999999999999, 0.8601000000000001, 0.9522999999999999]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"precision_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001]}], \"f1_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"f1_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9454409908953988, 0.9472018036714414, 0.9219370459050173, 0.8957241285558718, 0.8336383870783749, 0.9188596878685606, 0.8565870942537458, 0.8826419785837547, 0.8452825543180399, 0.9462127060098208]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"f1_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9454409908953988, 0.9472018036714414, 0.9472018036714414, 0.9472018036714414, 0.9472018036714414, 0.9472018036714414, 0.9472018036714414, 0.9472018036714414, 0.9472018036714414, 0.9472018036714414]}], \"f1_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"f1_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.951525872795924, 0.953060824473698, 0.9307838738247038, 0.9090819437849259, 0.8477652897790545, 0.9281272052572049, 0.8717517063068401, 0.8935899410063023, 0.861209408711394, 0.9522300858385437]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"f1_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.951525872795924, 0.953060824473698, 0.953060824473698, 0.953060824473698, 0.953060824473698, 0.953060824473698, 0.953060824473698, 0.953060824473698, 0.953060824473698, 0.953060824473698]}], \"AUC_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"AUC_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9904426831775627, 0.9901363381909428, 0.9799875631590194, 0.972876537424591, 0.932032237790299, 0.9798512121204069, 0.9383478538322411, 0.9654147990937917, 0.9336927973185819, 0.9901387530932206]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"AUC_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627]}], \"weighted_accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"weighted_accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9576144671870581, 0.9582753858834163, 0.9402683455938206, 0.93555228266066, 0.836868103810079, 0.9385200234898274, 0.8795828305271899, 0.886497072613279, 0.867130526466315, 0.9581599781415612]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"weighted_accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9576144671870581, 0.9582753858834163, 0.9582753858834163, 0.9582753858834163, 0.9582753858834163, 0.9582753858834163, 0.9582753858834163, 0.9582753858834163, 0.9582753858834163, 0.9582753858834163]}], \"log_loss\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"log_loss\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.11810503522790523, 0.12355458879130007, 0.20029542689856225, 0.6810231414345467, 0.3386996428944162, 0.22212314578011133, 0.31053275139669534, 0.3796118785211995, 0.32575279659079326, 0.1653918467284418]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"log_loss_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.11810503522790523, 0.11810503522790523, 0.11810503522790523, 0.11810503522790523, 0.11810503522790523, 0.11810503522790523, 0.11810503522790523, 0.11810503522790523, 0.11810503522790523, 0.11810503522790523]}], \"recall_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"recall_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9309999999999998, 0.9112, 0.8445, 0.9284000000000001, 0.8711, 0.8917999999999999, 0.8601000000000001, 0.9522999999999999]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"recall_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001]}], \"f1_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"f1_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9309999999999998, 0.9112, 0.8445, 0.9283999999999999, 0.8710999999999999, 0.8917999999999999, 0.8601000000000001, 0.9522999999999999]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"f1_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001]}], \"recall_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"recall_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9309999999999998, 0.9112, 0.8445, 0.9284000000000001, 0.8711, 0.8917999999999999, 0.8601000000000001, 0.9522999999999999]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"recall_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001]}], \"norm_macro_recall\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"norm_macro_recall\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.8881639949237587, 0.893278604206332, 0.8388124485672321, 0.7615462303764298, 0.7083269164652368, 0.8314896487525113, 0.7210328369861567, 0.7968826432924381, 0.7026488825115176, 0.8899645543126191]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"norm_macro_recall_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.8881639949237587, 0.893278604206332, 0.893278604206332, 0.893278604206332, 0.893278604206332, 0.893278604206332, 0.893278604206332, 0.893278604206332, 0.893278604206332, 0.893278604206332]}], \"recall_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"recall_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9440819974618796, 0.946639302103166, 0.9194062242836161, 0.880773115188215, 0.8541634582326182, 0.9157448243762556, 0.8605164184930784, 0.898441321646219, 0.8513244412557588, 0.9449822771563096]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"recall_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9440819974618796, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166]}], \"average_precision_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"average_precision_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9907832843118888, 0.9904387921847764, 0.9803897362802267, 0.9735418439152046, 0.932100275918488, 0.9804539607003336, 0.9364782850574249, 0.9668819854494644, 0.935493912653141, 0.9903198495294756]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"average_precision_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9907832843118888, 0.9907832843118888, 0.9907832843118888, 0.9907832843118888, 0.9907832843118888, 0.9907832843118888, 0.9907832843118888, 0.9907832843118888, 0.9907832843118888, 0.9907832843118888]}], \"AUC_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"AUC_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9904426831775627, 0.990136338190943, 0.9799875631590194, 0.972876537424591, 0.932032237790299, 0.9798512121204069, 0.9383478538322411, 0.9654147990937917, 0.9336927973185819, 0.9901387530932206]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"AUC_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627]}], \"accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9309999999999998, 0.9112, 0.8445, 0.9284000000000001, 0.8711, 0.8917999999999999, 0.8601000000000001, 0.9522999999999999]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001]}], \"matthews_correlation\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"matthews_correlation\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.8909693671988277, 0.8944856430405238, 0.8441163994810769, 0.7983959938080952, 0.6792401491152986, 0.8380082427805704, 0.7137361600527138, 0.771400151111146, 0.6917022122897022, 0.8925327853728297]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"matthews_correlation_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.8909693671988277, 0.8944856430405238, 0.8944856430405238, 0.8944856430405238, 0.8944856430405238, 0.8944856430405238, 0.8944856430405238, 0.8944856430405238, 0.8944856430405238, 0.8944856430405238]}], \"precision_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"precision_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.951529651244859, 0.9530946926472017, 0.930783855397262, 0.9131743472859288, 0.8617494958270815, 0.9281127732714897, 0.8728995183456005, 0.9008334580645505, 0.8633242215052686, 0.9522562343307065]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"precision_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.951529651244859, 0.9530946926472017, 0.9530946926472017, 0.9530946926472017, 0.9530946926472017, 0.9530946926472017, 0.9530946926472017, 0.9530946926472017, 0.9530946926472017, 0.9530946926472017]}], \"AUC_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"AUC_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9914617, 0.99123075, 0.9819810999999998, 0.9706379500000001, 0.92947205, 0.98174315, 0.94582075, 0.9610767499999999, 0.93733745, 0.9911770499999999]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"AUC_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9914617, 0.9914617, 0.9914617, 0.9914617, 0.9914617, 0.9914617, 0.9914617, 0.9914617, 0.9914617, 0.9914617]}]}, \"metricName\": null, \"primaryMetricName\": \"AUC_weighted\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"experiment_status\", \"run_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"series\": [{\"data\": [\"DatasetEvaluation\", \"FeaturesGeneration\", \"DatasetFeaturization\", \"DatasetFeaturizationCompleted\", \"DatasetCrossValidationSplit\", \"ModelSelection\", \"BestRunExplainModel\", \"ModelExplanationDataSetSetup\", \"EngineeredFeatureExplanations\", \"EngineeredFeatureExplanations\", \"BestRunExplainModel\"]}]}, {\"name\": \"experiment_status_description\", \"run_id\": \"AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"series\": [{\"data\": [\"Gathering dataset statistics.\", \"Generating features for the dataset.\", \"Beginning to fit featurizers and featurize the dataset.\", \"Completed fit featurizers and featurizing the dataset.\", \"Generating individually featurized CV splits.\", \"Beginning model selection.\", \"Best run model explanations started\", \"Model explanations data setup completed\", \"Computation of engineered features started\", \"Computation of engineered features completed\", \"Best run model explanations completed\"]}]}], \"run_logs\": \"\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.2.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-04-13T09:33:33.634736Z',\n",
       " 'endTimeUtc': '2020-04-13T09:37:01.647311Z',\n",
       " 'properties': {'num_iterations': '10',\n",
       "  'training_type': 'TrainFull',\n",
       "  'acquisition_function': 'EI',\n",
       "  'primary_metric': 'AUC_weighted',\n",
       "  'train_split': '0',\n",
       "  'acquisition_parameter': '0',\n",
       "  'num_cross_validation': '5',\n",
       "  'target': 'local',\n",
       "  'RawAMLSettingsString': \"{'name': 'automl-classification', 'path': '.', 'subscription_id': '43c1f93a-903d-4b23-a4bf-92bd7a150627', 'resource_group': 'myResourceGroup', 'workspace_name': 'ml_workspace', 'region': 'northeurope', 'compute_target': 'local', 'spark_service': None, 'azure_service': 'local', 'iterations': 10, 'primary_metric': 'AUC_weighted', 'task_type': 'classification', 'data_script': None, 'validation_size': 0.0, 'n_cross_validations': 5, 'y_min': None, 'y_max': None, 'num_classes': 2, 'featurization': 'auto', 'lag_length': 0, 'is_timeseries': False, 'max_cores_per_iteration': -1, 'max_concurrent_iterations': 1, 'iteration_timeout_minutes': 5, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'experiment_timeout_minutes': 15, 'experiment_exit_score': None, 'whitelist_models': None, 'blacklist_algos': ['KNN', 'KNN', 'SVM'], 'supported_models': ['ExtremeRandomTrees', 'KNN', 'BernoulliNaiveBayes', 'AveragedPerceptronClassifier', 'MultinomialNaiveBayes', 'SGD', 'LightGBM', 'TensorFlowDNN', 'DecisionTree', 'GradientBoosting', 'SVM', 'LogisticRegression', 'XGBoostClassifier', 'LinearSVM', 'RandomForest', 'TensorFlowLinearClassifier'], 'auto_blacklist': True, 'blacklist_samples_reached': True, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'automl_errors.log', 'show_warnings': False, 'model_explainability': True, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'enable_onnx_compatible_models': True, 'enable_split_onnx_featurizer_estimator_models': False, 'vm_type': None, 'telemetry_verbosity': 'INFO', 'send_telemetry': True, 'enable_dnn': False, 'force_text_dnn': False, 'enable_feature_sweeping': False, 'enable_early_stopping': True, 'early_stopping_n_iters': 10, 'metrics': None, 'enable_ensembling': True, 'enable_stack_ensembling': False, 'ensemble_iterations': 10, 'enable_tf': False, 'enable_cache': True, 'enable_subsampling': False, 'subsample_seed': None, 'enable_nimbusml': False, 'enable_streaming': False, 'force_streaming': False, 'label_column_name': 'Diabetic', 'weight_column_name': None, 'cost_mode': 1, 'metric_operation': 'maximize', 'preprocess': True, 'scenario': 'SDK'}\",\n",
       "  'AMLSettingsJsonString': '{\"name\": \"automl-classification\", \"path\": \".\", \"subscription_id\": \"43c1f93a-903d-4b23-a4bf-92bd7a150627\", \"resource_group\": \"myResourceGroup\", \"workspace_name\": \"ml_workspace\", \"region\": \"northeurope\", \"compute_target\": \"local\", \"spark_service\": null, \"azure_service\": \"local\", \"iterations\": 10, \"primary_metric\": \"AUC_weighted\", \"task_type\": \"classification\", \"data_script\": null, \"validation_size\": 0.0, \"n_cross_validations\": 5, \"y_min\": null, \"y_max\": null, \"num_classes\": 2, \"featurization\": \"auto\", \"lag_length\": 0, \"is_timeseries\": false, \"max_cores_per_iteration\": -1, \"max_concurrent_iterations\": 1, \"iteration_timeout_minutes\": 5, \"mem_in_mb\": null, \"enforce_time_on_windows\": false, \"experiment_timeout_minutes\": 15, \"experiment_exit_score\": null, \"whitelist_models\": null, \"blacklist_algos\": [\"KNN\", \"KNN\", \"SVM\"], \"supported_models\": [\"ExtremeRandomTrees\", \"KNN\", \"BernoulliNaiveBayes\", \"AveragedPerceptronClassifier\", \"MultinomialNaiveBayes\", \"SGD\", \"LightGBM\", \"TensorFlowDNN\", \"DecisionTree\", \"GradientBoosting\", \"SVM\", \"LogisticRegression\", \"XGBoostClassifier\", \"LinearSVM\", \"RandomForest\", \"TensorFlowLinearClassifier\"], \"auto_blacklist\": true, \"blacklist_samples_reached\": true, \"exclude_nan_labels\": true, \"verbosity\": 20, \"debug_log\": \"automl_errors.log\", \"show_warnings\": false, \"model_explainability\": true, \"service_url\": null, \"sdk_url\": null, \"sdk_packages\": null, \"enable_onnx_compatible_models\": true, \"enable_split_onnx_featurizer_estimator_models\": false, \"vm_type\": null, \"telemetry_verbosity\": \"INFO\", \"send_telemetry\": true, \"enable_dnn\": false, \"force_text_dnn\": false, \"enable_feature_sweeping\": false, \"enable_early_stopping\": true, \"early_stopping_n_iters\": 10, \"metrics\": null, \"enable_ensembling\": true, \"enable_stack_ensembling\": false, \"ensemble_iterations\": 10, \"enable_tf\": false, \"enable_cache\": true, \"enable_subsampling\": false, \"subsample_seed\": null, \"enable_nimbusml\": false, \"enable_streaming\": false, \"force_streaming\": false, \"label_column_name\": \"Diabetic\", \"weight_column_name\": null, \"cost_mode\": 1, \"metric_operation\": \"maximize\", \"preprocess\": true, \"scenario\": \"SDK\"}',\n",
       "  'DataPrepJsonString': None,\n",
       "  'EnableSubsampling': 'False',\n",
       "  'runTemplate': 'AutoML',\n",
       "  'azureml.runsource': 'automl',\n",
       "  'display_task_type': 'classification',\n",
       "  'dependencies_versions': '{\"azureml-widgets\": \"1.2.0\", \"azureml-train\": \"1.2.0\", \"azureml-train-restclients-hyperdrive\": \"1.2.0\", \"azureml-train-core\": \"1.2.0\", \"azureml-train-automl\": \"1.2.0\", \"azureml-train-automl-runtime\": \"1.2.0\", \"azureml-train-automl-client\": \"1.2.0\", \"azureml-tensorboard\": \"1.0.85\", \"azureml-telemetry\": \"1.2.0\", \"azureml-sdk\": \"1.2.0\", \"azureml-pipeline\": \"1.2.0\", \"azureml-pipeline-steps\": \"1.2.0\", \"azureml-pipeline-core\": \"1.2.0\", \"azureml-opendatasets\": \"1.0.85\", \"azureml-model-management-sdk\": \"1.0.1b6.post1\", \"azureml-interpret\": \"1.2.0\", \"azureml-explain-model\": \"1.2.0\", \"azureml-defaults\": \"1.2.0\", \"azureml-dataprep\": \"1.3.5\", \"azureml-dataprep-native\": \"14.1.0\", \"azureml-datadrift\": \"1.0.85\", \"azureml-core\": \"1.2.0.post1\", \"azureml-contrib-reinforcementlearning\": \"0.1.0.5919674\", \"azureml-contrib-notebook\": \"1.0.85\", \"azureml-contrib-interpret\": \"1.0.85\", \"azureml-contrib-functions\": \"1.2.0\", \"azureml-automl-runtime\": \"1.2.0\", \"azureml-automl-core\": \"1.2.0\"}',\n",
       "  'ClientType': 'SDK',\n",
       "  'ClientSdkVersion': '1.2.0',\n",
       "  'environment_cpu_name': '',\n",
       "  'environment_cpu_version': '',\n",
       "  'environment_gpu_name': '',\n",
       "  'environment_gpu_version': '',\n",
       "  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": true, \"subsampling\": false, \"dataset_classes\": 2, \"dataset_features\": 23, \"dataset_samples\": 10000, \"single_frequency_class_detected\": false}',\n",
       "  'feature_skus': 'automatedml_sdk_guardrails',\n",
       "  'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': 'f834abad85fa91c96a624045592b837ae8834960',\n",
       "  'mlflow.source.git.commit': 'f834abad85fa91c96a624045592b837ae8834960',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'logFiles': {}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunDetails(automl_run).show()\n",
    "automl_run.wait_for_completion() # get more parameter info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**option 1:** select any pipeline iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = automl_run.get_output(iteration=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**option 2:** select best pipeline iteration automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = automl_run.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspect model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatransformer\n",
      "MaxAbsScaler\n",
      "LightGBMClassifier\n"
     ]
    }
   ],
   "source": [
    "# pipeline steps\n",
    "for step in fitted_model.named_steps:\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datatransformer': DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
       "         feature_sweeping_config=None, feature_sweeping_timeout=None,\n",
       "         featurization_config=None, force_text_dnn=None,\n",
       "         is_cross_validation=None, is_onnx_compatible=None, logger=None,\n",
       "         observer=None, task=None, working_dir=None),\n",
       " 'MaxAbsScaler': MaxAbsScaler(copy=True),\n",
       " 'LightGBMClassifier': LightGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "           colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
       "           max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
       "           min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "           objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "           silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "           subsample_freq=0, verbose=-10)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model properties\n",
    "fitted_model.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average_precision_score_micro': 0.9916787674263302,\n",
       " 'balanced_accuracy': 0.9440819974618796,\n",
       " 'accuracy_table': 'aml://artifactId/ExperimentRun/dcid.AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819_0/accuracy_table',\n",
       " 'precision_score_macro': 0.9468968210340906,\n",
       " 'average_precision_score_macro': 0.9885533270268901,\n",
       " 'precision_score_micro': 0.9516,\n",
       " 'f1_score_macro': 0.9454409908953988,\n",
       " 'f1_score_weighted': 0.951525872795924,\n",
       " 'AUC_macro': 0.9904426831775627,\n",
       " 'weighted_accuracy': 0.9576144671870581,\n",
       " 'confusion_matrix': 'aml://artifactId/ExperimentRun/dcid.AutoML_baca9fc8-a785-4e52-aa2d-dec9d390b819_0/confusion_matrix',\n",
       " 'log_loss': 0.11810503522790523,\n",
       " 'recall_score_micro': 0.9516,\n",
       " 'f1_score_micro': 0.9516,\n",
       " 'recall_score_weighted': 0.9516,\n",
       " 'norm_macro_recall': 0.8881639949237587,\n",
       " 'recall_score_macro': 0.9440819974618796,\n",
       " 'average_precision_score_weighted': 0.9907832843118888,\n",
       " 'AUC_weighted': 0.9904426831775627,\n",
       " 'accuracy': 0.9516,\n",
       " 'matthews_correlation': 0.8909693671988277,\n",
       " 'precision_score_weighted': 0.951529651244859,\n",
       " 'AUC_micro': 0.9914617}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all metrics\n",
    "best_run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare\n",
    "\n",
    "autoML generated a scoring script, environment file and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the score and environment files\n",
    "model_name = best_run.properties['model_name'] # score.py script will look for the name of the registered model\n",
    "\n",
    "# make a local copy of the best scoring script, environment file and the model file\n",
    "script_file_name = 'inference/score.py'\n",
    "conda_env_file_name = 'inference/env.yml'\n",
    "model_pickle_file_name = 'inference/model.pkl'\n",
    "model_onnx_file_name = 'inference/model.onnx'\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', script_file_name)\n",
    "best_run.download_file('outputs/conda_env_v_1_0_0.yml', conda_env_file_name)\n",
    "best_run.download_file('outputs/model.pkl', model_pickle_file_name)\n",
    "best_run.download_file('outputs/model.onnx', model_onnx_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\r",
      "\r\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\r",
      "\r\n",
      "\r\n",
      "# Details about the Conda environment file format:\r",
      "\r\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r",
      "\r\n",
      "\r\n",
      "name: project_environment\r\n",
      "dependencies:\r\n",
      "  # The python interpreter version.\r",
      "\r\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\r",
      "\r\n",
      "- python=3.6.2\r\n",
      "\r\n",
      "- pip:\r\n",
      "  - azureml-train-automl-runtime==1.2.0\r\n",
      "  - inference-schema\r\n",
      "  - azureml-explain-model==1.2.0\r\n",
      "  - azureml-defaults==1.2.0\r\n",
      "- numpy>=1.16.0,<=1.16.2\r\n",
      "- pandas>=0.21.0,<=0.23.4\r\n",
      "- scikit-learn>=0.19.0,<=0.20.3\r\n",
      "- py-xgboost<=0.90\r\n",
      "- fbprophet==0.5\r\n",
      "- psutil>=5.2.2,<6.0.0\r\n",
      "channels:\r\n",
      "- anaconda\r\n",
      "- conda-forge\r\n"
     ]
    }
   ],
   "source": [
    "! cat inference/env.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ---------------------------------------------------------\r\n",
      "# Copyright (c) Microsoft Corporation. All rights reserved.\r\n",
      "# ---------------------------------------------------------\r\n",
      "import json\r\n",
      "import pickle\r\n",
      "import numpy as np\r\n",
      "import pandas as pd\r\n",
      "import azureml.train.automl\r\n",
      "from sklearn.externals import joblib\r\n",
      "from azureml.core.model import Model\r\n",
      "\r\n",
      "from inference_schema.schema_decorators import input_schema, output_schema\r\n",
      "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\r\n",
      "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\r\n",
      "\r\n",
      "\r\n",
      "input_sample = pd.DataFrame({'PatientID': pd.Series(['1354778'], dtype='int64'), 'Pregnancies': pd.Series(['0'], dtype='int64'), 'PlasmaGlucose': pd.Series(['171'], dtype='int64'), 'DiastolicBloodPressure': pd.Series(['80'], dtype='int64'), 'TricepsThickness': pd.Series(['34'], dtype='int64'), 'SerumInsulin': pd.Series(['23'], dtype='int64'), 'BMI': pd.Series(['43.50972593'], dtype='float64'), 'DiabetesPedigree': pd.Series(['1.213191354'], dtype='float64'), 'Age': pd.Series(['21'], dtype='int64')})\r\n",
      "output_sample = np.array([0])\r\n",
      "\r\n",
      "\r\n",
      "def init():\r\n",
      "    global model\r\n",
      "    # This name is model.id of model that we want to deploy deserialize the model file back\r\n",
      "    # into a sklearn model\r\n",
      "    model_path = Model.get_model_path(model_name = 'AutoMLbaca9fc8a0')\r\n",
      "    model = joblib.load(model_path)\r\n",
      "\r\n",
      "\r\n",
      "@input_schema('data', PandasParameterType(input_sample))\r\n",
      "@output_schema(NumpyParameterType(output_sample))\r\n",
      "def run(data):\r\n",
      "    try:\r\n",
      "        result = model.predict(data)\r\n",
      "        return json.dumps({\"result\": result.tolist()})\r\n",
      "    except Exception as e:\r\n",
      "        result = str(e)\r\n",
      "        return json.dumps({\"error\": result})\r\n"
     ]
    }
   ],
   "source": [
    "! cat inference/score.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1:** from workspace /outputs folder with .register_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name=model_name, # registered model name used in scoring script init()\n",
    "                                model_framework=Model.Framework.SCIKITLEARN, # {TensorFlow, ScikitLearn, Onnx, Custom}\n",
    "                                model_framework_version='0.22.2',\n",
    "                                model_path='outputs/model.pkl', # fixed path in workspace {'model.pkl', 'model.onnx'}\n",
    "                                tags={'Training context': 'autoML Training'},\n",
    "                                properties={'AUC': best_run.get_metrics()['AUC_weighted'],\n",
    "                                            'Accuracy': best_run.get_metrics()['accuracy']},\n",
    "                                description=\"Classification model to predict diabetes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2:** from local /path/model folder with Model.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model AutoMLbaca9fc8a0\n"
     ]
    }
   ],
   "source": [
    "model = Model.register(workspace=ws,\n",
    "                       model_name=model_name, # registered model name used in scoring script init()\n",
    "                       model_framework=Model.Framework.SCIKITLEARN, # {TensorFlow, ScikitLearn, Onnx, Custom}\n",
    "                       model_framework_version='0.22.2',\n",
    "                       model_path='inference/model.pkl', # local file {'model.pkl', 'model.onnx'}\n",
    "                       tags={'Training context': 'autoML Training'},\n",
    "                       properties={'AUC': best_run.get_metrics()['AUC_weighted'],\n",
    "                                   'Accuracy': best_run.get_metrics()['accuracy']},\n",
    "                       description=\"Classification model to predict diabetes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoMLbaca9fc8a0 version: 2\n",
      "\t Training context : autoML Training\n",
      "\t AUC : 0.9904426831775627\n",
      "\t Accuracy : 0.9516\n",
      "\n",
      "\n",
      "AutoMLbaca9fc8a0 version: 1\n",
      "\t Training context : autoML Training\n",
      "\t AUC : 0.9904426831775627\n",
      "\t Accuracy : 0.9516\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list all registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='ml_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup'), name=AutoMLbaca9fc8a0, id=AutoMLbaca9fc8a0:2, version=2, tags={'Training context': 'autoML Training'}, properties={'AUC': '0.9904426831775627', 'Accuracy': '0.9516'})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the registered model for deployment (latest version)\n",
    "model = ws.models[model_name] # or replace with any registered modelname from Model.list(ws)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model as webservice (ACI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linux Azure Container Instance with 1 vCPU and 1GB of RAM cost â‚¬28 per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"automl-projname-service\" does not exist, creating the webservice...\n",
      "Running.........................................................................................................................................................................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# Configure the scoring environment\n",
    "service_name = \"automl-projname-service\" # only lowercase letters, numbers, or dashes\n",
    "\n",
    "# Remove any existing service under the same name\n",
    "try:\n",
    "    Webservice(ws, service_name).delete()\n",
    "except WebserviceException:\n",
    "    print('\"' + service_name + '\" does not exist, creating the webservice...')\n",
    "\n",
    "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=conda_env_file_name)\n",
    "inference_config = InferenceConfig(entry_script=script_file_name, environment=myenv)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                                       memory_gb=1)\n",
    "\n",
    "# build container from environment, start webservice ACI and deploy inference scrips \n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** load a running webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automl-projname-service\n"
     ]
    }
   ],
   "source": [
    "# list available webservices\n",
    "for i in ws.webservices:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name = \"automl-projname-service\" # only lowercase letters, numbers, or dashes\n",
    "service = Webservice(ws, service_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-13T10:00:50,785891561+00:00 - gunicorn/run \n",
      "2020-04-13T10:00:50,786579158+00:00 - rsyslog/run \n",
      "2020-04-13T10:00:50,786049161+00:00 - iot-server/run \n",
      "2020-04-13T10:00:50,818970215+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_29526d93bcbca0513e9c1ca0d57832a0/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_29526d93bcbca0513e9c1ca0d57832a0/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_29526d93bcbca0513e9c1ca0d57832a0/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_29526d93bcbca0513e9c1ca0d57832a0/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_29526d93bcbca0513e9c1ca0d57832a0/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "rsyslogd: /azureml-envs/azureml_29526d93bcbca0513e9c1ca0d57832a0/lib/libuuid.so.1: no version information available (required by rsyslogd)\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (13)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 38\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-04-13T10:00:52,094100788+00:00 - iot-server/finish 1 0\n",
      "2020-04-13T10:00:52,095176083+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "unable to import 'smart_open.gcs', disabling that module\n",
      "Users's init has completed successfully\n",
      "Scoring timeout is found from os.environ: 60000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get webservice logs\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webservice inference test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a HTTP triggered webrequest with testdata to the model for a prediction value.  \n",
    "In this example we test a person is diabetic (1) or not-diabetic (0).  \n",
    "The testdata must be a list of 9 features to predict a binary classification.  \n",
    "We demonstrate the use of **service** or **requests** method to send a prediction request.  \n",
    "Know that 'Postman' application or 'Rest Client' plugin in VSCode work as well.  \n",
    "\n",
    "|Web API|Example value|Options|\n",
    "|-|-|-|\n",
    "|**HTTP method**|POST|<i>POST</i><br><i>GET</i>|\n",
    "|**URI**|http://3bb0618b-ef7b-4b17-af32-a52f9c64f4d5.northeurope.azurecontainer.io/score||\n",
    "|**Header**|{Content-Type: Application/json}||\n",
    "|**Body**|{\"data\": [[5, 2, 180, 74, 24, 21, 24, 1.5, 22], <br>[6, 0, 148, 58, 11, 179, 39, 0.16, 45]]}|<i>one or </i><br><i>more records</i>|\n",
    "|**Response**|{\"result\": [1, 0]}|<i>json object</i>|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI: http://0b9d52d8-283f-45e6-8bf6-d27217a1dcb4.northeurope.azurecontainer.io/score\n",
      "Body: {\"data\": [[5, 2, 180, 74, 24, 21, 24, 1.5, 22], [6, 0, 148, 58, 11, 179, 39, 0.16, 45]]}\n"
     ]
    }
   ],
   "source": [
    "# get webservice URI\n",
    "endpoint = service.scoring_uri\n",
    "\n",
    "# raw test data\n",
    "rawdata = [[5, 2, 180, 74, 24, 21, 24, 1.5, 22],\n",
    "           [6, 0, 148, 58, 11, 179, 39, 0.16, 45]]\n",
    "\n",
    "print(\"URI: \" + endpoint)\n",
    "print(\"Body: \" + json.dumps({\"data\": rawdata})) # convert array to a serialized JSON formatted string object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 1:** service.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"result\": [1, 0]}'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.run(json.dumps({\"data\": rawdata}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 2:** requests.post()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"result\": [1, 0]}'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.post(endpoint, json={\"data\": rawdata})\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are finished testing your service, clean up the deployment with service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired from autoML results is an alternative customML development.  \n",
    "Using inline method to test and develop, train local or with remote compute and deploy and test the model.  \n",
    "\n",
    "1. option1: inline method\n",
    "1. option2: script method\n",
    "  * create training script\n",
    "  * create training environment\n",
    "  * creating and register dataset (File)\n",
    "  * train model\n",
    "1. create an inference script\n",
    "1. create an inference environment\n",
    "1. register the model\n",
    "1. deploy the model\n",
    "1. inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Inline method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|log metric function|Description|Example|\n",
    "|-|-|-|\n",
    "|**log**|<i>Record a single named value</i>|run.log(\"accuracy\", 0.95)|\n",
    "|**log_list**|<i>Record a named list of values</i>|run.log_list(\"accuracies\", [0.6, 0.7, 0.87])|\n",
    "|**log_row**|<i>Record a row with multiple columns</i>|run.log_row(\"Y over X\", x=1, y=0.4)|\n",
    "|**log_table**|<i>Record a dictionary as a table</i>|run.log_table(\"Y over X\", {\"x\":[1, 2, 3], \"y\":[0.6, 0.7, 0.89]})|\n",
    "|**log_image**|<i>Record an image file or a plot</i>|run.log_image(\"ROC\", plot=plt)|\n",
    "|**upload_file**|<i>Upload any file to \"./outputs\"</i>|run.upload_file(\"best_model.pkl\", \"./model.pkl\")|\n",
    "\n",
    "https://aka.ms/AA70zf6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: diabetes-training\n",
      "Loading data lake gen2 data in a pandas dataframe...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8873333333333333\n",
      "AUC: 0.8741181153291208\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Model\n",
    "from azureml.core import Datastore\n",
    "from azureml.core import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace=ws, name=\"diabetes-training\")\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "# load the diabetes dataset (File method)\n",
    "print(\"Loading data lake gen2 data in a pandas dataframe...\")\n",
    "ds = Datastore.get(ws, 'datalakestoragegen2')\n",
    "ds_path = [DataPath(ds, 'platinum/diabetes.parquet')] # {path/*.parquet or path/**}\n",
    "dataset = Dataset.File.from_files(path=ds_path)\n",
    "mount_context = dataset.mount(mount_point='/tmp/platinum') # read-only mount from delta lake\n",
    "mount_context.start()\n",
    "diabetes = pd.read_parquet('/tmp/platinum/diabetes.parquet') # {'/tmp/path/'} can load latest delta lake parquet files\n",
    "mount_context.stop()\n",
    "\n",
    "# load the diabetes dataset (Tabular method)\n",
    "# print(\"Loading data lake gen2 data in a pandas dataframe...\")\n",
    "# ds = Datastore.get(ws, 'datalakestoragegen2')\n",
    "# ds_path = [DataPath(ds, 'platinum/diabetes.parquet')] # {path/*.parquet or path/**}\n",
    "# dataset = Dataset.Tabular.from_parquet_files(path=ds_path) # {delimited, json, parquet, sql}\n",
    "# diabetes = dataset.to_pandas_dataframe() # create a pandas dataframe\n",
    "\n",
    "# Separate features and labels as numpy array\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=model, filename=model_file) # backup model local\n",
    "run.upload_file(name='outputs/' + model_file,\n",
    "                path_or_stream='./' + model_file) # save model to workspace\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Script method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_service folder created\n"
     ]
    }
   ],
   "source": [
    "# Create a local folder for the experiment files\n",
    "folder_name = 'diabetes_service'\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "print(folder_name, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./diabetes_service/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import glob\n",
    "print(\"libraries imported...\")\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "print(\"argparse parameters loaded...\")\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "print(\"run context loaded...\")\n",
    "\n",
    "# load the diabetes dataset (File method)\n",
    "# Get the training data from the estimator input identified as 'diabetes'\n",
    "mount = run.input_datasets['diabetes'] # read-only mount from delta lake as '/mnt/data'\n",
    "print(\"delta lake mounted...\")\n",
    "diabetes = pd.read_parquet('/mnt/data/diabetes.parquet') # load any file(s) from this delta lake mounted folder\n",
    "print(\"dataset loaded...\")\n",
    "\n",
    "# save data into workspace\n",
    "diabetes.to_csv(\"outputs/dataset.csv\", index=False) # {logs/  outputs/}\n",
    "print(\"test: write dataset to workspace 'outputs/dataset.csv'\")\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"training_environment\",\n",
       "    \"version\": \"1\",\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"python\": {\n",
       "        \"userManagedDependencies\": false,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults\",\n",
       "                        \"azureml-dataprep[pandas,fuse]\",\n",
       "                        \"pyarrow\",\n",
       "                        \"fastparquet\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn\",\n",
       "                \"joblib\"\n",
       "            ],\n",
       "            \"name\": \"azureml_b9a1534962684a800c586e9fce04292e\"\n",
       "        }\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"enabled\": true,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\",\n",
       "        \"baseDockerfile\": null,\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null,\n",
       "        \"arguments\": [],\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"username\": null,\n",
       "            \"password\": null\n",
       "        }\n",
       "    },\n",
       "    \"spark\": {\n",
       "        \"repositories\": [],\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true\n",
       "    },\n",
       "    \"databricks\": {\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"eggLibraries\": []\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"inferencingStackVersion\": null\n",
       "}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myenv = Environment(\"training_environment\")\n",
    "myenv.docker.enabled = True\n",
    "myenv.python.user_managed_dependencies = False\n",
    "conda_packages = ['scikit-learn', 'joblib', 'python==3.6.2']\n",
    "pip_packages = ['azureml-defaults', 'azureml-dataprep[pandas,fuse]', 'pyarrow', 'fastparquet']\n",
    "myenv.python.conda_dependencies = CondaDependencies.create(conda_packages=conda_packages, pip_packages=pip_packages)\n",
    "myenv.register(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: training_environment\n",
      "Name: AzureML-PyTorch-1.3-GPU\n",
      "Name: AzureML-TensorFlow-2.0-CPU\n",
      "Name: AzureML-Tutorial\n",
      "Name: AzureML-PyTorch-1.3-CPU\n",
      "Name: AzureML-TensorFlow-2.0-GPU\n",
      "Name: AzureML-Chainer-5.1.0-GPU\n",
      "Name: AzureML-Minimal\n",
      "Name: AzureML-PyTorch-1.2-CPU\n",
      "Name: AzureML-TensorFlow-1.12-CPU\n",
      "Name: AzureML-TensorFlow-1.13-CPU\n",
      "Name: AzureML-PyTorch-1.1-CPU\n",
      "Name: AzureML-TensorFlow-1.10-CPU\n",
      "Name: AzureML-PyTorch-1.0-GPU\n",
      "Name: AzureML-TensorFlow-1.12-GPU\n",
      "Name: AzureML-TensorFlow-1.13-GPU\n",
      "Name: AzureML-Chainer-5.1.0-CPU\n",
      "Name: AzureML-PyTorch-1.0-CPU\n",
      "Name: AzureML-Scikit-learn-0.20.3\n",
      "Name: AzureML-PyTorch-1.2-GPU\n",
      "Name: AzureML-PyTorch-1.1-GPU\n",
      "Name: AzureML-TensorFlow-1.10-GPU\n",
      "Name: AzureML-PySpark-MmlSpark-0.15\n",
      "Name: AzureML-AutoML\n",
      "Name: AzureML-PyTorch-1.4-GPU\n",
      "Name: AzureML-PyTorch-1.4-CPU\n",
      "Name: AzureML-VowpalWabbit-8.8.0\n",
      "Name: AzureML-Hyperdrive-ForecastDNN\n",
      "Name: AzureML-AutoML-GPU\n",
      "Name: AzureML-AutoML-DNN-GPU\n",
      "Name: AzureML-AutoML-DNN\n",
      "Name: AzureML-Designer-R\n",
      "Name: AzureML-Designer-Recommender\n",
      "Name: AzureML-Designer-Transform\n",
      "Name: AzureML-Designer\n",
      "Name: AzureML-Designer-IO\n",
      "Name: AzureML-Designer-NLP\n",
      "Name: AzureML-Dask-CPU\n",
      "Name: AzureML-Dask-GPU\n"
     ]
    }
   ],
   "source": [
    "# list environments\n",
    "env_names = Environment.list(workspace=ws)\n",
    "for env_name in env_names:\n",
    "    print('Name:',env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and register dataset (File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset registered\n"
     ]
    }
   ],
   "source": [
    "# load the diabetes dataset (File method)\n",
    "ds = Datastore.get(ws, 'datalakestoragegen2')\n",
    "ds_path = [DataPath(ds, 'platinum/**')] # {path/*.parquet or path/**}\n",
    "file_ds = Dataset.File.from_files(path=ds_path)\n",
    "   \n",
    "# Register the file dataset\n",
    "try:\n",
    "    file_ds = file_ds.register(workspace=ws,\n",
    "                               name='diabetes file dataset',\n",
    "                               description='diabetes files',\n",
    "                               tags = {'format':'parquet'},\n",
    "                               create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "print('Dataset registered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "\t diabetes file dataset \t version 1\n"
     ]
    }
   ],
   "source": [
    "# show a list of registered dataset(s)\n",
    "print(\"Datasets:\")\n",
    "for dataset_name in list(ws.datasets.keys()):\n",
    "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
    "    print(\"\\t\", dataset.name, '\\t version', dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/diabetes.csv\n",
      "/diabetes.parquet\n",
      "/folder/diabetes2.csv\n"
     ]
    }
   ],
   "source": [
    "# list of the file path(s)\n",
    "for file_path in file_ds.to_path():\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e64935874104d49a6cef7accc8ff963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-training/runs/diabetes-training_1586772329_209a6e9f?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/ml_workspace\", \"run_id\": \"diabetes-training_1586772329_209a6e9f\", \"run_properties\": {\"run_id\": \"diabetes-training_1586772329_209a6e9f\", \"created_utc\": \"2020-04-13T10:05:30.537364Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"248d42ac-0c5c-4ca1-94d2-40aa06848d22\", \"azureml.git.repository_uri\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"mlflow.source.git.repoURL\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"f834abad85fa91c96a624045592b837ae8834960\", \"mlflow.source.git.commit\": \"f834abad85fa91c96a624045592b837ae8834960\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-04-13T10:06:30.809718Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://mlworkspace5331841681.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1586772329_209a6e9f/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=XQ0GzqhxDVO0UqGKN7uh%2BkpKg7hCcecinyIjpKqxJyg%3D&st=2020-04-13T09%3A56%3A35Z&se=2020-04-13T18%3A06%3A35Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://mlworkspace5331841681.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1586772329_209a6e9f/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=eFzFAKHfde50HqEFAvHatLkgy1SjY4So4xq42mUllSk%3D&st=2020-04-13T09%3A56%3A36Z&se=2020-04-13T18%3A06%3A36Z&sp=r\", \"logs/azureml/8_azureml.log\": \"https://mlworkspace5331841681.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1586772329_209a6e9f/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=QAKO6cYhQnZxDqzNPJKzTuH35mz6aRgcDVDN%2B58IXzA%3D&st=2020-04-13T09%3A56%3A35Z&se=2020-04-13T18%3A06%3A35Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/8_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:01:00\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"diabetes-training_1586772329_209a6e9f\", \"categories\": [0], \"series\": [{\"data\": [0.1]}]}, {\"name\": \"Accuracy\", \"run_id\": \"diabetes-training_1586772329_209a6e9f\", \"categories\": [0], \"series\": [{\"data\": [0.774]}]}, {\"name\": \"AUC\", \"run_id\": \"diabetes-training_1586772329_209a6e9f\", \"categories\": [0], \"series\": [{\"data\": [0.8484377332205582]}]}], \"run_logs\": \"Initialize DatasetContextManager.\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nEnter __enter__ of DatasetContextManager\\nSDK version: azureml-core==1.2.0.post2 azureml-dataprep==1.4.3\\nProcessing 'diabetes'\\nProcessing dataset FileDataset\\n{\\n  \\\"source\\\": [\\n    \\\"('datalakestoragegen2', 'platinum/**')\\\"\\n  ],\\n  \\\"definition\\\": [\\n    \\\"GetDatastoreFiles\\\"\\n  ],\\n  \\\"registration\\\": {\\n    \\\"id\\\": \\\"d44da7dc-672f-401c-bde9-6c7abfb03e2c\\\",\\n    \\\"name\\\": \\\"diabetes file dataset\\\",\\n    \\\"version\\\": 1,\\n    \\\"description\\\": \\\"diabetes files\\\",\\n    \\\"tags\\\": {\\n      \\\"format\\\": \\\"parquet\\\"\\n    },\\n    \\\"workspace\\\": \\\"Workspace.create(name='ml_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup')\\\"\\n  }\\n}\\nMounting diabetes to /mnt/data\\nMounted diabetes to /mnt/data\\nExit __enter__ of DatasetContextManager\\nEntering Run History Context Manager.\\nPreparing to call script [ diabetes_training.py ] with arguments: ['--regularization', '0.1']\\nAfter variable expansion, calling script [ diabetes_training.py ] with arguments: ['--regularization', '0.1']\\n\\nlibraries imported...\\nargparse parameters loaded...\\nrun context loaded...\\ndelta lake mounted...\\ndataset loaded...\\ntest: write dataset to workspace 'outputs/dataset.csv'\\nTraining a logistic regression model with regularization rate of 0.1\\nAccuracy: 0.774\\nAUC: 0.8484377332205582\\n\\n\\nThe experiment completed successfully. Finalizing run...\\nLogging experiment finalizing status in history service.\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.30414700508117676 seconds\\nEnter __exit__ of DatasetContextManager\\nUnmounting /mnt/data.\\nFinishing unmounting /mnt/data.\\nExit __exit__ of DatasetContextManager\\nEngine process terminated with returncode=0\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.2.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'diabetes-training_1586772329_209a6e9f',\n",
       " 'target': 'local',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2020-04-13T10:05:37.127525Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '248d42ac-0c5c-4ca1-94d2-40aa06848d22',\n",
       "  'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': 'f834abad85fa91c96a624045592b837ae8834960',\n",
       "  'mlflow.source.git.commit': 'f834abad85fa91c96a624045592b837ae8834960',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [{'dataset': {'id': 'd44da7dc-672f-401c-bde9-6c7abfb03e2c'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes', 'mechanism': 'Mount', 'pathOnCompute': '/mnt/data'}}],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization', '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'diabetes': {'dataLocation': {'dataset': {'id': 'd44da7dc-672f-401c-bde9-6c7abfb03e2c'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'diabetes',\n",
       "    'pathOnCompute': '/mnt/data',\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'training_environment',\n",
       "   'version': '1',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'azureml-dataprep[pandas,fuse]',\n",
       "        'pyarrow',\n",
       "        'fastparquet']},\n",
       "      'scikit-learn',\n",
       "      'joblib'],\n",
       "     'name': 'azureml_b9a1534962684a800c586e9fce04292e'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://mlworkspace5331841681.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1586772329_209a6e9f/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=t%2BlGx72%2FzLu4VsIIZEiEjTq6uOD9uk9NQJw0ycsfsnw%3D&st=2020-04-13T09%3A56%3A27Z&se=2020-04-13T18%3A06%3A27Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://mlworkspace5331841681.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1586772329_209a6e9f/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=0VCew0HPQojrhq6rPZKsnb6mZZTVoreRJl00jitoSUA%3D&st=2020-04-13T09%3A56%3A27Z&se=2020-04-13T18%3A06%3A27Z&sp=r',\n",
       "  'logs/azureml/8_azureml.log': 'https://mlworkspace5331841681.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1586772329_209a6e9f/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=8D7v%2F0qCfHkG4v%2B%2Fy5zj%2BmX%2BIWv%2FVj2vzah9up0T0gg%3D&st=2020-04-13T09%3A56%3A27Z&se=2020-04-13T18%3A06%3A27Z&sp=r'}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the script parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1\n",
    "}\n",
    "\n",
    "# get the registered dataset by name\n",
    "file_ds = Dataset.get_by_name(ws, \"diabetes file dataset\")\n",
    "\n",
    "# Get the docker environment\n",
    "training_env = Environment.get(ws, 'training_environment')\n",
    "\n",
    "# get the training compute cluster\n",
    "training_cluster = ComputeTarget(ws, 'aml-cluster')\n",
    "\n",
    "estimator = Estimator(source_directory=experiment_folder, # All the files in this directory are uploaded into the cluster nodes for execution\n",
    "                      compute_target='local', # {'local', training_cluster}\n",
    "                      entry_script='diabetes_training.py',\n",
    "                      script_params=script_params,\n",
    "                      environment_definition=training_env,\n",
    "                      inputs=[file_ds.as_named_input('diabetes').as_mount(path_on_compute='/mnt/data')],\n",
    "                     )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'diabetes-training'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion() # get more parameter info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inference script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_service folder created\n"
     ]
    }
   ],
   "source": [
    "# Create a local folder for the experiment files\n",
    "folder_name = 'diabetes_service'\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "print(folder_name, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_service/diabetes_score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $folder_name/diabetes_score.py\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load a registered model\n",
    "    model_path = Model.get_model_path(model_name='diabetes_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-diabetic', 'diabetic']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inference environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved inference environment file in diabetes_service/diabetes_env.yml\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = folder_name + \"/diabetes_env.yml\"\n",
    "with open(env_file, \"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved inference environment file in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and registered\n"
     ]
    }
   ],
   "source": [
    "# define model name\n",
    "model_name = 'diabetes_model'\n",
    "\n",
    "# register model from the workspace \n",
    "run.register_model(model_name=model_name, # registered model name used in scoring script init()\n",
    "                   model_path='outputs/diabetes_model.pkl', # fixed path in workspace {'model.pkl', 'model.onnx'}\n",
    "                   tags={'Training context': 'Custom Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'],\n",
    "                               'Accuracy': run.get_metrics()['Accuracy']},\n",
    "                   description=\"Classification model to predict diabetes\",\n",
    "                   model_framework=Model.Framework.SCIKITLEARN, # {TensorFlow, ScikitLearn, Onnx, Custom}\n",
    "                   model_framework_version='0.22.2')\n",
    "\n",
    "print('Model trained and registered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"diabetes-service\" does not exist, creating the webservice...\n",
      "Running........................................................................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "service_name = \"diabetes-service\"\n",
    "\n",
    "# Remove any existing service under the same name\n",
    "try:\n",
    "    Webservice(ws, service_name).delete()\n",
    "except WebserviceException:\n",
    "    print('\"' + service_name + '\" does not exist, creating the webservice...')\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime=\"python\",\n",
    "                                   source_directory=folder_name,\n",
    "                                   entry_script=\"diabetes_score.py\",\n",
    "                                   conda_file=\"diabetes_env.yml\")\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                                       memory_gb=1)\n",
    "\n",
    "# load the registered model\n",
    "model = ws.models['diabetes_model']\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI: http://2c134555-40dd-4061-a2cb-3a0a8ee7bf34.northeurope.azurecontainer.io/score\n",
      "Body: {\"data\": [[2, 180, 74, 24, 21, 24, 1.5, 22], [0, 148, 58, 11, 179, 39, 0.16, 45]]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\"not-diabetic\", \"not-diabetic\"]'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get webservice URI\n",
    "endpoint = service.scoring_uri\n",
    "\n",
    "# raw test data\n",
    "rawdata = [[2, 180, 74, 24, 21, 24, 1.5, 22],\n",
    "           [0, 148, 58, 11, 179, 39, 0.16, 45]]\n",
    "\n",
    "print(\"URI: \" + endpoint)\n",
    "print(\"Body: \" + json.dumps({\"data\": rawdata})) # convert array to a serialized JSON formatted string object\n",
    "\n",
    "service.run(json.dumps({\"data\": rawdata}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are finished testing your service, clean up the deployment with service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning of the model using HyperDrive.  \n",
    "Hyperdrive runs enable comparison for metrics on all different hyper parameter combinations tried.  \n",
    "\n",
    "[doc: how to tune hyperparameters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)  \n",
    "[git: examples](https://github.com/microsoft/MLHyperparameterTuning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AmlCompute\n",
    "training_cluster = ComputeTarget(ws, 'aml-cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a project directory\n",
    "project_folder = './diabetes_hyperdrive'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment folder\n",
    "experiment_folder = './' + project_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ././diabetes_hyperdrive/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import glob\n",
    "print(\"libraries imported...\")\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "print(\"run context loaded...\")\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "parser.add_argument('--C', type=float, default=1.0, help='Inverse of regularization strength')\n",
    "parser.add_argument('--solver', type=str, default='lbfgs', help='Algorithm to use in the optimization problem')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "run.log('Inverse of regularization strength', np.float(args.C))\n",
    "run.log('Algorithm to use in the optimization problem', np.str(args.solver))\n",
    "print(\"argparse parameters loaded...\")\n",
    "\n",
    "# load the diabetes dataset (File method)\n",
    "# Get the training data from the estimator input identified as 'diabetes'\n",
    "mount = run.input_datasets['diabetes'] # read-only mount from delta lake as '/mnt/data'\n",
    "print(\"delta lake mounted...\")\n",
    "diabetes = pd.read_parquet('/mnt/data/diabetes.parquet') # load any file(s) from this delta lake mounted folder\n",
    "print(\"dataset loaded...\")\n",
    "\n",
    "# save data into workspace\n",
    "diabetes.to_csv(\"outputs/dataset.csv\", index=False) # {logs/  outputs/}\n",
    "print(\"test: write dataset to workspace 'outputs/dataset.csv'\")\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=args.C, solver=args.solver).fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment name\n",
    "experiment = Experiment(ws, 'diabetes-hyperdrive-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Scikit-learn estimator\n",
    "\n",
    "# get the training compute cluster\n",
    "training_cluster = ComputeTarget(ws, 'aml-cluster')\n",
    "\n",
    "# Set the script parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1,\n",
    "    '--C': 10,\n",
    "    '--solver': 'lbfgs',\n",
    "}\n",
    "\n",
    "# Get the docker environment\n",
    "training_env = Environment.get(ws, 'training_environment')\n",
    "\n",
    "# get the registered dataset by name\n",
    "file_ds = Dataset.get_by_name(ws, \"diabetes file dataset\")\n",
    "\n",
    "estimator = Estimator(source_directory=experiment_folder, # All the files in this directory are uploaded into the cluster nodes for execution\n",
    "                      compute_target=training_cluster, # only compute allowed for hyperparameter tuning\n",
    "                      entry_script='diabetes_training.py',\n",
    "                      script_params=script_params,\n",
    "                      environment_definition=training_env,\n",
    "                      inputs=[file_ds.as_named_input('diabetes').as_mount(path_on_compute='/mnt/data')],\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameter space\n",
    "\n",
    "param_sampling = RandomParameterSampling( {\n",
    "    '--regularization': choice(1, 0.333, 0.1, 0.033),\n",
    "    '--C': choice(1, 3, 10, 30),\n",
    "    '--solver': choice('lbfgs', 'liblinear', 'newton-cg', 'lbfgs', 'sag'),\n",
    "    } )\n",
    "\n",
    "hyperdrive_run_config = HyperDriveConfig(estimator=estimator,\n",
    "                                         hyperparameter_sampling=param_sampling,\n",
    "                                         primary_metric_name='Accuracy',\n",
    "                                         primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                         max_total_runs=20,\n",
    "                                         max_concurrent_runs=5,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the HyperDrive experiment run (~25')\n",
    "hyperdrive_run = experiment.submit(config=hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2ce7aa11904cf58993b530db4ba87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-training/runs/diabetes-training_1586854014_10de8db3?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/ml_workspace\", \"run_id\": \"diabetes-training_1586854014_10de8db3\", \"run_properties\": {\"run_id\": \"diabetes-training_1586854014_10de8db3\", \"created_utc\": \"2020-04-14T08:46:55.783036Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"f8570092-78f7-443c-bb89-10ace0c51dda\", \"azureml.git.repository_uri\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"mlflow.source.git.repoURL\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"55c5a1ece4a8e829bd87f3ea8a3c7c024092511a\", \"mlflow.source.git.commit\": \"55c5a1ece4a8e829bd87f3ea8a3c7c024092511a\", \"azureml.git.dirty\": \"False\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-04-14T08:47:19.792825Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://mlworkspace5331841681.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1586854014_10de8db3/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=u%2BbBWtGzORKi4c7fIQJ9kTTtqkik17ZPZ9kQc6GrwoY%3D&st=2020-04-14T08%3A37%3A23Z&se=2020-04-14T16%3A47%3A23Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://mlworkspace5331841681.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1586854014_10de8db3/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=IJclu5qCxzX63ZMtde%2BsQMr7ztHRxXg2F40SArURzhw%3D&st=2020-04-14T08%3A37%3A23Z&se=2020-04-14T16%3A47%3A23Z&sp=r\", \"logs/azureml/8_azureml.log\": \"https://mlworkspace5331841681.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1586854014_10de8db3/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=aG9Ek0ksdh%2FC5ASls4U52lP8cs4B7WQgflTd1IHL75c%3D&st=2020-04-14T08%3A37%3A23Z&se=2020-04-14T16%3A47%3A23Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/8_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:00:24\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Inverse of regularization strength\", \"run_id\": \"diabetes-training_1586854014_10de8db3\", \"categories\": [0], \"series\": [{\"data\": [10.0]}]}, {\"name\": \"Algorithm to use in the optimization problem\", \"run_id\": \"diabetes-training_1586854014_10de8db3\", \"categories\": [0], \"series\": [{\"data\": [\"lbfgs\"]}]}, {\"name\": \"Regularization Rate\", \"run_id\": \"diabetes-training_1586854014_10de8db3\", \"categories\": [0], \"series\": [{\"data\": [0.1]}]}, {\"name\": \"Accuracy\", \"run_id\": \"diabetes-training_1586854014_10de8db3\", \"categories\": [0], \"series\": [{\"data\": [0.7723333333333333]}]}, {\"name\": \"AUC\", \"run_id\": \"diabetes-training_1586854014_10de8db3\", \"categories\": [0], \"series\": [{\"data\": [0.8424319617891437]}]}], \"run_logs\": \"Initialize DatasetContextManager.\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nEnter __enter__ of DatasetContextManager\\nSDK version: azureml-core==1.2.0.post2 azureml-dataprep==1.4.3\\nProcessing 'diabetes'\\nProcessing dataset FileDataset\\n{\\n  \\\"source\\\": [\\n    \\\"('datalakestoragegen2', 'platinum/**')\\\"\\n  ],\\n  \\\"definition\\\": [\\n    \\\"GetDatastoreFiles\\\"\\n  ],\\n  \\\"registration\\\": {\\n    \\\"id\\\": \\\"d44da7dc-672f-401c-bde9-6c7abfb03e2c\\\",\\n    \\\"name\\\": \\\"diabetes file dataset\\\",\\n    \\\"version\\\": 1,\\n    \\\"description\\\": \\\"diabetes files\\\",\\n    \\\"tags\\\": {\\n      \\\"format\\\": \\\"parquet\\\"\\n    },\\n    \\\"workspace\\\": \\\"Workspace.create(name='ml_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup')\\\"\\n  }\\n}\\nMounting diabetes to /mnt/data\\nMounted diabetes to /mnt/data\\nExit __enter__ of DatasetContextManager\\nEntering Run History Context Manager.\\nPreparing to call script [ diabetes_training.py ] with arguments: ['--regularization', '0.1', '--C', '10', '--solver', 'lbfgs']\\nAfter variable expansion, calling script [ diabetes_training.py ] with arguments: ['--regularization', '0.1', '--C', '10', '--solver', 'lbfgs']\\n\\nlibraries imported...\\nrun context loaded...\\nargparse parameters loaded...\\ndelta lake mounted...\\ndataset loaded...\\ntest: write dataset to workspace 'outputs/dataset.csv'\\nTraining a logistic regression model with regularization rate of 0.1\\n/azureml-envs/azureml_b9a1534962684a800c586e9fce04292e/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\\n\\nIncrease the number of iterations (max_iter) or scale the data as shown in:\\n    https://scikit-learn.org/stable/modules/preprocessing.html\\nPlease also refer to the documentation for alternative solver options:\\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\\nAccuracy: 0.7723333333333333\\nAUC: 0.8424319617891437\\n\\n\\nThe experiment completed successfully. Finalizing run...\\nLogging experiment finalizing status in history service.\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.23608112335205078 seconds\\nEnter __exit__ of DatasetContextManager\\nUnmounting /mnt/data.\\nFinishing unmounting /mnt/data.\\nExit __exit__ of DatasetContextManager\\nEngine process terminated with returncode=0\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.2.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the run details while running\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--C', '3', '--regularization', '0.033', '--solver', 'liblinear']\n"
     ]
    }
   ],
   "source": [
    "# Find best run\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "print(best_run.get_details()['runDefinition']['arguments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py36_automl",
   "language": "python",
   "name": "conda-env-azureml_py36_automl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
