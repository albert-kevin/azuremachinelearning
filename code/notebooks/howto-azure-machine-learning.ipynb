{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Kevin ALBERT  \n",
    "\n",
    "Created: April 2020  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning\n",
    "_**Classification project with data residing on a data lake gen2 using remote compute with autoML and customML**_\n",
    "\n",
    "## Contents\n",
    "1. [AutoML](#AutoML)\n",
    "1. [Setup](#Setup)\n",
    "1. [Train](#Train)\n",
    "1. [Results](#Results)\n",
    "1. [Register](#Register)\n",
    "1. [Deploy](#Deploy)\n",
    "1. [Test](#Test)\n",
    "1. [CustomML](#CustomML)\n",
    "1. [Finetuning](#Finetuning)\n",
    "1. [Pipelines](#Pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Cleaned datasets created in datafactory onto a delta lake Gen2.  \n",
    "This notebook is using delta lake data and remote compute to autoML train a classification model.  \n",
    "We use example data to detect diabetic or non-diabetic based on 8 features.  \n",
    "\n",
    "This notebook show how to:\n",
    "1. Setup packages\n",
    "1. Setup workspace\n",
    "1. Create an experiment\n",
    "1. Load data\n",
    "1. Setup compute\n",
    "1. Configure autoML\n",
    "1. Train pipelines\n",
    "1. Explore the best pipeline\n",
    "1. Inspect model properties\n",
    "1. Register the model\n",
    "1. Deploy model as webservice\n",
    "1. Webservice inference test\n",
    "1. customML inline method\n",
    "1. customML script method\n",
    "1. HyperParametertuning\n",
    "1. Pipelines endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* required\n",
    "  * **disable shield on Brave** webbrowser for the widgets to work\n",
    "  * download **config.json** from the machine learning workspace portal\n",
    "  * install extra azureml packages on **py37_default** when using **'local'** compute  \n",
    "  * split the data up in train and test dataset on data lake, validation dataset is not needed due to cross_validation\n",
    "* optional\n",
    "  * register datastore(s) manually\n",
    "  * register dataset(s) manually\n",
    "  * register compute cluster(s) manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update local\n",
    "# ! /anaconda/envs/py37_default/bin/python -m pip install --upgrade --upgrade-strategy eager azureml-sdk[explain,automl] azureml-widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update virtual env (will break it - do not use)\n",
    "# ! pip install --upgrade --upgrade-strategy eager azureml-sdk[explain,automl] azureml-widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import open-source packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import azure machine learning SDK packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml.core version: 1.16.0\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Dataset, Datastore, Run\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, AksCompute\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.webservice import Webservice, AciWebservice, AksWebservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling, GridParameterSampling\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.pipeline.core import PipelineData, Pipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.explain.model._internal.explanation_client import ExplanationClient\n",
    "import azureml.core\n",
    "print(\"azureml.core version:\", azureml.core.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml-accel-models                  1.8.0\r\n",
      "azureml-automl-core                   1.16.0\r\n",
      "azureml-automl-runtime                1.16.0\r\n",
      "azureml-cli-common                    1.8.0\r\n",
      "azureml-contrib-dataset               1.8.0\r\n",
      "azureml-contrib-fairness              1.8.0\r\n",
      "azureml-contrib-gbdt                  1.8.0\r\n",
      "azureml-contrib-interpret             1.8.0\r\n",
      "azureml-contrib-notebook              1.8.0\r\n",
      "azureml-contrib-pipeline-steps        1.8.0\r\n",
      "azureml-contrib-reinforcementlearning 1.8.0\r\n",
      "azureml-contrib-server                1.8.0\r\n",
      "azureml-contrib-services              1.8.0\r\n",
      "azureml-core                          1.16.0.post1\r\n",
      "azureml-datadrift                     1.8.0\r\n",
      "azureml-dataprep                      2.3.3\r\n",
      "azureml-dataprep-native               23.0.0\r\n",
      "azureml-dataprep-rslex                1.1.2\r\n",
      "azureml-dataset-runtime               1.16.0\r\n",
      "azureml-defaults                      1.16.0\r\n",
      "azureml-explain-model                 1.16.0\r\n",
      "azureml-interpret                     1.16.0\r\n",
      "azureml-mlflow                        1.8.0\r\n",
      "azureml-model-management-sdk          1.0.1b6.post1\r\n",
      "azureml-monitoring                    0.1.0a18\r\n",
      "azureml-opendatasets                  1.8.0\r\n",
      "azureml-pipeline                      1.16.0\r\n",
      "azureml-pipeline-core                 1.16.0\r\n",
      "azureml-pipeline-steps                1.16.0\r\n",
      "azureml-sdk                           1.16.0\r\n",
      "azureml-telemetry                     1.16.0\r\n",
      "azureml-tensorboard                   1.8.0\r\n",
      "azureml-train                         1.16.0\r\n",
      "azureml-train-automl                  1.16.0\r\n",
      "azureml-train-automl-client           1.16.0\r\n",
      "azureml-train-automl-runtime          1.16.0\r\n",
      "azureml-train-core                    1.16.0\r\n",
      "azureml-train-restclients-hyperdrive  1.16.0\r\n",
      "azureml-widgets                       1.16.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip list |grep -i azureml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose an experiment name\n",
    "experiment = Experiment(ws, 'automl-classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Factory has prepped data from /bronze to /silver to /gold and /platinum for model training  \n",
    "**note:** this demonstration had files in the Data Lake Gen2 datalake container /platinum folder  \n",
    "  * /datalake/platinum/diabetes.csv\n",
    "  * /datalake/platinum/diabetes.parquet\n",
    "  * copy from ../data/platinum/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the datastore 'data lake gen2' as a **blob container**  \n",
    "**optional:** manually register in ML workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datalakestoragegen2': {\n",
       "   \"name\": \"datalakestoragegen2\",\n",
       "   \"container_name\": \"datalake\",\n",
       "   \"account_name\": \"datalake15102020\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " },\n",
       " 'workspacefilestore': {\n",
       "   \"name\": \"workspacefilestore\",\n",
       "   \"container_name\": \"azureml-filestore-d4c83106-e1e1-4e75-83ee-252b1c859da0\",\n",
       "   \"account_name\": \"machinelstoragece02c4ea7\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " },\n",
       " 'workspaceblobstore': {\n",
       "   \"name\": \"workspaceblobstore\",\n",
       "   \"container_name\": \"azureml-blobstore-d4c83106-e1e1-4e75-83ee-252b1c859da0\",\n",
       "   \"account_name\": \"machinelstoragece02c4ea7\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " }}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Datastore.register_azure_blob_container(\n",
    "    workspace=ws,\n",
    "    datastore_name=\"datalakestoragegen2\",\n",
    "    container_name=\"datalake\",\n",
    "    account_name=\"datalake15102020\",\n",
    "    account_key=\"mk9ftVkp1KnObAujAfHVl5dbQznfZmWYS4nP3/QFzsG0xXMCW5OluHx2zIYyrHSItkIC7d9I/RbFIZ2km3SMIQ==\",\n",
    "    create_if_not_exists=False)\n",
    "# list available datastores\n",
    "ws.datastores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register file(s) into a tabular dataset  \n",
    "**Note:** do not import Delta lake parquet file(s)  \n",
    "**Fix:** you can import pandas single gold/*.csv or gold/*.parquet file(s)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datastore\n",
    "ds = Datastore.get(ws, 'datalakestoragegen2')\n",
    "# show datastore settings\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1 Tabular:** loading *.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('datalakestoragegen2', 'platinum/diabetes.parquet')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ReadParquetFile\",\n",
       "    \"DropColumns\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup parquet file(s) into a tabular dataset\n",
    "ds_path = [DataPath(ds, 'platinum/diabetes.parquet')] # {path/*.parquet}\n",
    "dataset = Dataset.Tabular.from_parquet_files(path=ds_path)\n",
    "# show dataset settings\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2 Tabular:** loading *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup csv file(s) into a tabular dataset\n",
    "ds_path = [DataPath(ds, 'platinum/diabetes.csv')]\n",
    "dataset = Dataset.Tabular.from_delimited_files(path=ds_path)\n",
    "# show dataset settings\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 3 Registered:** loading a registered dataset (manually register in ML workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list available datasets\n",
    "ws.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a registered dataset\n",
    "dataset = Dataset.get_by_name(ws, 'diabetes_parquet_from_datastore_datalakegen2')\n",
    "# show dataset settings\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check possible compute type **names** to create auto-scaling cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>vCPUs</th>\n",
       "      <th>gpus</th>\n",
       "      <th>memoryGB</th>\n",
       "      <th>maxResourceVolumeMB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard_D1_v2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>51200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Standard_DS1_v2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Standard_D1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>51200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  vCPUs  gpus  memoryGB  maxResourceVolumeMB\n",
       "0    Standard_D1_v2      1     0       3.5                51200\n",
       "14  Standard_DS1_v2      1     0       3.5                 7168\n",
       "68      Standard_D1      1     0       3.5                51200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example: list all with 1=vCPUs 2>GB and no-GPU\n",
    "vm_df = pd.DataFrame(AmlCompute.supported_vmsizes(ws))\n",
    "vm_df[(vm_df.vCPUs == 1) & (vm_df.memoryGB >= 2) & (vm_df.gpus == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option 1: Create training cluster  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# Specify a name for the compute (unique within the workspace)\n",
    "compute_name = 'aml-cluster'\n",
    "# Define compute configuration\n",
    "compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_D1_v2',\n",
    "                                                       min_nodes=0, # you are not paying if not using\n",
    "                                                       max_nodes=10, # depending quota limits\n",
    "                                                       vm_priority='dedicated', # {lowpriority, dedicated}\n",
    "                                                       admin_username='ubuntu',\n",
    "                                                       admin_user_password='ABCD1234abcd',\n",
    "                                                       idle_seconds_before_scaledown=120, # {default: 120}\n",
    "                                                      )\n",
    "# Create the compute\n",
    "training_cluster = ComputeTarget.create(ws, compute_name, compute_config)\n",
    "training_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option 2: Load already known training cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aml-cluster\n"
     ]
    }
   ],
   "source": [
    "# list all available training cluster(s):\n",
    "for cluster in ws.compute_targets:\n",
    "    print(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training cluster\n",
    "compute_name = 'aml-cluster'\n",
    "training_cluster = ComputeTarget(ws, name=compute_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure autoML\n",
    "Define settings to run the experiment.\n",
    "\n",
    "|Property|Description|Options|\n",
    "|-|-|-|\n",
    "|**task**||<i>classification</i><br><i>regression</i><br><i>forecasting</i>|\n",
    "|**compute_target**|execution on local DSVM serialized<br>execution on remote AML or AKS parallel|<i>local</i><br><i>training_cluster</i>|\n",
    "|**primary_metric**|the metric you want to optimize<br>[metrics](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml)|**classification:**<br><i>accuracy</i><br><i>AUC_weighted</i><br><i>average_precision_score_weighted</i><br><i>norm_macro_recall</i><br><i>precision_score_weighted</i><br><br>**regression:**<br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>|\n",
    "|**training_data**|input dataset, containing both X_train and y_train|<i>DataFrame</i><br><i>Dataset</i><br><i>DatasetDefinition</i><br><i>TabularDataset</i>|\n",
    "|**validation_data**|input dataset, covered with cross validation|N/A|\n",
    "|**label_column_name**|the name of the 'target' or 'label' column||\n",
    "|**enable_early_stopping**|stop the run if metric score is not improving|<i>True</i><br><i>False</i>|\n",
    "|**n_cross_validations**|number of cross validation splits|5|\n",
    "|**experiment_timeout_hours**|max time in hours the experiment terminates (+15min)|<i>0.25</i>|\n",
    "|**max_concurrent_iterations**|less or equal to the number of cores per node|2|\n",
    "\n",
    "\n",
    "\n",
    "**_You can find more information_** [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"enable_early_stopping\":True,\n",
    "    \"experiment_timeout_hours\":0.25,\n",
    "    \"iterations\":10, # number of runs\n",
    "    \"iteration_timeout_minutes\":5,\n",
    "    \"max_concurrent_iterations\":1,\n",
    "    \"max_cores_per_iteration\":-1,\n",
    "    #\"experiment_exit_score\":0.9920,\n",
    "    \"model_explainability\":True,\n",
    "    \"n_cross_validations\":5,\n",
    "    \"primary_metric\":'AUC_weighted',\n",
    "    \"featurization\":'auto',\n",
    "    \"verbosity\":logging.INFO, # {INFO, DEBUG, CRITICAL, ERROR, WARNING} -- debug_log=<*.log>\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task='classification',\n",
    "                             debug_log='automl_errors.log',\n",
    "                             compute_target='local', # {training_cluster or 'local'}\n",
    "                             #blacklist_models=['KNN','LinearSVM'],\n",
    "                             enable_onnx_compatible_models=True,\n",
    "                             training_data=dataset,\n",
    "                             label_column_name=\"Diabetic\",\n",
    "                             **automl_settings\n",
    "                            )\n",
    "# ouputs \"model.pkl\" and \"automl_errors.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4\n",
      "\n",
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Classes are balanced in the training data.\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:00:18       0.9904    0.9904\n",
      "         1   MaxAbsScaler XGBoostClassifier                 0:00:20       0.9901    0.9904\n",
      "         2   MaxAbsScaler LightGBM                          0:00:15       0.9800    0.9904\n",
      "         3   StandardScalerWrapper XGBoostClassifier        0:00:16       0.9729    0.9904\n",
      "         4   MaxAbsScaler SGD                               0:00:15       0.9322    0.9904\n",
      "         5   StandardScalerWrapper LightGBM                 0:00:15       0.9799    0.9904\n",
      "         6   SparseNormalizer XGBoostClassifier             0:00:15       0.9383    0.9904\n",
      "         7   MaxAbsScaler RandomForest                      0:00:17       0.9646    0.9904\n",
      "         8   MaxAbsScaler SGD                               0:00:15       0.9353    0.9904\n",
      "         9   VotingEnsemble                                 0:00:17       0.9901    0.9904\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Matplotlib is building the font cache using fc-list. This may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: BestRunExplainModel. Best run model explanations started\n",
      "Current status: ModelExplanationDataSetSetup. Model explanations data setup completed\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features started\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features completed\n",
      "Current status: BestRunExplainModel. Best run model explanations completed\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "automl_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: retrieve a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runId = 'AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4'\n",
    "automl_run = AutoMLRun(experiment, run_id=runId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the best pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20b794411c24b75862a06635b24085b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/automl-classification/runs/AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup4/workspaces/machine_learning_workspace4\", \"run_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4\", \"run_properties\": {\"run_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4\", \"created_utc\": \"2020-04-20T15:17:21.440986Z\", \"properties\": {\"num_iterations\": \"10\", \"training_type\": \"TrainFull\", \"acquisition_function\": \"EI\", \"primary_metric\": \"AUC_weighted\", \"train_split\": \"0\", \"acquisition_parameter\": \"0\", \"num_cross_validation\": \"5\", \"target\": \"local\", \"RawAMLSettingsString\": \"{'name': 'automl-classification', 'path': '.', 'subscription_id': '43c1f93a-903d-4b23-a4bf-92bd7a150627', 'resource_group': 'myResourceGroup4', 'workspace_name': 'machine_learning_workspace4', 'region': 'westeurope', 'compute_target': 'local', 'spark_service': None, 'azure_service': 'local', 'iterations': 10, 'primary_metric': 'AUC_weighted', 'task_type': 'classification', 'data_script': None, 'validation_size': 0.0, 'n_cross_validations': 5, 'y_min': None, 'y_max': None, 'num_classes': 2, 'featurization': 'auto', 'lag_length': 0, 'is_timeseries': False, 'max_cores_per_iteration': -1, 'max_concurrent_iterations': 1, 'iteration_timeout_minutes': 5, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'experiment_timeout_minutes': 15, 'experiment_exit_score': None, 'whitelist_models': None, 'blacklist_algos': ['KNN', 'KNN', 'SVM'], 'supported_models': ['MultinomialNaiveBayes', 'SGD', 'TensorFlowDNN', 'XGBoostClassifier', 'ExtremeRandomTrees', 'LinearSVM', 'KNN', 'LightGBM', 'RandomForest', 'GradientBoosting', 'TensorFlowLinearClassifier', 'LogisticRegression', 'BernoulliNaiveBayes', 'DecisionTree', 'SVM', 'AveragedPerceptronClassifier'], 'auto_blacklist': True, 'blacklist_samples_reached': True, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'automl_errors.log', 'show_warnings': False, 'model_explainability': True, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'enable_onnx_compatible_models': True, 'enable_split_onnx_featurizer_estimator_models': False, 'vm_type': None, 'telemetry_verbosity': 20, 'send_telemetry': True, 'enable_dnn': False, 'force_text_dnn': False, 'enable_feature_sweeping': False, 'enable_early_stopping': True, 'early_stopping_n_iters': 10, 'metrics': None, 'enable_ensembling': True, 'enable_stack_ensembling': False, 'ensemble_iterations': 10, 'enable_tf': False, 'enable_cache': True, 'enable_subsampling': False, 'subsample_seed': None, 'enable_nimbusml': False, 'enable_streaming': False, 'force_streaming': False, 'label_column_name': 'Diabetic', 'weight_column_name': None, 'cost_mode': 1, 'metric_operation': 'maximize', 'preprocess': True, 'scenario': 'SDK'}\", \"AMLSettingsJsonString\": \"{\\\"name\\\": \\\"automl-classification\\\", \\\"path\\\": \\\".\\\", \\\"subscription_id\\\": \\\"43c1f93a-903d-4b23-a4bf-92bd7a150627\\\", \\\"resource_group\\\": \\\"myResourceGroup4\\\", \\\"workspace_name\\\": \\\"machine_learning_workspace4\\\", \\\"region\\\": \\\"westeurope\\\", \\\"compute_target\\\": \\\"local\\\", \\\"spark_service\\\": null, \\\"azure_service\\\": \\\"local\\\", \\\"iterations\\\": 10, \\\"primary_metric\\\": \\\"AUC_weighted\\\", \\\"task_type\\\": \\\"classification\\\", \\\"data_script\\\": null, \\\"validation_size\\\": 0.0, \\\"n_cross_validations\\\": 5, \\\"y_min\\\": null, \\\"y_max\\\": null, \\\"num_classes\\\": 2, \\\"featurization\\\": \\\"auto\\\", \\\"lag_length\\\": 0, \\\"is_timeseries\\\": false, \\\"max_cores_per_iteration\\\": -1, \\\"max_concurrent_iterations\\\": 1, \\\"iteration_timeout_minutes\\\": 5, \\\"mem_in_mb\\\": null, \\\"enforce_time_on_windows\\\": false, \\\"experiment_timeout_minutes\\\": 15, \\\"experiment_exit_score\\\": null, \\\"whitelist_models\\\": null, \\\"blacklist_algos\\\": [\\\"KNN\\\", \\\"KNN\\\", \\\"SVM\\\"], \\\"supported_models\\\": [\\\"MultinomialNaiveBayes\\\", \\\"SGD\\\", \\\"TensorFlowDNN\\\", \\\"XGBoostClassifier\\\", \\\"ExtremeRandomTrees\\\", \\\"LinearSVM\\\", \\\"KNN\\\", \\\"LightGBM\\\", \\\"RandomForest\\\", \\\"GradientBoosting\\\", \\\"TensorFlowLinearClassifier\\\", \\\"LogisticRegression\\\", \\\"BernoulliNaiveBayes\\\", \\\"DecisionTree\\\", \\\"SVM\\\", \\\"AveragedPerceptronClassifier\\\"], \\\"auto_blacklist\\\": true, \\\"blacklist_samples_reached\\\": true, \\\"exclude_nan_labels\\\": true, \\\"verbosity\\\": 20, \\\"debug_log\\\": \\\"automl_errors.log\\\", \\\"show_warnings\\\": false, \\\"model_explainability\\\": true, \\\"service_url\\\": null, \\\"sdk_url\\\": null, \\\"sdk_packages\\\": null, \\\"enable_onnx_compatible_models\\\": true, \\\"enable_split_onnx_featurizer_estimator_models\\\": false, \\\"vm_type\\\": null, \\\"telemetry_verbosity\\\": 20, \\\"send_telemetry\\\": true, \\\"enable_dnn\\\": false, \\\"force_text_dnn\\\": false, \\\"enable_feature_sweeping\\\": false, \\\"enable_early_stopping\\\": true, \\\"early_stopping_n_iters\\\": 10, \\\"metrics\\\": null, \\\"enable_ensembling\\\": true, \\\"enable_stack_ensembling\\\": false, \\\"ensemble_iterations\\\": 10, \\\"enable_tf\\\": false, \\\"enable_cache\\\": true, \\\"enable_subsampling\\\": false, \\\"subsample_seed\\\": null, \\\"enable_nimbusml\\\": false, \\\"enable_streaming\\\": false, \\\"force_streaming\\\": false, \\\"label_column_name\\\": \\\"Diabetic\\\", \\\"weight_column_name\\\": null, \\\"cost_mode\\\": 1, \\\"metric_operation\\\": \\\"maximize\\\", \\\"preprocess\\\": true, \\\"scenario\\\": \\\"SDK\\\"}\", \"DataPrepJsonString\": null, \"EnableSubsampling\": \"False\", \"runTemplate\": \"AutoML\", \"azureml.runsource\": \"automl\", \"display_task_type\": \"classification\", \"dependencies_versions\": \"{\\\"azureml-widgets\\\": \\\"1.3.0\\\", \\\"azureml-train\\\": \\\"1.3.0\\\", \\\"azureml-train-restclients-hyperdrive\\\": \\\"1.3.0\\\", \\\"azureml-train-core\\\": \\\"1.3.0\\\", \\\"azureml-train-automl\\\": \\\"1.3.0\\\", \\\"azureml-train-automl-runtime\\\": \\\"1.3.0\\\", \\\"azureml-train-automl-client\\\": \\\"1.3.0\\\", \\\"azureml-tensorboard\\\": \\\"1.0.85\\\", \\\"azureml-telemetry\\\": \\\"1.3.0\\\", \\\"azureml-sdk\\\": \\\"1.3.0\\\", \\\"azureml-pipeline\\\": \\\"1.3.0\\\", \\\"azureml-pipeline-steps\\\": \\\"1.3.0\\\", \\\"azureml-pipeline-core\\\": \\\"1.3.0\\\", \\\"azureml-opendatasets\\\": \\\"1.0.85\\\", \\\"azureml-model-management-sdk\\\": \\\"1.0.1b6.post1\\\", \\\"azureml-interpret\\\": \\\"1.3.0\\\", \\\"azureml-explain-model\\\": \\\"1.3.0\\\", \\\"azureml-defaults\\\": \\\"1.3.0\\\", \\\"azureml-dataprep\\\": \\\"1.4.3\\\", \\\"azureml-dataprep-native\\\": \\\"14.1.0\\\", \\\"azureml-datadrift\\\": \\\"1.0.85\\\", \\\"azureml-core\\\": \\\"1.3.0.post1\\\", \\\"azureml-contrib-services\\\": \\\"1.3.0\\\", \\\"azureml-contrib-reinforcementlearning\\\": \\\"0.1.0.5919674\\\", \\\"azureml-contrib-notebook\\\": \\\"1.3.0\\\", \\\"azureml-contrib-interpret\\\": \\\"1.0.85\\\", \\\"azureml-automl-runtime\\\": \\\"1.3.0\\\", \\\"azureml-automl-core\\\": \\\"1.3.0\\\"}\", \"ClientType\": \"SDK\", \"ClientSdkVersion\": \"1.3.0\", \"environment_cpu_name\": \"\", \"environment_cpu_version\": \"\", \"environment_gpu_name\": \"\", \"environment_gpu_version\": \"\", \"ProblemInfoJsonString\": \"{\\\"dataset_num_categorical\\\": 0, \\\"is_sparse\\\": true, \\\"subsampling\\\": false, \\\"dataset_classes\\\": 2, \\\"dataset_features\\\": 23, \\\"dataset_samples\\\": 10000, \\\"single_frequency_class_detected\\\": false}\", \"feature_skus\": \"automatedml_sdk_guardrails\", \"azureml.git.repository_uri\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"mlflow.source.git.repoURL\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"3b0b9f345b8ba523ffcf9a3cb26aecd0e097d138\", \"mlflow.source.git.commit\": \"3b0b9f345b8ba523ffcf9a3cb26aecd0e097d138\", \"azureml.git.dirty\": \"True\"}, \"tags\": {\"model_explain_run\": \"best_run\", \"model_explain_best_run_child_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4_0\", \"best_score\": \"0.9904426831775627\", \"best_pipeline\": \"LightGBM\"}, \"end_time_utc\": \"2020-04-20T15:21:04.102187Z\", \"status\": \"Completed\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:03:42\"}, \"child_runs\": [{\"run_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4_0\", \"run_number\": 2, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-20T15:17:36.525522Z\", \"end_time\": \"2020-04-20T15:17:54.95533Z\", \"created_time\": \"2020-04-20T15:17:36.360724Z\", \"created_time_dt\": \"2020-04-20T15:17:36.360724Z\", \"duration\": \"0:00:18\", \"iteration\": \"0\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, LightGBM\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.99044268, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4_1\", \"run_number\": 3, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-20T15:17:56.901631Z\", \"end_time\": \"2020-04-20T15:18:17.494694Z\", \"created_time\": \"2020-04-20T15:17:56.781062Z\", \"created_time_dt\": \"2020-04-20T15:17:56.781062Z\", \"duration\": \"0:00:20\", \"iteration\": \"1\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, XGBoostClassifier\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.99013634, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4_2\", \"run_number\": 4, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-20T15:18:19.693134Z\", \"end_time\": \"2020-04-20T15:18:35.428072Z\", \"created_time\": \"2020-04-20T15:18:19.444396Z\", \"created_time_dt\": \"2020-04-20T15:18:19.444396Z\", \"duration\": \"0:00:15\", \"iteration\": \"2\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, LightGBM\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.97998756, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4_3\", \"run_number\": 5, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-20T15:18:37.911549Z\", \"end_time\": \"2020-04-20T15:18:54.141043Z\", \"created_time\": \"2020-04-20T15:18:37.651628Z\", \"created_time_dt\": \"2020-04-20T15:18:37.651628Z\", \"duration\": \"0:00:16\", \"iteration\": \"3\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"StandardScalerWrapper, XGBoostClassifier\", \"run_properties\": \"<azureml.automl.runtime.shared.model_wrappers.StandardScalerWrapper object at 0x7ff21c0226a0\", \"primary_metric\": 0.97287654, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4_4\", \"run_number\": 6, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-20T15:18:56.813733Z\", \"end_time\": \"2020-04-20T15:19:12.198211Z\", \"created_time\": \"2020-04-20T15:18:56.679136Z\", \"created_time_dt\": \"2020-04-20T15:18:56.679136Z\", \"duration\": \"0:00:15\", \"iteration\": \"4\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, SGD\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.93220696, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4_5\", \"run_number\": 7, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-20T15:19:14.449908Z\", \"end_time\": \"2020-04-20T15:19:30.263539Z\", \"created_time\": \"2020-04-20T15:19:14.167115Z\", \"created_time_dt\": \"2020-04-20T15:19:14.167115Z\", \"duration\": \"0:00:16\", \"iteration\": \"5\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"StandardScalerWrapper, LightGBM\", \"run_properties\": \"<azureml.automl.runtime.shared.model_wrappers.StandardScalerWrapper object at 0x7ff2143e9358\", \"primary_metric\": 0.97985121, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4_6\", \"run_number\": 8, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-20T15:19:32.19781Z\", \"end_time\": \"2020-04-20T15:19:48.092724Z\", \"created_time\": \"2020-04-20T15:19:32.057229Z\", \"created_time_dt\": \"2020-04-20T15:19:32.057229Z\", \"duration\": \"0:00:16\", \"iteration\": \"6\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"SparseNormalizer, XGBoostClassifier\", \"run_properties\": \"<azureml.automl.runtime.shared.model_wrappers.SparseNormalizer object at 0x7ff217f8d7b8\", \"primary_metric\": 0.93834785, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4_7\", \"run_number\": 9, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-20T15:19:50.794727Z\", \"end_time\": \"2020-04-20T15:20:07.896887Z\", \"created_time\": \"2020-04-20T15:19:50.673128Z\", \"created_time_dt\": \"2020-04-20T15:19:50.673128Z\", \"duration\": \"0:00:17\", \"iteration\": \"7\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, RandomForest\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.96462334, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4_8\", \"run_number\": 10, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-20T15:20:09.814814Z\", \"end_time\": \"2020-04-20T15:20:25.502811Z\", \"created_time\": \"2020-04-20T15:20:09.655625Z\", \"created_time_dt\": \"2020-04-20T15:20:09.655625Z\", \"duration\": \"0:00:15\", \"iteration\": \"8\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, SGD\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.93529366, \"best_metric\": 0.99044268}, {\"run_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4_9\", \"run_number\": 11, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-04-20T15:20:26.603718Z\", \"end_time\": \"2020-04-20T15:20:43.736837Z\", \"created_time\": \"2020-04-20T15:20:26.479761Z\", \"created_time_dt\": \"2020-04-20T15:20:26.479761Z\", \"duration\": \"0:00:17\", \"iteration\": \"9\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"VotingEnsemble\", \"run_properties\": \"classification_labels=None,\\n               estimators=[('0', Pipeline(memory=None,\\n     steps=[('maxabsscaler', MaxAbsScaler(copy=True\", \"primary_metric\": 0.99013875, \"best_metric\": 0.99044268}], \"children_metrics\": {\"categories\": [0], \"series\": {\"recall_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"recall_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9309999999999998, 0.9112, 0.8422000000000001, 0.9284000000000001, 0.8711, 0.8899999999999999, 0.8571, 0.9522999999999999]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"recall_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001]}], \"precision_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"precision_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.951529651244859, 0.9530946926472017, 0.930783855397262, 0.9131743472859288, 0.8617772664166399, 0.9281127732714897, 0.8728995183456005, 0.8984785596811499, 0.8637680381252597, 0.9522562343307065]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"precision_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.951529651244859, 0.9530946926472017, 0.9530946926472017, 0.9530946926472017, 0.9530946926472017, 0.9530946926472017, 0.9530946926472017, 0.9530946926472017, 0.9530946926472017, 0.9530946926472017]}], \"log_loss\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"log_loss\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.11810503522790523, 0.12355458879130007, 0.20029542689856225, 0.6810231414345467, 0.3427743182232581, 0.22212314578011133, 0.31053275139669534, 0.3901959288804277, 0.320552019412212, 0.1653918467284418]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"log_loss_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.11810503522790523, 0.11810503522790523, 0.11810503522790523, 0.11810503522790523, 0.11810503522790523, 0.11810503522790523, 0.11810503522790523, 0.11810503522790523, 0.11810503522790523, 0.11810503522790523]}], \"AUC_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"AUC_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9914617, 0.99123075, 0.9819810999999998, 0.9706379500000001, 0.9278126, 0.98174315, 0.94582075, 0.9599209, 0.9381278500000001, 0.9911770499999999]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"AUC_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9914617, 0.9914617, 0.9914617, 0.9914617, 0.9914617, 0.9914617, 0.9914617, 0.9914617, 0.9914617, 0.9914617]}], \"average_precision_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"average_precision_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9916787674263302, 0.9914207655503823, 0.9824355147560763, 0.971443166105584, 0.9285742221396406, 0.9821738696776879, 0.9455192723189926, 0.960663884654231, 0.9390766504403013, 0.9913005215775158]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"average_precision_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9916787674263302, 0.9916787674263302, 0.9916787674263302, 0.9916787674263302, 0.9916787674263302, 0.9916787674263302, 0.9916787674263302, 0.9916787674263302, 0.9916787674263302, 0.9916787674263302]}], \"precision_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"precision_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9309999999999998, 0.9112, 0.8422000000000001, 0.9284000000000001, 0.8711, 0.8899999999999999, 0.8571, 0.9522999999999999]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"precision_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001]}], \"average_precision_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"average_precision_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9907832843118888, 0.9904387921847764, 0.9803897362802267, 0.9735418439152046, 0.9323126938284467, 0.9804539607003336, 0.9364782850574249, 0.9655627510789859, 0.9369791629314624, 0.9903198495294756]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"average_precision_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9907832843118888, 0.9907832843118888, 0.9907832843118888, 0.9907832843118888, 0.9907832843118888, 0.9907832843118888, 0.9907832843118888, 0.9907832843118888, 0.9907832843118888, 0.9907832843118888]}], \"average_precision_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"average_precision_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9885533270268901, 0.9881262999794401, 0.9755397381214033, 0.9671138262930693, 0.9159184351299627, 0.9757088226944444, 0.9211101585594055, 0.9571687578946673, 0.9221470055867236, 0.9879551118771186]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"average_precision_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9885533270268901, 0.9885533270268901, 0.9885533270268901, 0.9885533270268901, 0.9885533270268901, 0.9885533270268901, 0.9885533270268901, 0.9885533270268901, 0.9885533270268901, 0.9885533270268901]}], \"AUC_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"AUC_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9904426831775627, 0.9901363381909428, 0.9799875631590194, 0.972876537424591, 0.9322069608124774, 0.9798512121204069, 0.9383478538322411, 0.9646233391439193, 0.935293656820452, 0.9901387530932206]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"AUC_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627]}], \"f1_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"f1_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9309999999999998, 0.9112, 0.8422000000000001, 0.9283999999999999, 0.8710999999999999, 0.8899999999999999, 0.8571, 0.9522999999999999]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"f1_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001]}], \"weighted_accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"weighted_accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9576144671870581, 0.9582753858834163, 0.9402683455938206, 0.93555228266066, 0.8324912864099081, 0.9385200234898274, 0.8795828305271899, 0.8857250921752321, 0.8604193845538519, 0.9581599781415612]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"weighted_accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9576144671870581, 0.9582753858834163, 0.9582753858834163, 0.9582753858834163, 0.9582753858834163, 0.9582753858834163, 0.9582753858834163, 0.9582753858834163, 0.9582753858834163, 0.9582753858834163]}], \"recall_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"recall_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9309999999999998, 0.9112, 0.8422000000000001, 0.9284000000000001, 0.8711, 0.8899999999999999, 0.8571, 0.9522999999999999]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"recall_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001]}], \"f1_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"f1_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9454409908953988, 0.9472018036714414, 0.9219370459050173, 0.8957241285558718, 0.8318722230305529, 0.9188596878685606, 0.8565870942537458, 0.880535372867414, 0.8433194534476431, 0.9462127060098208]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"f1_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9454409908953988, 0.9472018036714414, 0.9472018036714414, 0.9472018036714414, 0.9472018036714414, 0.9472018036714414, 0.9472018036714414, 0.9472018036714414, 0.9472018036714414, 0.9472018036714414]}], \"matthews_correlation\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"matthews_correlation\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.8909693671988277, 0.8944856430405238, 0.8441163994810769, 0.7983959938080952, 0.6776668122163889, 0.8380082427805704, 0.7137361600527138, 0.7666990908422905, 0.6905680606080631, 0.8925327853728297]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"matthews_correlation_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.8909693671988277, 0.8944856430405238, 0.8944856430405238, 0.8944856430405238, 0.8944856430405238, 0.8944856430405238, 0.8944856430405238, 0.8944856430405238, 0.8944856430405238, 0.8944856430405238]}], \"recall_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"recall_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9440819974618796, 0.946639302103166, 0.9194062242836161, 0.880773115188215, 0.8543787713871719, 0.9157448243762556, 0.8605164184930784, 0.8953660921791305, 0.8530220664404912, 0.9449822771563096]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"recall_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9440819974618796, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166]}], \"norm_macro_recall\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"norm_macro_recall\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.8881639949237587, 0.893278604206332, 0.8388124485672321, 0.7615462303764298, 0.7087575427743439, 0.8314896487525113, 0.7210328369861567, 0.7907321843582611, 0.7060441328809823, 0.8899645543126191]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"norm_macro_recall_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.8881639949237587, 0.893278604206332, 0.893278604206332, 0.893278604206332, 0.893278604206332, 0.893278604206332, 0.893278604206332, 0.893278604206332, 0.893278604206332, 0.893278604206332]}], \"accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9309999999999998, 0.9112, 0.8422000000000001, 0.9284000000000001, 0.8711, 0.8899999999999999, 0.8571, 0.9522999999999999]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9516, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001, 0.9531000000000001]}], \"f1_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"f1_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.951525872795924, 0.953060824473698, 0.9307838738247038, 0.9090819437849259, 0.8457297872608347, 0.9281272052572049, 0.8717517063068401, 0.8917298968265, 0.8586788552856588, 0.9522300858385437]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"f1_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.951525872795924, 0.953060824473698, 0.953060824473698, 0.953060824473698, 0.953060824473698, 0.953060824473698, 0.953060824473698, 0.953060824473698, 0.953060824473698, 0.953060824473698]}], \"precision_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"precision_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9468968210340906, 0.9478551551034957, 0.9247363415195327, 0.9185584651821628, 0.8239938850201979, 0.9222938365489398, 0.853269753017879, 0.871722556491088, 0.837802057406017, 0.9475619059933074]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"precision_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9468968210340906, 0.9478551551034957, 0.9478551551034957, 0.9478551551034957, 0.9478551551034957, 0.9478551551034957, 0.9478551551034957, 0.9478551551034957, 0.9478551551034957, 0.9478551551034957]}], \"balanced_accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"balanced_accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9440819974618796, 0.946639302103166, 0.9194062242836161, 0.880773115188215, 0.8543787713871719, 0.9157448243762556, 0.8605164184930784, 0.8953660921791305, 0.8530220664404912, 0.9449822771563096]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"balanced_accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9440819974618796, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166, 0.946639302103166]}], \"AUC_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"markers\", \"name\": \"AUC_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9904426831775627, 0.990136338190943, 0.9799875631590194, 0.972876537424591, 0.9322069608124774, 0.9798512121204069, 0.9383478538322411, 0.9646233391439191, 0.935293656820452, 0.9901387530932206]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"], \"mode\": \"lines\", \"name\": \"AUC_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627, 0.9904426831775627]}]}, \"metricName\": null, \"primaryMetricName\": \"AUC_weighted\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"experiment_status\", \"run_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"series\": [{\"data\": [\"FeaturesGeneration\", \"DatasetEvaluation\", \"DatasetFeaturization\", \"DatasetFeaturizationCompleted\", \"DatasetCrossValidationSplit\", \"ModelSelection\", \"BestRunExplainModel\", \"ModelExplanationDataSetSetup\", \"EngineeredFeatureExplanations\", \"EngineeredFeatureExplanations\", \"BestRunExplainModel\"]}]}, {\"name\": \"experiment_status_description\", \"run_id\": \"AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"series\": [{\"data\": [\"Gathering dataset statistics.\", \"Generating features for the dataset.\", \"Beginning to fit featurizers and featurize the dataset.\", \"Completed fit featurizers and featurizing the dataset.\", \"Generating individually featurized CV splits.\", \"Beginning model selection.\", \"Best run model explanations started\", \"Model explanations data setup completed\", \"Computation of engineered features started\", \"Computation of engineered features completed\", \"Best run model explanations completed\"]}]}], \"run_logs\": \"\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.3.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-04-20T15:17:33.469605Z',\n",
       " 'endTimeUtc': '2020-04-20T15:21:04.102187Z',\n",
       " 'properties': {'num_iterations': '10',\n",
       "  'training_type': 'TrainFull',\n",
       "  'acquisition_function': 'EI',\n",
       "  'primary_metric': 'AUC_weighted',\n",
       "  'train_split': '0',\n",
       "  'acquisition_parameter': '0',\n",
       "  'num_cross_validation': '5',\n",
       "  'target': 'local',\n",
       "  'RawAMLSettingsString': \"{'name': 'automl-classification', 'path': '.', 'subscription_id': '43c1f93a-903d-4b23-a4bf-92bd7a150627', 'resource_group': 'myResourceGroup4', 'workspace_name': 'machine_learning_workspace4', 'region': 'westeurope', 'compute_target': 'local', 'spark_service': None, 'azure_service': 'local', 'iterations': 10, 'primary_metric': 'AUC_weighted', 'task_type': 'classification', 'data_script': None, 'validation_size': 0.0, 'n_cross_validations': 5, 'y_min': None, 'y_max': None, 'num_classes': 2, 'featurization': 'auto', 'lag_length': 0, 'is_timeseries': False, 'max_cores_per_iteration': -1, 'max_concurrent_iterations': 1, 'iteration_timeout_minutes': 5, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'experiment_timeout_minutes': 15, 'experiment_exit_score': None, 'whitelist_models': None, 'blacklist_algos': ['KNN', 'KNN', 'SVM'], 'supported_models': ['MultinomialNaiveBayes', 'SGD', 'TensorFlowDNN', 'XGBoostClassifier', 'ExtremeRandomTrees', 'LinearSVM', 'KNN', 'LightGBM', 'RandomForest', 'GradientBoosting', 'TensorFlowLinearClassifier', 'LogisticRegression', 'BernoulliNaiveBayes', 'DecisionTree', 'SVM', 'AveragedPerceptronClassifier'], 'auto_blacklist': True, 'blacklist_samples_reached': True, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'automl_errors.log', 'show_warnings': False, 'model_explainability': True, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'enable_onnx_compatible_models': True, 'enable_split_onnx_featurizer_estimator_models': False, 'vm_type': None, 'telemetry_verbosity': 20, 'send_telemetry': True, 'enable_dnn': False, 'force_text_dnn': False, 'enable_feature_sweeping': False, 'enable_early_stopping': True, 'early_stopping_n_iters': 10, 'metrics': None, 'enable_ensembling': True, 'enable_stack_ensembling': False, 'ensemble_iterations': 10, 'enable_tf': False, 'enable_cache': True, 'enable_subsampling': False, 'subsample_seed': None, 'enable_nimbusml': False, 'enable_streaming': False, 'force_streaming': False, 'label_column_name': 'Diabetic', 'weight_column_name': None, 'cost_mode': 1, 'metric_operation': 'maximize', 'preprocess': True, 'scenario': 'SDK'}\",\n",
       "  'AMLSettingsJsonString': '{\"name\": \"automl-classification\", \"path\": \".\", \"subscription_id\": \"43c1f93a-903d-4b23-a4bf-92bd7a150627\", \"resource_group\": \"myResourceGroup4\", \"workspace_name\": \"machine_learning_workspace4\", \"region\": \"westeurope\", \"compute_target\": \"local\", \"spark_service\": null, \"azure_service\": \"local\", \"iterations\": 10, \"primary_metric\": \"AUC_weighted\", \"task_type\": \"classification\", \"data_script\": null, \"validation_size\": 0.0, \"n_cross_validations\": 5, \"y_min\": null, \"y_max\": null, \"num_classes\": 2, \"featurization\": \"auto\", \"lag_length\": 0, \"is_timeseries\": false, \"max_cores_per_iteration\": -1, \"max_concurrent_iterations\": 1, \"iteration_timeout_minutes\": 5, \"mem_in_mb\": null, \"enforce_time_on_windows\": false, \"experiment_timeout_minutes\": 15, \"experiment_exit_score\": null, \"whitelist_models\": null, \"blacklist_algos\": [\"KNN\", \"KNN\", \"SVM\"], \"supported_models\": [\"MultinomialNaiveBayes\", \"SGD\", \"TensorFlowDNN\", \"XGBoostClassifier\", \"ExtremeRandomTrees\", \"LinearSVM\", \"KNN\", \"LightGBM\", \"RandomForest\", \"GradientBoosting\", \"TensorFlowLinearClassifier\", \"LogisticRegression\", \"BernoulliNaiveBayes\", \"DecisionTree\", \"SVM\", \"AveragedPerceptronClassifier\"], \"auto_blacklist\": true, \"blacklist_samples_reached\": true, \"exclude_nan_labels\": true, \"verbosity\": 20, \"debug_log\": \"automl_errors.log\", \"show_warnings\": false, \"model_explainability\": true, \"service_url\": null, \"sdk_url\": null, \"sdk_packages\": null, \"enable_onnx_compatible_models\": true, \"enable_split_onnx_featurizer_estimator_models\": false, \"vm_type\": null, \"telemetry_verbosity\": 20, \"send_telemetry\": true, \"enable_dnn\": false, \"force_text_dnn\": false, \"enable_feature_sweeping\": false, \"enable_early_stopping\": true, \"early_stopping_n_iters\": 10, \"metrics\": null, \"enable_ensembling\": true, \"enable_stack_ensembling\": false, \"ensemble_iterations\": 10, \"enable_tf\": false, \"enable_cache\": true, \"enable_subsampling\": false, \"subsample_seed\": null, \"enable_nimbusml\": false, \"enable_streaming\": false, \"force_streaming\": false, \"label_column_name\": \"Diabetic\", \"weight_column_name\": null, \"cost_mode\": 1, \"metric_operation\": \"maximize\", \"preprocess\": true, \"scenario\": \"SDK\"}',\n",
       "  'DataPrepJsonString': None,\n",
       "  'EnableSubsampling': 'False',\n",
       "  'runTemplate': 'AutoML',\n",
       "  'azureml.runsource': 'automl',\n",
       "  'display_task_type': 'classification',\n",
       "  'dependencies_versions': '{\"azureml-widgets\": \"1.3.0\", \"azureml-train\": \"1.3.0\", \"azureml-train-restclients-hyperdrive\": \"1.3.0\", \"azureml-train-core\": \"1.3.0\", \"azureml-train-automl\": \"1.3.0\", \"azureml-train-automl-runtime\": \"1.3.0\", \"azureml-train-automl-client\": \"1.3.0\", \"azureml-tensorboard\": \"1.0.85\", \"azureml-telemetry\": \"1.3.0\", \"azureml-sdk\": \"1.3.0\", \"azureml-pipeline\": \"1.3.0\", \"azureml-pipeline-steps\": \"1.3.0\", \"azureml-pipeline-core\": \"1.3.0\", \"azureml-opendatasets\": \"1.0.85\", \"azureml-model-management-sdk\": \"1.0.1b6.post1\", \"azureml-interpret\": \"1.3.0\", \"azureml-explain-model\": \"1.3.0\", \"azureml-defaults\": \"1.3.0\", \"azureml-dataprep\": \"1.4.3\", \"azureml-dataprep-native\": \"14.1.0\", \"azureml-datadrift\": \"1.0.85\", \"azureml-core\": \"1.3.0.post1\", \"azureml-contrib-services\": \"1.3.0\", \"azureml-contrib-reinforcementlearning\": \"0.1.0.5919674\", \"azureml-contrib-notebook\": \"1.3.0\", \"azureml-contrib-interpret\": \"1.0.85\", \"azureml-automl-runtime\": \"1.3.0\", \"azureml-automl-core\": \"1.3.0\"}',\n",
       "  'ClientType': 'SDK',\n",
       "  'ClientSdkVersion': '1.3.0',\n",
       "  'environment_cpu_name': '',\n",
       "  'environment_cpu_version': '',\n",
       "  'environment_gpu_name': '',\n",
       "  'environment_gpu_version': '',\n",
       "  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": true, \"subsampling\": false, \"dataset_classes\": 2, \"dataset_features\": 23, \"dataset_samples\": 10000, \"single_frequency_class_detected\": false}',\n",
       "  'feature_skus': 'automatedml_sdk_guardrails',\n",
       "  'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '3b0b9f345b8ba523ffcf9a3cb26aecd0e097d138',\n",
       "  'mlflow.source.git.commit': '3b0b9f345b8ba523ffcf9a3cb26aecd0e097d138',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'logFiles': {}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunDetails(automl_run).show()\n",
    "automl_run.wait_for_completion() # get more parameter info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**option 1:** select any pipeline iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = automl_run.get_output(iteration=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**option 2:** select best pipeline iteration automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = automl_run.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspect model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatransformer\n",
      "MaxAbsScaler\n",
      "LightGBMClassifier\n"
     ]
    }
   ],
   "source": [
    "# pipeline steps\n",
    "for step in fitted_model.named_steps:\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datatransformer': DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
       "         feature_sweeping_config=None, feature_sweeping_timeout=None,\n",
       "         featurization_config=None, force_text_dnn=None,\n",
       "         is_cross_validation=None, is_onnx_compatible=None, logger=None,\n",
       "         observer=None, task=None, working_dir=None),\n",
       " 'MaxAbsScaler': MaxAbsScaler(copy=True),\n",
       " 'LightGBMClassifier': LightGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "           colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
       "           max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n",
       "           min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "           objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "           silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "           subsample_freq=0, verbose=-10)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model properties\n",
    "fitted_model.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall_score_micro': 0.9516,\n",
       " 'confusion_matrix': 'aml://artifactId/ExperimentRun/dcid.AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4_0/confusion_matrix',\n",
       " 'precision_score_weighted': 0.951529651244859,\n",
       " 'accuracy_table': 'aml://artifactId/ExperimentRun/dcid.AutoML_afb6fbc1-05a7-427a-9768-e30de3d147a4_0/accuracy_table',\n",
       " 'log_loss': 0.11810503522790523,\n",
       " 'AUC_micro': 0.9914617,\n",
       " 'average_precision_score_micro': 0.9916787674263302,\n",
       " 'precision_score_micro': 0.9516,\n",
       " 'average_precision_score_weighted': 0.9907832843118888,\n",
       " 'average_precision_score_macro': 0.9885533270268901,\n",
       " 'AUC_macro': 0.9904426831775627,\n",
       " 'f1_score_micro': 0.9516,\n",
       " 'weighted_accuracy': 0.9576144671870581,\n",
       " 'recall_score_weighted': 0.9516,\n",
       " 'f1_score_macro': 0.9454409908953988,\n",
       " 'matthews_correlation': 0.8909693671988277,\n",
       " 'recall_score_macro': 0.9440819974618796,\n",
       " 'norm_macro_recall': 0.8881639949237587,\n",
       " 'accuracy': 0.9516,\n",
       " 'f1_score_weighted': 0.951525872795924,\n",
       " 'precision_score_macro': 0.9468968210340906,\n",
       " 'balanced_accuracy': 0.9440819974618796,\n",
       " 'AUC_weighted': 0.9904426831775627}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all metrics\n",
    "best_run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ExplanationClient.from_run(best_run)\n",
    "engineered_explanations = client.download_model_explanation(raw=False)\n",
    "feature_importance = engineered_explanations.get_feature_importance_dict() # get model feature importance values\n",
    "columns = [\"modelFeatureImportance_name\", \"modelFeatureImportance_value\"]\n",
    "pd.DataFrame(list(feature_importance.items()), columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare\n",
    "\n",
    "autoML generated a scoring script, environment file and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the score and environment files\n",
    "model_name = best_run.properties['model_name'] # score.py script will look for the name of the registered model\n",
    "\n",
    "# make a local copy of the best scoring script, environment file and the model file\n",
    "script_file_name = 'inference/score.py'\n",
    "conda_env_file_name = 'inference/env.yml'\n",
    "model_pickle_file_name = 'inference/model.pkl'\n",
    "model_onnx_file_name = 'inference/model.onnx'\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', script_file_name)\n",
    "best_run.download_file('outputs/conda_env_v_1_0_0.yml', conda_env_file_name)\n",
    "best_run.download_file('outputs/model.pkl', model_pickle_file_name)\n",
    "best_run.download_file('outputs/model.onnx', model_onnx_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\r",
      "\r\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\r",
      "\r\n",
      "\r\n",
      "# Details about the Conda environment file format:\r",
      "\r\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r",
      "\r\n",
      "\r\n",
      "name: project_environment\r\n",
      "dependencies:\r\n",
      "  # The python interpreter version.\r",
      "\r\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\r",
      "\r\n",
      "- python=3.6.2\r\n",
      "\r\n",
      "- pip:\r\n",
      "  - azureml-train-automl-runtime==1.3.0\r\n",
      "  - inference-schema\r\n",
      "  - azureml-explain-model==1.3.0\r\n",
      "  - azureml-defaults==1.3.0\r\n",
      "- numpy>=1.16.0,<=1.16.2\r\n",
      "- pandas>=0.21.0,<=0.23.4\r\n",
      "- scikit-learn>=0.19.0,<=0.20.3\r\n",
      "- py-xgboost<=0.90\r\n",
      "- fbprophet==0.5\r\n",
      "- psutil>=5.2.2,<6.0.0\r\n",
      "channels:\r\n",
      "- anaconda\r\n",
      "- conda-forge\r\n"
     ]
    }
   ],
   "source": [
    "! cat inference/env.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ---------------------------------------------------------\r\n",
      "# Copyright (c) Microsoft Corporation. All rights reserved.\r\n",
      "# ---------------------------------------------------------\r\n",
      "import json\r\n",
      "import pickle\r\n",
      "import numpy as np\r\n",
      "import pandas as pd\r\n",
      "import azureml.train.automl\r\n",
      "from sklearn.externals import joblib\r\n",
      "from azureml.core.model import Model\r\n",
      "\r\n",
      "from inference_schema.schema_decorators import input_schema, output_schema\r\n",
      "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\r\n",
      "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\r\n",
      "\r\n",
      "\r\n",
      "input_sample = pd.DataFrame({'PatientID': pd.Series(['1354778'], dtype='int64'), 'Pregnancies': pd.Series(['0'], dtype='int64'), 'PlasmaGlucose': pd.Series(['171'], dtype='int64'), 'DiastolicBloodPressure': pd.Series(['80'], dtype='int64'), 'TricepsThickness': pd.Series(['34'], dtype='int64'), 'SerumInsulin': pd.Series(['23'], dtype='int64'), 'BMI': pd.Series(['43.50972593'], dtype='float64'), 'DiabetesPedigree': pd.Series(['1.213191354'], dtype='float64'), 'Age': pd.Series(['21'], dtype='int64')})\r\n",
      "output_sample = np.array([0])\r\n",
      "\r\n",
      "\r\n",
      "def init():\r\n",
      "    global model\r\n",
      "    # This name is model.id of model that we want to deploy deserialize the model file back\r\n",
      "    # into a sklearn model\r\n",
      "    model_path = Model.get_model_path(model_name = 'AutoMLafb6fbc100')\r\n",
      "    model = joblib.load(model_path)\r\n",
      "\r\n",
      "\r\n",
      "@input_schema('data', PandasParameterType(input_sample))\r\n",
      "@output_schema(NumpyParameterType(output_sample))\r\n",
      "def run(data):\r\n",
      "    try:\r\n",
      "        result = model.predict(data)\r\n",
      "        return json.dumps({\"result\": result.tolist()})\r\n",
      "    except Exception as e:\r\n",
      "        result = str(e)\r\n",
      "        return json.dumps({\"error\": result})\r\n"
     ]
    }
   ],
   "source": [
    "! cat inference/score.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1:** from workspace /outputs folder with .register_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name=model_name, # registered model name used in scoring script init()\n",
    "                                model_framework=Model.Framework.SCIKITLEARN, # {TensorFlow, ScikitLearn, Onnx, Custom}\n",
    "                                model_framework_version='0.22.2',\n",
    "                                model_path='outputs/model.pkl', # fixed path in workspace {'model.pkl', 'model.onnx'}\n",
    "                                tags={'Training context': 'autoML Training'},\n",
    "                                properties={'AUC': best_run.get_metrics()['AUC_weighted'],\n",
    "                                            'Accuracy': best_run.get_metrics()['accuracy']},\n",
    "                                description=\"Classification model to predict diabetes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2:** from local /path/model folder with Model.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model AutoMLafb6fbc100\n"
     ]
    }
   ],
   "source": [
    "model = Model.register(workspace=ws,\n",
    "                       model_name=model_name, # registered model name used in scoring script init()\n",
    "                       model_framework=Model.Framework.SCIKITLEARN, # {TensorFlow, ScikitLearn, Onnx, Custom}\n",
    "                       model_framework_version='0.22.2',\n",
    "                       model_path='inference/model.pkl', # local file {'model.pkl', 'model.onnx'}\n",
    "                       tags={'Training context': 'autoML Training'},\n",
    "                       properties={'AUC': best_run.get_metrics()['AUC_weighted'],\n",
    "                                   'Accuracy': best_run.get_metrics()['accuracy']},\n",
    "                       description=\"Classification model to predict diabetes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoMLafb6fbc100 version: 1\n",
      "\t Training context : autoML Training\n",
      "\t AUC : 0.9904426831775627\n",
      "\t Accuracy : 0.9516\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list all registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the registered model for deployment (latest version)\n",
    "model = ws.models[model_name] # or replace with any registered modelname from Model.list(ws)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model as webservice (ACI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linux Azure Container Instance with 1 vCPU and 1GB of RAM cost â‚¬28 per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"automl-projname-service\" does not exist, creating the webservice...\n",
      "Running................................................................................................................................................................................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# Configure the scoring environment\n",
    "service_name = \"automl-projname-service\" # only lowercase letters, numbers, or dashes\n",
    "\n",
    "# Remove any existing service under the same name\n",
    "try:\n",
    "    Webservice(ws, service_name).delete()\n",
    "except WebserviceException:\n",
    "    print('\"' + service_name + '\" does not exist, creating the webservice...')\n",
    "\n",
    "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=conda_env_file_name)\n",
    "inference_config = InferenceConfig(entry_script=script_file_name, environment=myenv)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                                       memory_gb=1)\n",
    "\n",
    "# build container from environment, start webservice ACI and deploy inference scrips \n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** load a running webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automl-projname-service\n"
     ]
    }
   ],
   "source": [
    "# list available webservices\n",
    "for i in ws.webservices:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name = \"automl-projname-service\" # only lowercase letters, numbers, or dashes\n",
    "service = Webservice(ws, service_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-20T15:41:59,762511984+00:00 - iot-server/run \n",
      "2020-04-20T15:41:59,761930572+00:00 - gunicorn/run \n",
      "2020-04-20T15:41:59,764030716+00:00 - rsyslog/run \n",
      "2020-04-20T15:41:59,822608762+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_faa7a7b8ebfe27e4f27f49576cf50f1f/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_faa7a7b8ebfe27e4f27f49576cf50f1f/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_faa7a7b8ebfe27e4f27f49576cf50f1f/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_faa7a7b8ebfe27e4f27f49576cf50f1f/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_faa7a7b8ebfe27e4f27f49576cf50f1f/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "rsyslogd: /azureml-envs/azureml_faa7a7b8ebfe27e4f27f49576cf50f1f/lib/libuuid.so.1: no version information available (required by rsyslogd)\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (10)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 26\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-04-20T15:42:02,146419786+00:00 - iot-server/finish 1 0\n",
      "2020-04-20T15:42:02,155929088+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "Users's init has completed successfully\n",
      "Scoring timeout is found from os.environ: 60000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get webservice logs\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webservice inference test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a HTTP triggered webrequest with testdata to the model for a prediction value.  \n",
    "In this example we test a person is diabetic (1) or not-diabetic (0).  \n",
    "The testdata must be a list of 9 features to predict a binary classification.  \n",
    "We demonstrate the use of **service** or **requests** method to send a prediction request.  \n",
    "Know that 'Postman' application or 'Rest Client' plugin in VSCode work as well.  \n",
    "\n",
    "|Web API|Example value|Options|\n",
    "|-|-|-|\n",
    "|**HTTP method**|POST|<i>POST</i><br><i>GET</i>|\n",
    "|**URI**|http://3bb0618b-ef7b-4b17-af32-a52f9c64f4d5.northeurope.azurecontainer.io/score||\n",
    "|**Header**|{Content-Type: Application/json}||\n",
    "|**Body**|{\"data\": [[5, 2, 180, 74, 24, 21, 24, 1.5, 22], <br>[6, 0, 148, 58, 11, 179, 39, 0.16, 45]]}|<i>one or </i><br><i>more records</i>|\n",
    "|**Response**|{\"result\": [1, 0]}|<i>json object</i>|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI: http://a839d171-f3dc-43c3-a1f3-d8ff9b64ae9f.westeurope.azurecontainer.io/score\n",
      "Body: {\"data\": [[5, 2, 180, 74, 24, 21, 24, 1.5, 22], [6, 0, 148, 58, 11, 179, 39, 0.16, 45]]}\n"
     ]
    }
   ],
   "source": [
    "# get webservice URI\n",
    "endpoint = service.scoring_uri\n",
    "\n",
    "# raw test data\n",
    "rawdata = [[5, 2, 180, 74, 24, 21, 24, 1.5, 22],\n",
    "           [6, 0, 148, 58, 11, 179, 39, 0.16, 45]]\n",
    "\n",
    "print(\"URI: \" + endpoint)\n",
    "print(\"Body: \" + json.dumps({\"data\": rawdata})) # convert array to a serialized JSON formatted string object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 1:** service.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"result\": [1, 0]}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.run(json.dumps({\"data\": rawdata}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 2:** requests.post()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"result\": [1, 0]}'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.post(endpoint, json={\"data\": rawdata})\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are finished testing your service, clean up the deployment with service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired from autoML results is an alternative customML development.  \n",
    "Using inline method to test and develop, train local or with remote compute and deploy and test the model.  \n",
    "\n",
    "1. option1: inline method\n",
    "1. option2: script method\n",
    "  * create training script\n",
    "  * create training environment\n",
    "  * creating and register dataset (File)\n",
    "  * train model\n",
    "1. create an inference script\n",
    "1. create an inference environment\n",
    "1. register the model\n",
    "1. deploy the model\n",
    "1. inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Inline method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|log metric function|Description|Example|\n",
    "|-|-|-|\n",
    "|**log**|<i>Record a single named value</i>|run.log(\"accuracy\", 0.95)|\n",
    "|**log_list**|<i>Record a named list of values</i>|run.log_list(\"accuracies\", [0.6, 0.7, 0.87])|\n",
    "|**log_row**|<i>Record a row with multiple columns</i>|run.log_row(\"Y over X\", x=1, y=0.4)|\n",
    "|**log_table**|<i>Record a dictionary as a table</i>|run.log_table(\"Y over X\", {\"x\":[1, 2, 3], \"y\":[0.6, 0.7, 0.89]})|\n",
    "|**log_image**|<i>Record an image file or a plot</i>|run.log_image(\"ROC\", plot=plt)|\n",
    "|**upload_file**|<i>Upload any file to \"./outputs\"</i>|run.upload_file(\"best_model.pkl\", \"./model.pkl\")|\n",
    "\n",
    "https://aka.ms/AA70zf6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: diabetes-training\n",
      "Loading data lake gen2 data in a pandas dataframe...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8873333333333333\n",
      "AUC: 0.8741181153291208\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Model\n",
    "from azureml.core import Datastore\n",
    "from azureml.core import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace=ws, name=\"diabetes-training\")\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "# load the diabetes dataset (File method)\n",
    "print(\"Loading data lake gen2 data in a pandas dataframe...\")\n",
    "ds = Datastore.get(ws, 'datalakestoragegen2')\n",
    "ds_path = [DataPath(ds, 'platinum/diabetes.parquet')] # {path/*.parquet or path/**}\n",
    "dataset = Dataset.File.from_files(path=ds_path)\n",
    "mount_context = dataset.mount(mount_point='/tmp/platinum') # read-only mount from delta lake\n",
    "mount_context.start()\n",
    "diabetes = pd.read_parquet('/tmp/platinum/diabetes.parquet') # {'/tmp/path/'} can load latest delta lake parquet files\n",
    "mount_context.stop()\n",
    "\n",
    "# load the diabetes dataset (Tabular method)\n",
    "# print(\"Loading data lake gen2 data in a pandas dataframe...\")\n",
    "# ds = Datastore.get(ws, 'datalakestoragegen2')\n",
    "# ds_path = [DataPath(ds, 'platinum/diabetes.parquet')] # {path/*.parquet or path/**}\n",
    "# dataset = Dataset.Tabular.from_parquet_files(path=ds_path) # {delimited, json, parquet, sql}\n",
    "# diabetes = dataset.to_pandas_dataframe() # create a pandas dataframe\n",
    "\n",
    "# Separate features and labels as numpy array\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=model, filename=model_file) # backup model local\n",
    "run.upload_file(name='outputs/' + model_file,\n",
    "                path_or_stream='./' + model_file) # save model to workspace\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Script method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_service folder created\n"
     ]
    }
   ],
   "source": [
    "# Create a local folder for the experiment files\n",
    "folder_name = 'diabetes_service'\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "print(folder_name, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./diabetes_service/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import glob\n",
    "print(\"libraries imported...\")\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "print(\"argparse parameters loaded...\")\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "print(\"run context loaded...\")\n",
    "\n",
    "# load the diabetes dataset (File method)\n",
    "# Get the training data from the estimator input identified as 'diabetes'\n",
    "mount = run.input_datasets['diabetes'] # read-only mount from delta lake as '/mnt/data'\n",
    "print(\"delta lake mounted...\")\n",
    "diabetes = pd.read_parquet('/mnt/data/diabetes.parquet') # load any file(s) from this delta lake mounted folder\n",
    "print(\"dataset loaded...\")\n",
    "\n",
    "# save data into workspace\n",
    "diabetes.to_csv(\"outputs/dataset.csv\", index=False) # {logs/  outputs/}\n",
    "print(\"test: write dataset to workspace 'outputs/dataset.csv'\")\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": true,\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"training_environment\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults\",\n",
       "                        \"azureml-dataprep[pandas,fuse]\",\n",
       "                        \"pyarrow\",\n",
       "                        \"fastparquet\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn\",\n",
       "                \"joblib\"\n",
       "            ],\n",
       "            \"name\": \"azureml_b9a1534962684a800c586e9fce04292e\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myenv = Environment(\"training_environment\")\n",
    "myenv.docker.enabled = True\n",
    "myenv.python.user_managed_dependencies = False\n",
    "conda_packages = ['scikit-learn', 'joblib', 'python==3.6.2']\n",
    "pip_packages = ['azureml-defaults', 'azureml-dataprep[pandas,fuse]', 'pyarrow', 'fastparquet']\n",
    "myenv.python.conda_dependencies = CondaDependencies.create(conda_packages=conda_packages, pip_packages=pip_packages)\n",
    "myenv.register(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: training_environment\n",
      "Name: AzureML-Tutorial\n",
      "Name: AzureML-Minimal\n",
      "Name: AzureML-Chainer-5.1.0-GPU\n",
      "Name: AzureML-PyTorch-1.2-CPU\n",
      "Name: AzureML-TensorFlow-1.12-CPU\n",
      "Name: AzureML-TensorFlow-1.13-CPU\n",
      "Name: AzureML-PyTorch-1.1-CPU\n",
      "Name: AzureML-TensorFlow-1.10-CPU\n",
      "Name: AzureML-PyTorch-1.0-GPU\n",
      "Name: AzureML-TensorFlow-1.12-GPU\n",
      "Name: AzureML-TensorFlow-1.13-GPU\n",
      "Name: AzureML-Chainer-5.1.0-CPU\n",
      "Name: AzureML-PyTorch-1.0-CPU\n",
      "Name: AzureML-Scikit-learn-0.20.3\n",
      "Name: AzureML-PyTorch-1.2-GPU\n",
      "Name: AzureML-PyTorch-1.1-GPU\n",
      "Name: AzureML-TensorFlow-1.10-GPU\n",
      "Name: AzureML-PyTorch-1.3-GPU\n",
      "Name: AzureML-TensorFlow-2.0-CPU\n",
      "Name: AzureML-PyTorch-1.3-CPU\n",
      "Name: AzureML-TensorFlow-2.0-GPU\n",
      "Name: AzureML-PySpark-MmlSpark-0.15\n",
      "Name: AzureML-AutoML\n",
      "Name: AzureML-PyTorch-1.4-GPU\n",
      "Name: AzureML-PyTorch-1.4-CPU\n",
      "Name: AzureML-VowpalWabbit-8.8.0\n",
      "Name: AzureML-Hyperdrive-ForecastDNN\n",
      "Name: AzureML-AutoML-GPU\n",
      "Name: AzureML-AutoML-DNN-GPU\n",
      "Name: AzureML-AutoML-DNN\n",
      "Name: AzureML-Designer-R\n",
      "Name: AzureML-Designer-Recommender\n",
      "Name: AzureML-Designer-Transform\n",
      "Name: AzureML-Designer\n",
      "Name: AzureML-Designer-IO\n",
      "Name: AzureML-Designer-NLP\n",
      "Name: AzureML-Dask-CPU\n",
      "Name: AzureML-Dask-GPU\n"
     ]
    }
   ],
   "source": [
    "# list environments\n",
    "env_names = Environment.list(workspace=ws)\n",
    "for env_name in env_names:\n",
    "    print('Name:',env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and register dataset (File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset registered\n"
     ]
    }
   ],
   "source": [
    "# load the diabetes dataset (File method)\n",
    "ds = Datastore.get(ws, 'datalakestoragegen2')\n",
    "ds_path = [DataPath(ds, 'platinum/**')] # {path/*.parquet or path/**}\n",
    "file_ds = Dataset.File.from_files(path=ds_path)\n",
    "   \n",
    "# Register the file dataset\n",
    "try:\n",
    "    file_ds = file_ds.register(workspace=ws,\n",
    "                               name='diabetes file dataset',\n",
    "                               description='diabetes files',\n",
    "                               tags = {'format':'parquet'},\n",
    "                               create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "print('Dataset registered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "\t diabetes file dataset \t version 1\n"
     ]
    }
   ],
   "source": [
    "# show a list of registered dataset(s)\n",
    "print(\"Datasets:\")\n",
    "for dataset_name in list(ws.datasets.keys()):\n",
    "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
    "    print(\"\\t\", dataset.name, '\\t version', dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/diabetes.parquet\n"
     ]
    }
   ],
   "source": [
    "# list of the file path(s)\n",
    "for file_path in file_ds.to_path():\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed7024e7d82463691d62b6286ca6ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Preparing\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-training/runs/diabetes-training_1587397611_097b5668?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup4/workspaces/machine_learning_workspace4\", \"run_id\": \"diabetes-training_1587397611_097b5668\", \"run_properties\": {\"run_id\": \"diabetes-training_1587397611_097b5668\", \"created_utc\": \"2020-04-20T15:46:52.671276Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"97af77b5-9a08-4d94-a47f-e81d6b5f8a8c\", \"azureml.git.repository_uri\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"mlflow.source.git.repoURL\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"3b0b9f345b8ba523ffcf9a3cb26aecd0e097d138\", \"mlflow.source.git.commit\": \"3b0b9f345b8ba523ffcf9a3cb26aecd0e097d138\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Preparing\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1587397611_097b5668/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=lfHtDxN3YvrGO8GV1eeT2DDCglUSHCKBBlnr7Rc%2FtgQ%3D&st=2020-04-20T15%3A41%3A59Z&se=2020-04-20T23%3A51%3A59Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/60_control_log.txt\"]], \"run_duration\": \"0:05:06\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"Streaming log file azureml-logs/60_control_log.txt\\nStarting the daemon thread to refresh tokens in background for process with pid = 5710\\nRunning: ['/bin/bash', '/tmp/azureml_runs/diabetes-training_1587397611_097b5668/azureml-environment-setup/docker_env_checker.sh']\\n\\nMaterialized image not found on target: azureml/azureml_cd18bf124e93ff30565b12ff728f0435\\n\\n\\nLogging experiment preparation status in history service.\\nRunning: ['/bin/bash', '/tmp/azureml_runs/diabetes-training_1587397611_097b5668/azureml-environment-setup/docker_env_builder.sh']\\nRunning: ['sudo', 'docker', 'build', '-f', 'azureml-environment-setup/Dockerfile', '-t', 'azureml/azureml_cd18bf124e93ff30565b12ff728f0435', '.']\\nSending build context to Docker daemon  436.7kB\\nStep 1/15 : FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\\nsha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05: Pulling from azureml/base\\na1298f4ce990: Pulling fs layer\\n04a3282d9c4b: Pulling fs layer\\n9b0d3db6dc03: Pulling fs layer\\n8269c605f3f1: Pulling fs layer\\n6504d449e70c: Pulling fs layer\\n4e38f320d0d4: Pulling fs layer\\nb0a763e8ee03: Pulling fs layer\\n11917a028ca4: Pulling fs layer\\na6c378d11cbf: Pulling fs layer\\n6cc007ad9140: Pulling fs layer\\n6c1698a608f3: Pulling fs layer\\n6504d449e70c: Waiting\\n4e38f320d0d4: Waiting\\nb0a763e8ee03: Waiting\\n11917a028ca4: Waiting\\n8269c605f3f1: Waiting\\na6c378d11cbf: Waiting\\n6cc007ad9140: Waiting\\n6c1698a608f3: Waiting\\n9b0d3db6dc03: Verifying Checksum\\n9b0d3db6dc03: Download complete\\n04a3282d9c4b: Verifying Checksum\\n04a3282d9c4b: Download complete\\n8269c605f3f1: Verifying Checksum\\n8269c605f3f1: Download complete\\na1298f4ce990: Verifying Checksum\\na1298f4ce990: Download complete\\n4e38f320d0d4: Verifying Checksum\\n4e38f320d0d4: Download complete\\n6504d449e70c: Verifying Checksum\\n6504d449e70c: Download complete\\n11917a028ca4: Verifying Checksum\\n11917a028ca4: Download complete\\n6cc007ad9140: Verifying Checksum\\n6cc007ad9140: Download complete\\nb0a763e8ee03: Verifying Checksum\\nb0a763e8ee03: Download complete\\n6c1698a608f3: Verifying Checksum\\n6c1698a608f3: Download complete\\na6c378d11cbf: Verifying Checksum\\na6c378d11cbf: Download complete\\na1298f4ce990: Pull complete\\n04a3282d9c4b: Pull complete\\n9b0d3db6dc03: Pull complete\\n8269c605f3f1: Pull complete\\n6504d449e70c: Pull complete\\n4e38f320d0d4: Pull complete\\nb0a763e8ee03: Pull complete\\n11917a028ca4: Pull complete\\na6c378d11cbf: Pull complete\\n6cc007ad9140: Pull complete\\n6c1698a608f3: Pull complete\\nDigest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\\n ---> 93a72e6bd1ce\\nStep 2/15 : USER root\\n ---> Running in e04dc43c0bf9\\nRemoving intermediate container e04dc43c0bf9\\n ---> 5d775bece192\\nStep 3/15 : RUN mkdir -p $HOME/.cache\\n ---> Running in e936cc8a87ce\\nRemoving intermediate container e936cc8a87ce\\n ---> 69b2aa356c32\\nStep 4/15 : WORKDIR /\\n ---> Running in a68e9dd17879\\nRemoving intermediate container a68e9dd17879\\n ---> ea3f239c8e40\\nStep 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\\n ---> 66f22b3b63f1\\nStep 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\\n ---> Running in eee9e3398046\\nRemoving intermediate container eee9e3398046\\n ---> daebe9e934fc\\nStep 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\\n ---> 4c7cf1e4313f\\nStep 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \\\"$HOME/.cache/pip\\\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \\\"$CONDA_ROOT_DIR/pkgs\\\" && find \\\"$CONDA_ROOT_DIR\\\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\\n ---> Running in f19058630fc2\\nSolving environment: ...working... done\\n\\u001b[91m\\n\\n==> WARNING: A newer version of conda exists. <==\\n  current version: 4.5.11\\n  latest version: 4.8.3\\n\\nPlease update conda by running\\n\\n    $ conda update -n base -c defaults conda\\n\\n\\nmkl_fft-1.0.15       | 173 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\nmkl-2019.5           | 205.3 MB  | ########## | 100% \\u001b[0m\\u001b[91m\\nncurses-6.0          | 907 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\nlibstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\nsix-1.14.0           | 27 KB     | ########## | 100% \\u001b[0m\\u001b[91m\\nzlib-1.2.11          | 120 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\nlibgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\nopenssl-1.0.2u       | 3.1 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\nreadline-7.0         | 387 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\nintel-openmp-2020.0  | 916 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\nxz-5.2.4             | 366 KB    | ########## | 100% \\npip-20.0.2           | 1.9 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\ntk-8.6.8             | 3.1 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\nmkl_random-1.1.0     | 369 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\nscipy-1.4.1          | 18.9 MB   | ########## | 100% \\nscikit-learn-0.22.1  | 7.1 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\nsetuptools-46.1.3    | 663 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\nblas-1.0             | 6 KB      | ########## | 100% \\u001b[0m\\u001b[91m\\nmkl-service-2.3.0    | 208 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\nlibgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\nlibffi-3.2.1         | 43 KB     | ########## | 100% \\u001b[0m\\u001b[91m\\ncertifi-2020.4.5.1   | 159 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\npython-3.6.2         | 27.0 MB   | ########## | 100% \\u001b[0m\\u001b[91m\\nca-certificates-2020 | 132 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\nlibedit-3.1          | 171 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\njoblib-0.14.1        | 202 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\nsqlite-3.23.1        | 1.5 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\nwheel-0.34.2         | 49 KB     | ########## | 100% \\nnumpy-1.18.1         | 5 KB      | ########## | 100% \\u001b[0m\\u001b[91m\\nnumpy-base-1.18.1    | 5.2 MB    | ########## | 100% \\u001b[0m\\nDownloading and Extracting Packages\\nPreparing transaction: ...working... done\\nVerifying transaction: ...working... done\\nExecuting transaction: ...working... done\\nCollecting azureml-defaults\\n  Downloading azureml_defaults-1.3.0-py3-none-any.whl (3.0 kB)\\nCollecting azureml-dataprep[fuse,pandas]\\n  Downloading azureml_dataprep-1.4.6-py3-none-any.whl (26.7 MB)\\nCollecting pyarrow\\n  Downloading pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1 MB)\\nCollecting fastparquet\\n  Downloading fastparquet-0.3.3.tar.gz (152 kB)\\nCollecting applicationinsights>=0.11.7\\n  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\\nCollecting werkzeug==0.16.1\\n  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\\nCollecting json-logging-py==0.2\\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\\nCollecting azureml-core~=1.3.0\\n  Downloading azureml_core-1.3.0.post1-py3-none-any.whl (1.2 MB)\\nCollecting gunicorn==19.9.0\\n  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\\nCollecting azureml-model-management-sdk==1.0.1b6.post1\\n  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\\nCollecting flask==1.0.3\\n  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\\nCollecting configparser==3.7.4\\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\\nCollecting azureml-dataprep-native<15.0.0,>=14.1.0\\n  Downloading azureml_dataprep_native-14.1.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\\nCollecting azure-identity<1.3.0,>=1.2.0\\n  Downloading azure_identity-1.2.0-py2.py3-none-any.whl (58 kB)\\nCollecting dotnetcore2>=2.1.13\\n  Downloading dotnetcore2-2.1.13-py3-none-manylinux1_x86_64.whl (29.3 MB)\\nCollecting cloudpickle>=1.1.0\\n  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\\nCollecting fusepy>=3.0.1; extra == \\\"fuse\\\"\\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\\nCollecting pandas>=0.23.4; extra == \\\"pandas\\\"\\n  Downloading pandas-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (10.0 MB)\\nRequirement already satisfied: numpy>=1.14.0; extra == \\\"pandas\\\" in /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e/lib/python3.6/site-packages (from azureml-dataprep[fuse,pandas]->-r /azureml-environment-setup/condaenv.udewa_pg.requirements.txt (line 2)) (1.18.1)\\nRequirement already satisfied: six>=1.0.0 in /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e/lib/python3.6/site-packages (from pyarrow->-r /azureml-environment-setup/condaenv.udewa_pg.requirements.txt (line 3)) (1.14.0)\\nCollecting numba>=0.28\\n  Downloading numba-0.49.0-cp36-cp36m-manylinux2014_x86_64.whl (3.6 MB)\\nCollecting thrift>=0.11.0\\n  Downloading thrift-0.13.0.tar.gz (59 kB)\\nCollecting msrest>=0.5.1\\n  Downloading msrest-0.6.13-py2.py3-none-any.whl (83 kB)\\nCollecting azure-common>=1.1.12\\n  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\\nCollecting msrestazure>=0.4.33\\n  Downloading msrestazure-0.6.3-py2.py3-none-any.whl (40 kB)\\nCollecting python-dateutil>=2.7.3\\n  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\\nCollecting pathspec\\n  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\\nCollecting ruamel.yaml<=0.15.89,>=0.15.35\\n  Downloading ruamel.yaml-0.15.89-cp36-cp36m-manylinux1_x86_64.whl (651 kB)\\nCollecting SecretStorage\\n  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\\nCollecting azure-graphrbac>=0.40.0\\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\\nCollecting contextlib2\\n  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\\nCollecting docker\\n  Downloading docker-4.2.0-py2.py3-none-any.whl (143 kB)\\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\\n  Downloading cryptography-2.9-cp35-abi3-manylinux2010_x86_64.whl (2.7 MB)\\nCollecting urllib3>=1.23\\n  Downloading urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\\nCollecting azure-mgmt-authorization>=0.40.0\\n  Downloading azure_mgmt_authorization-0.60.0-py2.py3-none-any.whl (82 kB)\\nCollecting ndg-httpsclient\\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\\nCollecting azure-mgmt-keyvault>=0.40.0\\n  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\\nCollecting adal>=1.2.0\\n  Downloading adal-1.2.2-py2.py3-none-any.whl (53 kB)\\nCollecting pytz\\n  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)\\nCollecting azure-mgmt-resource<9.0.0,>=1.2.1\\n  Downloading azure_mgmt_resource-8.0.1-py2.py3-none-any.whl (758 kB)\\nCollecting requests>=2.19.1\\n  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\\nCollecting backports.tempfile\\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\\nCollecting jsonpickle\\n  Downloading jsonpickle-1.4-py2.py3-none-any.whl (36 kB)\\nCollecting pyopenssl\\n  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\\nCollecting PyJWT\\n  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\\nCollecting azure-mgmt-storage>=1.5.0\\n  Downloading azure_mgmt_storage-9.0.0-py2.py3-none-any.whl (525 kB)\\nCollecting azure-mgmt-containerregistry>=2.0.0\\n  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\\nCollecting jmespath\\n  Downloading jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\\nCollecting liac-arff>=2.1.1\\n  Downloading liac-arff-2.4.0.tar.gz (15 kB)\\nCollecting dill>=0.2.7.1\\n  Downloading dill-0.3.1.1.tar.gz (151 kB)\\nCollecting click>=5.1\\n  Downloading click-7.1.1-py2.py3-none-any.whl (82 kB)\\nCollecting itsdangerous>=0.24\\n  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\\nCollecting Jinja2>=2.10\\n  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\\nCollecting azure-core<2.0.0,>=1.0.0\\n  Downloading azure_core-1.4.0-py2.py3-none-any.whl (114 kB)\\nCollecting msal<2.0.0,>=1.0.0\\n  Downloading msal-1.2.0-py2.py3-none-any.whl (46 kB)\\nCollecting msal-extensions~=0.1.3\\n  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\\nCollecting distro>=1.2.0\\n  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\\nRequirement already satisfied: setuptools in /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e/lib/python3.6/site-packages (from numba>=0.28->fastparquet->-r /azureml-environment-setup/condaenv.udewa_pg.requirements.txt (line 4)) (46.1.3.post20200330)\\nCollecting llvmlite<=0.33.0.dev0,>=0.31.0.dev0\\n  Downloading llvmlite-0.32.0-cp36-cp36m-manylinux1_x86_64.whl (20.2 MB)\\nCollecting requests-oauthlib>=0.5.0\\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core~=1.3.0->azureml-defaults->-r /azureml-environment-setup/condaenv.udewa_pg.requirements.txt (line 1)) (2020.4.5.1)\\nCollecting isodate>=0.6.0\\n  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\\nCollecting jeepney>=0.4.2\\n  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\\nCollecting websocket-client>=0.32.0\\n  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\\nCollecting cffi!=1.11.3,>=1.8\\n  Downloading cffi-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (399 kB)\\nCollecting pyasn1>=0.1.1\\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\\nCollecting chardet<4,>=3.0.2\\n  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\\nCollecting idna<3,>=2.5\\n  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\\nCollecting backports.weakref\\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\\nCollecting importlib-metadata\\n  Downloading importlib_metadata-1.6.0-py2.py3-none-any.whl (30 kB)\\nCollecting MarkupSafe>=0.23\\n  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\\nCollecting portalocker~=1.0\\n  Downloading portalocker-1.7.0-py2.py3-none-any.whl (14 kB)\\nCollecting oauthlib>=3.0.0\\n  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\\nCollecting pycparser\\n  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\\nCollecting zipp>=0.5\\n  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\\nBuilding wheels for collected packages: fastparquet, json-logging-py, fusepy, thrift, liac-arff, dill\\n  Building wheel for fastparquet (setup.py): started\\n  Building wheel for fastparquet (setup.py): finished with status 'done'\\n  Created wheel for fastparquet: filename=fastparquet-0.3.3-cp36-cp36m-linux_x86_64.whl size=258176 sha256=a42b6dcc3284dc85c10cabf6e81ccb5e2a6cad4143c72ffe71da910104ea0c0e\\n  Stored in directory: /root/.cache/pip/wheels/17/0b/fe/81b4ce36e4b0abb7220e29ea450ac345efb6219b9ac888e5c9\\n  Building wheel for json-logging-py (setup.py): started\\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3923 sha256=f0a6a5a80520b263996b595bd3fdefefb6348756854f73a2bca86f160fcb5ddb\\n  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\\n  Building wheel for fusepy (setup.py): started\\n  Building wheel for fusepy (setup.py): finished with status 'done'\\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=c9ff0d20d493113012967f0ba5fe527cc8e9be856cca7f7ac0965bf71140a9d4\\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\\n  Building wheel for thrift (setup.py): started\\n  Building wheel for thrift (setup.py): finished with status 'done'\\n  Created wheel for thrift: filename=thrift-0.13.0-cp36-cp36m-linux_x86_64.whl size=371597 sha256=ecae4f1fd26414adb0f0efdf15656a744e55ce3396163c0328ad26b3691b11c6\\n  Stored in directory: /root/.cache/pip/wheels/e0/38/fc/472fe18756b177b42096961f8bd3ff2dc5c5620ac399fce52d\\n  Building wheel for liac-arff (setup.py): started\\n  Building wheel for liac-arff (setup.py): finished with status 'done'\\n  Created wheel for liac-arff: filename=liac_arff-2.4.0-py3-none-any.whl size=13333 sha256=37571649cf592066ade7a4eb178fb5abd1207e6df042d8ad2d1f587475891eff\\n  Stored in directory: /root/.cache/pip/wheels/ba/2a/e1/6f7be2e2ea150e2486bff64fd6f0670f4f35f4c8f31c819fb8\\n  Building wheel for dill (setup.py): started\\n  Building wheel for dill (setup.py): finished with status 'done'\\n  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=f5c49f28ae909fcf089ef5a5e096dfe156124b2f2004c57ed29d53bbf7e6815a\\n  Stored in directory: /root/.cache/pip/wheels/09/84/74/d2b4feb9ac9488bc83c475cb2cbe8e8b7d9cea8320d32f3787\\nSuccessfully built fastparquet json-logging-py fusepy thrift liac-arff dill\\n\\u001b[91mERROR: azureml-defaults 1.3.0 has requirement azureml-dataprep[fuse]<1.4.5a,>=1.4.3a, but you'll have azureml-dataprep 1.4.6 which is incompatible.\\n\\u001b[0mInstalling collected packages: applicationinsights, werkzeug, json-logging-py, oauthlib, chardet, idna, urllib3, requests, requests-oauthlib, isodate, msrest, azure-common, pycparser, cffi, cryptography, python-dateutil, PyJWT, adal, msrestazure, pathspec, ruamel.yaml, jeepney, SecretStorage, azure-graphrbac, contextlib2, websocket-client, docker, azure-mgmt-authorization, pyopenssl, pyasn1, ndg-httpsclient, azure-mgmt-keyvault, pytz, azure-mgmt-resource, backports.weakref, backports.tempfile, zipp, importlib-metadata, jsonpickle, azure-mgmt-storage, azure-mgmt-containerregistry, jmespath, azureml-core, gunicorn, liac-arff, dill, pandas, azureml-model-management-sdk, azureml-dataprep-native, azure-core, msal, portalocker, msal-extensions, azure-identity, distro, dotnetcore2, cloudpickle, fusepy, pyarrow, azureml-dataprep, click, itsdangerous, MarkupSafe, Jinja2, flask, configparser, azureml-defaults, llvmlite, numba, thrift, fastparquet\\nSuccessfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.1.2 adal-1.2.2 applicationinsights-0.11.9 azure-common-1.1.25 azure-core-1.4.0 azure-graphrbac-0.61.1 azure-identity-1.2.0 azure-mgmt-authorization-0.60.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-8.0.1 azure-mgmt-storage-9.0.0 azureml-core-1.3.0.post1 azureml-dataprep-1.4.6 azureml-dataprep-native-14.1.0 azureml-defaults-1.3.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.0 chardet-3.0.4 click-7.1.1 cloudpickle-1.3.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-2.9 dill-0.3.1.1 distro-1.5.0 docker-4.2.0 dotnetcore2-2.1.13 fastparquet-0.3.3 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.9 importlib-metadata-1.6.0 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.4.3 jmespath-0.9.5 json-logging-py-0.2 jsonpickle-1.4 liac-arff-2.4.0 llvmlite-0.32.0 msal-1.2.0 msal-extensions-0.1.3 msrest-0.6.13 msrestazure-0.6.3 ndg-httpsclient-0.5.1 numba-0.49.0 oauthlib-3.1.0 pandas-1.0.3 pathspec-0.8.0 portalocker-1.7.0 pyarrow-0.16.0 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 python-dateutil-2.8.1 pytz-2019.3 requests-2.23.0 requests-oauthlib-1.3.0 ruamel.yaml-0.15.89 thrift-0.13.0 urllib3-1.25.9 websocket-client-0.57.0 werkzeug-0.16.1 zipp-3.1.0\\n\\u001b[91m\\n\\u001b[0m#\\n# To activate this environment, use:\\n# > source activate /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e\\n#\\n# To deactivate an active environment, use:\\n# > source deactivate\\n#\\n\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.3.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'diabetes-training_1587397611_097b5668',\n",
       " 'target': 'local',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2020-04-20T15:53:22.844143Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '97af77b5-9a08-4d94-a47f-e81d6b5f8a8c',\n",
       "  'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '3b0b9f345b8ba523ffcf9a3cb26aecd0e097d138',\n",
       "  'mlflow.source.git.commit': '3b0b9f345b8ba523ffcf9a3cb26aecd0e097d138',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [{'dataset': {'id': '642bff52-df41-4dd7-a6b7-353d164ed1ab'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes', 'mechanism': 'Mount', 'pathOnCompute': '/mnt/data'}}],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization', '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'diabetes': {'dataLocation': {'dataset': {'id': '642bff52-df41-4dd7-a6b7-353d164ed1ab'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'diabetes',\n",
       "    'pathOnCompute': '/mnt/data',\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'training_environment',\n",
       "   'version': '1',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'azureml-dataprep[pandas,fuse]',\n",
       "        'pyarrow',\n",
       "        'fastparquet']},\n",
       "      'scikit-learn',\n",
       "      'joblib'],\n",
       "     'name': 'azureml_b9a1534962684a800c586e9fce04292e'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1587397611_097b5668/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=z924GVBZuHh94hU0XU92lZ1glcewmHSNl5d2bhryvyU%3D&st=2020-04-20T15%3A43%3A42Z&se=2020-04-20T23%3A53%3A42Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1587397611_097b5668/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=41PPZDQWfGtyKdnjTehEHcqh4hrVijrfe8JWT%2FJY9bo%3D&st=2020-04-20T15%3A43%3A42Z&se=2020-04-20T23%3A53%3A42Z&sp=r',\n",
       "  'logs/azureml/8_azureml.log': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1587397611_097b5668/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=Zws5r1XS504fgimI9q2vviGmdzXHHRZIAjo37QI7WIM%3D&st=2020-04-20T15%3A43%3A42Z&se=2020-04-20T23%3A53%3A42Z&sp=r'}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the script parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1\n",
    "}\n",
    "\n",
    "# load the registered dataset by name\n",
    "file_ds = Dataset.get_by_name(ws, \"diabetes file dataset\")\n",
    "\n",
    "# load the docker environment\n",
    "training_env = Environment.get(ws, 'training_environment')\n",
    "\n",
    "# load the training compute cluster\n",
    "training_cluster = ComputeTarget(ws, 'aml-cluster')\n",
    "\n",
    "estimator = Estimator(source_directory=experiment_folder, # All the files in this directory are uploaded into the cluster nodes for execution\n",
    "                      compute_target='local', # {'local', training_cluster}\n",
    "                      entry_script='diabetes_training.py',\n",
    "                      script_params=script_params,\n",
    "                      environment_definition=training_env,\n",
    "                      inputs=[file_ds.as_named_input('diabetes').as_mount(path_on_compute='/mnt/data')],\n",
    "                     )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'diabetes-training'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion() # get more parameter info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inference script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_service folder created\n"
     ]
    }
   ],
   "source": [
    "# Create a local folder for the experiment files\n",
    "folder_name = 'diabetes_service'\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "print(folder_name, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_service/diabetes_score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $folder_name/diabetes_score.py\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load a registered model\n",
    "    model_path = Model.get_model_path(model_name='diabetes_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-diabetic', 'diabetic']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inference environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved inference environment file in diabetes_service/diabetes_env.yml\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = folder_name + \"/diabetes_env.yml\"\n",
    "with open(env_file, \"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved inference environment file in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and registered\n"
     ]
    }
   ],
   "source": [
    "# define model name\n",
    "model_name = 'diabetes_model'\n",
    "\n",
    "# register model from the workspace \n",
    "run.register_model(model_name=model_name, # registered model name used in scoring script init()\n",
    "                   model_path='outputs/diabetes_model.pkl', # fixed path in workspace {'model.pkl', 'model.onnx'}\n",
    "                   tags={'Training context': 'Custom Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'],\n",
    "                               'Accuracy': run.get_metrics()['Accuracy']},\n",
    "                   description=\"Classification model to predict diabetes\",\n",
    "                   model_framework=Model.Framework.SCIKITLEARN, # {TensorFlow, ScikitLearn, Onnx, Custom}\n",
    "                   model_framework_version='0.22.2')\n",
    "\n",
    "print('Model trained and registered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"diabetes-service\" does not exist, creating the webservice...\n",
      "Running...........................................................................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "service_name = \"diabetes-service\"\n",
    "\n",
    "# Remove any existing service under the same name\n",
    "try:\n",
    "    Webservice(ws, service_name).delete()\n",
    "except WebserviceException:\n",
    "    print('\"' + service_name + '\" does not exist, creating the webservice...')\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime=\"python\",\n",
    "                                   source_directory=folder_name,\n",
    "                                   entry_script=\"diabetes_score.py\",\n",
    "                                   conda_file=\"diabetes_env.yml\")\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                                       memory_gb=1)\n",
    "\n",
    "# load the registered model\n",
    "model = ws.models['diabetes_model']\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI: http://712a95c4-9b83-46f8-8600-01befdb4da0f.westeurope.azurecontainer.io/score\n",
      "Body: {\"data\": [[9, 103, 78, 25, 304, 29.6, 1.28, 43], [0, 148, 58, 11, 179, 39, 0.16, 45]]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\"diabetic\", \"not-diabetic\"]'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get webservice URI\n",
    "endpoint = service.scoring_uri\n",
    "\n",
    "# raw test data\n",
    "rawdata = [[9, 103, 78, 25, 304, 29.6, 1.28, 43],\n",
    "           [0, 148, 58, 11, 179, 39, 0.16, 45]]\n",
    "\n",
    "print(\"URI: \" + endpoint)\n",
    "print(\"Body: \" + json.dumps({\"data\": rawdata})) # convert array to a serialized JSON formatted string object\n",
    "\n",
    "service.run(json.dumps({\"data\": rawdata}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are finished testing your service, clean up the deployment with service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning of the model using HyperDrive.  \n",
    "Hyperdrive runs enable comparison for metrics on all different hyper parameter combinations tried.  \n",
    "\n",
    "[doc: how to tune hyperparameters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)  \n",
    "[git: examples](https://github.com/microsoft/MLHyperparameterTuning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AmlCompute\n",
    "training_cluster = ComputeTarget(ws, 'aml-cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a project directory\n",
    "project_folder = './diabetes_hyperdrive'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment folder\n",
    "experiment_folder = './' + project_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ././diabetes_hyperdrive/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import glob\n",
    "print(\"libraries imported...\")\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "print(\"run context loaded...\")\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "parser.add_argument('--C', type=float, default=1.0, help='Inverse of regularization strength')\n",
    "parser.add_argument('--solver', type=str, default='lbfgs', help='Algorithm to use in the optimization problem')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "run.log('Inverse of regularization strength', np.float(args.C))\n",
    "run.log('Algorithm to use in the optimization problem', np.str(args.solver))\n",
    "print(\"argparse parameters loaded...\")\n",
    "\n",
    "# load the diabetes dataset (File method)\n",
    "# Get the training data from the estimator input identified as 'diabetes'\n",
    "mount = run.input_datasets['diabetes'] # read-only mount from delta lake as '/mnt/data'\n",
    "print(\"delta lake mounted...\")\n",
    "diabetes = pd.read_parquet('/mnt/data/diabetes.parquet') # load any file(s) from this delta lake mounted folder\n",
    "print(\"dataset loaded...\")\n",
    "\n",
    "# save data into workspace\n",
    "diabetes.to_csv(\"outputs/dataset.csv\", index=False) # {logs/  outputs/}\n",
    "print(\"test: write dataset to workspace 'outputs/dataset.csv'\")\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=args.C, solver=args.solver).fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment name\n",
    "experiment = Experiment(ws, 'diabetes-hyperdrive-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Scikit-learn estimator\n",
    "\n",
    "# get the training compute cluster\n",
    "training_cluster = ComputeTarget(ws, 'aml-cluster')\n",
    "\n",
    "# Set the script parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1,\n",
    "    '--C': 10,\n",
    "    '--solver': 'lbfgs',\n",
    "}\n",
    "\n",
    "# Get the docker environment\n",
    "training_env = Environment.get(ws, 'training_environment')\n",
    "\n",
    "# get the registered dataset by name\n",
    "file_ds = Dataset.get_by_name(ws, \"diabetes file dataset\")\n",
    "\n",
    "estimator = Estimator(source_directory=experiment_folder, # All the files in this directory are uploaded into the cluster nodes for execution\n",
    "                      compute_target=training_cluster, # only compute allowed for hyperparameter tuning\n",
    "                      entry_script='diabetes_training.py',\n",
    "                      script_params=script_params,\n",
    "                      environment_definition=training_env,\n",
    "                      inputs=[file_ds.as_named_input('diabetes').as_mount(path_on_compute='/mnt/data')],\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameter space\n",
    "\n",
    "param_sampling = RandomParameterSampling( {\n",
    "    '--regularization': choice(1, 0.333, 0.1, 0.033),\n",
    "    '--C': choice(1, 3, 10, 30),\n",
    "    '--solver': choice('lbfgs', 'liblinear', 'newton-cg', 'lbfgs', 'sag'),\n",
    "    } )\n",
    "\n",
    "hyperdrive_run_config = HyperDriveConfig(estimator=estimator,\n",
    "                                         hyperparameter_sampling=param_sampling,\n",
    "                                         primary_metric_name='Accuracy',\n",
    "                                         primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                         max_total_runs=20,   # 20 = reg x C x solver = 4 x 4 x 5 script uses C + solver = 20\n",
    "                                         max_concurrent_runs=5,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the HyperDrive experiment run (~25')\n",
    "hyperdrive_run = experiment.submit(config=hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a3b2c10ff84b6186b02d6f455e8877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-hyperdrive-training/runs/HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup4/workspaces/machine_learning_workspace4\", \"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"run_properties\": {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"created_utc\": \"2020-04-20T16:14:13.922003Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"986ba56f-648a-49d5-959f-769f53b6390b\", \"score\": \"0.7743333333333333\", \"best_child_run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_14\", \"best_metric_status\": \"Succeeded\"}, \"tags\": {\"max_concurrent_jobs\": \"5\", \"max_total_jobs\": \"20\", \"max_duration_minutes\": \"10080\", \"policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--regularization\\\": [\\\"choice\\\", [[1, 0.333, 0.1, 0.033]]], \\\"--C\\\": [\\\"choice\\\", [[1, 3, 10, 30]]], \\\"--solver\\\": [\\\"choice\\\", [[\\\"lbfgs\\\", \\\"liblinear\\\", \\\"newton-cg\\\", \\\"lbfgs\\\", \\\"sag\\\"]]]}}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://westeurope.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourceGroups/myResourceGroup4/providers/Microsoft.MachineLearningServices/workspaces/machine_learning_workspace4/experiments/diabetes-hyperdrive-training\\\", \\\"SubscriptionId\\\": \\\"43c1f93a-903d-4b23-a4bf-92bd7a150627\\\", \\\"ResourceGroupName\\\": \\\"myResourceGroup4\\\", \\\"WorkspaceName\\\": \\\"machine_learning_workspace4\\\", \\\"ExperimentName\\\": \\\"diabetes-hyperdrive-training\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"diabetes_training.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"aml-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": \\\"training_environment\\\", \\\"version\\\": \\\"1\\\", \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"], \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\", \\\"azureml-dataprep[pandas,fuse]\\\", \\\"pyarrow\\\", \\\"fastparquet\\\"]}, \\\"scikit-learn\\\", \\\"joblib\\\"], \\\"name\\\": \\\"azureml_b9a1534962684a800c586e9fce04292e\\\"}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": null, \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1}, \\\"dataReferences\\\": {}, \\\"data\\\": {\\\"diabetes\\\": {\\\"dataLocation\\\": {\\\"dataset\\\": {\\\"id\\\": \\\"642bff52-df41-4dd7-a6b7-353d164ed1ab\\\"}, \\\"datapath\\\": null}, \\\"createOutputDirectories\\\": false, \\\"mechanism\\\": \\\"mount\\\", \\\"environmentVariableName\\\": \\\"diabetes\\\", \\\"pathOnCompute\\\": \\\"/mnt/data\\\", \\\"overwrite\\\": false}}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"986ba56f-648a-49d5-959f-769f53b6390b\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"73b49191-8db3-45ab-87b3-b8f956ac123b\\\", \\\"amlClientRequestId\\\": \\\"0a6d56aa-8072-4cf1-b9e9-ddcc3a5acba8\\\", \\\"amlClientSessionId\\\": \\\"efcf5569-8c1a-4793-a71f-dea0d349d556\\\", \\\"subscriptionId\\\": \\\"43c1f93a-903d-4b23-a4bf-92bd7a150627\\\", \\\"estimator\\\": \\\"Estimator\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 5, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"resume_child_runs\": \"null\", \"all_jobs_generated\": \"true\", \"cancellation_requested\": \"false\", \"progress_metadata_evaluation_timestamp\": \"\\\"2020-04-20T16:14:14.963868\\\"\", \"progress_metadata_digest\": \"\\\"c8afdf3c8399691b83857dfbb1ce362f6f3b3192da9b3889811e7af1d92bcc0e\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2020-04-20T16:14:14.963868\\\"\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_0\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_1\": \"{\\\"--C\\\": 30, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_2\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 1, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_3\": \"{\\\"--C\\\": 30, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_4\": \"{\\\"--C\\\": 30, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"environment_preparation_status\": \"PREPARED\", \"prepare_run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_preparation\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_5\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 1, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_6\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"liblinear\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_7\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"sag\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_8\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_9\": \"{\\\"--C\\\": 30, \\\"--regularization\\\": 0.333, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_10\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 0.333, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_11\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 0.333, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_12\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_13\": \"{\\\"--C\\\": 30, \\\"--regularization\\\": 0.333, \\\"--solver\\\": \\\"sag\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_14\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"liblinear\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_15\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 0.333, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_16\": \"{\\\"--C\\\": 30, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_17\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_18\": \"{\\\"--C\\\": 30, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"liblinear\\\"}\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_19\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"liblinear\\\"}\", \"final_best_metric_update_retry_count\": \"1\"}, \"end_time_utc\": \"2020-04-20T16:52:23.562669Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=TR5%2BgaRXb01131P0tpdZ6hGyvWmfmqANaTrx6G0f4fc%3D&st=2020-04-20T16%3A42%3A34Z&se=2020-04-21T00%3A52%3A34Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:38:09\", \"hyper_parameters\": {\"--regularization\": [\"choice\", [[1, 0.333, 0.1, 0.033]]], \"--C\": [\"choice\", [[1, 3, 10, 30]]], \"--solver\": [\"choice\", [[\"lbfgs\", \"liblinear\", \"newton-cg\", \"lbfgs\", \"sag\"]]]}}, \"child_runs\": [{\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_3\", \"run_number\": 3, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:38:35.448744Z\", \"end_time\": \"2020-04-20T16:42:57.882268Z\", \"created_time\": \"2020-04-20T16:20:54.878062Z\", \"created_time_dt\": \"2020-04-20T16:20:54.878062Z\", \"duration\": \"0:22:03\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 30, \"param_--regularization\": 0.033, \"param_--solver\": \"newton-cg\", \"best_metric\": 0.774}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_1\", \"run_number\": 4, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:40:38.095056Z\", \"end_time\": \"2020-04-20T16:45:04.000307Z\", \"created_time\": \"2020-04-20T16:20:54.934257Z\", \"created_time_dt\": \"2020-04-20T16:20:54.934257Z\", \"duration\": \"0:24:09\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 30, \"param_--regularization\": 0.033, \"param_--solver\": \"newton-cg\", \"best_metric\": 0.774}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_4\", \"run_number\": 5, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:38:31.007887Z\", \"end_time\": \"2020-04-20T16:42:53.171245Z\", \"created_time\": \"2020-04-20T16:20:54.991842Z\", \"created_time_dt\": \"2020-04-20T16:20:54.991842Z\", \"duration\": \"0:21:58\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 30, \"param_--regularization\": 0.1, \"param_--solver\": \"newton-cg\", \"best_metric\": 0.774}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_2\", \"run_number\": 6, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:38:31.304679Z\", \"end_time\": \"2020-04-20T16:42:52.826812Z\", \"created_time\": \"2020-04-20T16:20:55.088534Z\", \"created_time_dt\": \"2020-04-20T16:20:55.088534Z\", \"duration\": \"0:21:57\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 10, \"param_--regularization\": 1, \"param_--solver\": \"newton-cg\", \"best_metric\": 0.774}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_0\", \"run_number\": 7, \"metric\": 0.77233333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:38:45.284645Z\", \"end_time\": \"2020-04-20T16:42:47.32983Z\", \"created_time\": \"2020-04-20T16:20:54.997842Z\", \"created_time_dt\": \"2020-04-20T16:20:54.997842Z\", \"duration\": \"0:21:52\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 10, \"param_--regularization\": 0.033, \"param_--solver\": \"lbfgs\", \"best_metric\": 0.774}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_5\", \"run_number\": 8, \"metric\": 0.768, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:43:42.113293Z\", \"end_time\": \"2020-04-20T16:44:36.390917Z\", \"created_time\": \"2020-04-20T16:43:10.855643Z\", \"created_time_dt\": \"2020-04-20T16:43:10.855643Z\", \"duration\": \"0:01:25\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 3, \"param_--regularization\": 1, \"param_--solver\": \"lbfgs\", \"best_metric\": 0.774}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_6\", \"run_number\": 9, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:43:43.72026Z\", \"end_time\": \"2020-04-20T16:44:39.591382Z\", \"created_time\": \"2020-04-20T16:43:10.962807Z\", \"created_time_dt\": \"2020-04-20T16:43:10.962807Z\", \"duration\": \"0:01:28\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 10, \"param_--regularization\": 0.033, \"param_--solver\": \"liblinear\", \"best_metric\": 0.774}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_7\", \"run_number\": 10, \"metric\": 0.70933333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:43:43.75504Z\", \"end_time\": \"2020-04-20T16:44:49.586065Z\", \"created_time\": \"2020-04-20T16:43:10.986281Z\", \"created_time_dt\": \"2020-04-20T16:43:10.986281Z\", \"duration\": \"0:01:38\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 1, \"param_--regularization\": 0.033, \"param_--solver\": \"sag\", \"best_metric\": 0.774}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_8\", \"run_number\": 11, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:44:13.070195Z\", \"end_time\": \"2020-04-20T16:45:22.476116Z\", \"created_time\": \"2020-04-20T16:43:42.125465Z\", \"created_time_dt\": \"2020-04-20T16:43:42.125465Z\", \"duration\": \"0:01:40\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 3, \"param_--regularization\": 0.033, \"param_--solver\": \"newton-cg\", \"best_metric\": 0.774}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_11\", \"run_number\": 12, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:45:49.901607Z\", \"end_time\": \"2020-04-20T16:47:06.747247Z\", \"created_time\": \"2020-04-20T16:45:13.727977Z\", \"created_time_dt\": \"2020-04-20T16:45:13.727977Z\", \"duration\": \"0:01:53\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 1, \"param_--regularization\": 0.333, \"param_--solver\": \"newton-cg\", \"best_metric\": 0.774}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_9\", \"run_number\": 13, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:45:46.361043Z\", \"end_time\": \"2020-04-20T16:47:54.617295Z\", \"created_time\": \"2020-04-20T16:45:13.911919Z\", \"created_time_dt\": \"2020-04-20T16:45:13.911919Z\", \"duration\": \"0:02:40\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 30, \"param_--regularization\": 0.333, \"param_--solver\": \"newton-cg\", \"best_metric\": 0.774}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_10\", \"run_number\": 14, \"metric\": 0.767, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:45:45.279903Z\", \"end_time\": \"2020-04-20T16:46:36.562218Z\", \"created_time\": \"2020-04-20T16:45:14.078219Z\", \"created_time_dt\": \"2020-04-20T16:45:14.078219Z\", \"duration\": \"0:01:22\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 1, \"param_--regularization\": 0.333, \"param_--solver\": \"lbfgs\", \"best_metric\": 0.774}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_12\", \"run_number\": 15, \"metric\": 0.767, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:46:17.835523Z\", \"end_time\": \"2020-04-20T16:47:07.400379Z\", \"created_time\": \"2020-04-20T16:45:45.504056Z\", \"created_time_dt\": \"2020-04-20T16:45:45.504056Z\", \"duration\": \"0:01:21\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 1, \"param_--regularization\": 0.1, \"param_--solver\": \"lbfgs\", \"best_metric\": 0.774}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_13\", \"run_number\": 16, \"metric\": 0.70933333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:46:18.271132Z\", \"end_time\": \"2020-04-20T16:47:09.626009Z\", \"created_time\": \"2020-04-20T16:45:47.128178Z\", \"created_time_dt\": \"2020-04-20T16:45:47.128178Z\", \"duration\": \"0:01:22\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 30, \"param_--regularization\": 0.333, \"param_--solver\": \"sag\", \"best_metric\": 0.774}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_14\", \"run_number\": 17, \"metric\": 0.77433333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:48:01.279777Z\", \"end_time\": \"2020-04-20T16:48:42.050376Z\", \"created_time\": \"2020-04-20T16:47:18.681114Z\", \"created_time_dt\": \"2020-04-20T16:47:18.681114Z\", \"duration\": \"0:01:23\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 3, \"param_--regularization\": 0.1, \"param_--solver\": \"liblinear\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_15\", \"run_number\": 18, \"metric\": 0.768, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:48:21.496609Z\", \"end_time\": \"2020-04-20T16:49:15.254843Z\", \"created_time\": \"2020-04-20T16:47:49.413366Z\", \"created_time_dt\": \"2020-04-20T16:47:49.413366Z\", \"duration\": \"0:01:25\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 3, \"param_--regularization\": 0.333, \"param_--solver\": \"lbfgs\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_16\", \"run_number\": 19, \"metric\": 0.77366667, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:48:21.728095Z\", \"end_time\": \"2020-04-20T16:49:09.048936Z\", \"created_time\": \"2020-04-20T16:47:49.544099Z\", \"created_time_dt\": \"2020-04-20T16:47:49.544099Z\", \"duration\": \"0:01:19\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 30, \"param_--regularization\": 0.033, \"param_--solver\": \"lbfgs\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_17\", \"run_number\": 20, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:48:21.215712Z\", \"end_time\": \"2020-04-20T16:49:13.202808Z\", \"created_time\": \"2020-04-20T16:47:49.761155Z\", \"created_time_dt\": \"2020-04-20T16:47:49.761155Z\", \"duration\": \"0:01:23\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 10, \"param_--regularization\": 0.033, \"param_--solver\": \"newton-cg\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_18\", \"run_number\": 21, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:48:52.21473Z\", \"end_time\": \"2020-04-20T16:49:47.034088Z\", \"created_time\": \"2020-04-20T16:48:20.837756Z\", \"created_time_dt\": \"2020-04-20T16:48:20.837756Z\", \"duration\": \"0:01:26\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 30, \"param_--regularization\": 0.1, \"param_--solver\": \"liblinear\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_19\", \"run_number\": 22, \"metric\": 0.77433333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-04-20T16:49:55.014725Z\", \"end_time\": \"2020-04-20T16:51:46.163265Z\", \"created_time\": \"2020-04-20T16:49:22.385242Z\", \"created_time_dt\": \"2020-04-20T16:49:22.385242Z\", \"duration\": \"0:02:23\", \"hyperdrive_id\": \"80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"arguments\": null, \"param_--C\": 3, \"param_--regularization\": 0.033, \"param_--solver\": \"liblinear\", \"best_metric\": 0.77433333}], \"children_metrics\": {\"categories\": [0], \"series\": {\"Inverse of regularization strength\": [{\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"markers\", \"name\": \"Inverse of regularization strength\", \"stepped\": false, \"type\": \"scatter\", \"data\": [30.0, 30.0, 30.0, 10.0, 10.0, 3.0, 10.0, 1.0, 3.0, 1.0, 30.0, 1.0, 1.0, 30.0, 3.0, 3.0, 30.0, 10.0, 30.0, 3.0]}, {\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"lines\", \"name\": \"Inverse of regularization strength_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0]}], \"Algorithm to use in the optimization problem\": [{\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"markers\", \"name\": \"Algorithm to use in the optimization problem\", \"stepped\": false, \"type\": \"scatter\", \"data\": [\"newton-cg\", \"newton-cg\", \"newton-cg\", \"newton-cg\", \"lbfgs\", \"lbfgs\", \"liblinear\", \"sag\", \"newton-cg\", \"newton-cg\", \"newton-cg\", \"lbfgs\", \"lbfgs\", \"sag\", \"liblinear\", \"lbfgs\", \"lbfgs\", \"newton-cg\", \"liblinear\", \"liblinear\"]}, {\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"lines\", \"name\": \"Algorithm to use in the optimization problem_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": []}], \"Regularization Rate\": [{\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"markers\", \"name\": \"Regularization Rate\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.033, 0.033, 0.1, 1.0, 0.033, 1.0, 0.033, 0.033, 0.033, 0.333, 0.333, 0.333, 0.1, 0.333, 0.1, 0.333, 0.033, 0.033, 0.1, 0.033]}, {\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"lines\", \"name\": \"Regularization Rate_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.033, 0.033, 0.1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}], \"Accuracy\": [{\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"markers\", \"name\": \"Accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.774, 0.774, 0.774, 0.774, 0.7723333333333333, 0.768, 0.774, 0.7093333333333334, 0.774, 0.774, 0.774, 0.767, 0.767, 0.7093333333333334, 0.7743333333333333, 0.768, 0.7736666666666666, 0.774, 0.774, 0.7743333333333333]}, {\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"lines\", \"name\": \"Accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.774, 0.774, 0.774, 0.774, 0.774, 0.774, 0.774, 0.774, 0.774, 0.774, 0.774, 0.774, 0.774, 0.774, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333]}], \"AUC\": [{\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"markers\", \"name\": \"AUC\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.8484969401462759, 0.8484969401462759, 0.8484969401462759, 0.8484994278322306, 0.8424319617891437, 0.8239802975272401, 0.8484377332205582, 0.7438409871137867, 0.8484949499975123, 0.8485163440967213, 0.8484969401462759, 0.8287432210557739, 0.8287432210557739, 0.7438389969650232, 0.8483402159311408, 0.8239802975272401, 0.84811433404647, 0.8484994278322306, 0.8484317627742675, 0.8483402159311408]}, {\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"lines\", \"name\": \"AUC_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.8484969401462759, 0.8484969401462759, 0.8484969401462759, 0.8484994278322306, 0.8484994278322306, 0.8484994278322306, 0.8484994278322306, 0.8484994278322306, 0.8484994278322306, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213]}]}, \"metricName\": null, \"primaryMetricName\": \"Accuracy\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a\", \"categories\": [0], \"series\": [{\"data\": [{\"metric_name\": [\"Accuracy\", \"Accuracy\", \"Accuracy\"], \"timestamp\": [\"2020-04-20 16:42:31.705982+00:00\", \"2020-04-20 16:48:44.860022+00:00\", \"2020-04-20 16:48:44.860022+00:00\"], \"run_id\": [\"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_2\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_14\", \"HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_14\"], \"metric_value\": [0.774, 0.7743333333333333, 0.7743333333333333], \"final\": [false, false, true]}]}]}], \"run_logs\": \"[2020-04-20T16:14:14.199741][API][INFO]Experiment created\\r\\n[2020-04-20T16:14:15.256599][GENERATOR][INFO]Trying to sample '5' jobs from the hyperparameter space\\r\\n[2020-04-20T16:14:15.5484302Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\r\\n[2020-04-20T16:14:15.522470][GENERATOR][INFO]Successfully sampled '5' jobs, they will soon be submitted to the execution target.\\r\\n[2020-04-20T16:20:54.0828200Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_2'\\r\\n[2020-04-20T16:20:54.0849625Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_3'\\r\\n[2020-04-20T16:20:54.0785518Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_0'\\r\\n[2020-04-20T16:20:54.0777073Z][SCHEDULER][INFO]The execution environment was successfully prepared.\\r\\n[2020-04-20T16:20:54.0844732Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_4'\\r\\n[2020-04-20T16:20:54.0798250Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_1'\\r\\n[2020-04-20T16:20:54.9731220Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_3'\\r\\n[2020-04-20T16:20:55.0519924Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_1'\\r\\n[2020-04-20T16:20:55.1404693Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_4'\\r\\n[2020-04-20T16:20:55.2098413Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_0'\\r\\n[2020-04-20T16:20:55.1958831Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_2'\\r\\n[2020-04-20T16:42:54.020032][GENERATOR][INFO]Trying to sample '3' jobs from the hyperparameter space\\r\\n[2020-04-20T16:42:54.272361][GENERATOR][INFO]Successfully sampled '3' jobs, they will soon be submitted to the execution target.\\r\\n[2020-04-20T16:43:10.0458630Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_5'\\r\\n[2020-04-20T16:43:10.0491706Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_7'\\r\\n[2020-04-20T16:43:10.0479537Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_6'\\r\\n[2020-04-20T16:43:10.9467705Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_5'\\r\\n[2020-04-20T16:43:11.0838846Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_6'\\r\\n[2020-04-20T16:43:11.1099116Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_7'\\r\\n[2020-04-20T16:43:24.970674][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2020-04-20T16:43:25.175175][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2020-04-20T16:43:41.3248408Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_8'\\r\\n[2020-04-20T16:43:42.2231506Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_8'\\r\\n[2020-04-20T16:44:55.918226][GENERATOR][INFO]Trying to sample '3' jobs from the hyperparameter space\\r\\n[2020-04-20T16:44:56.130266][GENERATOR][INFO]Successfully sampled '3' jobs, they will soon be submitted to the execution target.\\r\\n[2020-04-20T16:45:12.8931897Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_9'\\r\\n[2020-04-20T16:45:12.8963172Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_11'\\r\\n[2020-04-20T16:45:12.8949987Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_10'\\r\\n[2020-04-20T16:45:13.8573555Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_11'\\r\\n[2020-04-20T16:45:14.0993058Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_9'\\r\\n[2020-04-20T16:45:14.2038698Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_10'\\r\\n[2020-04-20T16:45:25.847440][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2020-04-20T16:45:25.974812][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\r\\n[2020-04-20T16:45:44.4447606Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_12'\\r\\n[2020-04-20T16:45:44.4459865Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_13'\\r\\n[2020-04-20T16:45:45.7804286Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_12'\\r\\n[2020-04-20T16:45:47.2418768Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_13'\\r\\n[2020-04-20T16:46:55.758611][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2020-04-20T16:46:55.641763][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2020-04-20T16:47:17.8697212Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_14'\\r\\n[2020-04-20T16:47:18.7562436Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_14'\\r\\n[2020-04-20T16:47:26.111835][GENERATOR][INFO]Trying to sample '3' jobs from the hyperparameter space\\r\\n[2020-04-20T16:47:26.342846][GENERATOR][INFO]Successfully sampled '3' jobs, they will soon be submitted to the execution target.\\r\\n[2020-04-20T16:47:48.9316053Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_15'\\r\\n[2020-04-20T16:47:48.9341175Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_17'\\r\\n[2020-04-20T16:47:48.9328877Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_16'\\r\\n[2020-04-20T16:47:49.8571182Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_17'\\r\\n[2020-04-20T16:47:49.6288407Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_16'\\r\\n[2020-04-20T16:47:49.5381860Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_15'\\r\\n[2020-04-20T16:47:57.079395][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2020-04-20T16:47:56.972913][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2020-04-20T16:48:20.0983277Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_18'\\r\\n[2020-04-20T16:48:20.9435351Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_18'\\r\\n[2020-04-20T16:48:57.907953][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2020-04-20T16:48:58.126533][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2020-04-20T16:49:21.3844373Z][SCHEDULER][INFO]Scheduling job, id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_19'\\r\\n[2020-04-20T16:49:22.5066131Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_80e53b9d-ba8b-4c6c-8309-fcb534a1469a_19'\\r\\n[2020-04-20T16:49:27.943094][GENERATOR][INFO]Max number of jobs '20' reached for experiment.\\r\\n[2020-04-20T16:49:28.222228][GENERATOR][INFO]All jobs generated.\\r\\n[2020-04-20T16:52:23.873809][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.3.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the run details while running\n",
    "RunDetails(hyperdrive_run).show()  # <-- Completed, no it is running in the background !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the RUN must FINISH first, then continue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--C', '3', '--regularization', '0.1', '--solver', 'liblinear']\n"
     ]
    }
   ],
   "source": [
    "# Find best run\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "print(best_run.get_details()['runDefinition']['arguments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "orchestrate machine learning operations, arranged sequentially or in parallel.  \n",
    "a workflow of machine learning tasks in which each task is implemented as a step.  \n",
    "Each step in the pipeline runs on its allocated compute target.  \n",
    "publish a pipeline as a REST endpoint, enabling client applications to initiate a pipeline run.\n",
    "\n",
    "What follow is a simple **_2-step_** pipeline that trains and registers a model.  \n",
    "\n",
    "1. storage\n",
    "1. compute\n",
    "1. environment\n",
    "1. scripts\n",
    "  * step 1: create a model\n",
    "  * step 2: register the model\n",
    "1. create pipeline\n",
    "1. run pipeline\n",
    "1. publish pipeline\n",
    "1. call pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### storage\n",
    "\n",
    "The PipelineData object is a special kind of data reference that is used to pass data from the output of one pipeline step to the input of another, creating a dependency between them. You'll create one and use it as the output for the first step and the input for the second step. Note that you also need to pass it as a script argument so your code can access the datastore location referenced by the data reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# load the training diabetes dataset (File method)\n",
    "ds = Datastore.get(ws, 'datalakestoragegen2')\n",
    "ds_path = [DataPath(ds, 'platinum/diabetes.parquet')] # {path/*.parquet or path/**}\n",
    "diabetes_ds = Dataset.File.from_files(path=ds_path)\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference)\n",
    "# data lake gen2: container \"datalake\" > azureml > 0b93a7bc-9bf2-46a9-b9c4-5afdba292d08 > model_folder\n",
    "model_folder = PipelineData(\"model_folder\", datastore=ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load compute cluster\n",
    "pipeline_cluster = ComputeTarget(ws, 'aml-cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the docker environment\n",
    "training_env = Environment.get(ws, 'training_environment')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above.\n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = training_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder for the pipeline step files\n",
    "project_folder = 'diabetes_pipeline'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment folder\n",
    "experiment_folder = './' + project_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**step 1:** create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./diabetes_pipeline/train_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/train_diabetes.py\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_folder', type=str, dest='output_folder', default=\"diabetes_model\", help='output folder')\n",
    "args = parser.parse_args()\n",
    "output_folder = args.output_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "#diabetes = run.input_datasets['diabetes_train'].to_pandas_dataframe()\n",
    "mount = run.input_datasets['diabetes_train'] # read-only mount from delta lake as '/mnt/data'\n",
    "print(\"delta lake mounted...\")\n",
    "diabetes = pd.read_parquet('/mnt/data/diabetes.parquet') # load any file(s) from this delta lake mounted folder\n",
    "print(\"dataset loaded...\")\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train adecision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = output_folder + \"/model.pkl\"\n",
    "joblib.dump(value=model, filename=output_path)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**step 2:** register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python script step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./diabetes_pipeline/register_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/register_diabetes.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Workspace, Model, Run\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_folder', type=str, dest='model_folder', default=\"diabetes_model\", help='model location')\n",
    "args = parser.parse_args()\n",
    "model_folder = args.model_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the model\n",
    "print(\"Loading model from \" + model_folder)\n",
    "model_file = model_folder + \"/model.pkl\"\n",
    "model = joblib.load(model_file)\n",
    "\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path=model_file,\n",
    "               model_name='diabetes_model',\n",
    "               tags={'Training context':'Pipeline'})\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Common kinds of step|Description|\n",
    "|-|-|\n",
    "|**PythonScriptStep**|<i>Runs a specified Python script</i>|\n",
    "|**EstimatorStep**|<i>Runs an estimator</i>|\n",
    "|**DataTransferStep**|<i>Uses Azure Data Factory to copy data between data stores</i>|\n",
    "|**DatabricksStep**|<i>Runs a notebook, script, or compiled JAR on a databricks cluster</i>|\n",
    "|**AdlaStep**|<i>Runs a U-SQL job in Azure Data Lake Analytics</i>|\n",
    "|**[6 more steps](https://aka.ms/AA70rrh)**||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(source_directory=experiment_folder, \n",
    "                      compute_target=pipeline_cluster, #training_cluster\n",
    "                      environment_definition=pipeline_run_config.environment, #training_env\n",
    "                      entry_script='train_diabetes.py', #'diabetes_training.py'\n",
    "                      # NO script_params=script_params,\n",
    "                      # NO inputs=[file_ds.as_named_input('diabetes').as_mount(path_on_compute='/mnt/data')],\n",
    "                     )\n",
    "\n",
    "# Step 1, run the estimator to train the model\n",
    "train_step = EstimatorStep(name=\"Train Model\",\n",
    "                           estimator=estimator,\n",
    "                           compute_target=pipeline_cluster, # {'aml-cluster'}\n",
    "                           estimator_entry_script_arguments=['--output_folder', model_folder],\n",
    "                           inputs=[diabetes_ds.as_named_input('diabetes_train').as_mount(path_on_compute='/mnt/data')],\n",
    "                           outputs=[model_folder],\n",
    "                           allow_reuse=True)\n",
    "\n",
    "# Step 2, run the model registration script\n",
    "register_step = PythonScriptStep(name=\"Register Model\",\n",
    "                                 source_directory=experiment_folder,\n",
    "                                 script_name=\"register_diabetes.py\",\n",
    "                                 compute_target=pipeline_cluster,\n",
    "                                 runconfig=pipeline_run_config,\n",
    "                                 inputs=[model_folder],\n",
    "                                 arguments=['--model_folder', model_folder],\n",
    "                                 allow_reuse=True)\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline = Pipeline(ws, [train_step, register_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run pipeline\n",
    "\n",
    "Run pipeline and verify it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Train Model [fc8c6401][cf50c66d-1485-4683-bb24-8faae2af198d], (This step will run and generate new outputs)Created step Register Model [946d0f72][e6f4f986-650c-498d-b23c-2547cc5bd773], (This step will run and generate new outputs)\n",
      "\n",
      "Submitted PipelineRun d9447ed8-c689-418f-a7ba-60ba05c743a8\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/d9447ed8-c689-418f-a7ba-60ba05c743a8?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup4/workspaces/machine_learning_workspace4\n"
     ]
    }
   ],
   "source": [
    "# Create an experiment\n",
    "experiment = Experiment(ws, 'diabetes-training-pipeline')\n",
    "\n",
    "# Run the pipeline\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bf9736af764f83b8cf2008f850e4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-training-pipeline/runs/d9447ed8-c689-418f-a7ba-60ba05c743a8?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup4/workspaces/machine_learning_workspace4\", \"run_id\": \"d9447ed8-c689-418f-a7ba-60ba05c743a8\", \"run_properties\": {\"run_id\": \"d9447ed8-c689-418f-a7ba-60ba05c743a8\", \"created_utc\": \"2020-04-20T16:55:12.00023Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d9447ed8-c689-418f-a7ba-60ba05c743a8/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=gA865a%2BN2NdHfWRUmB2CcyHkD8N%2BJNMUpeJ1jkLYcqg%3D&st=2020-04-20T16%3A51%3A44Z&se=2020-04-21T01%3A01%3A44Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d9447ed8-c689-418f-a7ba-60ba05c743a8/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=ODTz9JDR3zLFqQcexQB1pJ2JrmWfiaP3Li02b7PY9%2FY%3D&st=2020-04-20T16%3A51%3A44Z&se=2020-04-21T01%3A01%3A44Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d9447ed8-c689-418f-a7ba-60ba05c743a8/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=9yxHShQjVoEfi2rAlrSl5IisJkkIhSCynVBpU995Pmw%3D&st=2020-04-20T16%3A51%3A44Z&se=2020-04-21T01%3A01%3A44Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:06:32\"}, \"child_runs\": [{\"run_id\": \"d3d253d8-f099-4441-b09c-0e12de2c9428\", \"name\": \"Train Model\", \"status\": \"Running\", \"start_time\": \"\", \"created_time\": \"2020-04-20T16:55:23.41509Z\", \"end_time\": \"\", \"duration\": \"0:06:22\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-04-20T16:55:23.41509Z\", \"is_reused\": \"\"}, {\"run_id\": \"\", \"name\": \"Register Model\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2020-04-20 16:55:23Z] Submitting 1 runs, first five are: fc8c6401:d3d253d8-f099-4441-b09c-0e12de2c9428\\n\", \"graph\": {\"datasource_nodes\": {\"65a4d2ff\": {\"node_id\": \"65a4d2ff\", \"name\": \"0fb901ef-11b7-4b1a-8e9f-f1012f27d6c3\"}}, \"module_nodes\": {\"fc8c6401\": {\"node_id\": \"fc8c6401\", \"name\": \"Train Model\", \"status\": \"Running\", \"_is_reused\": false, \"run_id\": \"d3d253d8-f099-4441-b09c-0e12de2c9428\"}, \"946d0f72\": {\"node_id\": \"946d0f72\", \"name\": \"Register Model\", \"status\": \"NotStarted\"}}, \"edges\": [{\"source_node_id\": \"65a4d2ff\", \"source_node_name\": \"0fb901ef-11b7-4b1a-8e9f-f1012f27d6c3\", \"source_name\": \"data\", \"target_name\": \"diabetes_train\", \"dst_node_id\": \"fc8c6401\", \"dst_node_name\": \"Train Model\"}, {\"source_node_id\": \"fc8c6401\", \"source_node_name\": \"Train Model\", \"source_name\": \"model_folder\", \"target_name\": \"model_folder\", \"dst_node_id\": \"946d0f72\", \"dst_node_name\": \"Register Model\"}], \"child_runs\": [{\"run_id\": \"d3d253d8-f099-4441-b09c-0e12de2c9428\", \"name\": \"Train Model\", \"status\": \"Running\", \"start_time\": \"\", \"created_time\": \"2020-04-20T16:55:23.41509Z\", \"end_time\": \"\", \"duration\": \"0:06:22\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-04-20T16:55:23.41509Z\", \"is_reused\": \"\"}, {\"run_id\": \"\", \"name\": \"Register Model\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.3.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: d9447ed8-c689-418f-a7ba-60ba05c743a8\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/d9447ed8-c689-418f-a7ba-60ba05c743a8?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup4/workspaces/machine_learning_workspace4\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: d3d253d8-f099-4441-b09c-0e12de2c9428\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/d3d253d8-f099-4441-b09c-0e12de2c9428?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup4/workspaces/machine_learning_workspace4\n",
      "StepRun( Train Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2020/04/20 16:56:09 Downloading source code...\n",
      "2020/04/20 16:56:10 Finished downloading source code\n",
      "2020/04/20 16:56:11 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2020/04/20 16:56:11 Successfully set up Docker network: acb_default_network\n",
      "2020/04/20 16:56:11 Setting up Docker configuration...\n",
      "2020/04/20 16:56:12 Successfully set up Docker configuration\n",
      "2020/04/20 16:56:12 Logging in to registry: machinelearnc5ceeadf.azurecr.io\n",
      "2020/04/20 16:56:13 Successfully logged into machinelearnc5ceeadf.azurecr.io\n",
      "2020/04/20 16:56:13 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/04/20 16:56:13 Scanning for dependencies...\n",
      "2020/04/20 16:56:14 Successfully scanned dependencies\n",
      "2020/04/20 16:56:14 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  60.93kB\n",
      "\n",
      "Step 1/15 : FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05: Pulling from azureml/base\n",
      "Digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      " ---> 93a72e6bd1ce\n",
      "Step 2/15 : USER root\n",
      " ---> Running in 50659aa65698\n",
      "Removing intermediate container 50659aa65698\n",
      " ---> 6215eeda818f\n",
      "Step 3/15 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in dffa72d7420b\n",
      "Removing intermediate container dffa72d7420b\n",
      " ---> 957a7c822094\n",
      "Step 4/15 : WORKDIR /\n",
      " ---> Running in d9b4398679e8\n",
      "Removing intermediate container d9b4398679e8\n",
      " ---> 071d7b4c5b29\n",
      "Step 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 804cb639de4a\n",
      "Step 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in c3d3dd5ab466\n",
      "Removing intermediate container c3d3dd5ab466\n",
      " ---> 0e2e9c6b6d0c\n",
      "Step 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> bfa817c97447\n",
      "Step 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 75b154f6541a\n",
      "Solving environment: ...working... \n",
      "done\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "intel-openmp-2020.0  | 916 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "intel-openmp-2020.0  | 916 KB    | #######5   |  76% \u001b[0m\u001b[91m\n",
      "intel-openmp-2020.0  | 916 KB    | #########8 |  98% \u001b[0m\u001b[91m\n",
      "intel-openmp-2020.0  | 916 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 387 KB    | ########9  |  89% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 387 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "certifi-2020.4.5.1   | 159 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "certifi-2020.4.5.1   | 159 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl-2019.5           | 205.3 MB  |            |   0% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | 1          |   2% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | 4          |   4% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | 6          |   7% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | 9          |   9% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #1         |  11% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #3         |  13% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #4         |  15% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #6         |  16% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #7         |  18% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ##         |  20% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ##2        |  22% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ##4        |  24% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ##5        |  26% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ##8        |  28% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ###        |  30% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ###1       |  32% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ###6       |  36% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ###8       |  39% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ####       |  41% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ####3      |  43% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ####5      |  45% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ####8      |  48% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #####      |  51% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #####3     |  54% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #####6     |  56% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #####8     |  59% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ######1    |  61% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ######3    |  64% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ######5    |  66% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ######8    |  69% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #######    |  71% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #######3   |  73% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #######5   |  75% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #######7   |  77% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #######8   |  78% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #######9   |  79% \u001b[0m\n",
      "\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #######9   |  80% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########   |  80% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########   |  80% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########   |  81% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########   |  81% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########1  |  81% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########1  |  81% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########1  |  81% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########1  |  81% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########1  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########1  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########1  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########1  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########1  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########1  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########2  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########2  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########2  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########2  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########2  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########2  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########2  |  82% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########2  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########2  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########2  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########2  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########2  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########2  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########2  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########3  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########3  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########3  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########3  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########3  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########3  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########3  |  83% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########3  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########3  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########3  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########3  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########3  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########3  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########3  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  84% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########4  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########5  |  85% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########5  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########6  |  86% \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########6  |  86% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########6  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########7  |  87% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########7  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########8  |  88% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########8  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########9  |  89% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########9  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########  |  90% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########  |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########1 |  91% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########1 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########2 |  92% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########2 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########3 |  93% \u001b[0m\n",
      "\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########3 |  93% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########3 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########4 |  94% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########4 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########5 |  95% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########5 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########6 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  97% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########7 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########8 |  98% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########8 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########9 |  99% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########9 | 100% \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | #########9 | 100% \u001b[0m\u001b[91m\n",
      "mkl-2019.5           | 205.3 MB  | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #2         |  13% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ####6      |  46% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #########2 |  93% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | #####8     |  59% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | #######7   |  78% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | #########5 |  96% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "setuptools-46.1.3    | 663 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "setuptools-46.1.3    | 663 KB    | 1          |   2% \u001b[0m\u001b[91m\n",
      "setuptools-46.1.3    | 663 KB    | #########1 |  92% \u001b[0m\u001b[91m\n",
      "setuptools-46.1.3    | 663 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "six-1.14.0           | 27 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "six-1.14.0           | 27 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "tk-8.6.8             | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #######5   |  76% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #########8 |  98% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "joblib-0.14.1        | 202 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "joblib-0.14.1        | 202 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "numpy-1.18.1         | 5 KB      |            |   0% \u001b[0m\u001b[91m\n",
      "numpy-1.18.1         | 5 KB      | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl-service-2.3.0    | 208 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl-service-2.3.0    | 208 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "wheel-0.34.2         | 49 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "wheel-0.34.2         | 49 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | #######8   |  78% \u001b[0m\u001b[91m\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "scikit-learn-0.22.1  | 7.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.22.1  | 7.1 MB    | ####8      |  49% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.22.1  | 7.1 MB    | #######6   |  77% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.22.1  | 7.1 MB    | #########2 |  93% \u001b[0m\u001b[91m\n",
      "scikit-learn-0.22.1  | 7.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libffi-3.2.1         | 43 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "libffi-3.2.1         | 43 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ca-certificates-2020 | 132 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ca-certificates-2020 | 132 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | #######9   |  79% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | #########1 |  92% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | #######8   |  78% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \u001b[0m\u001b[91m\n",
      "blas-1.0             | 6 KB      | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "libedit-3.1          | 171 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "xz-5.2.4             | 366 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "xz-5.2.4             | 366 KB    | #########4 |  95% \u001b[0m\u001b[91m\n",
      "xz-5.2.4             | 366 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ####       |  40% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | #####2     |  52% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | #######8   |  78% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | #########3 |  94% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "scipy-1.4.1          | 18.9 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | ##4        |  25% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | #######    |  70% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | ########9  |  89% \u001b[0m\u001b[91m\n",
      "scipy-1.4.1          | 18.9 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ##4        |  24% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #########5 |  95% \u001b[0m\u001b[91m\n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl_fft-1.0.15       | 173 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl_fft-1.0.15       | 173 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "numpy-base-1.18.1    | 5.2 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "numpy-base-1.18.1    | 5.2 MB    | #######2   |  72% \u001b[0m\u001b[91m\n",
      "numpy-base-1.18.1    | 5.2 MB    | #########4 |  94% \u001b[0m\u001b[91m\n",
      "numpy-base-1.18.1    | 5.2 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pip-20.0.2           | 1.9 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | #######8   |  78% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | #########3 |  94% \u001b[0m\u001b[91m\n",
      "pip-20.0.2           | 1.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "mkl_random-1.1.0     | 369 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "mkl_random-1.1.0     | 369 KB    | #########6 |  96% \u001b[0m\u001b[91m\n",
      "mkl_random-1.1.0     | 369 KB    | ########## | 100% \u001b[0m\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting azureml-defaults\n",
      "  Downloading azureml_defaults-1.3.0-py3-none-any.whl (3.0 kB)\n",
      "Collecting azureml-dataprep[fuse,pandas]\n",
      "  Downloading azureml_dataprep-1.4.6-py3-none-any.whl (26.7 MB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1 MB)\n",
      "Collecting fastparquet\n",
      "  Downloading fastparquet-0.3.3.tar.gz (152 kB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting gunicorn==19.9.0\n",
      "  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
      "Collecting azureml-core~=1.3.0\n",
      "  Downloading azureml_core-1.3.0.post1-py3-none-any.whl (1.2 MB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting werkzeug==0.16.1\n",
      "  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting dotnetcore2>=2.1.13\n",
      "  Downloading dotnetcore2-2.1.13-py3-none-manylinux1_x86_64.whl (29.3 MB)\n",
      "Collecting azureml-dataprep-native<15.0.0,>=14.1.0\n",
      "  Downloading azureml_dataprep_native-14.1.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting cloudpickle>=1.1.0\n",
      "  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting azure-identity<1.3.0,>=1.2.0\n",
      "  Downloading azure_identity-1.2.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting fusepy>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting pandas>=0.23.4; extra == \"pandas\"\n",
      "  Downloading pandas-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (10.0 MB)\n",
      "Requirement already satisfied: numpy>=1.14.0; extra == \"pandas\" in /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e/lib/python3.6/site-packages (from azureml-dataprep[fuse,pandas]->-r /azureml-environment-setup/condaenv.8sh6iq6s.requirements.txt (line 2)) (1.18.1)\n",
      "Requirement already satisfied: six>=1.0.0 in /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e/lib/python3.6/site-packages (from pyarrow->-r /azureml-environment-setup/condaenv.8sh6iq6s.requirements.txt (line 3)) (1.14.0)\n",
      "Collecting numba>=0.28\n",
      "  Downloading numba-0.49.0-cp36-cp36m-manylinux2014_x86_64.whl (3.6 MB)\n",
      "Collecting thrift>=0.11.0\n",
      "  Downloading thrift-0.13.0.tar.gz (59 kB)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.4.0.tar.gz (15 kB)\n",
      "Collecting python-dateutil>=2.5.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting dill>=0.2.7.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "Collecting adal>=0.4.5\n",
      "  Downloading adal-1.2.2-py2.py3-none-any.whl (53 kB)\n",
      "Collecting requests>=2.17.3\n",
      "  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-7.1.1-py2.py3-none-any.whl (82 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\n",
      "Collecting msrest>=0.5.1\n",
      "  Downloading msrest-0.6.13-py2.py3-none-any.whl (83 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.25.9-py2.py3-none-any.whl (126 kB)\n",
      "Collecting azure-graphrbac>=0.40.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting SecretStorage\n",
      "  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting contextlib2\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting azure-mgmt-authorization>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.60.0-py2.py3-none-any.whl (82 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.3-py2.py3-none-any.whl (40 kB)\n",
      "Collecting azure-mgmt-resource<9.0.0,>=1.2.1\n",
      "  Downloading azure_mgmt_resource-8.0.1-py2.py3-none-any.whl (758 kB)\n",
      "Collecting pyopenssl\n",
      "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting pathspec\n",
      "  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\n",
      "  Downloading cryptography-2.9-cp35-abi3-manylinux2010_x86_64.whl (2.7 MB)\n",
      "Collecting azure-mgmt-keyvault>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting docker\n",
      "  Downloading docker-4.2.0-py2.py3-none-any.whl (143 kB)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\n",
      "Collecting azure-mgmt-storage>=1.5.0\n",
      "  Downloading azure_mgmt_storage-9.0.0-py2.py3-none-any.whl (525 kB)\n",
      "Collecting PyJWT\n",
      "  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting azure-common>=1.1.12\n",
      "  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-1.4-py2.py3-none-any.whl (36 kB)\n",
      "Collecting ruamel.yaml<=0.15.89,>=0.15.35\n",
      "  Downloading ruamel.yaml-0.15.89-cp36-cp36m-manylinux1_x86_64.whl (651 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.4.0-py2.py3-none-any.whl (114 kB)\n",
      "Collecting msal-extensions~=0.1.3\n",
      "  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting msal<2.0.0,>=1.0.0\n",
      "  Downloading msal-1.2.0-py2.py3-none-any.whl (46 kB)\n",
      "Collecting llvmlite<=0.33.0.dev0,>=0.31.0.dev0\n",
      "  Downloading llvmlite-0.32.0-cp36-cp36m-manylinux1_x86_64.whl (20.2 MB)\n",
      "Requirement already satisfied: setuptools in /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e/lib/python3.6/site-packages (from numba>=0.28->fastparquet->-r /azureml-environment-setup/condaenv.8sh6iq6s.requirements.txt (line 4)) (46.1.3.post20200330)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e/lib/python3.6/site-packages (from requests>=2.17.3->azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults->-r /azureml-environment-setup/condaenv.8sh6iq6s.requirements.txt (line 1)) (2020.4.5.1)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting jeepney>=0.4.2\n",
      "  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting cffi!=1.11.3,>=1.8\n",
      "  Downloading cffi-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (399 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-1.6.0-py2.py3-none-any.whl (30 kB)\n",
      "Collecting portalocker~=1.0\n",
      "  Downloading portalocker-1.7.0-py2.py3-none-any.whl (14 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "Building wheels for collected packages: fastparquet, json-logging-py, fusepy, thrift, liac-arff, dill\n",
      "  Building wheel for fastparquet (setup.py): started\n",
      "  Building wheel for fastparquet (setup.py): finished with status 'done'\n",
      "  Created wheel for fastparquet: filename=fastparquet-0.3.3-cp36-cp36m-linux_x86_64.whl size=258179 sha256=3690019d74fed492340fe93809e5c0e177199286a9169d6a0977319bbfc83a9b\n",
      "  Stored in directory: /root/.cache/pip/wheels/17/0b/fe/81b4ce36e4b0abb7220e29ea450ac345efb6219b9ac888e5c9\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3923 sha256=8e028967ea592b1c621299785afdf4a004e26280e5ba44c0ebea5e05d9c51eca\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=fe071c65d5dde20f14f42265567a58f4899b7c3122ecfe5107741a607681bfed\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for thrift (setup.py): started\n",
      "  Building wheel for thrift (setup.py): finished with status 'done'\n",
      "  Created wheel for thrift: filename=thrift-0.13.0-cp36-cp36m-linux_x86_64.whl size=371593 sha256=8bb79a3adddd44726b7b71f5b2055761e46308e1d232e6017ad32db85f5c6db1\n",
      "  Stored in directory: /root/.cache/pip/wheels/e0/38/fc/472fe18756b177b42096961f8bd3ff2dc5c5620ac399fce52d\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.4.0-py3-none-any.whl size=13333 sha256=4d73392b973a0d1e6293bcfa2112d4dc095dbbb5ead72e13d731f994424249cf\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/2a/e1/6f7be2e2ea150e2486bff64fd6f0670f4f35f4c8f31c819fb8\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=7c168f9f9d66097582c31851e2e89ec451414f9295e50bd8c9c3cbdaf2dff5a1\n",
      "  Stored in directory: /root/.cache/pip/wheels/09/84/74/d2b4feb9ac9488bc83c475cb2cbe8e8b7d9cea8320d32f3787\n",
      "Successfully built fastparquet json-logging-py fusepy thrift liac-arff dill\n",
      "\u001b[91mERROR: azureml-defaults 1.3.0 has requirement azureml-dataprep[fuse]<1.4.5a,>=1.4.3a, but you'll have azureml-dataprep 1.4.6 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: liac-arff, python-dateutil, pytz, pandas, dill, PyJWT, idna, chardet, urllib3, requests, pycparser, cffi, cryptography, adal, azureml-model-management-sdk, itsdangerous, werkzeug, click, MarkupSafe, Jinja2, flask, gunicorn, azure-common, isodate, oauthlib, requests-oauthlib, msrest, msrestazure, azure-mgmt-containerregistry, azure-graphrbac, jeepney, SecretStorage, contextlib2, azure-mgmt-authorization, azure-mgmt-resource, pyopenssl, pyasn1, ndg-httpsclient, pathspec, azure-mgmt-keyvault, websocket-client, docker, jmespath, azure-mgmt-storage, backports.weakref, backports.tempfile, zipp, importlib-metadata, jsonpickle, ruamel.yaml, azureml-core, json-logging-py, configparser, applicationinsights, distro, dotnetcore2, azureml-dataprep-native, cloudpickle, azure-core, portalocker, msal, msal-extensions, azure-identity, fusepy, pyarrow, azureml-dataprep, azureml-defaults, llvmlite, numba, thrift, fastparquet\n",
      "\n",
      "Successfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.1.2 adal-1.2.2 applicationinsights-0.11.9 azure-common-1.1.25 azure-core-1.4.0 azure-graphrbac-0.61.1 azure-identity-1.2.0 azure-mgmt-authorization-0.60.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-8.0.1 azure-mgmt-storage-9.0.0 azureml-core-1.3.0.post1 azureml-dataprep-1.4.6 azureml-dataprep-native-14.1.0 azureml-defaults-1.3.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.0 chardet-3.0.4 click-7.1.1 cloudpickle-1.3.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-2.9 dill-0.3.1.1 distro-1.5.0 docker-4.2.0 dotnetcore2-2.1.13 fastparquet-0.3.3 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.9 importlib-metadata-1.6.0 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.4.3 jmespath-0.9.5 json-logging-py-0.2 jsonpickle-1.4 liac-arff-2.4.0 llvmlite-0.32.0 msal-1.2.0 msal-extensions-0.1.3 msrest-0.6.13 msrestazure-0.6.3 ndg-httpsclient-0.5.1 numba-0.49.0 oauthlib-3.1.0 pandas-1.0.3 pathspec-0.8.0 portalocker-1.7.0 pyarrow-0.16.0 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 python-dateutil-2.8.1 pytz-2019.3 requests-2.23.0 requests-oauthlib-1.3.0 ruamel.yaml-0.15.89 thrift-0.13.0 urllib3-1.25.9 websocket-client-0.57.0 werkzeug-0.16.1 zipp-3.1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\n",
      "\u001b[0m#\n",
      "# To activate this environment, use:\n",
      "# > source activate /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e\n",
      "#\n",
      "# To deactivate an active environment, use:\n",
      "# > source deactivate\n",
      "#\n",
      "\n",
      "\n",
      "Removing intermediate container 75b154f6541a\n",
      " ---> 00371a6e2d79\n",
      "Step 9/15 : ENV PATH /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e/bin:$PATH\n",
      " ---> Running in 770e24e720a5\n",
      "Removing intermediate container 770e24e720a5\n",
      " ---> 7c2b537ea211\n",
      "Step 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e\n",
      " ---> Running in 611f6fced5d7\n",
      "Removing intermediate container 611f6fced5d7\n",
      " ---> 829052d6621d\n",
      "Step 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in d5d352d2f2f7\n",
      "Removing intermediate container d5d352d2f2f7\n",
      " ---> 6deb097054aa\n",
      "Step 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 187e5cfee18f\n",
      "Step 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit \"--repositories\" \"[]\" /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 9a875e344b03\n",
      "Removing intermediate container 9a875e344b03\n",
      " ---> cc6eed90f7f0\n",
      "Step 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 1a2e7a843cd1\n",
      "Removing intermediate container 1a2e7a843cd1\n",
      " ---> 93a74a5961cf\n",
      "Step 15/15 : CMD [\"bash\"]\n",
      " ---> Running in f0ea6b9619c6\n",
      "Removing intermediate container f0ea6b9619c6\n",
      " ---> afa0429d2e2c\n",
      "Successfully built afa0429d2e2c\n",
      "Successfully tagged machinelearnc5ceeadf.azurecr.io/azureml/azureml_25db707bbbfa2a62132a58e7c231c3f6:latest\n",
      "2020/04/20 16:59:58 Successfully executed container: acb_step_0\n",
      "2020/04/20 16:59:58 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/04/20 16:59:58 Pushing image: machinelearnc5ceeadf.azurecr.io/azureml/azureml_25db707bbbfa2a62132a58e7c231c3f6:latest, attempt 1\n",
      "The push refers to repository [machinelearnc5ceeadf.azurecr.io/azureml/azureml_25db707bbbfa2a62132a58e7c231c3f6]\n",
      "f55d48c6d782: Preparing\n",
      "800a7161b832: Preparing\n",
      "fe15bbefe726: Preparing\n",
      "e941dbb5eb28: Preparing\n",
      "88dcd1a32a5b: Preparing\n",
      "08063ba16055: Preparing\n",
      "e1171d4d60ca: Preparing\n",
      "6ef1a8ae63b7: Preparing\n",
      "85389f9ead9e: Preparing\n",
      "f2608f66a0e3: Preparing\n",
      "0e259b09e5f4: Preparing\n",
      "340dc32eb998: Preparing\n",
      "df18b66efaa6: Preparing\n",
      "ccdb13a20bf2: Preparing\n",
      "9513cdf4e497: Preparing\n",
      "7f083f9454c0: Preparing\n",
      "29f36b5893dc: Preparing\n",
      "08063ba16055: Waiting\n",
      "e1171d4d60ca: Waiting\n",
      "6ef1a8ae63b7: Waiting\n",
      "85389f9ead9e: Waiting\n",
      "f2608f66a0e3: Waiting\n",
      "0e259b09e5f4: Waiting\n",
      "340dc32eb998: Waiting\n",
      "df18b66efaa6: Waiting\n",
      "ccdb13a20bf2: Waiting\n",
      "9513cdf4e497: Waiting\n",
      "7f083f9454c0: Waiting\n",
      "29f36b5893dc: Waiting\n",
      "f55d48c6d782: Pushed\n",
      "fe15bbefe726: Pushed\n",
      "88dcd1a32a5b: Pushed\n",
      "e941dbb5eb28: Pushed\n",
      "08063ba16055: Pushed\n",
      "e1171d4d60ca: Pushed\n",
      "6ef1a8ae63b7: Pushed\n",
      "340dc32eb998: Pushed\n",
      "85389f9ead9e: Pushed\n",
      "ccdb13a20bf2: Pushed\n",
      "9513cdf4e497: Pushed\n",
      "0e259b09e5f4: Pushed\n",
      "f2608f66a0e3: Pushed\n",
      "7f083f9454c0: Pushed\n",
      "\n",
      "29f36b5893dc: Pushed\n",
      "df18b66efaa6: Pushed\n",
      "800a7161b832: Pushed\n",
      "latest: digest: sha256:965429143f86820e4838d07e2d5b03ec38818a37342546db6aba4dd7ad4f3dfb size: 3883\n",
      "2020/04/20 17:02:26 Successfully pushed image: machinelearnc5ceeadf.azurecr.io/azureml/azureml_25db707bbbfa2a62132a58e7c231c3f6:latest\n",
      "2020/04/20 17:02:26 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 224.761169)\n",
      "2020/04/20 17:02:26 Populating digests for step ID: acb_step_0...\n",
      "2020/04/20 17:02:28 Successfully populated digests for step ID: acb_step_0\n",
      "2020/04/20 17:02:28 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 148.534159)\n",
      "2020/04/20 17:02:28 The following dependencies were found:\n",
      "2020/04/20 17:02:28 \n",
      "- image:\n",
      "    registry: machinelearnc5ceeadf.azurecr.io\n",
      "    repository: azureml/azureml_25db707bbbfa2a62132a58e7c231c3f6\n",
      "    tag: latest\n",
      "    digest: sha256:965429143f86820e4838d07e2d5b03ec38818a37342546db6aba4dd7ad4f3dfb\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/base\n",
      "    tag: intelmpi2018.3-ubuntu16.04\n",
      "    digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: cb4 was successful after 6m20s\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt\n",
      "========================================================================================================================\n",
      "2020-04-20T17:02:58Z Starting output-watcher...\n",
      "2020-04-20T17:02:59Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_25db707bbbfa2a62132a58e7c231c3f6\n",
      "a1298f4ce990: Already exists\n",
      "04a3282d9c4b: Already exists\n",
      "9b0d3db6dc03: Already exists\n",
      "8269c605f3f1: Already exists\n",
      "6504d449e70c: Already exists\n",
      "4e38f320d0d4: Already exists\n",
      "b0a763e8ee03: Already exists\n",
      "11917a028ca4: Already exists\n",
      "a6c378d11cbf: Already exists\n",
      "6cc007ad9140: Already exists\n",
      "6c1698a608f3: Already exists\n",
      "054adbce7d6e: Pulling fs layer\n",
      "e7b5162c62f3: Pulling fs layer\n",
      "2ad23120aa0f: Pulling fs layer\n",
      "da198e36f7b0: Pulling fs layer\n",
      "78270b8edf63: Pulling fs layer\n",
      "e742bfb7b9cc: Pulling fs layer\n",
      "da198e36f7b0: Waiting\n",
      "78270b8edf63: Waiting\n",
      "e742bfb7b9cc: Waiting\n",
      "e7b5162c62f3: Verifying Checksum\n",
      "e7b5162c62f3: Download complete\n",
      "054adbce7d6e: Verifying Checksum\n",
      "054adbce7d6e: Download complete\n",
      "054adbce7d6e: Pull complete\n",
      "e7b5162c62f3: Pull complete\n",
      "2ad23120aa0f: Verifying Checksum\n",
      "2ad23120aa0f: Download complete\n",
      "2ad23120aa0f: Pull complete\n",
      "da198e36f7b0: Verifying Checksum\n",
      "da198e36f7b0: Download complete\n",
      "da198e36f7b0: Pull complete\n",
      "e742bfb7b9cc: Verifying Checksum\n",
      "e742bfb7b9cc: Download complete\n",
      "78270b8edf63: Verifying Checksum\n",
      "78270b8edf63: Download complete\n",
      "78270b8edf63: Pull complete\n",
      "e742bfb7b9cc: Pull complete\n",
      "Digest: sha256:965429143f86820e4838d07e2d5b03ec38818a37342546db6aba4dd7ad4f3dfb\n",
      "Status: Downloaded newer image for machinelearnc5ceeadf.azurecr.io/azureml/azureml_25db707bbbfa2a62132a58e7c231c3f6:latest\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt\n",
      "===============================================================================================================\n",
      "Starting job_prep.py script\n",
      "Starting job preparation. Current time:2020-04-20T17:04:44.462842\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: f6527603-1428-4478-a885-9d0080b65cdc\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 75\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "Download from datastores if requested.\n",
      "Acquired lockfile /tmp/d3d253d8-f099-4441-b09c-0e12de2c9428-datastore.lock to downloading input data references\n",
      "Download or mount from datasets if requested.\n",
      "Job preparation is complete. Current time:2020-04-20T17:04:49.205154\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "Initialize DatasetContextManager.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 125\n",
      "Enter __enter__ of DatasetContextManager\n",
      "SDK version: azureml-core==1.3.0.post1 azureml-dataprep==1.4.6\n",
      "Processing 'diabetes_train'\n",
      "Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('datalakestoragegen2', 'platinum/diabetes.parquet')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"0fb901ef-11b7-4b1a-8e9f-f1012f27d6c3\",\n",
      "    \"name\": null,\n",
      "    \"version\": null,\n",
      "    \"workspace\": \"Workspace.create(name='machine_learning_workspace4', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup4')\"\n",
      "  }\n",
      "}\n",
      "Looking for variable: AZUREML_DATAREFERENCE_diabetes_train_0\n",
      "Variable value: None\n",
      "Mounting diabetes_train to /mnt/data\n",
      "Mounted diabetes_train to /mnt/data\n",
      "Exit __enter__ of DatasetContextManager\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ train_diabetes.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace4/azureml/d3d253d8-f099-4441-b09c-0e12de2c9428/mounts/datalakestoragegen2/azureml/d3d253d8-f099-4441-b09c-0e12de2c9428/model_folder']\n",
      "After variable expansion, calling script [ train_diabetes.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace4/azureml/d3d253d8-f099-4441-b09c-0e12de2c9428/mounts/datalakestoragegen2/azureml/d3d253d8-f099-4441-b09c-0e12de2c9428/model_folder']\n",
      "\n",
      "Loading Data...\n",
      "delta lake mounted...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8906666666666667\n",
      "AUC: 0.877118264590278\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.39716506004333496 seconds\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 125\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/data.\n",
      "Finishing unmounting /mnt/data.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "Engine process terminated with returncode=0\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt\n",
      "===============================================================================================================\n",
      "Starting job release. Current time:2020-04-20T17:05:33.834370\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 389\n",
      "Job release is complete. Current time:2020-04-20T17:05:36.753009\n",
      "\n",
      "StepRun(Train Model) Execution Summary\n",
      "=======================================\n",
      "StepRun( Train Model ) Status: Finished\n",
      "{'runId': 'd3d253d8-f099-4441-b09c-0e12de2c9428', 'target': 'aml-cluster', 'status': 'Completed', 'startTimeUtc': '2020-04-20T17:02:58.926074Z', 'endTimeUtc': '2020-04-20T17:06:42.732536Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'f6527603-1428-4478-a885-9d0080b65cdc', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': 'd9447ed8-c689-418f-a7ba-60ba05c743a8', '_azureml.ComputeTargetType': 'amlcompute', 'AzureML.DerivedImageName': 'azureml/azureml_25db707bbbfa2a62132a58e7c231c3f6', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '0fb901ef-11b7-4b1a-8e9f-f1012f27d6c3'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes_train', 'mechanism': 'Mount', 'pathOnCompute': '/mnt/data'}}], 'runDefinition': {'script': 'train_diabetes.py', 'useAbsolutePath': False, 'arguments': ['--output_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster', 'dataReferences': {'model_folder': {'dataStoreName': 'datalakestoragegen2', 'mode': 'Mount', 'pathOnDataStore': 'azureml/d3d253d8-f099-4441-b09c-0e12de2c9428/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'diabetes_train': {'dataLocation': {'dataset': {'id': '0fb901ef-11b7-4b1a-8e9f-f1012f27d6c3'}, 'dataPath': None}, 'createOutputDirectories': False, 'mechanism': 'Mount', 'environmentVariableName': 'diabetes_train', 'pathOnCompute': '/mnt/data', 'overwrite': False}}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment diabetes-training-pipeline Environment', 'version': 'Autosave_2020-04-20T16:55:42Z_53687263', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults', 'azureml-dataprep[pandas,fuse]', 'pyarrow', 'fastparquet']}, 'scikit-learn', 'joblib'], 'name': 'azureml_b9a1534962684a800c586e9fce04292e'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d3d253d8-f099-4441-b09c-0e12de2c9428/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=3KqVr%2FjjTGZfc44ixQAppVX%2FDGmoVucM0jarU63mEEg%3D&st=2020-04-20T16%3A56%3A49Z&se=2020-04-21T01%3A06%3A49Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d3d253d8-f099-4441-b09c-0e12de2c9428/azureml-logs/55_azureml-execution-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt?sv=2019-02-02&sr=b&sig=%2Fxdz5B0ntj5bfRL4gHPPmWuhA65CRyXPhIYNhhLLXEU%3D&st=2020-04-20T16%3A56%3A49Z&se=2020-04-21T01%3A06%3A49Z&sp=r', 'azureml-logs/65_job_prep-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d3d253d8-f099-4441-b09c-0e12de2c9428/azureml-logs/65_job_prep-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt?sv=2019-02-02&sr=b&sig=13mVzkU8ywa1vEy00zMqK7PcAl5plROF3EHi47jWkO4%3D&st=2020-04-20T16%3A56%3A49Z&se=2020-04-21T01%3A06%3A49Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d3d253d8-f099-4441-b09c-0e12de2c9428/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=1EpsrGN77OA7xeJ0hw4IfvKiqyLHe1JRINCDgBCz3q0%3D&st=2020-04-20T16%3A56%3A49Z&se=2020-04-21T01%3A06%3A49Z&sp=r', 'azureml-logs/75_job_post-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d3d253d8-f099-4441-b09c-0e12de2c9428/azureml-logs/75_job_post-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt?sv=2019-02-02&sr=b&sig=Qp%2BBjnSPZ8BoRO43NXLqaPWaBJo%2BlchxAw46adnb4GI%3D&st=2020-04-20T16%3A56%3A49Z&se=2020-04-21T01%3A06%3A49Z&sp=r', 'azureml-logs/process_info.json': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d3d253d8-f099-4441-b09c-0e12de2c9428/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=GzGiytmfcUsZeKptteb3QeTPxoiZKtB52wkSHTsdfNE%3D&st=2020-04-20T16%3A56%3A49Z&se=2020-04-21T01%3A06%3A49Z&sp=r', 'azureml-logs/process_status.json': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d3d253d8-f099-4441-b09c-0e12de2c9428/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=JSOu6o0w0wC1idddjbXQw4pOhzk0HEKCides54Fw1M8%3D&st=2020-04-20T16%3A56%3A49Z&se=2020-04-21T01%3A06%3A49Z&sp=r', 'logs/azureml/125_azureml.log': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d3d253d8-f099-4441-b09c-0e12de2c9428/logs/azureml/125_azureml.log?sv=2019-02-02&sr=b&sig=wtbPZgvABVBN265bwUKo%2FD%2BekkhCo9CJlHD%2Bn0Se9GI%3D&st=2020-04-20T16%3A56%3A49Z&se=2020-04-21T01%3A06%3A49Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d3d253d8-f099-4441-b09c-0e12de2c9428/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=M61ww%2FgcaUTv5XKaeagOrRh6Lrkxq2%2B2VT6SG0SIYTY%3D&st=2020-04-20T16%3A56%3A49Z&se=2020-04-21T01%3A06%3A49Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d3d253d8-f099-4441-b09c-0e12de2c9428/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=VaRt%2FUJzdy5%2B4Ec5%2Fi%2F7eWc3sx2xiLcbLnqW1IB74Qk%3D&st=2020-04-20T16%3A56%3A49Z&se=2020-04-21T01%3A06%3A49Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d3d253d8-f099-4441-b09c-0e12de2c9428/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=hoolQ1KOxXZL%2B0Uuln0t9%2BDAXHQaQzucvEQ9UMjyCcg%3D&st=2020-04-20T16%3A56%3A49Z&se=2020-04-21T01%3A06%3A49Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d3d253d8-f099-4441-b09c-0e12de2c9428/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=c3WHrvJZCP0AYl7rQ8DI3B%2BxoyXFYPCPsZvP0MhpXMI%3D&st=2020-04-20T16%3A56%3A49Z&se=2020-04-21T01%3A06%3A49Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d3d253d8-f099-4441-b09c-0e12de2c9428/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=voBQ0ccjEMW84kVJYQ7wudkAAct9YbmNjaEyCiRUo4I%3D&st=2020-04-20T16%3A56%3A49Z&se=2020-04-21T01%3A06%3A49Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: a98df897-13ea-4bb1-87e3-e89dee6b7e0b\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/a98df897-13ea-4bb1-87e3-e89dee6b7e0b?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup4/workspaces/machine_learning_workspace4\n",
      "StepRun( Register Model ) Status: NotStarted\n",
      "StepRun( Register Model ) Status: Queued\n",
      "StepRun( Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt\n",
      "========================================================================================================================\n",
      "2020-04-20T17:07:27Z Starting output-watcher...\n",
      "2020-04-20T17:07:27Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_25db707bbbfa2a62132a58e7c231c3f6\n",
      "Digest: sha256:965429143f86820e4838d07e2d5b03ec38818a37342546db6aba4dd7ad4f3dfb\n",
      "Status: Image is up to date for machinelearnc5ceeadf.azurecr.io/azureml/azureml_25db707bbbfa2a62132a58e7c231c3f6:latest\n",
      "d3b6823aa9c0c1ba885cf79e45e76fafab36db3338fb367c3fdfda6294a2c68d\n",
      "2020/04/20 17:07:30 Version: 3.0.01196.0002 Branch: hotfix1 Commit: bc95bff5\n",
      "2020/04/20 17:07:30 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2020/04/20 17:07:30 sshd runtime has already been installed in the container\n",
      "ssh-keygen: /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "ssh-keygen: /azureml-envs/azureml_b9a1534962684a800c586e9fce04292e/lib/libcrypto.so.1.0.0: no version information available (required by ssh-keygen)\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt\n",
      "===============================================================================================================\n",
      "Starting job_prep.py script\n",
      "Starting job preparation. Current time:2020-04-20T17:07:33.519168\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: f6527603-1428-4478-a885-9d0080b65cdc\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 75\n",
      "Starting project file download.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt\n",
      "===============================================================================================================\n",
      "Starting job release. Current time:2020-04-20T17:07:50.947330\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 152\n",
      "Job release is complete. Current time:2020-04-20T17:07:52.894787\n",
      "\n",
      "StepRun(Register Model) Execution Summary\n",
      "==========================================\n",
      "StepRun( Register Model ) Status: Finished\n",
      "{'runId': 'a98df897-13ea-4bb1-87e3-e89dee6b7e0b', 'target': 'aml-cluster', 'status': 'Completed', 'startTimeUtc': '2020-04-20T17:07:26.847008Z', 'endTimeUtc': '2020-04-20T17:07:56.744265Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': 'f6527603-1428-4478-a885-9d0080b65cdc', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': 'd9447ed8-c689-418f-a7ba-60ba05c743a8', '_azureml.ComputeTargetType': 'amlcompute', 'AzureML.DerivedImageName': 'azureml/azureml_25db707bbbfa2a62132a58e7c231c3f6', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'runDefinition': {'script': 'register_diabetes.py', 'useAbsolutePath': False, 'arguments': ['--model_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster', 'dataReferences': {'model_folder': {'dataStoreName': 'datalakestoragegen2', 'mode': 'Mount', 'pathOnDataStore': 'azureml/d3d253d8-f099-4441-b09c-0e12de2c9428/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment diabetes-training-pipeline Environment', 'version': 'Autosave_2020-04-20T16:55:42Z_53687263', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults', 'azureml-dataprep[pandas,fuse]', 'pyarrow', 'fastparquet']}, 'scikit-learn', 'joblib'], 'name': 'azureml_b9a1534962684a800c586e9fce04292e'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.a98df897-13ea-4bb1-87e3-e89dee6b7e0b/azureml-logs/55_azureml-execution-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt?sv=2019-02-02&sr=b&sig=8CtKdoE3P5t1kxeb1ca%2BJv0%2FICSx9YSm2tBZPUM3ioc%3D&st=2020-04-20T16%3A58%3A15Z&se=2020-04-21T01%3A08%3A15Z&sp=r', 'azureml-logs/65_job_prep-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.a98df897-13ea-4bb1-87e3-e89dee6b7e0b/azureml-logs/65_job_prep-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt?sv=2019-02-02&sr=b&sig=29QriIW%2B5V%2BLdNeS7YH8zHOPyEEUkWj4Ikk103fuCnA%3D&st=2020-04-20T16%3A58%3A15Z&se=2020-04-21T01%3A08%3A15Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.a98df897-13ea-4bb1-87e3-e89dee6b7e0b/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=ERowO%2F2X4RQJCu7UY81DkIfVoQziuKAw4FhXq%2BXTbWo%3D&st=2020-04-20T16%3A58%3A15Z&se=2020-04-21T01%3A08%3A15Z&sp=r', 'azureml-logs/75_job_post-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.a98df897-13ea-4bb1-87e3-e89dee6b7e0b/azureml-logs/75_job_post-tvmps_b8866aaa807c663004dafc0cfd1578194868072477aa849a9ae832d9e347ee40_d.txt?sv=2019-02-02&sr=b&sig=AGwocelhqBnuciu9FAmdrVncyVMrQTX42R5KMg5Opmc%3D&st=2020-04-20T16%3A58%3A15Z&se=2020-04-21T01%3A08%3A15Z&sp=r', 'azureml-logs/process_info.json': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.a98df897-13ea-4bb1-87e3-e89dee6b7e0b/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=73io8qQoNIjTBukjRJRE6OWHm85%2FROJ9sT6er0l8iGw%3D&st=2020-04-20T16%3A58%3A15Z&se=2020-04-21T01%3A08%3A15Z&sp=r', 'azureml-logs/process_status.json': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.a98df897-13ea-4bb1-87e3-e89dee6b7e0b/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=u1YUf2D6taQCaa3QsqktCvjmrhHbDwrLeCH7dys%2BkXo%3D&st=2020-04-20T16%3A58%3A15Z&se=2020-04-21T01%3A08%3A15Z&sp=r', 'logs/azureml/125_azureml.log': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.a98df897-13ea-4bb1-87e3-e89dee6b7e0b/logs/azureml/125_azureml.log?sv=2019-02-02&sr=b&sig=9phb5FcaCJ2A%2B4c%2B6ezAGitOjbeshDzsl%2FSdULjayTY%3D&st=2020-04-20T16%3A58%3A15Z&se=2020-04-21T01%3A08%3A15Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.a98df897-13ea-4bb1-87e3-e89dee6b7e0b/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=2HqaOL2r4pwgYrM%2FoF8dAanWXR9SJmk1Nni5yRokN3o%3D&st=2020-04-20T16%3A58%3A15Z&se=2020-04-21T01%3A08%3A15Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.a98df897-13ea-4bb1-87e3-e89dee6b7e0b/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=yz%2BCi%2B%2BUdM1FXZ%2BzGXpoPdAxgTddsOcltSzzIOkyOzU%3D&st=2020-04-20T16%3A58%3A15Z&se=2020-04-21T01%3A08%3A15Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.a98df897-13ea-4bb1-87e3-e89dee6b7e0b/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=t1yEaFc5rgCb0jOXSmzc%2B2BQ2s4IjprV%2BuP50pi%2F4Go%3D&st=2020-04-20T16%3A58%3A15Z&se=2020-04-21T01%3A08%3A15Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.a98df897-13ea-4bb1-87e3-e89dee6b7e0b/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=8%2Fj%2BwoJhC6yEUMFji0%2FCwKZsTHEV5%2B4G9EDQbVnuSVA%3D&st=2020-04-20T16%3A58%3A15Z&se=2020-04-21T01%3A08%3A15Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.a98df897-13ea-4bb1-87e3-e89dee6b7e0b/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=Ha15YxOF2Dq15WgVzKOOyRC1ITuNYgDfeFIE8%2BZcoKA%3D&st=2020-04-20T16%3A58%3A15Z&se=2020-04-21T01%3A08%3A15Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'd9447ed8-c689-418f-a7ba-60ba05c743a8', 'status': 'Completed', 'startTimeUtc': '2020-04-20T16:55:17.545117Z', 'endTimeUtc': '2020-04-20T17:08:15.049055Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d9447ed8-c689-418f-a7ba-60ba05c743a8/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=xRdXxj8K9Nyju2kjC1VTAAE4486jtAkRkew34OmnReU%3D&st=2020-04-20T16%3A58%3A16Z&se=2020-04-21T01%3A08%3A16Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d9447ed8-c689-418f-a7ba-60ba05c743a8/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=%2BYgjjbC1W%2Bpi6t09radcK5kHZv3Zd7%2BxEVoywRfv%2FIU%3D&st=2020-04-20T16%3A58%3A16Z&se=2020-04-21T01%3A08%3A16Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.d9447ed8-c689-418f-a7ba-60ba05c743a8/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=BUBVq11QNhwWrdapeJxMJSAn%2FOAH6eL7IvypMxBt56Y%3D&st=2020-04-20T16%3A58%3A16Z&se=2020-04-21T01%3A08%3A16Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show run details\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### publish pipeline\n",
    "\n",
    "publish pipeline as a REST service endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourceGroups/myResourceGroup4/providers/Microsoft.MachineLearningServices/workspaces/machine_learning_workspace4/PipelineRuns/PipelineSubmit/fea492c4-40bf-4740-aa79-2c778fe7c64d\n"
     ]
    }
   ],
   "source": [
    "published_pipeline = pipeline.publish(name=\"Diabetes_Training_Pipeline\",\n",
    "                                      description=\"Trains diabetes model\",\n",
    "                                      version=\"1.0\")\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### call pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20e79c0f-ab5c-4e0c-80eb-96bb1acbecf2'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = 'Run-diabetes-pipeline'\n",
    "\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you have the run ID, you can use the RunDetails widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ac9806947f4e6eb777c8441c93ba8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/Run-diabetes-pipeline/runs/20e79c0f-ab5c-4e0c-80eb-96bb1acbecf2?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup4/workspaces/machine_learning_workspace4\", \"run_id\": \"20e79c0f-ab5c-4e0c-80eb-96bb1acbecf2\", \"run_properties\": {\"run_id\": \"20e79c0f-ab5c-4e0c-80eb-96bb1acbecf2\", \"created_utc\": \"2020-04-20T17:09:57.472323Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"Unavailable\", \"runType\": \"HTTP\", \"azureml.parameters\": \"{}\", \"azureml.pipelineid\": \"fea492c4-40bf-4740-aa79-2c778fe7c64d\"}, \"tags\": {\"azureml.pipelineid\": \"fea492c4-40bf-4740-aa79-2c778fe7c64d\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2020-04-20T17:10:15.547012Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.20e79c0f-ab5c-4e0c-80eb-96bb1acbecf2/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=sI9tqdD5SQVN3AkPRiDu5ISJZ4I75UlfrSenrR51cgM%3D&st=2020-04-20T17%3A00%3A25Z&se=2020-04-21T01%3A10%3A25Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.20e79c0f-ab5c-4e0c-80eb-96bb1acbecf2/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=7Ft%2FBWbwg8%2BDkk7yo8KRhqFEyndVeu08dvlBuDPBJLk%3D&st=2020-04-20T17%3A00%3A25Z&se=2020-04-21T01%3A10%3A25Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://machinelstorage7defa4bf6.blob.core.windows.net/azureml/ExperimentRun/dcid.20e79c0f-ab5c-4e0c-80eb-96bb1acbecf2/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=9hdYfDqg9P5IHcg0gkQfgLRB%2F137zcWmR32Op48LSrE%3D&st=2020-04-20T17%3A00%3A25Z&se=2020-04-21T01%3A10%3A25Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:00:18\"}, \"child_runs\": [{\"run_id\": \"93c06a9d-5aca-4a59-97f9-dc4a2a9afbbc\", \"name\": \"Train Model\", \"status\": \"Finished\", \"start_time\": \"2020-04-20T17:10:11.180717Z\", \"created_time\": \"2020-04-20T17:10:11.180717Z\", \"end_time\": \"2020-04-20T17:10:11.271026Z\", \"duration\": \"0:00:00\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-04-20T17:10:11.180717Z\", \"is_reused\": \"Yes\"}, {\"run_id\": \"f3eda5b0-75a7-4459-b6df-a95af41b5d2b\", \"name\": \"Register Model\", \"status\": \"Finished\", \"start_time\": \"2020-04-20T17:10:15.068664Z\", \"created_time\": \"2020-04-20T17:10:15.068664Z\", \"end_time\": \"2020-04-20T17:10:15.168676Z\", \"duration\": \"0:00:00\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-04-20T17:10:15.068664Z\", \"is_reused\": \"Yes\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2020-04-20 17:10:11Z] Completing processing run id 93c06a9d-5aca-4a59-97f9-dc4a2a9afbbc.\\n[2020-04-20 17:10:15Z] Completing processing run id f3eda5b0-75a7-4459-b6df-a95af41b5d2b.\\n[2020-04-20 17:10:15Z] Finishing experiment: no runs left and nothing to schedule.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"65a4d2ff\": {\"node_id\": \"65a4d2ff\", \"name\": \"0fb901ef-11b7-4b1a-8e9f-f1012f27d6c3\"}}, \"module_nodes\": {\"fc8c6401\": {\"node_id\": \"fc8c6401\", \"name\": \"Train Model\", \"status\": \"Finished\", \"_is_reused\": true, \"run_id\": \"93c06a9d-5aca-4a59-97f9-dc4a2a9afbbc\"}, \"946d0f72\": {\"node_id\": \"946d0f72\", \"name\": \"Register Model\", \"status\": \"Finished\", \"_is_reused\": true, \"run_id\": \"f3eda5b0-75a7-4459-b6df-a95af41b5d2b\"}}, \"edges\": [{\"source_node_id\": \"65a4d2ff\", \"source_node_name\": \"0fb901ef-11b7-4b1a-8e9f-f1012f27d6c3\", \"source_name\": \"data\", \"target_name\": \"diabetes_train\", \"dst_node_id\": \"fc8c6401\", \"dst_node_name\": \"Train Model\"}, {\"source_node_id\": \"fc8c6401\", \"source_node_name\": \"Train Model\", \"source_name\": \"model_folder\", \"target_name\": \"model_folder\", \"dst_node_id\": \"946d0f72\", \"dst_node_name\": \"Register Model\"}], \"child_runs\": [{\"run_id\": \"93c06a9d-5aca-4a59-97f9-dc4a2a9afbbc\", \"name\": \"Train Model\", \"status\": \"Finished\", \"start_time\": \"2020-04-20T17:10:11.180717Z\", \"created_time\": \"2020-04-20T17:10:11.180717Z\", \"end_time\": \"2020-04-20T17:10:11.271026Z\", \"duration\": \"0:00:00\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-04-20T17:10:11.180717Z\", \"is_reused\": \"Yes\"}, {\"run_id\": \"f3eda5b0-75a7-4459-b6df-a95af41b5d2b\", \"name\": \"Register Model\", \"status\": \"Finished\", \"start_time\": \"2020-04-20T17:10:15.068664Z\", \"created_time\": \"2020-04-20T17:10:15.068664Z\", \"end_time\": \"2020-04-20T17:10:15.168676Z\", \"duration\": \"0:00:00\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2020-04-20T17:10:15.068664Z\", \"is_reused\": \"Yes\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.3.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
    "RunDetails(published_pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py36_automl",
   "language": "python",
   "name": "conda-env-azureml_py36_automl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
