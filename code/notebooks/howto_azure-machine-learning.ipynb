{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Kevin ALBERT  \n",
    "\n",
    "Created: April 2020  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest TestRun: 05 Apr 2022\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print ('latest TestRun: ' + datetime.now().strftime(\"%d %b %Y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning\n",
    "_**Classification project with data residing on a data lake gen2 using remote compute with autoML and customML**_\n",
    "\n",
    "## Contents\n",
    "1. [AutoML](#AutoML)\n",
    "1. [Setup](#Setup)\n",
    "1. [Train](#Train)\n",
    "1. [Results](#Results)\n",
    "1. [Register](#Register)\n",
    "1. [Deploy](#Deploy)\n",
    "1. [Test](#Test)\n",
    "1. [CustomML](#CustomML)\n",
    "1. [Finetuning](#Finetuning)\n",
    "1. [Pipelines](#Pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Cleaned datasets created in datafactory onto a delta lake Gen2.  \n",
    "This notebook is using delta lake data and remote compute to autoML train a classification model.  \n",
    "We use example data to detect diabetic or non-diabetic based on 8 features.  \n",
    "\n",
    "This notebook show how to:\n",
    "1. Setup packages\n",
    "1. Setup workspace\n",
    "1. Create an experiment\n",
    "1. Load data\n",
    "1. Setup compute\n",
    "1. Configure autoML\n",
    "1. Train pipelines\n",
    "1. Explore the best pipeline\n",
    "1. Inspect model properties\n",
    "1. Register the model\n",
    "1. Deploy model as webservice\n",
    "1. Webservice inference test\n",
    "1. customML inline method\n",
    "1. customML script method\n",
    "1. HyperParametertuning\n",
    "1. Pipelines endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* required\n",
    "  * **disable shield on Brave** webbrowser for the widgets to work\n",
    "  * download **config.json** from the machine learning workspace portal\n",
    "  * install extra azureml packages on **py37_default** when using **'local'** compute  \n",
    "  * split the data up in train and test dataset on data lake, validation dataset is not needed due to cross_validation\n",
    "* optional\n",
    "  * register datastore(s) manually\n",
    "  * register dataset(s) manually\n",
    "  * register compute cluster(s) manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import open-source packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment packages\n",
    "import platform\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "# other packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_colwidth', 100) # default 50, the maximum width in characters of a column\n",
    "pd.set_option('display.max_columns', 40)   # default 20, the maximum amount of columns in view \n",
    "pd.set_option('display.max_rows', 60)      # default 60, the maximum amount of rows in view\n",
    "import logging\n",
    "import json\n",
    "import requests\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import azure machine learning SDK packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml.core version: 1.40.0\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Dataset, Datastore, Run\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute, AksCompute\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.webservice import Webservice, AciWebservice, AksWebservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling, GridParameterSampling\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.pipeline.core import PipelineData, Pipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.interpret import ExplanationClient\n",
    "import azureml.core\n",
    "print(\"azureml.core version:\", azureml.core.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda   : 4.12.0\n",
      "pip     : 20.2.4\n",
      "python  : 3.8.13\n",
      "pandas  : 1.1.5\n",
      "numpy   : 1.19.5\n",
      "sklearn : 0.22.2.post1\n",
      "azureml-automl-core                   1.40.0\n",
      "azureml-automl-runtime                1.40.0\n",
      "azureml-contrib-automl-pipeline-steps 1.40.0\n",
      "azureml-contrib-dataset               1.40.0\n",
      "azureml-core                          1.40.0\n",
      "azureml-dataprep                      3.0.1\n",
      "azureml-dataprep-native               38.0.0\n",
      "azureml-dataprep-rslex                2.4.1\n",
      "azureml-dataset-runtime               1.40.0\n",
      "azureml-defaults                      1.40.0\n",
      "azureml-inference-server-http         0.4.11\n",
      "azureml-interpret                     1.40.0\n",
      "azureml-mlflow                        1.40.0\n",
      "azureml-pipeline-core                 1.40.0\n",
      "azureml-pipeline-steps                1.40.0\n",
      "azureml-telemetry                     1.40.0\n",
      "azureml-train-automl-client           1.40.0\n",
      "azureml-train-automl-runtime          1.40.0.post1\n",
      "azureml-train-core                    1.40.0\n",
      "azureml-train-restclients-hyperdrive  1.40.0\n",
      "azureml-training-tabular              1.40.0\n",
      "azureml-widgets                       1.40.0\n"
     ]
    }
   ],
   "source": [
    "conda_version = ! conda -V\n",
    "print(f\"conda   : {conda_version[0].split()[1]}\")\n",
    "pip_version = ! pip -V\n",
    "print(f\"pip     : {pip_version[0].split()[1]}\")\n",
    "python_version = ! python -V\n",
    "print(f\"python  : {python_version[0].split()[1]}\")\n",
    "pandas_version = ! pip list |grep -ie \"^pandas \"\n",
    "print(f\"pandas  : {pandas_version[0].split()[1]}\")\n",
    "numpy_version = ! pip list |grep -ie \"^numpy \"\n",
    "print(f\"numpy   : {numpy_version[0].split()[1]}\")\n",
    "sklearn_version = ! pip list |grep -ie \"^scikit-learn \"\n",
    "print(f\"sklearn : {sklearn_version[0].split()[1]}\")\n",
    "\n",
    "!pip list |grep -i azureml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![load the workspace](../../image/howto_automl/loadtheworkspace.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Authentication \n",
    "\n",
    "Use chapter **Service Principal Authentication** in:  \n",
    "[**how to authenticate**](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/manage-azureml-service/authentication-in-azureml/authentication-in-azureml.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "\n",
    "svc_pr = ServicePrincipalAuthentication(\n",
    "    tenant_id=\"73b49191-8db3-45ab-87b3-b8f956ac123b\",\n",
    "    service_principal_id=\"d7c04ded-ec80-4e62-a9d2-423b2553b83d\",\n",
    "    service_principal_password='lar7Q~9wkWUPEK0Eb06mUDM.b~4FhR6c56fzF')\n",
    "\n",
    "ws = Workspace.from_config(auth=svc_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose an experiment name\n",
    "experiment = Experiment(ws, 'automl-classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 ubuntu root 517752 Apr  4 12:35 ../../data/platinum/diabetes.csv\r\n",
      "-rw-r--r-- 1 ubuntu root 327574 Apr  4 12:35 ../../data/platinum/diabetes.parquet\r\n"
     ]
    }
   ],
   "source": [
    "# here is a backup\n",
    "!ls -al ../../data/platinum/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Factory has prepped data from /bronze to /silver to /gold and /platinum for model training  \n",
    "**note:** this demonstration had files in the Data Lake Gen2 datalake container /platinum folder  \n",
    "  * /datalake/platinum/diabetes.csv\n",
    "  * /datalake/platinum/diabetes.parquet\n",
    "  * copy from ../data/platinum/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the datastore 'data lake gen2' as a **blob container**  \n",
    "(**optionally** use WebGUI to manually register in ML workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datalakestoragegen2': {\n",
       "   \"name\": \"datalakestoragegen2\",\n",
       "   \"container_name\": \"datalake\",\n",
       "   \"account_name\": \"datalake04042022\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " },\n",
       " 'workspaceworkingdirectory': {\n",
       "   \"name\": \"workspaceworkingdirectory\",\n",
       "   \"container_name\": \"code-391ff5ac-6576-460f-ba4d-7e03433c68b6\",\n",
       "   \"account_name\": \"machinelstorage865aef211\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " },\n",
       " 'workspacefilestore': {\n",
       "   \"name\": \"workspacefilestore\",\n",
       "   \"container_name\": \"azureml-filestore-5224a85c-9ec5-4b58-86dd-d59b28efde48\",\n",
       "   \"account_name\": \"machinelstorage865aef211\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " },\n",
       " 'workspaceartifactstore': {\n",
       "   \"name\": \"workspaceartifactstore\",\n",
       "   \"container_name\": \"azureml\",\n",
       "   \"account_name\": \"machinelstorage865aef211\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " },\n",
       " 'workspaceblobstore': {\n",
       "   \"name\": \"workspaceblobstore\",\n",
       "   \"container_name\": \"azureml-blobstore-5224a85c-9ec5-4b58-86dd-d59b28efde48\",\n",
       "   \"account_name\": \"machinelstorage865aef211\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " }}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Datastore.register_azure_blob_container(\n",
    "    workspace=ws,\n",
    "    datastore_name=\"datalakestoragegen2\",\n",
    "    container_name=\"datalake\",\n",
    "    account_name=\"datalake04042022\",\n",
    "    account_key=\"hE8pYNR4hdI6NyKq0ZaGxM8Hcj3d57XVPiGaag4ctNw2TvSqGyhpI/7Q+EJ2mVUFHVg7DQtCrS6EiM+m06DguA==\",\n",
    "    create_if_not_exists=False)\n",
    "# list available datastores\n",
    "ws.datastores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register file(s) into a tabular dataset  \n",
    "**Note:** do not import Delta lake parquet file(s)  \n",
    "**Fix:** you can import pandas single gold/*.csv or gold/*.parquet file(s)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datastore\n",
    "ds = Datastore.get(ws, 'datalakestoragegen2')\n",
    "# show datastore settings\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1 Tabular:** loading *.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('datalakestoragegen2', 'platinum/diabetes.parquet')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ReadParquetFile\",\n",
       "    \"DropColumns\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup parquet file(s) into a tabular dataset\n",
    "ds_path = [DataPath(ds, 'platinum/diabetes.parquet')] # {path/*.parquet}\n",
    "dataset = Dataset.Tabular.from_parquet_files(path=ds_path)\n",
    "# show dataset settings\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2 Tabular:** loading *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup csv file(s) into a tabular dataset\n",
    "ds_path = [DataPath(ds, 'platinum/diabetes.csv')]\n",
    "dataset = Dataset.Tabular.from_delimited_files(path=ds_path)\n",
    "# show dataset settings\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 3 Registered:** loading a registered dataset (manually register in ML workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list available datasets\n",
    "ws.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a registered dataset\n",
    "dataset = Dataset.get_by_name(ws, 'diabetes_parquet_from_datastore_datalakegen2')\n",
    "# show dataset settings\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSplit\n",
    "Split the data into (train + validation) and test  \n",
    "The model will learn from train + validation using cross validation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>PlasmaGlucose</th>\n",
       "      <th>DiastolicBloodPressure</th>\n",
       "      <th>TricepsThickness</th>\n",
       "      <th>SerumInsulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7470</th>\n",
       "      <td>1015023</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>64</td>\n",
       "      <td>45</td>\n",
       "      <td>568</td>\n",
       "      <td>20.721635</td>\n",
       "      <td>0.299076</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td>1601246</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>95</td>\n",
       "      <td>34</td>\n",
       "      <td>80</td>\n",
       "      <td>40.635156</td>\n",
       "      <td>0.281180</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>1950687</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>268</td>\n",
       "      <td>25.821359</td>\n",
       "      <td>1.243973</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>1859047</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "      <td>261</td>\n",
       "      <td>42.308540</td>\n",
       "      <td>0.103749</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>1058480</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>41</td>\n",
       "      <td>93</td>\n",
       "      <td>28.399614</td>\n",
       "      <td>0.122858</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PatientID  Pregnancies  PlasmaGlucose  DiastolicBloodPressure  \\\n",
       "7470    1015023            1             75                      64   \n",
       "6143    1601246            0            165                      95   \n",
       "5708    1950687            2            175                      63   \n",
       "5403    1859047            0            124                      53   \n",
       "2002    1058480            4            100                      70   \n",
       "\n",
       "      TricepsThickness  SerumInsulin        BMI  DiabetesPedigree  Age  \\\n",
       "7470                45           568  20.721635          0.299076   23   \n",
       "6143                34            80  40.635156          0.281180   21   \n",
       "5708                44           268  25.821359          1.243973   62   \n",
       "5403                30           261  42.308540          0.103749   25   \n",
       "2002                41            93  28.399614          0.122858   21   \n",
       "\n",
       "      Diabetic  \n",
       "7470         0  \n",
       "6143         0  \n",
       "5708         1  \n",
       "5403         0  \n",
       "2002         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all records from the dataset into a pandas DataFrame\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the target variable\n",
    "y = df[\"Diabetic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the features (x1, x2, x3, ...)\n",
    "X = df.drop('Diabetic', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3344"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the target incidence (preferred > 5%)\n",
    "np.sum(y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical: []\n",
      "numerical  : ['Age', 'BMI', 'DiabetesPedigree', 'DiastolicBloodPressure', 'PatientID', 'PlasmaGlucose', 'Pregnancies', 'SerumInsulin', 'TricepsThickness']\n"
     ]
    }
   ],
   "source": [
    "# store the dummy columns for each categorical feature\n",
    "categorical = [col for col, value in X.iteritems() if value.dtype == 'object']\n",
    "print(f\"categorical: {categorical}\")\n",
    "# store the numerical columns for each numerical feature\n",
    "numerical = list(X.columns.difference(categorical))\n",
    "print(f\"numerical  : {numerical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into (train + validation) and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,                # features\n",
    "                                                    y,                # target\n",
    "                                                    test_size=0.2,    # 20% test data records\n",
    "                                                    random_state=101, # random number generator fixed sample\n",
    "                                                    stratify=y        # same target incidence, same amount of target %\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 10)\n",
      "(2000, 10)\n"
     ]
    }
   ],
   "source": [
    "# train + validation (~we call it training_data)\n",
    "training_data = pd.concat([x_train, y_train], axis=1)\n",
    "print(training_data.shape)\n",
    "# test (~we call it validation_data)\n",
    "validation_data = pd.concat([x_test, y_test], axis=1)\n",
    "print(validation_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check possible compute type **names** to create auto-scaling cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>vCPUs</th>\n",
       "      <th>gpus</th>\n",
       "      <th>memoryGB</th>\n",
       "      <th>maxResourceVolumeMB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard_D1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>51200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Standard_D1_v2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>51200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Standard_DS1_v2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  vCPUs  gpus  memoryGB  maxResourceVolumeMB\n",
       "0       Standard_D1      1     0       3.5                51200\n",
       "13   Standard_D1_v2      1     0       3.5                51200\n",
       "41  Standard_DS1_v2      1     0       3.5                 7168"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example: list all with 1=vCPUs 2>GB and no-GPU\n",
    "vm_df = pd.DataFrame(AmlCompute.supported_vmsizes(ws))\n",
    "vm_df[(vm_df.vCPUs == 1) & (vm_df.memoryGB >= 2) & (vm_df.gpus == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option 1: Create training cluster  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress..\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "CPU times: user 59.7 ms, sys: 9.19 ms, total: 68.9 ms\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Specify a name for the compute (unique within the workspace)\n",
    "compute_name = 'aml-cluster'\n",
    "# Define compute configuration\n",
    "compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_D1_v2',\n",
    "                                                       min_nodes=0, # you are not paying if not using\n",
    "                                                       max_nodes=10, # depending quota limits\n",
    "                                                       vm_priority='dedicated', # {lowpriority, dedicated}\n",
    "                                                       admin_username='ubuntu',\n",
    "                                                       admin_user_password='ABCD1234abcd',\n",
    "                                                       idle_seconds_before_scaledown=120, # {default: 120}\n",
    "                                                      )\n",
    "# Create the compute\n",
    "training_cluster = ComputeTarget.create(ws, compute_name, compute_config)\n",
    "training_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "option 2: Load already known training cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aml-cluster\n"
     ]
    }
   ],
   "source": [
    "# list all available training cluster(s):\n",
    "for cluster in ws.compute_targets:\n",
    "    print(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training cluster\n",
    "compute_name = 'aml-cluster'\n",
    "training_cluster = ComputeTarget(ws, name=compute_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure autoML\n",
    "Define settings to run the experiment.\n",
    "\n",
    "|Property|Description|Options|\n",
    "|-|-|-|\n",
    "|**task**||<i>classification</i><br><i>regression</i><br><i>forecasting</i>|\n",
    "|**compute_target**|execution on local DSVM serialized<br>execution on remote AML or AKS parallel|<i>local</i><br><i>training_cluster</i>|\n",
    "|**primary_metric**|the metric you want to optimize<br>[metrics](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-understand-automated-ml)|**classification:**<br><i>accuracy</i><br><i>AUC_weighted</i><br><i>average_precision_score_weighted</i><br><i>norm_macro_recall</i><br><i>precision_score_weighted</i><br><br>**regression:**<br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>|\n",
    "|**training_data**|input dataset, containing both X_train and y_train|<i>DataFrame</i><br><i>Dataset</i><br><i>DatasetDefinition</i><br><i>TabularDataset</i>|\n",
    "|**validation_data**|input dataset, covered with cross validation|N/A|\n",
    "|**label_column_name**|the name of the 'target' or 'label' column||\n",
    "|**enable_early_stopping**|stop the run if metric score is not improving|<i>True</i><br><i>False</i>|\n",
    "|**n_cross_validations**|number of cross validation splits|5|\n",
    "|**experiment_timeout_hours**|max time in hours the experiment terminates (+15min)|<i>0.25</i>|\n",
    "|**max_concurrent_iterations**|less or equal to the number of cores per node|2|\n",
    "\n",
    "\n",
    "\n",
    "**_You can find more information_** [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"enable_early_stopping\":True,\n",
    "    \"experiment_timeout_hours\":0.75, # (0.75 = 45min)\n",
    "    \"iterations\":5, # number of runs\n",
    "    \"iteration_timeout_minutes\":10,\n",
    "    \"max_concurrent_iterations\":1,\n",
    "    \"max_cores_per_iteration\":-1,\n",
    "#     \"experiment_exit_score\":0.9920,\n",
    "    \"model_explainability\":True,\n",
    "#     \"n_cross_validations\":5,\n",
    "    \"primary_metric\":'AUC_weighted',\n",
    "    \"featurization\":'auto',\n",
    "    \"verbosity\":logging.INFO, # {INFO, DEBUG, CRITICAL, ERROR, WARNING} -- debug_log=<*.log>\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task='classification',\n",
    "                             debug_log='automl_errors.log',\n",
    "                             compute_target='local', # {training_cluster or 'local'}\n",
    "#                              blacklist_models=['KNN','LinearSVM'],\n",
    "                             enable_onnx_compatible_models=True,\n",
    "                             training_data=training_data, # (train + validation) will use automatic cross_validation \n",
    "                             label_column_name=\"Diabetic\",\n",
    "                             **automl_settings\n",
    "                            )\n",
    "# ouputs \"model.pkl\" and \"automl_errors.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05:11:08:44,350 INFO     [modeling_bert.py:226] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "2022-04-05:11:08:44,367 INFO     [modeling_xlnet.py:339] Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in the active local environment.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-classification</td><td>AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923</td><td>automl</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup01/workspaces/machine_learning_workspace01&amp;tid=73b49191-8db3-45ab-87b3-b8f956ac123b\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "\n",
      "********************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Cross validation\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  Each iteration of the trained model was validated through cross-validation.\n",
      "              \n",
      "DETAILS:      \n",
      "+------------------------------+\n",
      "|Number of folds               |\n",
      "+==============================+\n",
      "|3                             |\n",
      "+------------------------------+\n",
      "\n",
      "********************************************************************************************\n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and all classes are balanced in your training data.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "\n",
      "********************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "********************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "********************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "********************************************************************************************\n",
      "ITER: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "********************************************************************************************\n",
      "\n",
      " ITER   PIPELINE                                       DURATION            METRIC      BEST\n",
      "    0   MaxAbsScaler LightGBM                          0:06:29             0.9889    0.9889\n",
      "    1   MaxAbsScaler XGBoostClassifier                 0:02:51             0.9888    0.9889\n",
      "    2   MaxAbsScaler ExtremeRandomTrees                0:00:51             0.9493    0.9889\n",
      "    3   MaxAbsScaler RandomForest                      0:00:51             0.9700    0.9889\n",
      "    4   VotingEnsemble                                 0:00:43             0.9894    0.9894\n",
      "********************************************************************************************\n",
      "Current status: BestRunExplainModel. Best run model explanations started\n",
      "Current status: ModelExplanationDataSetSetup. Model explanations data setup completed\n",
      "Current status: PickSurrogateModel. Choosing LightGBM as the surrogate model for explanations\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05:11:22:33,349 INFO     [explanation_client.py:334] Using default datastore for uploads\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: EngineeredFeatureExplanations. Computation of engineered features completed\n",
      "Current status: RawFeaturesExplanations. Computation of raw features started\n",
      "Current status: RawFeaturesExplanations. Computation of raw features completed\n",
      "Current status: BestRunExplainModel. Best run model explanations completed\n",
      "********************************************************************************************\n",
      "CPU times: user 7min 26s, sys: 52.6 s, total: 8min 19s\n",
      "Wall time: 14min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "automl_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: retrieve a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "runId = 'AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923'\n",
    "automl_run = AutoMLRun(experiment, run_id=runId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the best pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89efd9425e4b4f33aa1890ff05f9f42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup01/workspaces/machine_learning_workspace01&tid=73b49191-8db3-45ab-87b3-b8f956ac123b\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"run_properties\": {\"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"created_utc\": \"2022-04-05T09:08:58.14659Z\", \"properties\": {\"num_iterations\": \"5\", \"training_type\": \"TrainFull\", \"acquisition_function\": \"EI\", \"primary_metric\": \"AUC_weighted\", \"train_split\": \"0\", \"acquisition_parameter\": \"0\", \"num_cross_validation\": null, \"target\": \"local\", \"AMLSettingsJsonString\": \"{\\\"path\\\":null,\\\"name\\\":\\\"automl-classification\\\",\\\"subscription_id\\\":\\\"43c1f93a-903d-4b23-a4bf-92bd7a150627\\\",\\\"resource_group\\\":\\\"myResourceGroup01\\\",\\\"workspace_name\\\":\\\"machine_learning_workspace01\\\",\\\"region\\\":\\\"westeurope\\\",\\\"compute_target\\\":\\\"local\\\",\\\"spark_service\\\":null,\\\"azure_service\\\":\\\"remote\\\",\\\"many_models\\\":false,\\\"pipeline_fetch_max_batch_size\\\":1,\\\"enable_batch_run\\\":false,\\\"enable_run_restructure\\\":false,\\\"start_auxiliary_runs_before_parent_complete\\\":false,\\\"enable_code_generation\\\":false,\\\"iterations\\\":5,\\\"primary_metric\\\":\\\"AUC_weighted\\\",\\\"task_type\\\":\\\"classification\\\",\\\"positive_label\\\":null,\\\"data_script\\\":null,\\\"test_size\\\":0.0,\\\"test_include_predictions_only\\\":false,\\\"validation_size\\\":0.0,\\\"n_cross_validations\\\":null,\\\"y_min\\\":null,\\\"y_max\\\":null,\\\"num_classes\\\":null,\\\"featurization\\\":\\\"auto\\\",\\\"_ignore_package_version_incompatibilities\\\":false,\\\"is_timeseries\\\":false,\\\"max_cores_per_iteration\\\":-1,\\\"max_concurrent_iterations\\\":1,\\\"iteration_timeout_minutes\\\":10,\\\"mem_in_mb\\\":null,\\\"enforce_time_on_windows\\\":false,\\\"experiment_timeout_minutes\\\":45,\\\"experiment_exit_score\\\":null,\\\"partition_column_names\\\":null,\\\"whitelist_models\\\":null,\\\"blacklist_algos\\\":[\\\"TensorFlowLinearClassifier\\\",\\\"TensorFlowDNN\\\"],\\\"supported_models\\\":[\\\"MultinomialNaiveBayes\\\",\\\"BernoulliNaiveBayes\\\",\\\"DecisionTree\\\",\\\"LogisticRegression\\\",\\\"RandomForest\\\",\\\"LightGBM\\\",\\\"XGBoostClassifier\\\",\\\"AveragedPerceptronClassifier\\\",\\\"TensorFlowLinearClassifier\\\",\\\"SVM\\\",\\\"TabnetClassifier\\\",\\\"KNN\\\",\\\"LinearSVM\\\",\\\"GradientBoosting\\\",\\\"TensorFlowDNN\\\",\\\"SGD\\\",\\\"ExtremeRandomTrees\\\"],\\\"private_models\\\":[],\\\"auto_blacklist\\\":true,\\\"blacklist_samples_reached\\\":false,\\\"exclude_nan_labels\\\":true,\\\"verbosity\\\":20,\\\"_debug_log\\\":\\\"automl_errors.log\\\",\\\"show_warnings\\\":false,\\\"model_explainability\\\":true,\\\"service_url\\\":null,\\\"sdk_url\\\":null,\\\"sdk_packages\\\":null,\\\"enable_onnx_compatible_models\\\":true,\\\"enable_split_onnx_featurizer_estimator_models\\\":false,\\\"vm_type\\\":null,\\\"telemetry_verbosity\\\":20,\\\"send_telemetry\\\":true,\\\"enable_dnn\\\":false,\\\"scenario\\\":\\\"SDK-1.13.0\\\",\\\"environment_label\\\":null,\\\"save_mlflow\\\":false,\\\"enable_categorical_indicators\\\":false,\\\"force_text_dnn\\\":false,\\\"enable_feature_sweeping\\\":false,\\\"enable_early_stopping\\\":true,\\\"early_stopping_n_iters\\\":10,\\\"arguments\\\":null,\\\"dataset_id\\\":null,\\\"hyperdrive_config\\\":null,\\\"validation_dataset_id\\\":null,\\\"run_source\\\":null,\\\"metrics\\\":null,\\\"enable_metric_confidence\\\":false,\\\"enable_ensembling\\\":true,\\\"enable_stack_ensembling\\\":false,\\\"ensemble_iterations\\\":5,\\\"enable_tf\\\":false,\\\"enable_subsampling\\\":false,\\\"subsample_seed\\\":null,\\\"enable_nimbusml\\\":false,\\\"enable_streaming\\\":false,\\\"force_streaming\\\":false,\\\"track_child_runs\\\":true,\\\"allowed_private_models\\\":[],\\\"label_column_name\\\":\\\"Diabetic\\\",\\\"weight_column_name\\\":null,\\\"cv_split_column_names\\\":null,\\\"enable_local_managed\\\":false,\\\"_local_managed_run_id\\\":null,\\\"cost_mode\\\":1,\\\"lag_length\\\":0,\\\"metric_operation\\\":\\\"maximize\\\",\\\"preprocess\\\":true}\", \"DataPrepJsonString\": null, \"EnableSubsampling\": \"False\", \"runTemplate\": \"AutoML\", \"azureml.runsource\": \"automl\", \"display_task_type\": \"classification\", \"dependencies_versions\": \"{\\\"azureml-dataprep-native\\\": \\\"38.0.0\\\", \\\"azureml-dataprep\\\": \\\"3.0.1\\\", \\\"azureml-dataprep-rslex\\\": \\\"2.4.1\\\", \\\"azureml-train-automl-runtime\\\": \\\"1.40.0.post1\\\", \\\"azureml-pipeline-steps\\\": \\\"1.40.0\\\", \\\"azureml-interpret\\\": \\\"1.40.0\\\", \\\"azureml-core\\\": \\\"1.40.0\\\", \\\"azureml-dataset-runtime\\\": \\\"1.40.0\\\", \\\"azureml-widgets\\\": \\\"1.40.0\\\", \\\"azureml-train-automl-client\\\": \\\"1.40.0\\\", \\\"azureml-defaults\\\": \\\"1.40.0\\\", \\\"azureml-telemetry\\\": \\\"1.40.0\\\", \\\"azureml-contrib-dataset\\\": \\\"1.40.0\\\", \\\"azureml-automl-runtime\\\": \\\"1.40.0\\\", \\\"azureml-training-tabular\\\": \\\"1.40.0\\\", \\\"azureml-contrib-automl-pipeline-steps\\\": \\\"1.40.0\\\", \\\"azureml-pipeline-core\\\": \\\"1.40.0\\\", \\\"azureml-train-restclients-hyperdrive\\\": \\\"1.40.0\\\", \\\"azureml-mlflow\\\": \\\"1.40.0\\\", \\\"azureml-automl-core\\\": \\\"1.40.0\\\", \\\"azureml-train-core\\\": \\\"1.40.0\\\", \\\"azureml-inference-server-http\\\": \\\"0.4.11\\\"}\", \"_aml_system_scenario_identification\": \"Local.Parent\", \"ClientSdkVersion\": \"1.40.0\", \"ClientType\": \"SDK\", \"environment_cpu_name\": \"AzureML-AutoML\", \"environment_cpu_label\": \"prod\", \"environment_gpu_name\": \"AzureML-AutoML-GPU\", \"environment_gpu_label\": \"prod\", \"root_attribution\": \"automl\", \"attribution\": \"AutoML\", \"Orchestrator\": \"AutoML\", \"_azureml.ComputeTargetType\": \"local\", \"ProblemInfoJsonString\": \"{\\\"dataset_num_categorical\\\": 0, \\\"is_sparse\\\": true, \\\"subsampling\\\": false, \\\"has_extra_col\\\": true, \\\"dataset_classes\\\": 2, \\\"dataset_features\\\": 23, \\\"dataset_samples\\\": 8000, \\\"single_frequency_class_detected\\\": false}\", \"azureml.git.repository_uri\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"mlflow.source.git.repoURL\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"ce3f85771ef6dc0e0dc6b753d38261a14b0603d7\", \"mlflow.source.git.commit\": \"ce3f85771ef6dc0e0dc6b753d38261a14b0603d7\", \"azureml.git.dirty\": \"True\"}, \"tags\": {\"model_explain_run\": \"best_run\", \"_aml_system_automl_run_workspace_id\": \"5224a85c-9ec5-4b58-86dd-d59b28efde48\", \"best_score\": \"0.9893651579769843\", \"best_pipeline\": \"VotingEnsemble\", \"automl_best_child_run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923_4\", \"model_explain_best_run_child_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923_4\"}, \"end_time_utc\": \"2022-04-05T09:21:04.850886Z\", \"status\": \"Completed\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:12:06\", \"run_number\": \"1649149738\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923_0\", \"run_number\": 1649149753, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-04-05T09:09:13.948672Z\", \"end_time\": \"2022-04-05T09:15:43.383881Z\", \"created_time\": \"2022-04-05T09:09:13.774888Z\", \"created_time_dt\": \"2022-04-05T09:09:13.774888Z\", \"duration\": \"0:06:29\", \"iteration\": \"0\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, LightGBM\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.98893101, \"best_metric\": 0.98893101}, {\"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923_1\", \"run_number\": 1649150143, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-04-05T09:15:43.838418Z\", \"end_time\": \"2022-04-05T09:18:35.095554Z\", \"created_time\": \"2022-04-05T09:15:43.688153Z\", \"created_time_dt\": \"2022-04-05T09:15:43.688153Z\", \"duration\": \"0:02:51\", \"iteration\": \"1\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, XGBoostClassifier\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.98876698, \"best_metric\": 0.98893101}, {\"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923_2\", \"run_number\": 1649150316, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-04-05T09:18:36.238527Z\", \"end_time\": \"2022-04-05T09:19:27.440435Z\", \"created_time\": \"2022-04-05T09:18:36.029293Z\", \"created_time_dt\": \"2022-04-05T09:18:36.029293Z\", \"duration\": \"0:00:51\", \"iteration\": \"2\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, ExtremeRandomTrees\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.94926267, \"best_metric\": 0.98893101}, {\"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923_3\", \"run_number\": 1649150368, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-04-05T09:19:28.817789Z\", \"end_time\": \"2022-04-05T09:20:20.463916Z\", \"created_time\": \"2022-04-05T09:19:28.654047Z\", \"created_time_dt\": \"2022-04-05T09:19:28.654047Z\", \"duration\": \"0:00:51\", \"iteration\": \"3\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, RandomForest\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.9699989, \"best_metric\": 0.98893101}, {\"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923_4\", \"run_number\": 1649150420, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2022-04-05T09:20:20.894277Z\", \"end_time\": \"2022-04-05T09:21:04.36218Z\", \"created_time\": \"2022-04-05T09:20:20.756571Z\", \"created_time_dt\": \"2022-04-05T09:20:20.756571Z\", \"duration\": \"0:00:43\", \"iteration\": \"4\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"VotingEnsemble\", \"run_properties\": \"classification_labels=array([0, 1]\", \"primary_metric\": 0.98936516, \"best_metric\": 0.98936516}], \"children_metrics\": {\"categories\": [0], \"series\": {\"weighted_accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"weighted_accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9528355112553637, 0.9552092613359707, 0.8908010646736356, 0.9301879410989077, 0.9538001219466592]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"weighted_accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9528355112553637, 0.9552092613359707, 0.9552092613359707, 0.9552092613359707, 0.9552092613359707]}], \"AUC_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"AUC_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9889310060568878, 0.9887669778369675, 0.9492626675183633, 0.9699989000278694, 0.9893651579769843]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"AUC_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9889310060568878, 0.9889310060568878, 0.9889310060568878, 0.9889310060568878, 0.9893651579769843]}], \"precision_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"precision_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9411211289424788, 0.9439789025090004, 0.8663600062690873, 0.9109002146811237, 0.9422963468457747]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"precision_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9411211289424788, 0.9439789025090004, 0.9439789025090004, 0.9439789025090004, 0.9439789025090004]}], \"norm_macro_recall\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"norm_macro_recall\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.8805391085180713, 0.884768406763811, 0.7387474145797834, 0.7852626391655999, 0.8826437993014379]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"norm_macro_recall_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.8805391085180713, 0.884768406763811, 0.884768406763811, 0.884768406763811, 0.884768406763811]}], \"recall_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"recall_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9472499827244025, 0.9494999827947238, 0.8812485273549359, 0.9134988565289053, 0.9482499983826104]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"recall_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9472499827244025, 0.9494999827947238, 0.9494999827947238, 0.9494999827947238, 0.9494999827947238]}], \"average_precision_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"average_precision_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9871352774186574, 0.9869519395798036, 0.9385566122842293, 0.9646316113179035, 0.9876003578559868]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"average_precision_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9871352774186574, 0.9871352774186574, 0.9871352774186574, 0.9871352774186574, 0.9876003578559868]}], \"precision_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"precision_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9472033268188875, 0.9494270304263351, 0.8826568544531076, 0.9131458184131421, 0.9481983501104886]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"precision_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9472033268188875, 0.9494270304263351, 0.9494270304263351, 0.9494270304263351, 0.9494270304263351]}], \"balanced_accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"balanced_accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9402695542590357, 0.9423842033819055, 0.8693737072898916, 0.8926313195828, 0.941321899650719]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"balanced_accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9402695542590357, 0.9423842033819055, 0.9423842033819055, 0.9423842033819055, 0.9423842033819055]}], \"AUC_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"AUC_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9889310060568879, 0.9887669778369675, 0.9492626675183633, 0.9699989000278694, 0.9893651579769843]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"AUC_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9889310060568879, 0.9889310060568879, 0.9889310060568879, 0.9889310060568879, 0.9893651579769843]}], \"average_precision_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"average_precision_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9894832131217713, 0.989331114560645, 0.9497327411005759, 0.9712138034562043, 0.9898733064764281]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"average_precision_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9894832131217713, 0.9894832131217713, 0.9894832131217713, 0.9894832131217713, 0.9898733064764281]}], \"recall_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"recall_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9472499827244025, 0.9494999827947238, 0.8812485273549359, 0.9134988565289053, 0.9482499983826104]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"recall_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9472499827244025, 0.9494999827947238, 0.9494999827947238, 0.9494999827947238, 0.9494999827947238]}], \"AUC_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"AUC_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9902186358077073, 0.9901328306037599, 0.9539624859793693, 0.972041352138378, 0.9906130300982952]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"AUC_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9902186358077073, 0.9902186358077073, 0.9902186358077073, 0.9902186358077073, 0.9906130300982952]}], \"f1_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"f1_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9472499827244025, 0.9494999827947238, 0.8812485273549359, 0.9134988565289053, 0.9482499983826101]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"f1_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9472499827244025, 0.9494999827947238, 0.9494999827947238, 0.9494999827947238, 0.9494999827947238]}], \"f1_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"f1_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9472230129853932, 0.9494534013209265, 0.881546593657372, 0.9125269475477599, 0.9482215244064863]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"f1_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9472230129853932, 0.9494534013209265, 0.9494534013209265, 0.9494534013209265, 0.9494534013209265]}], \"precision_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"precision_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9472499827244025, 0.9494999827947238, 0.8812485273549359, 0.9134988565289053, 0.9482499983826104]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"precision_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9472499827244025, 0.9494999827947238, 0.9494999827947238, 0.9494999827947238, 0.9494999827947238]}], \"average_precision_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"average_precision_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9903872726940194, 0.9902927776757618, 0.9536684407658399, 0.9726650960686011, 0.9907705875118978]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"average_precision_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9903872726940194, 0.9903872726940194, 0.9903872726940194, 0.9903872726940194, 0.9907705875118978]}], \"matthews_correlation\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"matthews_correlation\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.8813898032287959, 0.8863609525779487, 0.7356477517534697, 0.8033142854795422, 0.8836176634010481]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"matthews_correlation_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.8813898032287959, 0.8863609525779487, 0.8863609525779487, 0.8863609525779487, 0.8863609525779487]}], \"log_loss\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"log_loss\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.12722240856346553, 0.13460884473949677, 0.3091822171136645, 0.2718268848914929, 0.12520224565941063]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"log_loss_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.12722240856346553, 0.12722240856346553, 0.12722240856346553, 0.12722240856346553, 0.12520224565941063]}], \"f1_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"f1_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9406907984438874, 0.9431692622212838, 0.8673644263801044, 0.9007600821478441, 0.9418058767127504]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"f1_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9406907984438874, 0.9431692622212838, 0.9431692622212838, 0.9431692622212838, 0.9431692622212838]}], \"recall_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"recall_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9402695542590357, 0.9423842033819055, 0.8693737072898916, 0.8926313195828, 0.941321899650719]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"recall_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9402695542590357, 0.9423842033819055, 0.9423842033819055, 0.9423842033819055, 0.9423842033819055]}], \"accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"markers\", \"name\": \"accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9472499827244025, 0.9494999827947238, 0.8812485273549359, 0.9134988565289053, 0.9482499983826104]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\"], \"mode\": \"lines\", \"name\": \"accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9472499827244025, 0.9494999827947238, 0.9494999827947238, 0.9494999827947238, 0.9494999827947238]}]}, \"metricName\": null, \"primaryMetricName\": \"AUC_weighted\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"f1_score_macro\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9418058767127504]}]}, {\"name\": \"recall_score_micro\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9482499983826104]}]}, {\"name\": \"log_loss\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.12520224565941063]}]}, {\"name\": \"recall_score_macro\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.941321899650719]}]}, {\"name\": \"accuracy\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9482499983826104]}]}, {\"name\": \"precision_score_macro\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9422963468457747]}]}, {\"name\": \"precision_score_micro\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9482499983826104]}]}, {\"name\": \"f1_score_micro\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9482499983826101]}]}, {\"name\": \"average_precision_score_weighted\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9898733064764281]}]}, {\"name\": \"balanced_accuracy\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.941321899650719]}]}, {\"name\": \"f1_score_weighted\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9482215244064863]}]}, {\"name\": \"AUC_micro\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9906130300982952]}]}, {\"name\": \"average_precision_score_macro\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9876003578559868]}]}, {\"name\": \"recall_score_weighted\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9482499983826104]}]}, {\"name\": \"weighted_accuracy\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9538001219466592]}]}, {\"name\": \"matthews_correlation\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.8836176634010481]}]}, {\"name\": \"norm_macro_recall\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.8826437993014379]}]}, {\"name\": \"average_precision_score_micro\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9907705875118978]}]}, {\"name\": \"precision_score_weighted\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9481983501104886]}]}, {\"name\": \"AUC_weighted\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9893651579769843]}]}, {\"name\": \"AUC_macro\", \"run_id\": \"AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923\", \"categories\": [0], \"series\": [{\"data\": [0.9893651579769843]}]}], \"run_logs\": \"\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.40.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2022-04-05T09:08:58.949983Z',\n",
       " 'endTimeUtc': '2022-04-05T09:21:04.850886Z',\n",
       " 'services': {},\n",
       " 'properties': {'num_iterations': '5',\n",
       "  'training_type': 'TrainFull',\n",
       "  'acquisition_function': 'EI',\n",
       "  'primary_metric': 'AUC_weighted',\n",
       "  'train_split': '0',\n",
       "  'acquisition_parameter': '0',\n",
       "  'num_cross_validation': None,\n",
       "  'target': 'local',\n",
       "  'AMLSettingsJsonString': '{\"path\":null,\"name\":\"automl-classification\",\"subscription_id\":\"43c1f93a-903d-4b23-a4bf-92bd7a150627\",\"resource_group\":\"myResourceGroup01\",\"workspace_name\":\"machine_learning_workspace01\",\"region\":\"westeurope\",\"compute_target\":\"local\",\"spark_service\":null,\"azure_service\":\"remote\",\"many_models\":false,\"pipeline_fetch_max_batch_size\":1,\"enable_batch_run\":false,\"enable_run_restructure\":false,\"start_auxiliary_runs_before_parent_complete\":false,\"enable_code_generation\":false,\"iterations\":5,\"primary_metric\":\"AUC_weighted\",\"task_type\":\"classification\",\"positive_label\":null,\"data_script\":null,\"test_size\":0.0,\"test_include_predictions_only\":false,\"validation_size\":0.0,\"n_cross_validations\":null,\"y_min\":null,\"y_max\":null,\"num_classes\":null,\"featurization\":\"auto\",\"_ignore_package_version_incompatibilities\":false,\"is_timeseries\":false,\"max_cores_per_iteration\":-1,\"max_concurrent_iterations\":1,\"iteration_timeout_minutes\":10,\"mem_in_mb\":null,\"enforce_time_on_windows\":false,\"experiment_timeout_minutes\":45,\"experiment_exit_score\":null,\"partition_column_names\":null,\"whitelist_models\":null,\"blacklist_algos\":[\"TensorFlowLinearClassifier\",\"TensorFlowDNN\"],\"supported_models\":[\"MultinomialNaiveBayes\",\"BernoulliNaiveBayes\",\"DecisionTree\",\"LogisticRegression\",\"RandomForest\",\"LightGBM\",\"XGBoostClassifier\",\"AveragedPerceptronClassifier\",\"TensorFlowLinearClassifier\",\"SVM\",\"TabnetClassifier\",\"KNN\",\"LinearSVM\",\"GradientBoosting\",\"TensorFlowDNN\",\"SGD\",\"ExtremeRandomTrees\"],\"private_models\":[],\"auto_blacklist\":true,\"blacklist_samples_reached\":false,\"exclude_nan_labels\":true,\"verbosity\":20,\"_debug_log\":\"automl_errors.log\",\"show_warnings\":false,\"model_explainability\":true,\"service_url\":null,\"sdk_url\":null,\"sdk_packages\":null,\"enable_onnx_compatible_models\":true,\"enable_split_onnx_featurizer_estimator_models\":false,\"vm_type\":null,\"telemetry_verbosity\":20,\"send_telemetry\":true,\"enable_dnn\":false,\"scenario\":\"SDK-1.13.0\",\"environment_label\":null,\"save_mlflow\":false,\"enable_categorical_indicators\":false,\"force_text_dnn\":false,\"enable_feature_sweeping\":false,\"enable_early_stopping\":true,\"early_stopping_n_iters\":10,\"arguments\":null,\"dataset_id\":null,\"hyperdrive_config\":null,\"validation_dataset_id\":null,\"run_source\":null,\"metrics\":null,\"enable_metric_confidence\":false,\"enable_ensembling\":true,\"enable_stack_ensembling\":false,\"ensemble_iterations\":5,\"enable_tf\":false,\"enable_subsampling\":false,\"subsample_seed\":null,\"enable_nimbusml\":false,\"enable_streaming\":false,\"force_streaming\":false,\"track_child_runs\":true,\"allowed_private_models\":[],\"label_column_name\":\"Diabetic\",\"weight_column_name\":null,\"cv_split_column_names\":null,\"enable_local_managed\":false,\"_local_managed_run_id\":null,\"cost_mode\":1,\"lag_length\":0,\"metric_operation\":\"maximize\",\"preprocess\":true}',\n",
       "  'DataPrepJsonString': None,\n",
       "  'EnableSubsampling': 'False',\n",
       "  'runTemplate': 'AutoML',\n",
       "  'azureml.runsource': 'automl',\n",
       "  'display_task_type': 'classification',\n",
       "  'dependencies_versions': '{\"azureml-dataprep-native\": \"38.0.0\", \"azureml-dataprep\": \"3.0.1\", \"azureml-dataprep-rslex\": \"2.4.1\", \"azureml-train-automl-runtime\": \"1.40.0.post1\", \"azureml-pipeline-steps\": \"1.40.0\", \"azureml-interpret\": \"1.40.0\", \"azureml-core\": \"1.40.0\", \"azureml-dataset-runtime\": \"1.40.0\", \"azureml-widgets\": \"1.40.0\", \"azureml-train-automl-client\": \"1.40.0\", \"azureml-defaults\": \"1.40.0\", \"azureml-telemetry\": \"1.40.0\", \"azureml-contrib-dataset\": \"1.40.0\", \"azureml-automl-runtime\": \"1.40.0\", \"azureml-training-tabular\": \"1.40.0\", \"azureml-contrib-automl-pipeline-steps\": \"1.40.0\", \"azureml-pipeline-core\": \"1.40.0\", \"azureml-train-restclients-hyperdrive\": \"1.40.0\", \"azureml-mlflow\": \"1.40.0\", \"azureml-automl-core\": \"1.40.0\", \"azureml-train-core\": \"1.40.0\", \"azureml-inference-server-http\": \"0.4.11\"}',\n",
       "  '_aml_system_scenario_identification': 'Local.Parent',\n",
       "  'ClientSdkVersion': '1.40.0',\n",
       "  'ClientType': 'SDK',\n",
       "  'environment_cpu_name': 'AzureML-AutoML',\n",
       "  'environment_cpu_label': 'prod',\n",
       "  'environment_gpu_name': 'AzureML-AutoML-GPU',\n",
       "  'environment_gpu_label': 'prod',\n",
       "  'root_attribution': 'automl',\n",
       "  'attribution': 'AutoML',\n",
       "  'Orchestrator': 'AutoML',\n",
       "  '_azureml.ComputeTargetType': 'local',\n",
       "  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": true, \"subsampling\": false, \"has_extra_col\": true, \"dataset_classes\": 2, \"dataset_features\": 23, \"dataset_samples\": 8000, \"single_frequency_class_detected\": false}',\n",
       "  'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': 'ce3f85771ef6dc0e0dc6b753d38261a14b0603d7',\n",
       "  'mlflow.source.git.commit': 'ce3f85771ef6dc0e0dc6b753d38261a14b0603d7',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'logFiles': {},\n",
       " 'submittedBy': 'd7c04ded-ec80-4e62-a9d2-423b2553b83d'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunDetails(automl_run).show()\n",
    "automl_run.wait_for_completion() # get more parameter info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![automl_run](../../image/howto_automl/automl_run.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**option 1:** select any pipeline iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = automl_run.get_output(iteration=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**option 2:** select best pipeline iteration automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = automl_run.get_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspect model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatransformer\n",
      "MaxAbsScaler\n",
      "LightGBMClassifier\n"
     ]
    }
   ],
   "source": [
    "# pipeline steps\n",
    "for step in fitted_model.named_steps:\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datatransformer': DataTransformer(enable_dnn=False, enable_feature_sweeping=False, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, is_onnx_compatible=True, task='classification'),\n",
       " 'MaxAbsScaler': MaxAbsScaler(copy=True),\n",
       " 'LightGBMClassifier': LightGBMClassifier(min_data_in_leaf=20, n_jobs=-1, problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=None)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model properties\n",
    "fitted_model.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weighted_accuracy': 0.9528355112553637,\n",
       " 'AUC_macro': 0.9889310060568878,\n",
       " 'precision_score_macro': 0.9411211289424788,\n",
       " 'norm_macro_recall': 0.8805391085180713,\n",
       " 'recall_score_micro': 0.9472499827244025,\n",
       " 'average_precision_score_macro': 0.9871352774186574,\n",
       " 'precision_score_weighted': 0.9472033268188875,\n",
       " 'balanced_accuracy': 0.9402695542590357,\n",
       " 'AUC_weighted': 0.9889310060568879,\n",
       " 'average_precision_score_weighted': 0.9894832131217713,\n",
       " 'recall_score_weighted': 0.9472499827244025,\n",
       " 'AUC_micro': 0.9902186358077073,\n",
       " 'f1_score_micro': 0.9472499827244025,\n",
       " 'f1_score_weighted': 0.9472230129853932,\n",
       " 'precision_score_micro': 0.9472499827244025,\n",
       " 'average_precision_score_micro': 0.9903872726940194,\n",
       " 'matthews_correlation': 0.8813898032287959,\n",
       " 'log_loss': 0.12722240856346553,\n",
       " 'f1_score_macro': 0.9406907984438874,\n",
       " 'recall_score_macro': 0.9402695542590357,\n",
       " 'accuracy': 0.9472499827244025,\n",
       " 'accuracy_table': 'aml://artifactId/ExperimentRun/dcid.AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923_0/accuracy_table',\n",
       " 'confusion_matrix': 'aml://artifactId/ExperimentRun/dcid.AutoML_99a62dfa-d65a-49d9-934b-2a78d4895923_0/confusion_matrix'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all metrics\n",
    "best_run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05:11:24:22,583 INFO     [explanation_client.py:334] Using default datastore for uploads\n"
     ]
    },
    {
     "ename": "ExplanationNotFoundException",
     "evalue": "ExplanationNotFoundException:\n\tMessage: Explanation asset ID None was not found to match the supplied filters ['comment', 'raw'].\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Explanation asset ID None was not found to match the supplied filters ['comment', 'raw'].\",\n        \"inner_error\": {\n            \"code\": \"NotFound\",\n            \"inner_error\": {\n                \"code\": \"ExplanationFiltersNotFound\"\n            }\n        }\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mExplanationNotFoundException\u001b[0m              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m client \u001b[38;5;241m=\u001b[39m ExplanationClient\u001b[38;5;241m.\u001b[39mfrom_run(best_run)\n\u001b[0;32m----> 2\u001b[0m engineered_explanations \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_model_explanation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m engineered_explanations\u001b[38;5;241m.\u001b[39mget_feature_importance_dict() \u001b[38;5;66;03m# get model feature importance values\u001b[39;00m\n\u001b[1;32m      4\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodelFeatureImportance_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodelFeatureImportance_value\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/anaconda/envs/py38_automl/lib/python3.8/site-packages/azureml/interpret/_internal/explanation_client.py:1105\u001b[0m, in \u001b[0;36mExplanationClient.download_model_explanation\u001b[0;34m(self, explanation_id, top_k, comment, raw, engineered)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m top_k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1104\u001b[0m     module_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloading model explanation as batch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_explanation_as_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexplanation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplanation_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mengineered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengineered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1108\u001b[0m     module_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloading explanations with top k features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/py38_automl/lib/python3.8/site-packages/azureml/interpret/_internal/explanation_client.py:1257\u001b[0m, in \u001b[0;36mExplanationClient._download_explanation_as_batch\u001b[0;34m(self, explanation_id, comment, raw, engineered)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         explanation_assets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(filtered)\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(explanation_assets) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1257\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExplanationNotFoundException\u001b[38;5;241m.\u001b[39m_with_error(\n\u001b[1;32m   1258\u001b[0m             AzureMLError\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m   1259\u001b[0m                 ExplanationFiltersNotFound, explanation_id\u001b[38;5;241m=\u001b[39mexplanation_id,\n\u001b[1;32m   1260\u001b[0m                 filter_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   1261\u001b[0m             )\n\u001b[1;32m   1262\u001b[0m         )\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1264\u001b[0m     explanation_assets \u001b[38;5;241m=\u001b[39m explanation_list\n",
      "\u001b[0;31mExplanationNotFoundException\u001b[0m: ExplanationNotFoundException:\n\tMessage: Explanation asset ID None was not found to match the supplied filters ['comment', 'raw'].\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Explanation asset ID None was not found to match the supplied filters ['comment', 'raw'].\",\n        \"inner_error\": {\n            \"code\": \"NotFound\",\n            \"inner_error\": {\n                \"code\": \"ExplanationFiltersNotFound\"\n            }\n        }\n    }\n}"
     ]
    }
   ],
   "source": [
    "client = ExplanationClient.from_run(best_run)\n",
    "engineered_explanations = client.download_model_explanation(raw=False)\n",
    "feature_importance = engineered_explanations.get_feature_importance_dict() # get model feature importance values\n",
    "columns = [\"modelFeatureImportance_name\", \"modelFeatureImportance_value\"]\n",
    "pd.DataFrame(list(feature_importance.items()), columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare\n",
    "\n",
    "autoML generated a scoring script, environment file and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the score and environment files\n",
    "model_name = best_run.properties['model_name'] # score.py script will look for the name of the registered model\n",
    "\n",
    "# make a local copy of the best scoring script, environment file and the model file\n",
    "script_file_name = 'inference/score.py'\n",
    "conda_env_file_name = 'inference/env.yml'\n",
    "model_pickle_file_name = 'inference/model.pkl'\n",
    "model_onnx_file_name = 'inference/model.onnx'\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', script_file_name)\n",
    "best_run.download_file('outputs/conda_env_v_1_0_0.yml', conda_env_file_name)\n",
    "best_run.download_file('outputs/model.pkl', model_pickle_file_name)\n",
    "best_run.download_file('outputs/model.onnx', model_onnx_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\r",
      "\r\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\r",
      "\r\n",
      "\r\n",
      "# Details about the Conda environment file format:\r",
      "\r\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r",
      "\r\n",
      "\r\n",
      "name: project_environment\r\n",
      "dependencies:\r\n",
      "  # The python interpreter version.\r",
      "\r\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\r",
      "\r\n",
      "- python=3.8.13\r\n",
      "\r\n",
      "- pip:\r\n",
      "  - azureml-train-automl-runtime==1.40.0.post1\r\n",
      "  - inference-schema\r\n",
      "  - azureml-interpret==1.40.0\r\n",
      "  - azureml-defaults==1.40.0\r\n",
      "- numpy==1.19.5\r\n",
      "- pandas==1.1.5\r\n",
      "- scikit-learn==0.22.2.post1\r\n",
      "- py-xgboost==1.3.3\r\n",
      "- fbprophet==0.7.1\r\n",
      "- holidays==0.10.3\r\n",
      "- psutil==5.9.0\r\n",
      "- pytorch==1.4.0\r\n",
      "- cudatoolkit==10.1.243\r\n",
      "channels:\r\n",
      "- anaconda\r\n",
      "- conda-forge\r\n"
     ]
    }
   ],
   "source": [
    "! cat inference/env.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ---------------------------------------------------------\r\n",
      "# Copyright (c) Microsoft Corporation. All rights reserved.\r\n",
      "# ---------------------------------------------------------\r\n",
      "import json\r\n",
      "import logging\r\n",
      "import os\r\n",
      "import pickle\r\n",
      "import numpy as np\r\n",
      "import pandas as pd\r\n",
      "import joblib\r\n",
      "\r\n",
      "import azureml.automl.core\r\n",
      "from azureml.automl.core.shared import logging_utilities, log_server\r\n",
      "from azureml.telemetry import INSTRUMENTATION_KEY\r\n",
      "\r\n",
      "from inference_schema.schema_decorators import input_schema, output_schema\r\n",
      "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\r\n",
      "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\r\n",
      "from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\r\n",
      "\r\n",
      "input_sample = pd.DataFrame({\"Age\": pd.Series([0], dtype=\"int64\"), \"BMI\": pd.Series([0.0], dtype=\"float64\"), \"DiabetesPedigree\": pd.Series([0.0], dtype=\"float64\"), \"DiastolicBloodPressure\": pd.Series([0], dtype=\"int64\"), \"PatientID\": pd.Series([0], dtype=\"int64\"), \"PlasmaGlucose\": pd.Series([0], dtype=\"int64\"), \"Pregnancies\": pd.Series([0], dtype=\"int64\"), \"SerumInsulin\": pd.Series([0], dtype=\"int64\"), \"TricepsThickness\": pd.Series([0], dtype=\"int64\")})\r\n",
      "output_sample = np.array([0])\r\n",
      "method_sample = StandardPythonParameterType(\"predict\")\r\n",
      "\r\n",
      "try:\r\n",
      "    log_server.enable_telemetry(INSTRUMENTATION_KEY)\r\n",
      "    log_server.set_verbosity('INFO')\r\n",
      "    logger = logging.getLogger('azureml.automl.core.scoring_script')\r\n",
      "except:\r\n",
      "    pass\r\n",
      "\r\n",
      "\r\n",
      "def init():\r\n",
      "    global model\r\n",
      "    # This name is model.id of model that we want to deploy deserialize the model file back\r\n",
      "    # into a sklearn model\r\n",
      "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pkl')\r\n",
      "    path = os.path.normpath(model_path)\r\n",
      "    path_split = path.split(os.sep)\r\n",
      "    log_server.update_custom_dimensions({'model_name': path_split[-3], 'model_version': path_split[-2]})\r\n",
      "    try:\r\n",
      "        logger.info(\"Loading model from path.\")\r\n",
      "        model = joblib.load(model_path)\r\n",
      "        logger.info(\"Loading successful.\")\r\n",
      "    except Exception as e:\r\n",
      "        logging_utilities.log_traceback(e, logger)\r\n",
      "        raise\r\n",
      "\r\n",
      "@input_schema('method', method_sample, convert_to_provided_type=False)\r\n",
      "@input_schema('data', PandasParameterType(input_sample))\r\n",
      "@output_schema(NumpyParameterType(output_sample))\r\n",
      "def run(data, method=\"predict\"):\r\n",
      "    try:\r\n",
      "        if method == \"predict_proba\":\r\n",
      "            result = model.predict_proba(data)\r\n",
      "        elif method == \"predict\":\r\n",
      "            result = model.predict(data)\r\n",
      "        else:\r\n",
      "            raise Exception(f\"Invalid predict method argument received ({method})\")\r\n",
      "        if isinstance(result, pd.DataFrame):\r\n",
      "            result = result.values\r\n",
      "        return json.dumps({\"result\": result.tolist()})\r\n",
      "    except Exception as e:\r\n",
      "        result = str(e)\r\n",
      "        return json.dumps({\"error\": result})\r\n"
     ]
    }
   ],
   "source": [
    "! cat inference/score.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1:** from workspace /outputs folder with .register_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name=model_name, # registered model name used in scoring script init()\n",
    "                                model_framework=Model.Framework.SCIKITLEARN, # {TensorFlow, ScikitLearn, Onnx, Custom}\n",
    "                                model_framework_version='0.22.2',\n",
    "                                model_path='outputs/model.pkl', # fixed path in workspace {'model.pkl', 'model.onnx'}\n",
    "                                tags={'Training context': 'autoML Training'},\n",
    "                                properties={'AUC': best_run.get_metrics()['AUC_weighted'],\n",
    "                                            'Accuracy': best_run.get_metrics()['accuracy']},\n",
    "                                description=\"Classification model to predict diabetes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2:** from local /path/model folder with Model.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model AutoML99a62dfad0\n"
     ]
    }
   ],
   "source": [
    "model = Model.register(workspace=ws,\n",
    "                       model_name=model_name, # registered model name used in scoring script init()\n",
    "                       model_framework=Model.Framework.SCIKITLEARN, # {TensorFlow, ScikitLearn, Onnx, Custom}\n",
    "                       model_framework_version='0.22.2',\n",
    "                       model_path='inference/model.pkl', # local file {'model.pkl', 'model.onnx'}\n",
    "                       tags={'Training context': 'autoML Training'},\n",
    "                       properties={'AUC': best_run.get_metrics()['AUC_weighted'],\n",
    "                                   'Accuracy': best_run.get_metrics()['accuracy']},\n",
    "                       description=\"Classification model to predict diabetes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML99a62dfad0 version: 1\n",
      "\t Training context : autoML Training\n",
      "\t AUC : 0.9889310060568879\n",
      "\t Accuracy : 0.9472499827244025\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list all registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the registered model for deployment (latest version)\n",
    "model = ws.models[model_name] # or replace with any registered modelname from Model.list(ws)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model as webservice (ACI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linux Azure Container Instance with 1 vCPU and 1GB of RAM cost â‚¬28 per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"automl-projname-service\" does not exist, creating the webservice...\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-04-05 11:30:31+02:00 Creating Container Registry if not exists..\n",
      "2022-04-05 11:40:31+02:00 Registering the environment.\n",
      "2022-04-05 11:40:33+02:00 Building image..\n",
      "2022-04-05 11:55:03+02:00 Generating deployment configuration..\n",
      "2022-04-05 11:55:04+02:00 Submitting deployment to compute..\n",
      "2022-04-05 11:55:10+02:00 Checking the status of deployment automl-projname-service..\n",
      "2022-04-05 12:00:11+02:00 Checking the status of inference endpoint automl-projname-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "CPU times: user 25.9 s, sys: 3.97 s, total: 29.9 s\n",
      "Wall time: 30min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Configure the scoring environment\n",
    "service_name = \"automl-projname-service\" # only lowercase letters, numbers, or dashes\n",
    "\n",
    "# Remove any existing service under the same name\n",
    "try:\n",
    "    Webservice(ws, service_name).delete()\n",
    "except WebserviceException:\n",
    "    print('\"' + service_name + '\" does not exist, creating the webservice...')\n",
    "\n",
    "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=conda_env_file_name)\n",
    "inference_config = InferenceConfig(entry_script=script_file_name, environment=myenv)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                                       memory_gb=1)\n",
    "\n",
    "# build container from environment, start webservice ACI and deploy inference scrips \n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** load a running webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automl-projname-service\n"
     ]
    }
   ],
   "source": [
    "# list available webservices\n",
    "for i in ws.webservices:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name = \"automl-projname-service\" # only lowercase letters, numbers, or dashes\n",
    "service = Webservice(ws, service_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-05T09:59:52,941744500+00:00 - iot-server/run \n",
      "2022-04-05T09:59:52,941745300+00:00 - gunicorn/run \n",
      "Dynamic Python package installation is disabled.\n",
      "Starting HTTP server\n",
      "2022-04-05T09:59:52,967272100+00:00 - nginx/run \n",
      "2022-04-05T09:59:52,969077500+00:00 - rsyslog/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2022-04-05T09:59:53,311964600+00:00 - iot-server/finish 1 0\n",
      "2022-04-05T09:59:53,318243500+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (72)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 99\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2022-04-05 10:00:08,085 | root | INFO | Starting up app insights client\n",
      "logging socket was found. logging is available.\n",
      "logging socket was found. logging is available.\n",
      "2022-04-05 10:00:08,086 | root | INFO | Starting up request id generator\n",
      "2022-04-05 10:00:08,086 | root | INFO | Starting up app insight hooks\n",
      "2022-04-05 10:00:08,086 | root | INFO | Invoking user's init function\n",
      "2022-04-05 10:00:57,603 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (urllib3 1.26.9 (/azureml-envs/azureml_174cf2a8cc39726143000f5a96e3404a/lib/python3.8/site-packages), Requirement.parse('urllib3<=1.26.7,>=1.23'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (urllib3 1.26.9 (/azureml-envs/azureml_174cf2a8cc39726143000f5a96e3404a/lib/python3.8/site-packages), Requirement.parse('urllib3<=1.26.7,>=1.23'), {'azureml-core'}).\n",
      "2022-04-05 10:00:57,684 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (urllib3 1.26.9 (/azureml-envs/azureml_174cf2a8cc39726143000f5a96e3404a/lib/python3.8/site-packages), Requirement.parse('urllib3<=1.26.7,>=1.23'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (urllib3 1.26.9 (/azureml-envs/azureml_174cf2a8cc39726143000f5a96e3404a/lib/python3.8/site-packages), Requirement.parse('urllib3<=1.26.7,>=1.23'), {'azureml-core'}).\n",
      "2022-04-05 10:00:57,692 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (urllib3 1.26.9 (/azureml-envs/azureml_174cf2a8cc39726143000f5a96e3404a/lib/python3.8/site-packages), Requirement.parse('urllib3<=1.26.7,>=1.23')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (urllib3 1.26.9 (/azureml-envs/azureml_174cf2a8cc39726143000f5a96e3404a/lib/python3.8/site-packages), Requirement.parse('urllib3<=1.26.7,>=1.23')).\n",
      "2022-04-05 10:01:01,525 | root | INFO | Users's init has completed successfully\n",
      "2022-04-05 10:01:01,529 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2022-04-05 10:01:01,529 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "Generating swagger file: /tmp/tmpw55kqn2j\n",
      "2022-04-05 10:01:01,536 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2022-04-05 10:01:01,562 | root | INFO | 200\n",
      "127.0.0.1 - - [05/Apr/2022:10:01:01 +0000] \"GET /swagger.json HTTP/1.0\" 200 2926 \"-\" \"Go-http-client/1.1\"\n",
      "2022-04-05 10:01:06,076 | root | INFO | 200\n",
      "127.0.0.1 - - [05/Apr/2022:10:01:06 +0000] \"GET /swagger.json HTTP/1.0\" 200 2926 \"-\" \"Go-http-client/1.1\"\n",
      "2022-04-05 10:01:14,960 | root | INFO | 200\n",
      "127.0.0.1 - - [05/Apr/2022:10:01:14 +0000] \"GET /swagger.json HTTP/1.0\" 200 2926 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get webservice logs\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webservice inference test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a HTTP triggered webrequest with testdata to the model for a prediction value.  \n",
    "In this example we test a person is diabetic (1) or not-diabetic (0).  \n",
    "The testdata must be a list of 9 features to predict a binary classification.  \n",
    "We demonstrate the use of **service** or **requests** method to send a prediction request.  \n",
    "Know that 'Postman' application or 'Rest Client' plugin in VSCode work as well.  \n",
    "\n",
    "|Web API|Example value|Options|\n",
    "|-|-|-|\n",
    "|**HTTP method**|POST|<i>POST</i><br><i>GET</i>|\n",
    "|**URI**|http://3bb0618b-ef7b-4b17-af32-a52f9c64f4d5.northeurope.azurecontainer.io/score||\n",
    "|**Header**|{Content-Type: Application/json}||\n",
    "|**Body**|{\"data\": [[5, 2, 180, 74, 24, 21, 24, 1.5, 22], <br>[6, 0, 148, 58, 11, 179, 39, 0.16, 45]]}|<i>one or </i><br><i>more records</i>|\n",
    "|**Response**|{\"result\": [1, 0]}|<i>json object</i>|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI: http://cb6a9619-f4c9-47fe-bca2-0b8841b3d018.westeurope.azurecontainer.io/score\n",
      "Body: {\"data\": [[5, 2, 180, 74, 24, 21, 24, 1.5, 22], [6, 0, 148, 58, 11, 179, 39, 0.16, 45]]}\n"
     ]
    }
   ],
   "source": [
    "# get webservice URI\n",
    "endpoint = service.scoring_uri\n",
    "\n",
    "# raw test data\n",
    "rawdata = [[5, 2, 180, 74, 24, 21, 24, 1.5, 22],\n",
    "           [6, 0, 148, 58, 11, 179, 39, 0.16, 45]]\n",
    "\n",
    "print(\"URI: \" + endpoint)\n",
    "print(\"Body: \" + json.dumps({\"data\": rawdata})) # convert array to a serialized JSON formatted string object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 1:** service.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"result\": [0, 0]}'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.run(json.dumps({\"data\": rawdata}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test 2:** requests.post()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"result\": [0, 0]}'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.post(endpoint, json={\"data\": rawdata})\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are finished testing your service, clean up the deployment with service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired from autoML results is an alternative customML development.  \n",
    "Using inline method to test and develop, train local or with remote compute and deploy and test the model.  \n",
    "\n",
    "1. option1: inline method\n",
    "1. option2: script method\n",
    "  * create training script\n",
    "  * create training environment\n",
    "  * creating and register dataset (File)\n",
    "  * train model\n",
    "1. create an inference script\n",
    "1. create an inference environment\n",
    "1. register the model\n",
    "1. deploy the model\n",
    "1. inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Inline method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|log metric function|Description|Example|\n",
    "|-|-|-|\n",
    "|**log**|<i>Record a single named value</i>|run.log(\"accuracy\", 0.95)|\n",
    "|**log_list**|<i>Record a named list of values</i>|run.log_list(\"accuracies\", [0.6, 0.7, 0.87])|\n",
    "|**log_row**|<i>Record a row with multiple columns</i>|run.log_row(\"Y over X\", x=1, y=0.4)|\n",
    "|**log_table**|<i>Record a dictionary as a table</i>|run.log_table(\"Y over X\", {\"x\":[1, 2, 3], \"y\":[0.6, 0.7, 0.89]})|\n",
    "|**log_image**|<i>Record an image file or a plot</i>|run.log_image(\"ROC\", plot=plt)|\n",
    "|**upload_file**|<i>Upload any file to \"./outputs\"</i>|run.upload_file(\"best_model.pkl\", \"./model.pkl\")|\n",
    "\n",
    "https://aka.ms/AA70zf6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05:12:06:12,701 WARNING  [connectionpool.py:304] Connection pool is full, discarding connection: machinelstorage865aef211.blob.core.windows.net\n",
      "2022-04-05:12:06:12,708 WARNING  [connectionpool.py:304] Connection pool is full, discarding connection: machinelstorage865aef211.blob.core.windows.net\n",
      "2022-04-05:12:06:13,353 WARNING  [connectionpool.py:304] Connection pool is full, discarding connection: machinelstorage865aef211.blob.core.windows.net\n",
      "2022-04-05:12:06:13,368 WARNING  [connectionpool.py:304] Connection pool is full, discarding connection: machinelstorage865aef211.blob.core.windows.net\n",
      "2022-04-05:12:06:13,425 WARNING  [connectionpool.py:304] Connection pool is full, discarding connection: machinelstorage865aef211.blob.core.windows.net\n",
      "2022-04-05:12:06:13,447 WARNING  [connectionpool.py:304] Connection pool is full, discarding connection: machinelstorage865aef211.blob.core.windows.net\n",
      "2022-04-05:12:06:14,234 WARNING  [connectionpool.py:304] Connection pool is full, discarding connection: machinelstorage865aef211.blob.core.windows.net\n",
      "2022-04-05:12:06:14,874 WARNING  [connectionpool.py:304] Connection pool is full, discarding connection: machinelstorage865aef211.blob.core.windows.net\n",
      "2022-04-05:12:06:14,934 WARNING  [connectionpool.py:304] Connection pool is full, discarding connection: machinelstorage865aef211.blob.core.windows.net\n",
      "2022-04-05:12:06:15,108 WARNING  [connectionpool.py:304] Connection pool is full, discarding connection: machinelstorage865aef211.blob.core.windows.net\n",
      "2022-04-05:12:06:15,108 WARNING  [connectionpool.py:304] Connection pool is full, discarding connection: machinelstorage865aef211.blob.core.windows.net\n",
      "2022-04-05:12:06:15,177 WARNING  [connectionpool.py:304] Connection pool is full, discarding connection: machinelstorage865aef211.blob.core.windows.net\n",
      "2022-04-05:12:06:17,79 INFO     [datastore_client.py:991] <azureml.core.authentication.ServicePrincipalAuthentication object at 0x7f96dc02a3a0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: diabetes-training\n",
      "Loading data lake gen2 data in a pandas dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fuse: warning: library too old, some operations may not not work\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a decision tree model\n",
      "Accuracy: 0.8953333333333333\n",
      "AUC: 0.8823424050947809\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Model\n",
    "from azureml.core import Datastore\n",
    "from azureml.core import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace=ws, name=\"diabetes-training\")\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "# load the diabetes dataset (File method)\n",
    "print(\"Loading data lake gen2 data in a pandas dataframe...\")\n",
    "ds = Datastore.get(ws, 'datalakestoragegen2')\n",
    "ds_path = [DataPath(ds, 'platinum/diabetes.parquet')] # {path/*.parquet or path/**}\n",
    "dataset = Dataset.File.from_files(path=ds_path)\n",
    "mount_context = dataset.mount(mount_point='/tmp/platinum') # read-only mount from delta lake\n",
    "mount_context.start()\n",
    "diabetes = pd.read_parquet('/tmp/platinum/diabetes.parquet') # {'/tmp/path/'} can load latest delta lake parquet files\n",
    "mount_context.stop()\n",
    "\n",
    "# load the diabetes dataset (Tabular method)\n",
    "# print(\"Loading data lake gen2 data in a pandas dataframe...\")\n",
    "# ds = Datastore.get(ws, 'datalakestoragegen2')\n",
    "# ds_path = [DataPath(ds, 'platinum/diabetes.parquet')] # {path/*.parquet or path/**}\n",
    "# dataset = Dataset.Tabular.from_parquet_files(path=ds_path) # {delimited, json, parquet, sql}\n",
    "# diabetes = dataset.to_pandas_dataframe() # create a pandas dataframe\n",
    "\n",
    "# Separate features and labels as numpy array\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=model, filename=model_file) # backup model local\n",
    "run.upload_file(name='outputs/' + model_file,\n",
    "                path_or_stream='./' + model_file) # save model to workspace\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Script method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_service folder created\n"
     ]
    }
   ],
   "source": [
    "# Create a local folder for the experiment files\n",
    "folder_name = 'diabetes_service'\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "print(folder_name, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./diabetes_service/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import glob\n",
    "print(\"libraries imported...\")\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "print(\"argparse parameters loaded...\")\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "print(\"run context loaded...\")\n",
    "\n",
    "# load the diabetes dataset (File method)\n",
    "# Get the training data from the estimator input identified as 'diabetes'\n",
    "mount = run.input_datasets['diabetes'] # read-only mount from delta lake as '/mnt/data'\n",
    "print(\"delta lake mounted...\")\n",
    "diabetes = pd.read_parquet('/mnt/data/diabetes.parquet') # load any file(s) from this delta lake mounted folder\n",
    "print(\"dataset loaded...\")\n",
    "\n",
    "# save data into workspace\n",
    "diabetes.to_csv(\"outputs/dataset.csv\", index=False) # {logs/  outputs/}\n",
    "print(\"test: write dataset to workspace 'outputs/dataset.csv'\")\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05:12:06:39,799 WARNING  [environment.py:342] 'enabled' is deprecated. Please use the azureml.core.runconfig.DockerConfiguration object with the 'use_docker' param instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220314.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": true,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"training_environment\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults~=1.40.0\",\n",
       "                        \"azureml-dataprep[pandas,fuse]\",\n",
       "                        \"pyarrow\",\n",
       "                        \"fastparquet\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn\",\n",
       "                \"joblib\"\n",
       "            ],\n",
       "            \"name\": \"azureml_1da841a808e222b919e9d6616f4cf9ed\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"1\"\n",
       "}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myenv = Environment(\"training_environment\")\n",
    "myenv.docker.enabled = True\n",
    "myenv.python.user_managed_dependencies = False\n",
    "conda_packages = ['scikit-learn', 'joblib', 'python==3.6.2']\n",
    "pip_packages = ['azureml-defaults', 'azureml-dataprep[pandas,fuse]', 'pyarrow', 'fastparquet']\n",
    "myenv.python.conda_dependencies = CondaDependencies.create(conda_packages=conda_packages, pip_packages=pip_packages)\n",
    "myenv.register(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: training_environment\n",
      "Name: AzureML-Triton\n",
      "Name: AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\n",
      "Name: AzureML-minimal-ubuntu18.04-py37-cpu-inference\n",
      "Name: AzureML-tensorflow-2.4-ubuntu18.04-py37-cpu-inference\n",
      "Name: AzureML-tensorflow-2.4-ubuntu18.04-py37-cuda11.0.3-gpu-inference\n",
      "Name: AzureML-tensorflow-2.4-ubuntu18.04-py37-cuda11-gpu\n",
      "Name: AzureML-pytorch-1.7-ubuntu18.04-py37-cuda11-gpu\n",
      "Name: AzureML-mlflow-ubuntu18.04-py37-cpu-inference\n",
      "Name: AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu-inference\n",
      "Name: AzureML-pytorch-1.10-ubuntu18.04-py37-cpu-inference\n",
      "Name: AzureML-pytorch-1.9-ubuntu18.04-py37-cpu-inference\n",
      "Name: AzureML-minimal-ubuntu18.04-py37-cuda11.0.3-gpu-inference\n",
      "Name: AzureML-pytorch-1.9-ubuntu18.04-py37-cuda11.0.3-gpu-inference\n",
      "Name: AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\n",
      "Name: AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu\n",
      "Name: AzureML-responsibleai-0.17-ubuntu20.04-py38-cpu\n",
      "Name: AzureML-sklearn-1.0-ubuntu20.04-py38-cpu\n",
      "Name: AzureML-tensorflow-2.6-ubuntu20.04-py38-cuda11-gpu\n",
      "Name: AzureML-tensorflow-2.5-ubuntu20.04-py38-cuda11-gpu\n",
      "Name: AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu\n",
      "Name: AzureML-pytorch-1.8-ubuntu18.04-py37-cuda11-gpu\n",
      "Name: AzureML-pytorch-1.9-ubuntu18.04-py37-cuda11-gpu\n",
      "Name: AzureML-pytorch-1.10-ubuntu18.04-py38-cuda11-gpu\n",
      "Name: AzureML-VowpalWabbit-8.8.0\n",
      "Name: AzureML-PyTorch-1.3-CPU\n"
     ]
    }
   ],
   "source": [
    "# list environments\n",
    "env_names = Environment.list(workspace=ws)\n",
    "for env_name in env_names:\n",
    "    print('Name:',env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and register dataset (File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05:12:06:48,108 INFO     [datastore_client.py:991] <azureml.core.authentication.ServicePrincipalAuthentication object at 0x7f96dc02a3a0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset registered\n"
     ]
    }
   ],
   "source": [
    "# load the diabetes dataset (File method)\n",
    "ds = Datastore.get(ws, 'datalakestoragegen2')\n",
    "ds_path = [DataPath(ds, 'platinum/**')] # {path/*.parquet or path/**}\n",
    "file_ds = Dataset.File.from_files(path=ds_path)\n",
    "   \n",
    "# Register the file dataset\n",
    "try:\n",
    "    file_ds = file_ds.register(workspace=ws,\n",
    "                               name='diabetes file dataset',\n",
    "                               description='diabetes files',\n",
    "                               tags = {'format':'parquet'},\n",
    "                               create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "print('Dataset registered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "\t diabetes file dataset \t version 1\n"
     ]
    }
   ],
   "source": [
    "# show a list of registered dataset(s)\n",
    "print(\"Datasets:\")\n",
    "for dataset_name in list(ws.datasets.keys()):\n",
    "    dataset = Dataset.get_by_name(ws, dataset_name)\n",
    "    print(\"\\t\", dataset.name, '\\t version', dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/diabetes.csv\n",
      "/diabetes.parquet\n",
      "/pharma_ref.xlsx\n"
     ]
    }
   ],
   "source": [
    "# list of the file path(s)\n",
    "for file_path in file_ds.to_path():\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05:12:07:00,468 WARNING  [_estimator.py:348] 'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.\n",
      "2022-04-05:12:07:00,590 WARNING  [script_run_config.py:375] If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "2022-04-05:12:07:00,591 WARNING  [script_run_config.py:382] If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n",
      "2022-04-05:12:07:00,709 INFO     [_loggerfactory.py:154] ScriptRunSubmit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63b44100b0549ccb392de3f9fff3c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/diabetes-training_1649153220_4fde8e7e?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup01/workspaces/machine_learning_workspace01&tid=73b49191-8db3-45ab-87b3-b8f956ac123b\", \"run_id\": \"diabetes-training_1649153220_4fde8e7e\", \"run_properties\": {\"run_id\": \"diabetes-training_1649153220_4fde8e7e\", \"created_utc\": \"2022-04-05T10:07:01.226604Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"70d47910-1467-4bc7-b33b-f965eaa46de3\", \"azureml.git.repository_uri\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"mlflow.source.git.repoURL\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"6fff6c6dbc2e7e872873ad08b697dec70d229e8e\", \"mlflow.source.git.commit\": \"6fff6c6dbc2e7e872873ad08b697dec70d229e8e\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-04-05T10:17:54.322245Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://machinelstorage865aef211.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1649153220_4fde8e7e/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=9DNNouyQUzgpTERkcBRSTQUayL%2FP2ShXV%2B5vbVz%2BQWY%3D&skoid=d7a875a7-31b4-45e7-88e9-78f0c526e9f4&sktid=73b49191-8db3-45ab-87b3-b8f956ac123b&skt=2022-04-05T08%3A24%3A14Z&ske=2022-04-06T16%3A34%3A14Z&sks=b&skv=2019-07-07&st=2022-04-05T11%3A32%3A19Z&se=2022-04-05T19%3A42%3A19Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://machinelstorage865aef211.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1649153220_4fde8e7e/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=861sPbqGrhY9YmuSD0hLWvImX%2FM572Ry%2FpATZQN4JTA%3D&skoid=d7a875a7-31b4-45e7-88e9-78f0c526e9f4&sktid=73b49191-8db3-45ab-87b3-b8f956ac123b&skt=2022-04-05T08%3A24%3A14Z&ske=2022-04-06T16%3A34%3A14Z&sks=b&skv=2019-07-07&st=2022-04-05T11%3A32%3A19Z&se=2022-04-05T19%3A42%3A19Z&sp=r\", \"logs/azureml/8_azureml.log\": \"https://machinelstorage865aef211.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1649153220_4fde8e7e/logs/azureml/8_azureml.log?sv=2019-07-07&sr=b&sig=gSzZoYftvCm9K7wYhzcfRZfYYTIpt1Rlmvoc%2FdjLxQY%3D&skoid=d7a875a7-31b4-45e7-88e9-78f0c526e9f4&sktid=73b49191-8db3-45ab-87b3-b8f956ac123b&skt=2022-04-05T08%3A24%3A14Z&ske=2022-04-06T16%3A34%3A14Z&sks=b&skv=2019-07-07&st=2022-04-05T11%3A31%3A16Z&se=2022-04-05T19%3A41%3A16Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess.log\": \"https://machinelstorage865aef211.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1649153220_4fde8e7e/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=aEN51hsIUOYKqtWLh1p%2BA2ONyL2jPmxKHZ3QmF%2B42Jg%3D&skoid=d7a875a7-31b4-45e7-88e9-78f0c526e9f4&sktid=73b49191-8db3-45ab-87b3-b8f956ac123b&skt=2022-04-05T08%3A24%3A14Z&ske=2022-04-06T16%3A34%3A14Z&sks=b&skv=2019-07-07&st=2022-04-05T11%3A31%3A16Z&se=2022-04-05T19%3A41%3A16Z&sp=r\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\": \"https://machinelstorage865aef211.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1649153220_4fde8e7e/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=%2FNPHUwo9yeyWn3bz97FfR5qgcZeRK7kljpXhxVKBg%2Bk%3D&skoid=d7a875a7-31b4-45e7-88e9-78f0c526e9f4&sktid=73b49191-8db3-45ab-87b3-b8f956ac123b&skt=2022-04-05T08%3A24%3A14Z&ske=2022-04-06T16%3A34%3A14Z&sks=b&skv=2019-07-07&st=2022-04-05T11%3A31%3A16Z&se=2022-04-05T19%3A41%3A16Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/dataprep/backgroundProcess.log\", \"logs/azureml/dataprep/backgroundProcess_Telemetry.log\"], [\"logs/azureml/8_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:10:53\", \"run_number\": \"1649153221\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"diabetes-training_1649153220_4fde8e7e\", \"categories\": [0], \"series\": [{\"data\": [0.1]}]}, {\"name\": \"Accuracy\", \"run_id\": \"diabetes-training_1649153220_4fde8e7e\", \"categories\": [0], \"series\": [{\"data\": [0.774]}]}, {\"name\": \"AUC\", \"run_id\": \"diabetes-training_1649153220_4fde8e7e\", \"categories\": [0], \"series\": [{\"data\": [0.8484377332205582]}]}], \"run_logs\": \"[2022-04-05T10:17:29.128266] Entering context manager injector.\\nCannot provide tracer without any exporter configured.\\n[2022-04-05T10:17:30.668178] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['diabetes_training.py', '--regularization', '0.1'])\\n[2022-04-05T10:17:32.411] Initialize DatasetContextManager.\\nScript type = None\\nSet Dataset diabetes's target path to /mnt/data\\n[2022-04-05T10:17:32.452] Enter __enter__ of DatasetContextManager\\n[2022-04-05T10:17:32.453] SDK version: azureml-core==1.40.0 azureml-dataprep==3.0.1. Session id: 27384a02-2c0b-4dee-9b42-44e9f5c86289. Run id: diabetes-training_1649153220_4fde8e7e.\\n[2022-04-05T10:17:32.453] Processing 'diabetes'.\\n[2022-04-05T10:17:32.453] Mode: 'mount'.\\n[2022-04-05T10:17:32.453] Path on compute is specified: 'False'.\\n[2022-04-05T10:17:32.454] asset_type: None, is_eval_mode: False, is_legacy_dataset: False for input: diabetes\\n[2022-04-05T10:17:36.461] Processing dataset FileDataset\\n{\\n  \\\"source\\\": [\\n    \\\"('datalakestoragegen2', 'platinum/**')\\\"\\n  ],\\n  \\\"definition\\\": [\\n    \\\"GetDatastoreFiles\\\"\\n  ],\\n  \\\"registration\\\": {\\n    \\\"id\\\": \\\"5232b173-8663-4f1e-ae7e-4f55879e07ed\\\",\\n    \\\"name\\\": \\\"diabetes file dataset\\\",\\n    \\\"version\\\": 1,\\n    \\\"description\\\": \\\"diabetes files\\\",\\n    \\\"tags\\\": {\\n      \\\"format\\\": \\\"parquet\\\"\\n    },\\n    \\\"workspace\\\": \\\"Workspace.create(name='machine_learning_workspace01', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup01')\\\"\\n  }\\n}\\n[2022-04-05T10:17:37.803] Mounting diabetes to /mnt/data as folder.\\n[2022-04-05T10:17:37.822] Mounting diabetes to /mnt/data.\\nfuse: warning: library too old, some operations may not not work\\n[2022-04-05T10:17:38.823] Mounted diabetes to /mnt/data.\\n[2022-04-05T10:17:38.923] Exit __enter__ of DatasetContextManager\\n[2022-04-05T10:17:38.924140] Entering Run History Context Manager.\\n[2022-04-05T10:17:39.602917] Current directory: /azureml-run\\n[2022-04-05T10:17:39.602967] Preparing to call script [diabetes_training.py] with arguments:['--regularization', '0.1']\\n[2022-04-05T10:17:39.602986] After variable expansion, calling script [diabetes_training.py] with arguments:['--regularization', '0.1']\\n\\nlibraries imported...\\nargparse parameters loaded...\\nrun context loaded...\\ndelta lake mounted...\\ndataset loaded...\\ntest: write dataset to workspace 'outputs/dataset.csv'\\nTraining a logistic regression model with regularization rate of 0.1\\nAccuracy: 0.774\\nAUC: 0.8484377332205582\\n\\n\\n[2022-04-05T10:17:47.648600] The experiment completed successfully. Finalizing run...\\n[2022-04-05T10:17:47.648622] Start FinalizingInRunHistory\\n[2022-04-05T10:17:47.650040] Logging experiment finalizing status in history service.\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.13105487823486328 seconds\\n[2022-04-05T10:17:48.832] Enter __exit__ of DatasetContextManager\\n[2022-04-05T10:17:48.832] Unmounting /mnt/data.\\n[2022-04-05T10:17:48.836] Finishing unmounting /mnt/data.\\n[2022-04-05T10:17:48.836] Exit __exit__ of DatasetContextManager\\n[2022-04-05T10:17:48.836538] Finished context manager injector.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.40.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.4 s, sys: 3.25 s, total: 27.6 s\n",
      "Wall time: 11min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'diabetes-training_1649153220_4fde8e7e',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2022-04-05T10:17:27.725978Z',\n",
       " 'endTimeUtc': '2022-04-05T10:17:54.322245Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '70d47910-1467-4bc7-b33b-f965eaa46de3',\n",
       "  'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '6fff6c6dbc2e7e872873ad08b697dec70d229e8e',\n",
       "  'mlflow.source.git.commit': '6fff6c6dbc2e7e872873ad08b697dec70d229e8e',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [{'dataset': {'id': '5232b173-8663-4f1e-ae7e-4f55879e07ed'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes', 'mechanism': 'Mount', 'pathOnCompute': '/mnt/data'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization', '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'diabetes': {'dataLocation': {'dataset': {'id': '5232b173-8663-4f1e-ae7e-4f55879e07ed',\n",
       "      'name': 'diabetes file dataset',\n",
       "      'version': '1'},\n",
       "     'dataPath': None,\n",
       "     'uri': None,\n",
       "     'type': None},\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'diabetes',\n",
       "    'pathOnCompute': '/mnt/data',\n",
       "    'overwrite': False,\n",
       "    'options': None}},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'training_environment',\n",
       "   'version': '1',\n",
       "   'assetId': 'azureml://locations/westeurope/workspaces/5224a85c-9ec5-4b58-86dd-d59b28efde48/environments/training_environment/versions/1',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults~=1.40.0',\n",
       "        'azureml-dataprep[pandas,fuse]',\n",
       "        'pyarrow',\n",
       "        'fastparquet']},\n",
       "      'scikit-learn',\n",
       "      'joblib'],\n",
       "     'name': 'azureml_1da841a808e222b919e9d6616f4cf9ed'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220314.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': 'pytorch-1.7.0',\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://machinelstorage865aef211.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1649153220_4fde8e7e/azureml-logs/60_control_log.txt?sv=2019-07-07&sr=b&sig=iDiBA0r7%2F9RALZsM18SFF4l7n0Diho5J8WP5s0zVwzY%3D&skoid=d7a875a7-31b4-45e7-88e9-78f0c526e9f4&sktid=73b49191-8db3-45ab-87b3-b8f956ac123b&skt=2022-04-05T08%3A24%3A14Z&ske=2022-04-06T16%3A34%3A14Z&sks=b&skv=2019-07-07&st=2022-04-05T10%3A07%3A55Z&se=2022-04-05T18%3A17%3A55Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://machinelstorage865aef211.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1649153220_4fde8e7e/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=2ivI1pCMF7BAt077qN%2B%2BeMMIvrK8MTO7WHlCFc4rL8U%3D&skoid=d7a875a7-31b4-45e7-88e9-78f0c526e9f4&sktid=73b49191-8db3-45ab-87b3-b8f956ac123b&skt=2022-04-05T08%3A24%3A14Z&ske=2022-04-06T16%3A34%3A14Z&sks=b&skv=2019-07-07&st=2022-04-05T10%3A07%3A55Z&se=2022-04-05T18%3A17%3A55Z&sp=r',\n",
       "  'logs/azureml/8_azureml.log': 'https://machinelstorage865aef211.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1649153220_4fde8e7e/logs/azureml/8_azureml.log?sv=2019-07-07&sr=b&sig=2dAWLEUnYuf5drSDwHyLepze0lf17BPLFqo1nOx6h7Y%3D&skoid=d7a875a7-31b4-45e7-88e9-78f0c526e9f4&sktid=73b49191-8db3-45ab-87b3-b8f956ac123b&skt=2022-04-05T08%3A24%3A14Z&ske=2022-04-06T16%3A34%3A14Z&sks=b&skv=2019-07-07&st=2022-04-05T10%3A07%3A40Z&se=2022-04-05T18%3A17%3A40Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://machinelstorage865aef211.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1649153220_4fde8e7e/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=S8bkFwEfw9SQLqGbiWCsYDO8BQPWdYBpHeBQ1bbhkcM%3D&skoid=d7a875a7-31b4-45e7-88e9-78f0c526e9f4&sktid=73b49191-8db3-45ab-87b3-b8f956ac123b&skt=2022-04-05T08%3A24%3A14Z&ske=2022-04-06T16%3A34%3A14Z&sks=b&skv=2019-07-07&st=2022-04-05T10%3A07%3A40Z&se=2022-04-05T18%3A17%3A40Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://machinelstorage865aef211.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1649153220_4fde8e7e/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=Q81SF45Rs7ZNqrXd8zW%2BNME1ght6%2FqgJ29oyDKGJKF0%3D&skoid=d7a875a7-31b4-45e7-88e9-78f0c526e9f4&sktid=73b49191-8db3-45ab-87b3-b8f956ac123b&skt=2022-04-05T08%3A24%3A14Z&ske=2022-04-06T16%3A34%3A14Z&sks=b&skv=2019-07-07&st=2022-04-05T10%3A07%3A40Z&se=2022-04-05T18%3A17%3A40Z&sp=r'},\n",
       " 'submittedBy': 'd7c04ded-ec80-4e62-a9d2-423b2553b83d'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Set the script parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1\n",
    "}\n",
    "\n",
    "# load the registered dataset by name\n",
    "file_ds = Dataset.get_by_name(ws, \"diabetes file dataset\")\n",
    "\n",
    "# load the docker environment\n",
    "training_env = Environment.get(ws, 'training_environment')\n",
    "\n",
    "# load the training compute cluster\n",
    "training_cluster = ComputeTarget(ws, 'aml-cluster')\n",
    "\n",
    "estimator = Estimator(source_directory=experiment_folder, # All the files in this directory are uploaded into the cluster nodes for execution\n",
    "                      compute_target='local', # {'local', training_cluster}\n",
    "                      entry_script='diabetes_training.py',\n",
    "                      script_params=script_params,\n",
    "                      environment_definition=training_env,\n",
    "                      inputs=[file_ds.as_named_input('diabetes').as_mount(path_on_compute='/mnt/data')],\n",
    "                     )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'diabetes-training'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion() # get more parameter info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ScriptRun Widget](../../image/howto_automl/script_run_widget1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inference script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_service folder created\n"
     ]
    }
   ],
   "source": [
    "# Create a local folder for the experiment files\n",
    "folder_name = 'diabetes_service'\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "print(folder_name, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_service/diabetes_score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $folder_name/diabetes_score.py\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load a registered model\n",
    "    model_path = Model.get_model_path(model_name='diabetes_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-diabetic', 'diabetic']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inference environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved inference environment file in diabetes_service/diabetes_env.yml\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = folder_name + \"/diabetes_env.yml\"\n",
    "with open(env_file, \"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved inference environment file in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and registered\n"
     ]
    }
   ],
   "source": [
    "# define model name\n",
    "model_name = 'diabetes_model'\n",
    "\n",
    "# register model from the workspace \n",
    "run.register_model(model_name=model_name, # registered model name used in scoring script init()\n",
    "                   model_path='outputs/diabetes_model.pkl', # fixed path in workspace {'model.pkl', 'model.onnx'}\n",
    "                   tags={'Training context': 'Custom Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'],\n",
    "                               'Accuracy': run.get_metrics()['Accuracy']},\n",
    "                   description=\"Classification model to predict diabetes\",\n",
    "                   model_framework=Model.Framework.SCIKITLEARN, # {TensorFlow, ScikitLearn, Onnx, Custom}\n",
    "                   model_framework_version='0.22.2')\n",
    "\n",
    "print('Model trained and registered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"diabetes-service\" does not exist, creating the webservice...\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2022-04-05 12:19:25+02:00 Creating Container Registry if not exists.\n",
      "2022-04-05 12:19:25+02:00 Registering the environment.\n",
      "2022-04-05 12:19:27+02:00 Building image..\n",
      "2022-04-05 12:25:39+02:00 Generating deployment configuration..\n",
      "2022-04-05 12:25:40+02:00 Submitting deployment to compute..\n",
      "2022-04-05 12:25:46+02:00 Checking the status of deployment diabetes-service..\n",
      "2022-04-05 12:27:40+02:00 Checking the status of inference endpoint diabetes-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "CPU times: user 12 s, sys: 1.83 s, total: 13.8 s\n",
      "Wall time: 8min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "service_name = \"diabetes-service\"\n",
    "\n",
    "# Remove any existing service under the same name\n",
    "try:\n",
    "    Webservice(ws, service_name).delete()\n",
    "except WebserviceException:\n",
    "    print('\"' + service_name + '\" does not exist, creating the webservice...')\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime=\"python\",\n",
    "                                   source_directory=folder_name,\n",
    "                                   entry_script=\"diabetes_score.py\",\n",
    "                                   conda_file=\"diabetes_env.yml\")\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                                       memory_gb=1)\n",
    "\n",
    "# load the registered model\n",
    "model = ws.models['diabetes_model']\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI: http://961f4622-8384-4fcb-86a0-e4aa8f56bbf1.westeurope.azurecontainer.io/score\n",
      "Body: {\"data\": [[9, 103, 78, 25, 304, 29.6, 1.28, 43], [0, 148, 58, 11, 179, 39, 0.16, 45]]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[\"diabetic\", \"not-diabetic\"]'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get webservice URI\n",
    "endpoint = service.scoring_uri\n",
    "\n",
    "# raw test data\n",
    "rawdata = [[9, 103, 78, 25, 304, 29.6, 1.28, 43],\n",
    "           [0, 148, 58, 11, 179, 39, 0.16, 45]]\n",
    "\n",
    "print(\"URI: \" + endpoint)\n",
    "print(\"Body: \" + json.dumps({\"data\": rawdata})) # convert array to a serialized JSON formatted string object\n",
    "\n",
    "service.run(json.dumps({\"data\": rawdata}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are finished testing your service, clean up the deployment with service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning of the model using HyperDrive.  \n",
    "Hyperdrive runs enable comparison for metrics on all different hyper parameter combinations tried.  \n",
    "\n",
    "[doc: how to tune hyperparameters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)  \n",
    "[git: examples](https://github.com/microsoft/MLHyperparameterTuning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AmlCompute\n",
    "training_cluster = ComputeTarget(ws, 'aml-cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a project directory\n",
    "project_folder = './diabetes_hyperdrive'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment folder\n",
    "experiment_folder = './' + project_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ././diabetes_hyperdrive/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "\n",
    "import argparse\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import glob\n",
    "print(\"libraries imported...\")\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "print(\"run context loaded...\")\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "parser.add_argument('--C', type=float, default=1.0, help='Inverse of regularization strength')\n",
    "parser.add_argument('--solver', type=str, default='lbfgs', help='Algorithm to use in the optimization problem')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "run.log('Inverse of regularization strength', np.float(args.C))\n",
    "run.log('Algorithm to use in the optimization problem', np.str(args.solver))\n",
    "print(\"argparse parameters loaded...\")\n",
    "\n",
    "# load the diabetes dataset (File method)\n",
    "# Get the training data from the estimator input identified as 'diabetes'\n",
    "mount = run.input_datasets['diabetes'] # read-only mount from delta lake as '/mnt/data'\n",
    "print(\"delta lake mounted...\")\n",
    "diabetes = pd.read_parquet('/mnt/data/diabetes.parquet') # load any file(s) from this delta lake mounted folder\n",
    "print(\"dataset loaded...\")\n",
    "\n",
    "# save data into workspace\n",
    "diabetes.to_csv(\"outputs/dataset.csv\", index=False) # {logs/  outputs/}\n",
    "print(\"test: write dataset to workspace 'outputs/dataset.csv'\")\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=args.C, solver=args.solver).fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment name\n",
    "experiment = Experiment(ws, 'diabetes-hyperdrive-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azureml.train.estimator._estimator:'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.\n"
     ]
    }
   ],
   "source": [
    "# Create a Scikit-learn estimator\n",
    "\n",
    "# get the training compute cluster\n",
    "training_cluster = ComputeTarget(ws, 'aml-cluster')\n",
    "\n",
    "# Set the script parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1,\n",
    "    '--C': 10,\n",
    "    '--solver': 'lbfgs',\n",
    "}\n",
    "\n",
    "# Get the docker environment\n",
    "training_env = Environment.get(ws, 'training_environment')\n",
    "\n",
    "# get the registered dataset by name\n",
    "file_ds = Dataset.get_by_name(ws, \"diabetes file dataset\")\n",
    "\n",
    "estimator = Estimator(source_directory=experiment_folder, # All the files in this directory are uploaded into the cluster nodes for execution\n",
    "                      compute_target=training_cluster, # only compute allowed for hyperparameter tuning\n",
    "                      entry_script='diabetes_training.py',\n",
    "                      script_params=script_params,\n",
    "                      environment_definition=training_env,\n",
    "                      inputs=[file_ds.as_named_input('diabetes').as_mount(path_on_compute='/mnt/data')],\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the hyperparameter space\n",
    "\n",
    "param_sampling = RandomParameterSampling( {\n",
    "    '--regularization': choice(1, 0.333, 0.1, 0.033),\n",
    "    '--C': choice(1, 3, 10, 30),\n",
    "    '--solver': choice('lbfgs', 'liblinear', 'newton-cg', 'lbfgs', 'sag'),\n",
    "    } )\n",
    "\n",
    "hyperdrive_run_config = HyperDriveConfig(estimator=estimator,\n",
    "                                         hyperparameter_sampling=param_sampling,\n",
    "                                         primary_metric_name='Accuracy',\n",
    "                                         primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                         max_total_runs=20,   # 20 = reg x C x solver = 4 x 4 x 5 script uses C + solver = 20\n",
    "                                         max_concurrent_runs=5,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "WARNING:root:If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 325 ms, sys: 238 ms, total: 563 ms\n",
      "Wall time: 3.97 s\n"
     ]
    }
   ],
   "source": [
    "# start the HyperDrive experiment run (~25')\n",
    "hyperdrive_run = experiment.submit(config=hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can take ~25min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9eef4599d743f08eab710e7c221b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-hyperdrive-training/runs/HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup02/workspaces/machine_learning_workspace02\", \"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"run_properties\": {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"created_utc\": \"2021-03-04T14:00:51.50102Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"46e74d94-2356-4568-b1b3-153f4cbb86a8\", \"score\": \"0.7743333333333333\", \"best_child_run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_1\", \"best_metric_status\": \"Succeeded\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"5\", \"max_concurrent_jobs\": \"5\", \"_aml_system_max_total_jobs\": \"20\", \"max_total_jobs\": \"20\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--regularization\\\": [\\\"choice\\\", [[1, 0.333, 0.1, 0.033]]], \\\"--C\\\": [\\\"choice\\\", [[1, 3, 10, 30]]], \\\"--solver\\\": [\\\"choice\\\", [[\\\"lbfgs\\\", \\\"liblinear\\\", \\\"newton-cg\\\", \\\"lbfgs\\\", \\\"sag\\\"]]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--regularization\\\": [\\\"choice\\\", [[1, 0.333, 0.1, 0.033]]], \\\"--C\\\": [\\\"choice\\\", [[1, 3, 10, 30]]], \\\"--solver\\\": [\\\"choice\\\", [[\\\"lbfgs\\\", \\\"liblinear\\\", \\\"newton-cg\\\", \\\"lbfgs\\\", \\\"sag\\\"]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://northeurope.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourceGroups/myResourceGroup02/providers/Microsoft.MachineLearningServices/workspaces/machine_learning_workspace02/experiments/diabetes-hyperdrive-training\\\", \\\"SubscriptionId\\\": \\\"43c1f93a-903d-4b23-a4bf-92bd7a150627\\\", \\\"ResourceGroupName\\\": \\\"myResourceGroup02\\\", \\\"WorkspaceName\\\": \\\"machine_learning_workspace02\\\", \\\"ExperimentName\\\": \\\"diabetes-hyperdrive-training\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"diabetes_training.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"aml-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"priority\\\": null, \\\"environment\\\": {\\\"name\\\": \\\"training_environment\\\", \\\"version\\\": \\\"1\\\", \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"], \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults~=1.23.0\\\", \\\"azureml-dataprep[pandas,fuse]\\\", \\\"pyarrow\\\", \\\"fastparquet\\\"]}, \\\"scikit-learn\\\", \\\"joblib\\\"], \\\"name\\\": \\\"azureml_71d6f591a76ce54ae892285bb7c673cd\\\"}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210129.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": null, \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"pytorch\\\": {\\\"communicationBackend\\\": \\\"nccl\\\", \\\"processCount\\\": null, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {\\\"diabetes\\\": {\\\"dataLocation\\\": {\\\"dataset\\\": {\\\"id\\\": \\\"b7710f77-23bc-4e21-8d40-17f610b46c31\\\", \\\"name\\\": \\\"diabetes file dataset\\\", \\\"version\\\": 1}, \\\"dataPath\\\": null}, \\\"createOutputDirectories\\\": false, \\\"mechanism\\\": \\\"mount\\\", \\\"environmentVariableName\\\": \\\"diabetes\\\", \\\"pathOnCompute\\\": \\\"/mnt/data\\\", \\\"overwrite\\\": false}}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"46e74d94-2356-4568-b1b3-153f4cbb86a8\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"73b49191-8db3-45ab-87b3-b8f956ac123b\\\", \\\"amlClientRequestId\\\": \\\"d41aed79-8643-4258-a79e-4b9d504704c4\\\", \\\"amlClientSessionId\\\": \\\"54377e2e-bcf3-4e20-9e89-2e9352108c1b\\\", \\\"subscriptionId\\\": \\\"43c1f93a-903d-4b23-a4bf-92bd7a150627\\\", \\\"estimator\\\": \\\"Estimator\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 5, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://northeurope.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourceGroups/myResourceGroup02/providers/Microsoft.MachineLearningServices/workspaces/machine_learning_workspace02/experiments/diabetes-hyperdrive-training\\\", \\\"SubscriptionId\\\": \\\"43c1f93a-903d-4b23-a4bf-92bd7a150627\\\", \\\"ResourceGroupName\\\": \\\"myResourceGroup02\\\", \\\"WorkspaceName\\\": \\\"machine_learning_workspace02\\\", \\\"ExperimentName\\\": \\\"diabetes-hyperdrive-training\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"diabetes_training.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"aml-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"priority\\\": null, \\\"environment\\\": {\\\"name\\\": \\\"training_environment\\\", \\\"version\\\": \\\"1\\\", \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"], \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults~=1.23.0\\\", \\\"azureml-dataprep[pandas,fuse]\\\", \\\"pyarrow\\\", \\\"fastparquet\\\"]}, \\\"scikit-learn\\\", \\\"joblib\\\"], \\\"name\\\": \\\"azureml_71d6f591a76ce54ae892285bb7c673cd\\\"}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210129.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": null, \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"pytorch\\\": {\\\"communicationBackend\\\": \\\"nccl\\\", \\\"processCount\\\": null, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {\\\"diabetes\\\": {\\\"dataLocation\\\": {\\\"dataset\\\": {\\\"id\\\": \\\"b7710f77-23bc-4e21-8d40-17f610b46c31\\\", \\\"name\\\": \\\"diabetes file dataset\\\", \\\"version\\\": 1}, \\\"dataPath\\\": null}, \\\"createOutputDirectories\\\": false, \\\"mechanism\\\": \\\"mount\\\", \\\"environmentVariableName\\\": \\\"diabetes\\\", \\\"pathOnCompute\\\": \\\"/mnt/data\\\", \\\"overwrite\\\": false}}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"46e74d94-2356-4568-b1b3-153f4cbb86a8\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"73b49191-8db3-45ab-87b3-b8f956ac123b\\\", \\\"amlClientRequestId\\\": \\\"d41aed79-8643-4258-a79e-4b9d504704c4\\\", \\\"amlClientSessionId\\\": \\\"54377e2e-bcf3-4e20-9e89-2e9352108c1b\\\", \\\"subscriptionId\\\": \\\"43c1f93a-903d-4b23-a4bf-92bd7a150627\\\", \\\"estimator\\\": \\\"Estimator\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 5, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2021-03-04T14:00:52.205684\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2021-03-04T14:00:52.205684\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"fe44d061377df5248a3a4f5a6d0b928bf44c7ac77792ecd954fa27dcef6a4d8d\\\"\", \"progress_metadata_digest\": \"\\\"fe44d061377df5248a3a4f5a6d0b928bf44c7ac77792ecd954fa27dcef6a4d8d\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2021-03-04T14:00:52.205684\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2021-03-04T14:00:52.205684\\\"\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_0\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 0.333, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_0\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 0.333, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_1\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 1, \\\"--solver\\\": \\\"liblinear\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_1\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 1, \\\"--solver\\\": \\\"liblinear\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_2\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_2\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_3\": \"{\\\"--C\\\": 30, \\\"--regularization\\\": 1, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_3\": \"{\\\"--C\\\": 30, \\\"--regularization\\\": 1, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_4\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"liblinear\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_4\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"liblinear\\\"}\", \"_aml_system_environment_preparation_status\": \"PREPARED\", \"environment_preparation_status\": \"PREPARED\", \"_aml_system_prepare_run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_preparation\", \"prepare_run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_preparation\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_5\": \"{\\\"--C\\\": 30, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_5\": \"{\\\"--C\\\": 30, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_6\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 1, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_6\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 1, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_7\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"sag\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_7\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"sag\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_8\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 1, \\\"--solver\\\": \\\"sag\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_8\": \"{\\\"--C\\\": 3, \\\"--regularization\\\": 1, \\\"--solver\\\": \\\"sag\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_9\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 0.333, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_9\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 0.333, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_10\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.333, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_10\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.333, \\\"--solver\\\": \\\"lbfgs\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_11\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_11\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_12\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_12\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_13\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"sag\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_13\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"sag\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_14\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"sag\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_14\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"sag\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_15\": \"{\\\"--C\\\": 30, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"sag\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_15\": \"{\\\"--C\\\": 30, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"sag\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_16\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"liblinear\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_16\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.033, \\\"--solver\\\": \\\"liblinear\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_17\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"liblinear\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_17\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"liblinear\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_18\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"liblinear\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_18\": \"{\\\"--C\\\": 1, \\\"--regularization\\\": 0.1, \\\"--solver\\\": \\\"liblinear\\\"}\", \"_aml_system_HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_19\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.333, \\\"--solver\\\": \\\"newton-cg\\\"}\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_19\": \"{\\\"--C\\\": 10, \\\"--regularization\\\": 0.333, \\\"--solver\\\": \\\"newton-cg\\\"}\"}, \"end_time_utc\": \"2021-03-04T14:23:39.921069Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=UDpup17E9EIUIVye0oOeGaS85UjeFvcXjuZ6my5J%2FXY%3D&st=2021-03-04T15%3A14%3A39Z&se=2021-03-04T23%3A24%3A39Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:22:48\", \"run_number\": \"1\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}, \"hyper_parameters\": {\"--regularization\": [\"choice\", [[1, 0.333, 0.1, 0.033]]], \"--C\": [\"choice\", [[1, 3, 10, 30]]], \"--solver\": [\"choice\", [[\"lbfgs\", \"liblinear\", \"newton-cg\", \"lbfgs\", \"sag\"]]]}}, \"child_runs\": [{\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_2\", \"run_number\": 3, \"metric\": 0.767, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:12:57.304121Z\", \"end_time\": \"2021-03-04T14:17:32.5621Z\", \"created_time\": \"2021-03-04T14:08:28.546399Z\", \"created_time_dt\": \"2021-03-04T14:08:28.546399Z\", \"duration\": \"0:09:04\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 1, \"param_--regularization\": 0.1, \"param_--solver\": \"lbfgs\", \"best_metric\": 0.767}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_0\", \"run_number\": 4, \"metric\": 0.76933333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:13:00.382796Z\", \"end_time\": \"2021-03-04T14:20:09.685812Z\", \"created_time\": \"2021-03-04T14:08:28.553931Z\", \"created_time_dt\": \"2021-03-04T14:08:28.553931Z\", \"duration\": \"0:11:41\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 3, \"param_--regularization\": 0.333, \"param_--solver\": \"lbfgs\", \"best_metric\": 0.76933333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_4\", \"run_number\": 5, \"metric\": 0.77433333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:12:57.93027Z\", \"end_time\": \"2021-03-04T14:17:12.940858Z\", \"created_time\": \"2021-03-04T14:08:28.573091Z\", \"created_time_dt\": \"2021-03-04T14:08:28.573091Z\", \"duration\": \"0:08:44\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 3, \"param_--regularization\": 0.033, \"param_--solver\": \"liblinear\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_3\", \"run_number\": 6, \"metric\": 0.77366667, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:12:54.203993Z\", \"end_time\": \"2021-03-04T14:17:17.728336Z\", \"created_time\": \"2021-03-04T14:08:28.678014Z\", \"created_time_dt\": \"2021-03-04T14:08:28.678014Z\", \"duration\": \"0:08:49\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 30, \"param_--regularization\": 1, \"param_--solver\": \"lbfgs\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_1\", \"run_number\": 7, \"metric\": 0.77433333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:12:57.436152Z\", \"end_time\": \"2021-03-04T14:17:22.143939Z\", \"created_time\": \"2021-03-04T14:08:28.802262Z\", \"created_time_dt\": \"2021-03-04T14:08:28.802262Z\", \"duration\": \"0:08:53\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 3, \"param_--regularization\": 1, \"param_--solver\": \"liblinear\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_6\", \"run_number\": 8, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:17:43.849152Z\", \"end_time\": \"2021-03-04T14:18:43.211173Z\", \"created_time\": \"2021-03-04T14:17:35.044243Z\", \"created_time_dt\": \"2021-03-04T14:17:35.044243Z\", \"duration\": \"0:01:08\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 1, \"param_--regularization\": 1, \"param_--solver\": \"newton-cg\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_5\", \"run_number\": 9, \"metric\": 0.77366667, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:17:42.907418Z\", \"end_time\": \"2021-03-04T14:18:39.120059Z\", \"created_time\": \"2021-03-04T14:17:35.155518Z\", \"created_time_dt\": \"2021-03-04T14:17:35.155518Z\", \"duration\": \"0:01:03\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 30, \"param_--regularization\": 0.1, \"param_--solver\": \"lbfgs\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_7\", \"run_number\": 10, \"metric\": 0.70933333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:17:42.847232Z\", \"end_time\": \"2021-03-04T14:18:42.010566Z\", \"created_time\": \"2021-03-04T14:17:35.25123Z\", \"created_time_dt\": \"2021-03-04T14:17:35.25123Z\", \"duration\": \"0:01:06\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 3, \"param_--regularization\": 0.033, \"param_--solver\": \"sag\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_8\", \"run_number\": 11, \"metric\": 0.70933333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:18:13.452572Z\", \"end_time\": \"2021-03-04T14:19:03.671991Z\", \"created_time\": \"2021-03-04T14:18:06.394612Z\", \"created_time_dt\": \"2021-03-04T14:18:06.394612Z\", \"duration\": \"0:00:57\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 3, \"param_--regularization\": 1, \"param_--solver\": \"sag\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_9\", \"run_number\": 12, \"metric\": 0.767, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:19:15.318303Z\", \"end_time\": \"2021-03-04T14:20:05.103795Z\", \"created_time\": \"2021-03-04T14:19:07.95846Z\", \"created_time_dt\": \"2021-03-04T14:19:07.95846Z\", \"duration\": \"0:00:57\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 1, \"param_--regularization\": 0.333, \"param_--solver\": \"lbfgs\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_11\", \"run_number\": 13, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:19:14.957809Z\", \"end_time\": \"2021-03-04T14:20:07.759Z\", \"created_time\": \"2021-03-04T14:19:08.072514Z\", \"created_time_dt\": \"2021-03-04T14:19:08.072514Z\", \"duration\": \"0:00:59\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 1, \"param_--regularization\": 0.033, \"param_--solver\": \"newton-cg\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_10\", \"run_number\": 14, \"metric\": 0.77233333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:19:15.352193Z\", \"end_time\": \"2021-03-04T14:20:08.204968Z\", \"created_time\": \"2021-03-04T14:19:08.189757Z\", \"created_time_dt\": \"2021-03-04T14:19:08.189757Z\", \"duration\": \"0:01:00\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 10, \"param_--regularization\": 0.333, \"param_--solver\": \"lbfgs\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_12\", \"run_number\": 15, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:19:48.974268Z\", \"end_time\": \"2021-03-04T14:20:42.694608Z\", \"created_time\": \"2021-03-04T14:19:39.403471Z\", \"created_time_dt\": \"2021-03-04T14:19:39.403471Z\", \"duration\": \"0:01:03\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 1, \"param_--regularization\": 0.1, \"param_--solver\": \"newton-cg\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_13\", \"run_number\": 16, \"metric\": 0.70933333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:20:48.215444Z\", \"end_time\": \"2021-03-04T14:21:47.121514Z\", \"created_time\": \"2021-03-04T14:20:41.086803Z\", \"created_time_dt\": \"2021-03-04T14:20:41.086803Z\", \"duration\": \"0:01:06\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 10, \"param_--regularization\": 0.1, \"param_--solver\": \"sag\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_14\", \"run_number\": 17, \"metric\": 0.70933333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:20:48.082464Z\", \"end_time\": \"2021-03-04T14:21:46.297656Z\", \"created_time\": \"2021-03-04T14:20:41.109695Z\", \"created_time_dt\": \"2021-03-04T14:20:41.109695Z\", \"duration\": \"0:01:05\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 10, \"param_--regularization\": 0.033, \"param_--solver\": \"sag\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_16\", \"run_number\": 18, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:20:48.761458Z\", \"end_time\": \"2021-03-04T14:21:54.236437Z\", \"created_time\": \"2021-03-04T14:20:41.409795Z\", \"created_time_dt\": \"2021-03-04T14:20:41.409795Z\", \"duration\": \"0:01:12\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 10, \"param_--regularization\": 0.033, \"param_--solver\": \"liblinear\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_15\", \"run_number\": 19, \"metric\": 0.70933333, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:20:48.864293Z\", \"end_time\": \"2021-03-04T14:21:44.664431Z\", \"created_time\": \"2021-03-04T14:20:41.413667Z\", \"created_time_dt\": \"2021-03-04T14:20:41.413667Z\", \"duration\": \"0:01:03\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 30, \"param_--regularization\": 0.1, \"param_--solver\": \"sag\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_17\", \"run_number\": 20, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:21:18.573577Z\", \"end_time\": \"2021-03-04T14:22:13.662963Z\", \"created_time\": \"2021-03-04T14:21:12.380902Z\", \"created_time_dt\": \"2021-03-04T14:21:12.380902Z\", \"duration\": \"0:01:01\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 10, \"param_--regularization\": 0.1, \"param_--solver\": \"liblinear\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_18\", \"run_number\": 21, \"metric\": 0.77266667, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:22:20.725603Z\", \"end_time\": \"2021-03-04T14:23:16.044896Z\", \"created_time\": \"2021-03-04T14:22:13.7826Z\", \"created_time_dt\": \"2021-03-04T14:22:13.7826Z\", \"duration\": \"0:01:02\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 1, \"param_--regularization\": 0.1, \"param_--solver\": \"liblinear\", \"best_metric\": 0.77433333}, {\"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_19\", \"run_number\": 22, \"metric\": 0.774, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-03-04T14:22:21.313699Z\", \"end_time\": \"2021-03-04T14:23:15.764744Z\", \"created_time\": \"2021-03-04T14:22:13.881684Z\", \"created_time_dt\": \"2021-03-04T14:22:13.881684Z\", \"duration\": \"0:01:01\", \"hyperdrive_id\": \"ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"arguments\": null, \"param_--C\": 10, \"param_--regularization\": 0.333, \"param_--solver\": \"newton-cg\", \"best_metric\": 0.77433333}], \"children_metrics\": {\"categories\": [0], \"series\": {\"Inverse of regularization strength\": [{\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"markers\", \"name\": \"Inverse of regularization strength\", \"stepped\": false, \"type\": \"scatter\", \"data\": [1.0, 3.0, 3.0, 30.0, 3.0, 1.0, 30.0, 3.0, 3.0, 1.0, 1.0, 10.0, 1.0, 10.0, 10.0, 10.0, 30.0, 10.0, 1.0, 10.0]}, {\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"lines\", \"name\": \"Inverse of regularization strength_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [1.0, 3.0, 3.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0]}], \"Algorithm to use in the optimization problem\": [{\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"markers\", \"name\": \"Algorithm to use in the optimization problem\", \"stepped\": false, \"type\": \"scatter\", \"data\": [\"lbfgs\", \"lbfgs\", \"liblinear\", \"lbfgs\", \"liblinear\", \"newton-cg\", \"lbfgs\", \"sag\", \"sag\", \"lbfgs\", \"newton-cg\", \"lbfgs\", \"newton-cg\", \"sag\", \"sag\", \"liblinear\", \"sag\", \"liblinear\", \"liblinear\", \"newton-cg\"]}, {\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"lines\", \"name\": \"Algorithm to use in the optimization problem_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": []}], \"Regularization Rate\": [{\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"markers\", \"name\": \"Regularization Rate\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.1, 0.333, 0.033, 1.0, 1.0, 1.0, 0.1, 0.033, 1.0, 0.333, 0.033, 0.333, 0.1, 0.1, 0.033, 0.033, 0.1, 0.1, 0.1, 0.333]}, {\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"lines\", \"name\": \"Regularization Rate_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.1, 0.333, 0.333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}], \"Accuracy\": [{\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"markers\", \"name\": \"Accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.767, 0.7693333333333333, 0.7743333333333333, 0.7736666666666666, 0.7743333333333333, 0.774, 0.7736666666666666, 0.7093333333333334, 0.7093333333333334, 0.767, 0.774, 0.7723333333333333, 0.774, 0.7093333333333334, 0.7093333333333334, 0.774, 0.7093333333333334, 0.774, 0.7726666666666666, 0.774]}, {\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"lines\", \"name\": \"Accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.767, 0.7693333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333, 0.7743333333333333]}], \"AUC\": [{\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"markers\", \"name\": \"AUC\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.8287432210557739, 0.8241111498084482, 0.8483402159311408, 0.84811433404647, 0.8483402159311408, 0.8485163440967213, 0.84811433404647, 0.7438414846509777, 0.7438404895765959, 0.8287432210557739, 0.8485163440967213, 0.8424319617891437, 0.8485163440967213, 0.7438509378576048, 0.743849942783223, 0.8484377332205582, 0.743835016667496, 0.8483198169063138, 0.8479630827404347, 0.8484994278322306]}, {\"categories\": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], \"mode\": \"lines\", \"name\": \"AUC_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.8287432210557739, 0.8287432210557739, 0.8483402159311408, 0.8483402159311408, 0.8483402159311408, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213, 0.8485163440967213]}]}, \"metricName\": null, \"primaryMetricName\": \"Accuracy\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc\", \"categories\": [0], \"series\": [{\"data\": [{\"metric_name\": [\"Accuracy\", \"Accuracy\"], \"timestamp\": [\"2021-03-04 14:17:25.665241+00:00\", \"2021-03-04 14:17:25.665241+00:00\"], \"run_id\": [\"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_1\", \"HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_1\"], \"metric_value\": [0.7743333333333333, 0.7743333333333333], \"final\": [false, true]}]}]}], \"run_logs\": \"[2021-03-04T14:00:51.768133][API][INFO]Experiment created\\r\\n[2021-03-04T14:00:52.317212][GENERATOR][INFO]Trying to sample '5' jobs from the hyperparameter space\\r\\n[2021-03-04T14:00:52.475079][GENERATOR][INFO]Successfully sampled '5' jobs, they will soon be submitted to the execution target.\\r\\n[2021-03-04T14:00:52.8003961Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\r\\n[2021-03-04T14:08:28.0479605Z][SCHEDULER][INFO]The execution environment was successfully prepared.\\r\\n[2021-03-04T14:08:27.9460457Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_3'\\r\\n[2021-03-04T14:08:27.9115969Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_4'\\r\\n[2021-03-04T14:08:27.9910365Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_2'\\r\\n[2021-03-04T14:08:28.0267427Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_1'\\r\\n[2021-03-04T14:08:28.0367024Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_0'\\r\\n[2021-03-04T14:08:28.6787029Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_2'\\r\\n[2021-03-04T14:08:28.6993627Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_4'\\r\\n[2021-03-04T14:08:28.7413383Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_0'\\r\\n[2021-03-04T14:08:28.8718983Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_3'\\r\\n[2021-03-04T14:08:28.9550042Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_1'\\r\\n[2021-03-04T14:17:24.584900][GENERATOR][INFO]Successfully sampled '3' jobs, they will soon be submitted to the execution target.\\r\\n[2021-03-04T14:17:23.807931][GENERATOR][INFO]Trying to sample '3' jobs from the hyperparameter space\\r\\n[2021-03-04T14:17:34.4809401Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_5'\\r\\n[2021-03-04T14:17:34.4820948Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_6'\\r\\n[2021-03-04T14:17:34.4955678Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_7'\\r\\n[2021-03-04T14:17:35.1635886Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_6'\\r\\n[2021-03-04T14:17:35.3290408Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_5'\\r\\n[2021-03-04T14:17:35.3787799Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_7'\\r\\n[2021-03-04T14:17:54.855045][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2021-03-04T14:17:55.010292][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2021-03-04T14:18:05.6968333Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_8'\\r\\n[2021-03-04T14:18:06.5798298Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_8'\\r\\n[2021-03-04T14:18:55.125421][GENERATOR][INFO]Trying to sample '3' jobs from the hyperparameter space\\r\\n[2021-03-04T14:18:55.657287][GENERATOR][INFO]Successfully sampled '3' jobs, they will soon be submitted to the execution target.\\r\\n[2021-03-04T14:19:07.4584553Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_11'\\r\\n[2021-03-04T14:19:07.4915541Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_10'\\r\\n[2021-03-04T14:19:07.5017964Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_9'\\r\\n[2021-03-04T14:19:08.1089603Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_9'\\r\\n[2021-03-04T14:19:08.2118124Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_11'\\r\\n[2021-03-04T14:19:08.3962159Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_10'\\r\\n[2021-03-04T14:19:26.240235][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2021-03-04T14:19:26.477683][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2021-03-04T14:19:38.7346529Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_12'\\r\\n[2021-03-04T14:19:39.5347253Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_12'\\r\\n[2021-03-04T14:20:27.326562][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2021-03-04T14:20:27.612680][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\r\\n[2021-03-04T14:20:40.5632367Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_14'\\r\\n[2021-03-04T14:20:40.5211439Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_15'\\r\\n[2021-03-04T14:20:40.5776595Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_13'\\r\\n[2021-03-04T14:20:40.4996649Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_16'\\r\\n[2021-03-04T14:20:41.2447826Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_13'\\r\\n[2021-03-04T14:20:41.3446928Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_14'\\r\\n[2021-03-04T14:20:41.5590154Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_16'\\r\\n[2021-03-04T14:20:41.5833128Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_15'\\r\\n[2021-03-04T14:20:58.091193][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2021-03-04T14:20:58.270432][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2021-03-04T14:21:11.8226696Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_17'\\r\\n[2021-03-04T14:21:12.5424478Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_17'\\r\\n[2021-03-04T14:22:00.569727][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2021-03-04T14:22:00.783259][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\r\\n[2021-03-04T14:22:13.1773647Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_19'\\r\\n[2021-03-04T14:22:13.1750619Z][SCHEDULER][INFO]Scheduling job, id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_18'\\r\\n[2021-03-04T14:22:14.0527242Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_19'\\r\\n[2021-03-04T14:22:13.9440592Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_ab3aa65d-f6ae-4209-a277-c07c448c42dc_18'\\r\\n[2021-03-04T14:22:31.576685][GENERATOR][INFO]Max number of jobs '20' reached for experiment.\\r\\n[2021-03-04T14:22:31.703376][GENERATOR][INFO]All jobs generated.\\r\\n[2021-03-04T14:23:40.275906][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.23.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.3 ms, sys: 5.09 ms, total: 30.4 ms\n",
      "Wall time: 316 ms\n"
     ]
    }
   ],
   "source": [
    "# Show the run details while running\n",
    "RunDetails(hyperdrive_run).show()  # <-- Completed, no it is running in the background !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hyperdrive_run](../../image/howto_automl/hyperdrive_run.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the RUN must FINISH first, then continue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--C', '3', '--regularization', '1', '--solver', 'liblinear']\n"
     ]
    }
   ],
   "source": [
    "# Find best run\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "print(best_run.get_details()['runDefinition']['arguments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "orchestrate machine learning operations, arranged sequentially or in parallel.  \n",
    "a workflow of machine learning tasks in which each task is implemented as a step.  \n",
    "Each step in the pipeline runs on its allocated compute target.  \n",
    "publish a pipeline as a REST endpoint, enabling client applications to initiate a pipeline run.\n",
    "\n",
    "What follow is a simple **_2-step_** pipeline that trains and registers a model.  \n",
    "\n",
    "1. storage\n",
    "1. compute\n",
    "1. environment\n",
    "1. scripts\n",
    "  * step 1: create a model\n",
    "  * step 2: register the model\n",
    "1. create pipeline\n",
    "1. run pipeline\n",
    "1. publish pipeline\n",
    "1. call pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### storage\n",
    "\n",
    "The PipelineData object is a special kind of data reference that is used to pass data from the output of one pipeline step to the input of another, creating a dependency between them. You'll create one and use it as the output for the first step and the input for the second step. Note that you also need to pass it as a script argument so your code can access the datastore location referenced by the data reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# load the training diabetes dataset (File method)\n",
    "ds = Datastore.get(ws, 'datalakestoragegen2')\n",
    "ds_path = [DataPath(ds, 'platinum/diabetes.parquet')] # {path/*.parquet or path/**}\n",
    "diabetes_ds = Dataset.File.from_files(path=ds_path)\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference)\n",
    "# data lake gen2: container \"datalake\" > azureml > 0b93a7bc-9bf2-46a9-b9c4-5afdba292d08 > model_folder\n",
    "model_folder = PipelineData(\"model_folder\", datastore=ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load compute cluster\n",
    "pipeline_cluster = ComputeTarget(ws, 'aml-cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the docker environment\n",
    "training_env = Environment.get(ws, 'training_environment')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above.\n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = training_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder for the pipeline step files\n",
    "project_folder = 'diabetes_pipeline'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment folder\n",
    "experiment_folder = './' + project_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**step 1:** create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./diabetes_pipeline/train_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/train_diabetes.py\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_folder', type=str, dest='output_folder', default=\"diabetes_model\", help='output folder')\n",
    "args = parser.parse_args()\n",
    "output_folder = args.output_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "#diabetes = run.input_datasets['diabetes_train'].to_pandas_dataframe()\n",
    "mount = run.input_datasets['diabetes_train'] # read-only mount from delta lake as '/mnt/data'\n",
    "print(\"delta lake mounted...\")\n",
    "diabetes = pd.read_parquet('/mnt/data/diabetes.parquet') # load any file(s) from this delta lake mounted folder\n",
    "print(\"dataset loaded...\")\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train adecision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = output_folder + \"/model.pkl\"\n",
    "joblib.dump(value=model, filename=output_path)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**step 2:** register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python script step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./diabetes_pipeline/register_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/register_diabetes.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Workspace, Model, Run\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_folder', type=str, dest='model_folder', default=\"diabetes_model\", help='model location')\n",
    "args = parser.parse_args()\n",
    "model_folder = args.model_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the model\n",
    "print(\"Loading model from \" + model_folder)\n",
    "model_file = model_folder + \"/model.pkl\"\n",
    "model = joblib.load(model_file)\n",
    "\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path=model_file,\n",
    "               model_name='diabetes_model',\n",
    "               tags={'Training context':'Pipeline'})\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Common kinds of step|Description|\n",
    "|-|-|\n",
    "|**PythonScriptStep**|<i>Runs a specified Python script</i>|\n",
    "|**EstimatorStep**|<i>Runs an estimator</i>|\n",
    "|**DataTransferStep**|<i>Uses Azure Data Factory to copy data between data stores</i>|\n",
    "|**DatabricksStep**|<i>Runs a notebook, script, or compiled JAR on a databricks cluster</i>|\n",
    "|**AdlaStep**|<i>Runs a U-SQL job in Azure Data Lake Analytics</i>|\n",
    "|**[6 more steps](https://aka.ms/AA70rrh)**||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:azureml.train.estimator._estimator:'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.\n"
     ]
    }
   ],
   "source": [
    "estimator = Estimator(source_directory=experiment_folder, \n",
    "                      compute_target=pipeline_cluster, #training_cluster\n",
    "                      environment_definition=pipeline_run_config.environment, #training_env\n",
    "                      entry_script='train_diabetes.py', #'diabetes_training.py'\n",
    "                      # NO script_params=script_params,\n",
    "                      # NO inputs=[file_ds.as_named_input('diabetes').as_mount(path_on_compute='/mnt/data')],\n",
    "                     )\n",
    "\n",
    "# Step 1, run the estimator to train the model\n",
    "train_step = EstimatorStep(name=\"Train Model\",\n",
    "                           estimator=estimator,\n",
    "                           compute_target=pipeline_cluster, # {'aml-cluster'}\n",
    "                           estimator_entry_script_arguments=['--output_folder', model_folder],\n",
    "                           inputs=[diabetes_ds.as_named_input('diabetes_train').as_mount(path_on_compute='/mnt/data')],\n",
    "                           outputs=[model_folder],\n",
    "                           allow_reuse=True)\n",
    "\n",
    "# Step 2, run the model registration script\n",
    "register_step = PythonScriptStep(name=\"Register Model\",\n",
    "                                 source_directory=experiment_folder,\n",
    "                                 script_name=\"register_diabetes.py\",\n",
    "                                 compute_target=pipeline_cluster,\n",
    "                                 runconfig=pipeline_run_config,\n",
    "                                 inputs=[model_folder],\n",
    "                                 arguments=['--model_folder', model_folder],\n",
    "                                 allow_reuse=True)\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline = Pipeline(ws, [train_step, register_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run pipeline\n",
    "\n",
    "Run pipeline and verify it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Train Model [8bfdd59f][826a0671-8ad1-4c9e-a678-fbaab9404948], (This step will run and generate new outputs)Created step Register Model [02634b9d][cad22272-034a-4b99-8a28-c3be1aba9876], (This step will run and generate new outputs)\n",
      "\n",
      "Submitted PipelineRun fd40771b-9879-4c09-b4b0-41eb28ea2c02\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/fd40771b-9879-4c09-b4b0-41eb28ea2c02?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup02/workspaces/machine_learning_workspace02\n",
      "CPU times: user 328 ms, sys: 617 ms, total: 945 ms\n",
      "Wall time: 6.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create an experiment\n",
    "experiment = Experiment(ws, 'diabetes-training-pipeline')\n",
    "\n",
    "# Run the pipeline\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e47b9e4e549479aa0d47598b19bbb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-training-pipeline/runs/fd40771b-9879-4c09-b4b0-41eb28ea2c02?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup02/workspaces/machine_learning_workspace02\", \"run_id\": \"fd40771b-9879-4c09-b4b0-41eb28ea2c02\", \"run_properties\": {\"run_id\": \"fd40771b-9879-4c09-b4b0-41eb28ea2c02\", \"created_utc\": \"2021-03-04T14:52:36.359769Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-03-04T15:02:42.711558Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fd40771b-9879-4c09-b4b0-41eb28ea2c02/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=dF7v8WVUsBzmz2VsN0FDcoX%2BY7f%2FgJg7SXlz9wXcdeU%3D&st=2021-03-04T14%3A42%3A58Z&se=2021-03-04T22%3A52%3A58Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fd40771b-9879-4c09-b4b0-41eb28ea2c02/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=5OtvNiCzn1xIsGt8yxpOn8uzl7RVuHds2e6H%2F9Etr78%3D&st=2021-03-04T14%3A42%3A58Z&se=2021-03-04T22%3A52%3A58Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fd40771b-9879-4c09-b4b0-41eb28ea2c02/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=AyLWqev50h%2BM8g8DeolP66YkMtyCwiLbn7FXAyWvskg%3D&st=2021-03-04T14%3A42%3A58Z&se=2021-03-04T22%3A52%3A58Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:10:06\", \"run_number\": \"1\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"2465180b-abca-4371-a291-6d5885c8e6a4\", \"name\": \"Train Model\", \"status\": \"Finished\", \"start_time\": \"2021-03-04T14:56:56.600229Z\", \"created_time\": \"2021-03-04T14:52:45.741831Z\", \"end_time\": \"2021-03-04T15:01:33.878951Z\", \"duration\": \"0:08:48\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-03-04T14:52:45.741831Z\", \"is_reused\": \"\"}, {\"run_id\": \"fff63994-ea6e-4812-a484-42cf13584085\", \"name\": \"Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-03-04T15:01:57.48597Z\", \"created_time\": \"2021-03-04T15:01:44.530102Z\", \"end_time\": \"2021-03-04T15:02:28.251677Z\", \"duration\": \"0:00:43\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-03-04T15:01:44.530102Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-03-04 14:52:45Z] Submitting 1 runs, first five are: 8bfdd59f:2465180b-abca-4371-a291-6d5885c8e6a4\\n[2021-03-04 15:01:43Z] Completing processing run id 2465180b-abca-4371-a291-6d5885c8e6a4.\\n[2021-03-04 15:01:44Z] Submitting 1 runs, first five are: 02634b9d:fff63994-ea6e-4812-a484-42cf13584085\\n[2021-03-04 15:02:41Z] Completing processing run id fff63994-ea6e-4812-a484-42cf13584085.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"451f2a6e\": {\"node_id\": \"451f2a6e\", \"name\": \"080bc6dd-580d-4c4d-b66d-a97e51a96442\"}}, \"module_nodes\": {\"8bfdd59f\": {\"node_id\": \"8bfdd59f\", \"name\": \"Train Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"2465180b-abca-4371-a291-6d5885c8e6a4\"}, \"02634b9d\": {\"node_id\": \"02634b9d\", \"name\": \"Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"fff63994-ea6e-4812-a484-42cf13584085\"}}, \"edges\": [{\"source_node_id\": \"451f2a6e\", \"source_node_name\": \"080bc6dd-580d-4c4d-b66d-a97e51a96442\", \"source_name\": \"data\", \"target_name\": \"diabetes_train\", \"dst_node_id\": \"8bfdd59f\", \"dst_node_name\": \"Train Model\"}, {\"source_node_id\": \"8bfdd59f\", \"source_node_name\": \"Train Model\", \"source_name\": \"model_folder\", \"target_name\": \"model_folder\", \"dst_node_id\": \"02634b9d\", \"dst_node_name\": \"Register Model\"}], \"child_runs\": [{\"run_id\": \"2465180b-abca-4371-a291-6d5885c8e6a4\", \"name\": \"Train Model\", \"status\": \"Finished\", \"start_time\": \"2021-03-04T14:56:56.600229Z\", \"created_time\": \"2021-03-04T14:52:45.741831Z\", \"end_time\": \"2021-03-04T15:01:33.878951Z\", \"duration\": \"0:08:48\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-03-04T14:52:45.741831Z\", \"is_reused\": \"\"}, {\"run_id\": \"fff63994-ea6e-4812-a484-42cf13584085\", \"name\": \"Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-03-04T15:01:57.48597Z\", \"created_time\": \"2021-03-04T15:01:44.530102Z\", \"end_time\": \"2021-03-04T15:02:28.251677Z\", \"duration\": \"0:00:43\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-03-04T15:01:44.530102Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.23.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: fd40771b-9879-4c09-b4b0-41eb28ea2c02\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/fd40771b-9879-4c09-b4b0-41eb28ea2c02?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup02/workspaces/machine_learning_workspace02\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 2465180b-abca-4371-a291-6d5885c8e6a4\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/2465180b-abca-4371-a291-6d5885c8e6a4?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup02/workspaces/machine_learning_workspace02\n",
      "StepRun( Train Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt\n",
      "========================================================================================================================\n",
      "2021-03-04T14:56:58Z Starting output-watcher...\n",
      "2021-03-04T14:56:58Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-03-04T14:56:58Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-03-04T14:56:59Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_2a916f4728727b3b5b18dbee7e16a3e5\n",
      "4007a89234b4: Pulling fs layer\n",
      "5dfa26c6b9c9: Pulling fs layer\n",
      "0ba7bf18aa40: Pulling fs layer\n",
      "4c6ec688ebe3: Pulling fs layer\n",
      "a358e5622b47: Pulling fs layer\n",
      "b68b2629181d: Pulling fs layer\n",
      "b40419bab046: Pulling fs layer\n",
      "30e069d8e198: Pulling fs layer\n",
      "a82e4e12442c: Pulling fs layer\n",
      "1bb969deda78: Pulling fs layer\n",
      "85856583f10d: Pulling fs layer\n",
      "103fa978967f: Pulling fs layer\n",
      "a2c1d3a8444b: Pulling fs layer\n",
      "b6a2d3b4db15: Pulling fs layer\n",
      "a6551864b009: Pulling fs layer\n",
      "eefdb0b47728: Pulling fs layer\n",
      "65ac30946850: Pulling fs layer\n",
      "4c6ec688ebe3: Waiting\n",
      "a358e5622b47: Waiting\n",
      "b68b2629181d: Waiting\n",
      "b40419bab046: Waiting\n",
      "30e069d8e198: Waiting\n",
      "a82e4e12442c: Waiting\n",
      "1bb969deda78: Waiting\n",
      "85856583f10d: Waiting\n",
      "103fa978967f: Waiting\n",
      "a2c1d3a8444b: Waiting\n",
      "b6a2d3b4db15: Waiting\n",
      "a6551864b009: Waiting\n",
      "eefdb0b47728: Waiting\n",
      "65ac30946850: Waiting\n",
      "5dfa26c6b9c9: Verifying Checksum\n",
      "5dfa26c6b9c9: Download complete\n",
      "0ba7bf18aa40: Verifying Checksum\n",
      "0ba7bf18aa40: Download complete\n",
      "4c6ec688ebe3: Verifying Checksum\n",
      "4c6ec688ebe3: Download complete\n",
      "4007a89234b4: Verifying Checksum\n",
      "4007a89234b4: Download complete\n",
      "b68b2629181d: Verifying Checksum\n",
      "b68b2629181d: Download complete\n",
      "b40419bab046: Verifying Checksum\n",
      "b40419bab046: Download complete\n",
      "a358e5622b47: Verifying Checksum\n",
      "a358e5622b47: Download complete\n",
      "30e069d8e198: Verifying Checksum\n",
      "30e069d8e198: Download complete\n",
      "1bb969deda78: Verifying Checksum\n",
      "1bb969deda78: Download complete\n",
      "a82e4e12442c: Verifying Checksum\n",
      "a82e4e12442c: Download complete\n",
      "103fa978967f: Verifying Checksum\n",
      "103fa978967f: Download complete\n",
      "85856583f10d: Verifying Checksum\n",
      "85856583f10d: Download complete\n",
      "b6a2d3b4db15: Verifying Checksum\n",
      "b6a2d3b4db15: Download complete\n",
      "eefdb0b47728: Verifying Checksum\n",
      "eefdb0b47728: Download complete\n",
      "65ac30946850: Verifying Checksum\n",
      "65ac30946850: Download complete\n",
      "a6551864b009: Verifying Checksum\n",
      "a6551864b009: Download complete\n",
      "a2c1d3a8444b: Verifying Checksum\n",
      "a2c1d3a8444b: Download complete\n",
      "4007a89234b4: Pull complete\n",
      "5dfa26c6b9c9: Pull complete\n",
      "0ba7bf18aa40: Pull complete\n",
      "4c6ec688ebe3: Pull complete\n",
      "a358e5622b47: Pull complete\n",
      "b68b2629181d: Pull complete\n",
      "b40419bab046: Pull complete\n",
      "30e069d8e198: Pull complete\n",
      "a82e4e12442c: Pull complete\n",
      "1bb969deda78: Pull complete\n",
      "85856583f10d: Pull complete\n",
      "103fa978967f: Pull complete\n",
      "a2c1d3a8444b: Pull complete\n",
      "b6a2d3b4db15: Pull complete\n",
      "a6551864b009: Pull complete\n",
      "eefdb0b47728: Pull complete\n",
      "65ac30946850: Pull complete\n",
      "Digest: sha256:68ffd55d5df309a0bda6ab9bb4fe2c3a1739a44786f2902f8f3bd785a61b3e4c\n",
      "Status: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_2a916f4728727b3b5b18dbee7e16a3e5:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_2a916f4728727b3b5b18dbee7e16a3e5:latest\n",
      "2021-03-04T14:58:38Z Check if container 2465180b-abca-4371-a291-6d5885c8e6a4 already exist exited with 0, \n",
      "\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt\n",
      "===============================================================================================================\n",
      "[2021-03-04T14:58:49.905109] Entering job preparation.\n",
      "[2021-03-04T14:58:51.317383] Starting job preparation.\n",
      "[2021-03-04T14:58:51.317960] Extracting the control code.\n",
      "[2021-03-04T14:58:51.333483] fetching and extracting the control code on master node.\n",
      "[2021-03-04T14:58:51.333868] Starting extract_project.\n",
      "[2021-03-04T14:58:51.334206] Starting to extract zip file.\n",
      "[2021-03-04T14:58:51.973233] Finished extracting zip file.\n",
      "[2021-03-04T14:58:52.086411] Using urllib.request Python 3.0 or later\n",
      "[2021-03-04T14:58:52.086465] Start fetching snapshots.\n",
      "[2021-03-04T14:58:52.086496] Start fetching snapshot.\n",
      "[2021-03-04T14:58:52.086507] Retrieving project from snapshot: 97bab6d3-38ad-4959-9514-524683ac6227\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 37\n",
      "[2021-03-04T14:58:52.408821] Finished fetching snapshot.\n",
      "[2021-03-04T14:58:52.409217] Finished fetching snapshots.\n",
      "[2021-03-04T14:58:52.409445] Finished extract_project.\n",
      "[2021-03-04T14:58:52.418544] Finished fetching and extracting the control code.\n",
      "[2021-03-04T14:58:52.426606] Start run_history_prep.\n",
      "[2021-03-04T14:58:52.793353] Job preparation is complete.\n",
      "[2021-03-04T14:58:52.793436] Entering Data Context Managers in Sidecar\n",
      "[2021-03-04T14:58:52.795177] Running Sidecar prep cmd...\n",
      "[2021-03-04T14:58:52.854090] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/2465180b-abca-4371-a291-6d5885c8e6a4/mounts/workspaceblobstore/azureml/2465180b-abca-4371-a291-6d5885c8e6a4\n",
      "[2021-03-04T14:58:52.855371] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\", \"DataStoreCopy:context_managers.DataStores\"]}\n",
      "Enter __enter__ of DatasetContextManager\n",
      "SDK version: azureml-core==1.21.0.post2 azureml-dataprep==2.9.1. Session id: 3e125796-32dd-47b5-92a9-fffef9f2d4ab. Run id: 2465180b-abca-4371-a291-6d5885c8e6a4.\n",
      "Processing 'diabetes_train'.\n",
      "Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('datalakestoragegen2', 'platinum/diabetes.parquet')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"080bc6dd-580d-4c4d-b66d-a97e51a96442\",\n",
      "    \"name\": null,\n",
      "    \"version\": null,\n",
      "    \"workspace\": \"Workspace.create(name='machine_learning_workspace02', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup02')\"\n",
      "  }\n",
      "}\n",
      "Mounting diabetes_train to /mnt/hostfs/mnt/data.\n",
      "Mounted diabetes_train to /mnt/hostfs/mnt/data as single file.\n",
      "Exit __enter__ of DatasetContextManager\n",
      "Set Dataset diabetes_train's target path to /mnt/data/diabetes.parquet\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 1\n",
      "Sidecar adding paths_to_bind: ['/tmp/9d1aeb3f-4bd4-48ff-96fa-20dafcfac475']\n",
      "Acquired lockfile /tmp/2465180b-abca-4371-a291-6d5885c8e6a4-datastore.lock to downloading input data references\n",
      "[2021-03-04T14:59:09.000650] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      "[2021-03-04T14:59:13.041765] Ran Sidecar prep cmd.\n",
      "[2021-03-04T14:59:13.041814] Running Context Managers in Sidecar complete.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt\n",
      "===============================================================================================================\n",
      "[2021-03-04T15:01:12.088992] Entering job release\n",
      "[2021-03-04T15:01:14.044392] Starting job release\n",
      "[2021-03-04T15:01:14.045475] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 270\n",
      "[2021-03-04T15:01:14.046763] job release stage : upload_datastore starting...\n",
      "[2021-03-04T15:01:14.059305] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-03-04T15:01:14.064424] job release stage : execute_job_release starting...\n",
      "[2021-03-04T15:01:14.066135] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-03-04T15:01:14.066775] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-03-04T15:01:14.105564] Entering context manager injector.\n",
      "[2021-03-04T15:01:14.318143] job release stage : upload_datastore completed...\n",
      "[2021-03-04T15:01:14.344824] job release stage : execute_job_release completed...\n",
      "[2021-03-04T15:01:14.498348] job release stage : send_run_telemetry starting...\n",
      "[2021-03-04T15:01:14.673106] get vm size and vm region successfully.\n",
      "[2021-03-04T15:01:14.707410] get compute meta data successfully.\n",
      "[2021-03-04T15:01:14.890182] post artifact meta request successfully.\n",
      "[2021-03-04T15:01:14.941511] upload compute record artifact successfully.\n",
      "[2021-03-04T15:01:15.148465] job release stage : send_run_telemetry completed...\n",
      "[2021-03-04T15:01:15.148799] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-03-04T15:01:15.148893] Running Sidecar release cmd...\n",
      "[2021-03-04T15:01:15.293962] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/2465180b-abca-4371-a291-6d5885c8e6a4/mounts/workspaceblobstore/azureml/2465180b-abca-4371-a291-6d5885c8e6a4\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/data.\n",
      "Finishing unmounting /mnt/hostfs/mnt/data.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-03-04T15:01:15.549270] Removing absolute paths from host...\n",
      "[2021-03-04T15:01:15.755055] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-03-04T15:01:16.643491] Ran Sidecar release cmd.\n",
      "[2021-03-04T15:01:16.643538] Job release is complete\n",
      "\n",
      "StepRun(Train Model) Execution Summary\n",
      "=======================================\n",
      "StepRun( Train Model ) Status: Finished\n",
      "{'runId': '2465180b-abca-4371-a291-6d5885c8e6a4', 'target': 'aml-cluster', 'status': 'Completed', 'startTimeUtc': '2021-03-04T14:56:56.600229Z', 'endTimeUtc': '2021-03-04T15:01:33.878951Z', 'properties': {'ContentSnapshotId': '97bab6d3-38ad-4959-9514-524683ac6227', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '826a0671-8ad1-4c9e-a678-fbaab9404948', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '8bfdd59f', 'azureml.pipelinerunid': 'fd40771b-9879-4c09-b4b0-41eb28ea2c02', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '080bc6dd-580d-4c4d-b66d-a97e51a96442'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes_train', 'mechanism': 'Mount', 'pathOnCompute': '/mnt/data'}}], 'outputDatasets': [], 'runDefinition': {'script': 'train_diabetes.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--output_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster', 'dataReferences': {'model_folder': {'dataStoreName': 'datalakestoragegen2', 'mode': 'Mount', 'pathOnDataStore': 'azureml/2465180b-abca-4371-a291-6d5885c8e6a4/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'diabetes_train': {'dataLocation': {'dataset': {'id': '080bc6dd-580d-4c4d-b66d-a97e51a96442', 'name': None, 'version': None}, 'dataPath': None}, 'mechanism': 'Mount', 'environmentVariableName': 'diabetes_train', 'pathOnCompute': '/mnt/data', 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'training_environment', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.23.0', 'azureml-dataprep[pandas,fuse]', 'pyarrow', 'fastparquet']}, 'scikit-learn', 'joblib'], 'name': 'azureml_71d6f591a76ce54ae892285bb7c673cd'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210129.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'frameworkImage': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': None, 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/azureml-logs/55_azureml-execution-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt?sv=2019-02-02&sr=b&sig=f9Og4MeSXyou1%2FCqJsU7tmfnDL%2Fio2TbH31EO8zxfi8%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'azureml-logs/65_job_prep-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/azureml-logs/65_job_prep-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt?sv=2019-02-02&sr=b&sig=Jz0BRIPPz30%2FYcoE0kxdZygYgspdKIo16fKtjfLChJU%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=FOXOdtEdmlROMCgz3SnysXxLV%2BYzhUAApyBOQRQ4ZWg%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'azureml-logs/75_job_post-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/azureml-logs/75_job_post-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt?sv=2019-02-02&sr=b&sig=v575GfIe3G42F4%2FnZZjY%2FUtA9cYVoToSvS%2FlXU2YETA%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'azureml-logs/process_info.json': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=KPP8yDD0WXCuP5leaw9P61HSaWU0ZrM3nVdoDmll6Tk%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'azureml-logs/process_status.json': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=V11bL0g%2BVJ1cGnIn5wWgAug7dl5dQf3UVFD8D290Qy4%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'logs/azureml/74_azureml.log': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/logs/azureml/74_azureml.log?sv=2019-02-02&sr=b&sig=xPCVlSE8otUt0peP36j%2FiMjGfIlBsAyUcEspvwtg%2BPE%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=RkODv8o7YREzXwb%2BEJh706takE0YWS7yZ16c%2F71FJwM%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=kWHHHYVSEZBXTPnqDv3kohhqBRvxXs%2Ftc0d5V1T8BVM%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=L5UtVEXkB0YOvg1eVRqzp4pOeGaBpNAx7RLW143DazY%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=rYm59uLg8jeVwJdNDjKuQ1HIV0TkZMff607cuv41%2FSg%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=l%2BoqqW4oOfezpxlUsg0GGp%2BzP5yxNyop4Zql6XIZN1s%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'logs/azureml/sidecar/tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d/all.log': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/logs/azureml/sidecar/tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d/all.log?sv=2019-02-02&sr=b&sig=MPMk6bOMB%2FRGmhWrsS3iKO2VeSaYE2HF%2FUK5iTvmDSw%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'logs/azureml/sidecar/tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d/task.enter_contexts.log': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/logs/azureml/sidecar/tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=SJDyW2Zv4yFccvV9ukLDc21t61WbYG0NJfqQtZCBmcw%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'logs/azureml/sidecar/tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d/task.exit_contexts.log': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/logs/azureml/sidecar/tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=ESCDWntXpfbE%2FZd6dXXFC1hVNyxlQksga5pYejLseJw%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=e0L61F2iu0FAYGORaxLDeP4Di3xFLTXbQAG183KwdDg%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2465180b-abca-4371-a291-6d5885c8e6a4/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=ooEDlT8%2FX3nErMfwkf6sV3S637TekWrKSic6ghbZY20%3D&st=2021-03-04T14%3A51%3A19Z&se=2021-03-04T23%3A01%3A19Z&sp=r'}, 'submittedBy': 'Kevin albert'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: fff63994-ea6e-4812-a484-42cf13584085\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/diabetes-training-pipeline/runs/fff63994-ea6e-4812-a484-42cf13584085?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup02/workspaces/machine_learning_workspace02\n",
      "StepRun( Register Model ) Status: Queued\n",
      "StepRun( Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt\n",
      "========================================================================================================================\n",
      "2021-03-04T15:01:59Z Starting output-watcher...\n",
      "2021-03-04T15:01:59Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-03-04T15:02:00Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-03-04T15:02:00Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_956eb38cbf431181a612ddaaaf194ddc\n",
      "Digest: sha256:8e29d304dc2fa90d27c3c5c029c826f26e6cee6b991cb1728c0a06350aa6e2c2\n",
      "Status: Image is up to date for b7932f23fbca46acaff74240453392b3.azurecr.io/azureml/azureml_956eb38cbf431181a612ddaaaf194ddc:latest\n",
      "b7932f23fbca46acaff74240453392b3.azurecr.io/azureml/azureml_956eb38cbf431181a612ddaaaf194ddc:latest\n",
      "2021-03-04T15:02:02Z Check if container fff63994-ea6e-4812-a484-42cf13584085 already exist exited with 0, \n",
      "\n",
      "5448cf75544eb413fd10e35cbb989871df784cddd61f15dc30f7f1391e9a9a44\n",
      "2021/03/04 15:02:03 Starting App Insight Logger for task:  containerSetup\n",
      "2021/03/04 15:02:03 Version: 3.0.01509.0007 Branch: .SourceBranch Commit: 0d6b0ef\n",
      "2021/03/04 15:02:03 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/03/04 15:02:03 Starting infiniband setup\n",
      "2021/03/04 15:02:03 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/03/04 15:02:03 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/03/04 15:02:03 sshd inside container not required for job, skipping setup.\n",
      "2021/03/04 15:02:03 All App Insights Logs was send successfully\n",
      "2021-03-04T15:02:03Z Starting docker container succeeded.\n",
      "2021-03-04T15:02:08Z Job environment preparation succeeded on 10.0.0.4. Output: \n",
      ">>>   2021/03/04 15:01:55 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2021/03/04 15:01:55 Version: 3.0.01509.0007 Branch: .SourceBranch Commit: 0d6b0ef\n",
      ">>>   2021/03/04 15:01:55 runtime.GOOS linux\n",
      ">>>   2021/03/04 15:01:55 Reading dyanamic configs\n",
      ">>>   2021/03/04 15:01:55 Container sas url: https://baiscriptsdb3prod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=C5qYa8w7DcGiMMSKT2OPCw8bl0hKB9umyusoqUwMb%2Bk%3D\n",
      ">>>   2021/03/04 15:01:56 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables: no such file or directory\n",
      ">>>   2021/03/04 15:01:56 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installed false, isEnable false,\n",
      ">>>   2021/03/04 15:01:56 azsecpack isEnable:false,GetDisableVsatlsscan:true\n",
      ">>>   2021/03/04 15:01:56 [doTurnOffAzsecpack] output:   Active: inactive (dead)\n",
      ">>>   ,err:<nil>.\n",
      ">>>   2021/03/04 15:01:56 OS patching disabled by dynamic configs. Skipping.\n",
      ">>>   2021/03/04 15:01:56 DetonationChamber is not enabled on this subscription: 43c1f93a-903d-4b23-a4bf-92bd7a150627\n",
      ">>>   2021/03/04 15:01:56 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/03/04 15:01:56 GPU count found on the node: 0\n",
      ">>>   2021/03/04 15:01:56 AMLComputeXDSEndpoint:  https://db3-prodk8ds.batchai.core.windows.net\n",
      ">>>   2021/03/04 15:01:56 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2021/03/04 15:01:56 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/config\n",
      ">>>   2021/03/04 15:01:56 This is not a aml-workstation (compute instance), current offer type: azureml. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2021/03/04 15:01:56 Starting identity responder.\n",
      ">>>   2021/03/04 15:01:56 Starting identity responder.\n",
      ">>>   2021/03/04 15:01:56 Failed to open file /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/config/.batchai.IdentityResponder.envlist: open /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/config/.batchai.IdentityResponder.envlist: no such file or directory\n",
      ">>>   2021/03/04 15:01:56 Logfile used for identity responder: /mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/IdentityResponderLog-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt\n",
      ">>>   2021/03/04 15:01:56 Logfile used for identity responder: /mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/IdentityResponderLog-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt\n",
      ">>>   2021/03/04 15:01:56 Started Identity Responder for job.\n",
      ">>>   2021/03/04 15:01:56 Started Identity Responder for job.\n",
      ">>>   2021/03/04 15:01:56 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/wd\n",
      ">>>   2021/03/04 15:01:56 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/shared\n",
      ">>>   2021/03/04 15:01:56 Mounting job level file systems\n",
      ">>>   2021/03/04 15:01:56 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts\n",
      ">>>   2021/03/04 15:01:56 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/config/.amlcompute.datastorecredentials\n",
      ">>>   2021/03/04 15:01:56 Datastore credentials file not found, skipping.\n",
      ">>>   2021/03/04 15:01:56 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/config/.master.runtimesastokens\n",
      ">>>   2021/03/04 15:01:56 Runtime sas tokens file not found, skipping.\n",
      ">>>   2021/03/04 15:01:56 No NFS configured\n",
      ">>>   2021/03/04 15:01:56 No Azure File Shares configured\n",
      ">>>   2021/03/04 15:01:56 Mounting blob file systems\n",
      ">>>   2021/03/04 15:01:56 Blobfuse runtime version 1.3.6\n",
      ">>>   2021/03/04 15:01:56 Mounting azureml-blobstore-b7932f23-fbca-46ac-aff7-4240453392b3 container from machinelstorage209f93e17 account at /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore\n",
      ">>>   2021/03/04 15:01:56 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/03/04 15:01:56 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/03/04 15:01:56 Blobfuse cache size set to 42901 MB.\n",
      ">>>   2021/03/04 15:01:56 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=42901 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/03/04 15:01:56 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore\n",
      ">>>   2021/03/04 15:01:56 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore\n",
      ">>>   2021/03/04 15:01:56 Successfully mounted azureml-blobstore-b7932f23-fbca-46ac-aff7-4240453392b3 container from machinelstorage209f93e17 account at /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore\n",
      ">>>   2021/03/04 15:01:56 Mounting datalake container from datalake03032021 account at /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/datalakestoragegen2\n",
      ">>>   2021/03/04 15:01:56 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/03/04 15:01:56 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/03/04 15:01:56 Blobfuse cache size set to 42901 MB.\n",
      ">>>   2021/03/04 15:01:56 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/datalakestoragegen2 --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/caches/datalakestoragegen2 --file-cache-timeout-in-seconds=1000000 --cache-size-mb=42901 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/configs/datalakestoragegen2.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/03/04 15:01:56 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/datalakestoragegen2\n",
      ">>>   2021/03/04 15:01:56 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/datalakestoragegen2\n",
      ">>>   2021/03/04 15:01:56 Successfully mounted datalake container from datalake03032021 account at /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/datalakestoragegen2\n",
      ">>>   2021/03/04 15:01:56 No unmanaged file systems configured\n",
      ">>>   2021/03/04 15:01:56 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/03/04 15:01:56 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/03/04 15:01:56 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085/azureml_compute_logs\n",
      ">>>   2021/03/04 15:01:57 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085/logs\n",
      ">>>   2021/03/04 15:01:58 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085/outputs\n",
      ">>>   2021/03/04 15:01:59 Starting output-watcher...\n",
      ">>>   2021/03/04 15:01:59 Single file input dataset is enabled.\n",
      ">>>   2021/03/04 15:01:59 Start to pulling docker image: b7932f23fbca46acaff74240453392b3.azurecr.io/azureml/azureml_956eb38cbf431181a612ddaaaf194ddc\n",
      ">>>   2021/03/04 15:01:59 Start pull docker image: b7932f23fbca46acaff74240453392b3.azurecr.io\n",
      ">>>   2021/03/04 15:01:59 Getting credentials for image b7932f23fbca46acaff74240453392b3.azurecr.io/azureml/azureml_956eb38cbf431181a612ddaaaf194ddc with url b7932f23fbca46acaff74240453392b3.azurecr.io\n",
      ">>>   2021/03/04 15:01:59 Container registry is ACR.\n",
      ">>>   2021/03/04 15:01:59 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/03/04 15:01:59 Getting ACR Credentials from EMS for environment training_environment:1\n",
      ">>>   2021/03/04 15:01:59 Requesting XDS for registry details.\n",
      ">>>   2021/03/04 15:01:59 Attempt 1 of http call to https://db3-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourceGroups/myresourcegroup02/workspaces/machine_learning_workspace02/clusters/aml-cluster/nodes/tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d?api-version=2018-02-01\n",
      ">>>   2021/03/04 15:02:00 Attempt 1. XDS Api returned non-successful ErrorCode: Success\n",
      ">>>    ErrorMessage: \n",
      ">>>   \n",
      ">>>   2021/03/04 15:02:00 Got container registry details from credentials service for registry address: b7932f23fbca46acaff74240453392b3.azurecr.io.\n",
      ">>>   2021/03/04 15:02:00 Writing ACR Details to file...\n",
      ">>>   2021/03/04 15:02:00 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/03/04 15:02:00 Executing 'Copy ACR Details file' on 10.0.0.4\n",
      ">>>   2021/03/04 15:02:00 Begin executing 'Copy ACR Details file' task on Node\n",
      ">>>   2021/03/04 15:02:00 'Copy ACR Details file' task Node result: succeeded\n",
      ">>>   2021/03/04 15:02:00 Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/03/04 15:02:00 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/03/04 15:02:00 EMS returned b7932f23fbca46acaff74240453392b3.azurecr.io for environment training_environment\n",
      ">>>   2021/03/04 15:02:00 start login to the docker registry\n",
      ">>>   2021/03/04 15:02:00 Successfully logged into the docker registry.\n",
      ">>>   2021/03/04 15:02:00 Start run pull docker image command\n",
      ">>>   2021/03/04 15:02:01 Pull docker image succeeded.\n",
      ">>>   2021/03/04 15:02:01 Pull docker image time: 2.651693831s\n",
      ">>>   \n",
      ">>>   2021/03/04 15:02:02 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/03/04 15:02:02 Start to getting gpu count by running nvidia-smi command\n",
      ">>>   2021/03/04 15:02:02 Setting the memory limit for docker container to be 3091 MB\n",
      ">>>   2021/03/04 15:02:02 The env variable file size is 38891 bytes\n",
      ">>>   2021/03/04 15:02:02 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/03/04 15:02:02 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,fff63994-ea6e-4812-a484-42cf13584085,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/certs:/mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,3091m,-v,/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085/azureml_compute_logs,-v,/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085:/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085,-v,/mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/wd:/mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/wd,-w,/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/config/.batchai.envlist,--shm-size,2g\n",
      ">>>   2021/03/04 15:02:02 the binding /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085:/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085 \n",
      ">>>   2021/03/04 15:02:02 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,fff63994-ea6e-4812-a484-42cf13584085,-m,3091m,-w,/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/config/.batchai.envlist,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085:/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085,-v,/mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/wd:/mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/wd,-v,/mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/certs:/mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/certs\n",
      ">>>   2021/03/04 15:02:02 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name fff63994-ea6e-4812-a484-42cf13584085 -m 3091m -w /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/config/.batchai.envlist --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085:/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085 -v /mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/wd:/mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/wd -v /mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/certs:/mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/certs -d -it --privileged --net=host b7932f23fbca46acaff74240453392b3.azurecr.io/azureml/azureml_956eb38cbf431181a612ddaaaf194ddc\n",
      ">>>   2021/03/04 15:02:02 Check if container fff63994-ea6e-4812-a484-42cf13584085 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/03/04 15:02:02 Check if container fff63994-ea6e-4812-a484-42cf13584085 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/03/04 15:02:03 Container ssh is not required for job type.\n",
      ">>>   2021/03/04 15:02:03 Starting docker container succeeded.\n",
      ">>>   2021/03/04 15:02:03 Starting docker container succeeded.\n",
      ">>>   2021/03/04 15:02:03 Disk space after starting docker container: 44407MB\n",
      ">>>   2021/03/04 15:02:03 Begin execution of runSpecialJobTask\n",
      ">>>   2021/03/04 15:02:03 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085/azureml_compute_logs\n",
      ">>>   2021/03/04 15:02:03 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_71d6f591a76ce54ae892285bb7c673cd/bin/python /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"97bab6d3-38ad-4959-9514-524683ac6227\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/03/04 15:02:03 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085/azureml_compute_logs/65_job_prep-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt\n",
      ">>>   2021/03/04 15:02:03 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085/azureml_compute_logs/65_job_prep-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt\n",
      ">>>   2021/03/04 15:02:03 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085;/azureml-envs/azureml_71d6f591a76ce54ae892285bb7c673cd/bin/python /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"97bab6d3-38ad-4959-9514-524683ac6227\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/03/04 15:02:03 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/03/04 15:02:03 runSpecialJobTask: Running cmd: /usr/bin/docker exec -t fff63994-ea6e-4812-a484-42cf13584085 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/4f8b0d1e-1c35-4fae-bb36-bf25d3b500c9/job-1/fff63994-ea6e-4812-a_3b5f686e-e545-4383-9015-03e463a1b928/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085;/azureml-envs/azureml_71d6f591a76ce54ae892285bb7c673cd/bin/python /mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace02/azureml/fff63994-ea6e-4812-a484-42cf13584085/mounts/workspaceblobstore/azureml/fff63994-ea6e-4812-a484-42cf13584085-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"97bab6d3-38ad-4959-9514-524683ac6227\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/03/04 15:02:05 Attempt 1 of http call to https://northeurope.experiments.azureml.net/history/v1.0/private/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourceGroups/myResourceGroup02/providers/Microsoft.MachineLearningServices/workspaces/machine_learning_workspace02/runs/fff63994-ea6e-4812-a484-42cf13584085/spans\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:04.143202] Entering job preparation.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:05.462166] Starting job preparation.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:05.462211] Extracting the control code.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:05.477750] fetching and extracting the control code on master node.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:05.477804] Starting extract_project.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:05.477865] Starting to extract zip file.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:06.159062] Finished extracting zip file.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:06.302052] Using urllib.request Python 3.0 or later\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:06.302105] Start fetching snapshots.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:06.302140] Start fetching snapshot.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:06.302151] Retrieving project from snapshot: 97bab6d3-38ad-4959-9514-524683ac6227\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 47\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:06.595764] Finished fetching snapshot.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:06.596174] Finished fetching snapshots.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:06.596391] Finished extract_project.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:06.606067] Finished fetching and extracting the control code.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:06.614650] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:06.617166] Start run_history_prep.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:06.663464] Entering context manager injector.\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: Acquired lockfile /tmp/fff63994-ea6e-4812-a484-42cf13584085-datastore.lock to downloading input data references\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:07.984562] downloadDataStore completed\n",
      ">>>   2021/03/04 15:02:08 runSpecialJobTask: preparation: [2021-03-04T15:02:07.988536] Job preparation is complete.\n",
      ">>>   2021/03/04 15:02:08 Execution of runSpecialJobTask completed\n",
      ">>>   2021/03/04 15:02:08 All App Insights Logs was send successfully\n",
      ">>>   2021/03/04 15:02:08 Process Exiting with Code:  0\n",
      ">>>   \n",
      "2021-03-04T15:02:08Z 127.0.0.1 slots=1 max-slots=1\n",
      "2021-03-04T15:02:09Z launching Custom job\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt\n",
      "===============================================================================================================\n",
      "[2021-03-04T15:02:18.369422] Entering job release\n",
      "[2021-03-04T15:02:19.514656] Starting job release\n",
      "[2021-03-04T15:02:19.519191] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 137\n",
      "[2021-03-04T15:02:19.520168] job release stage : upload_datastore starting...\n",
      "[2021-03-04T15:02:19.524305] Entering context manager injector.\n",
      "[2021-03-04T15:02:19.532764] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-03-04T15:02:19.533229] job release stage : execute_job_release starting...\n",
      "[2021-03-04T15:02:19.538473] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-03-04T15:02:19.554607] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-03-04T15:02:19.679976] job release stage : upload_datastore completed...\n",
      "[2021-03-04T15:02:19.767715] job release stage : send_run_telemetry starting...\n",
      "[2021-03-04T15:02:19.831647] job release stage : execute_job_release completed...\n",
      "[2021-03-04T15:02:19.952190] get vm size and vm region successfully.\n",
      "[2021-03-04T15:02:20.117083] get compute meta data successfully.\n",
      "[2021-03-04T15:02:20.253221] post artifact meta request successfully.\n",
      "[2021-03-04T15:02:20.303660] upload compute record artifact successfully.\n",
      "[2021-03-04T15:02:20.519983] job release stage : send_run_telemetry completed...\n",
      "[2021-03-04T15:02:20.520157] Job release is complete\n",
      "\n",
      "StepRun(Register Model) Execution Summary\n",
      "==========================================\n",
      "StepRun( Register Model ) Status: Finished\n",
      "{'runId': 'fff63994-ea6e-4812-a484-42cf13584085', 'target': 'aml-cluster', 'status': 'Completed', 'startTimeUtc': '2021-03-04T15:01:57.48597Z', 'endTimeUtc': '2021-03-04T15:02:28.251677Z', 'properties': {'ContentSnapshotId': '97bab6d3-38ad-4959-9514-524683ac6227', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'cad22272-034a-4b99-8a28-c3be1aba9876', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '02634b9d', 'azureml.pipelinerunid': 'fd40771b-9879-4c09-b4b0-41eb28ea2c02', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'register_diabetes.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--model_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'aml-cluster', 'dataReferences': {'model_folder': {'dataStoreName': 'datalakestoragegen2', 'mode': 'Mount', 'pathOnDataStore': 'azureml/2465180b-abca-4371-a291-6d5885c8e6a4/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'training_environment', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.23.0', 'azureml-dataprep[pandas,fuse]', 'pyarrow', 'fastparquet']}, 'scikit-learn', 'joblib'], 'name': 'azureml_71d6f591a76ce54ae892285bb7c673cd'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210129.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'frameworkImage': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': None, 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fff63994-ea6e-4812-a484-42cf13584085/azureml-logs/55_azureml-execution-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt?sv=2019-02-02&sr=b&sig=yRARxwvVjkQBMlCEYHK%2FDiyawsB4s8PQ%2BEdUFX7b9J0%3D&st=2021-03-04T14%3A52%3A23Z&se=2021-03-04T23%3A02%3A23Z&sp=r', 'azureml-logs/65_job_prep-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fff63994-ea6e-4812-a484-42cf13584085/azureml-logs/65_job_prep-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt?sv=2019-02-02&sr=b&sig=4Tk06dKk3ElC9jD3LvE%2BbMocL9BgTcSoHOlYum%2FZUfo%3D&st=2021-03-04T14%3A52%3A23Z&se=2021-03-04T23%3A02%3A23Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fff63994-ea6e-4812-a484-42cf13584085/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=V%2Ba%2Bn0eXdT2VUtOcKnEQDSaxY6OS77OLiaBWRHUSdkQ%3D&st=2021-03-04T14%3A52%3A23Z&se=2021-03-04T23%3A02%3A23Z&sp=r', 'azureml-logs/75_job_post-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fff63994-ea6e-4812-a484-42cf13584085/azureml-logs/75_job_post-tvmps_10b995cbfa648953267dc71f615e5ee1469bbbdcec865bf581b238fb36ba6eb9_d.txt?sv=2019-02-02&sr=b&sig=xcy4DuncaYkW5QWjgY1CmIJIvoDqa5XgQ1nH8S2PYVk%3D&st=2021-03-04T14%3A52%3A23Z&se=2021-03-04T23%3A02%3A23Z&sp=r', 'azureml-logs/process_info.json': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fff63994-ea6e-4812-a484-42cf13584085/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=IaxLcN%2FavQq%2FzI9F2%2F2ji0c6tyQ%2BSpdiurLLajglF8o%3D&st=2021-03-04T14%3A52%3A23Z&se=2021-03-04T23%3A02%3A23Z&sp=r', 'azureml-logs/process_status.json': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fff63994-ea6e-4812-a484-42cf13584085/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=ZSLaq0JbEE%2BKl%2Fb%2BC2EvHRXu4SFKs9C67zVP9KMuBb0%3D&st=2021-03-04T14%3A52%3A23Z&se=2021-03-04T23%3A02%3A23Z&sp=r', 'logs/azureml/101_azureml.log': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fff63994-ea6e-4812-a484-42cf13584085/logs/azureml/101_azureml.log?sv=2019-02-02&sr=b&sig=I8V3UaiRff%2BWwf7AOrECea3CTbvAoMoO2jy9%2B%2Ftvee0%3D&st=2021-03-04T14%3A52%3A23Z&se=2021-03-04T23%3A02%3A23Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fff63994-ea6e-4812-a484-42cf13584085/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=mSIgqwK%2FVD%2BhEVeiwInngQ9h2VXkj5JE60nUaBtsylU%3D&st=2021-03-04T14%3A52%3A23Z&se=2021-03-04T23%3A02%3A23Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fff63994-ea6e-4812-a484-42cf13584085/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=9RQIb4j%2FrdZTd8IlMmpKv0k8UTWQntcMW0z4iNXBlgw%3D&st=2021-03-04T14%3A52%3A23Z&se=2021-03-04T23%3A02%3A23Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fff63994-ea6e-4812-a484-42cf13584085/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=gBTpQifLjx7Tl0n0eEzDCA0VbMn7EmX7O4Llc87%2FcD8%3D&st=2021-03-04T14%3A52%3A23Z&se=2021-03-04T23%3A02%3A23Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fff63994-ea6e-4812-a484-42cf13584085/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=FWpfuQjAt1aK5%2BDCjAs3JwKf4Lk8HKJS6%2BY8ogfZZxQ%3D&st=2021-03-04T14%3A52%3A23Z&se=2021-03-04T23%3A02%3A23Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fff63994-ea6e-4812-a484-42cf13584085/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=upc%2B6HwbmswTswC0J9z4My99YlMzXSHaxQyFJF7FPLw%3D&st=2021-03-04T14%3A52%3A23Z&se=2021-03-04T23%3A02%3A23Z&sp=r'}, 'submittedBy': 'Kevin albert'}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'fd40771b-9879-4c09-b4b0-41eb28ea2c02', 'status': 'Completed', 'startTimeUtc': '2021-03-04T14:52:43.206227Z', 'endTimeUtc': '2021-03-04T15:02:42.711558Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fd40771b-9879-4c09-b4b0-41eb28ea2c02/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=dF7v8WVUsBzmz2VsN0FDcoX%2BY7f%2FgJg7SXlz9wXcdeU%3D&st=2021-03-04T14%3A42%3A58Z&se=2021-03-04T22%3A52%3A58Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fd40771b-9879-4c09-b4b0-41eb28ea2c02/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=5OtvNiCzn1xIsGt8yxpOn8uzl7RVuHds2e6H%2F9Etr78%3D&st=2021-03-04T14%3A42%3A58Z&se=2021-03-04T22%3A52%3A58Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.fd40771b-9879-4c09-b4b0-41eb28ea2c02/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=AyLWqev50h%2BM8g8DeolP66YkMtyCwiLbn7FXAyWvskg%3D&st=2021-03-04T14%3A42%3A58Z&se=2021-03-04T22%3A52%3A58Z&sp=r'}, 'submittedBy': 'Kevin albert'}\n",
      "\n",
      "CPU times: user 29.2 s, sys: 2.39 s, total: 31.6 s\n",
      "Wall time: 9min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Show run details\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### publish pipeline\n",
    "\n",
    "publish pipeline as a REST service endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://northeurope.api.azureml.ms/pipelines/v1.0/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourceGroups/myResourceGroup02/providers/Microsoft.MachineLearningServices/workspaces/machine_learning_workspace02/PipelineRuns/PipelineSubmit/aff720bc-70bd-40a0-b922-a3e30bb88885\n",
      "CPU times: user 57.3 ms, sys: 193 ms, total: 250 ms\n",
      "Wall time: 672 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "published_pipeline = pipeline.publish(name=\"Diabetes_Training_Pipeline\",\n",
    "                                      description=\"Trains diabetes model\",\n",
    "                                      version=\"1.0\")\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### call pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2596b0ee-c5e7-4984-b865-50ab419322e9'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = 'Run-diabetes-pipeline'\n",
    "\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you have the run ID, you can use the RunDetails widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d34a4279cc242b39a2b90f10d6ea051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/Run-diabetes-pipeline/runs/2596b0ee-c5e7-4984-b865-50ab419322e9?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup02/workspaces/machine_learning_workspace02\", \"run_id\": \"2596b0ee-c5e7-4984-b865-50ab419322e9\", \"run_properties\": {\"run_id\": \"2596b0ee-c5e7-4984-b865-50ab419322e9\", \"created_utc\": \"2021-03-04T15:10:10.762745Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"Unavailable\", \"runType\": \"HTTP\", \"azureml.parameters\": \"{}\", \"azureml.pipelineid\": \"aff720bc-70bd-40a0-b922-a3e30bb88885\"}, \"tags\": {\"azureml.pipelineid\": \"aff720bc-70bd-40a0-b922-a3e30bb88885\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-03-04T15:20:44.554931Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2596b0ee-c5e7-4984-b865-50ab419322e9/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=4TGOCqKv936HDugFehexydkWdRYYUyP23H1gXNI0fGc%3D&st=2021-03-04T15%3A00%3A18Z&se=2021-03-04T23%3A10%3A18Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2596b0ee-c5e7-4984-b865-50ab419322e9/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=%2FpzUQedMQikr%2BWExLaZceGVSmK4N7H30ZWmj%2Fb7EvzU%3D&st=2021-03-04T15%3A00%3A18Z&se=2021-03-04T23%3A10%3A18Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://machinelstorage209f93e17.blob.core.windows.net/azureml/ExperimentRun/dcid.2596b0ee-c5e7-4984-b865-50ab419322e9/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=Lxa%2FSa0j4yzNSjt%2BrC1m0TmMdQFx3NLpUrdURzSruFc%3D&st=2021-03-04T15%3A00%3A18Z&se=2021-03-04T23%3A10%3A18Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:10:33\", \"run_number\": \"1\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"ffe7875a-5db6-4cf6-a08f-cce16d2f4b1f\", \"name\": \"Train Model\", \"status\": \"Finished\", \"start_time\": \"2021-03-04T15:14:50.147727Z\", \"created_time\": \"2021-03-04T15:10:19.943293Z\", \"end_time\": \"2021-03-04T15:19:29.75336Z\", \"duration\": \"0:09:09\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-03-04T15:10:19.943293Z\", \"is_reused\": \"\"}, {\"run_id\": \"3926fda0-7b84-431e-b4c4-25719870bc56\", \"name\": \"Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-03-04T15:19:55.173839Z\", \"created_time\": \"2021-03-04T15:19:45.721652Z\", \"end_time\": \"2021-03-04T15:20:38.823152Z\", \"duration\": \"0:00:53\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-03-04T15:19:45.721652Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-03-04 15:10:19Z] Submitting 1 runs, first five are: 8bfdd59f:ffe7875a-5db6-4cf6-a08f-cce16d2f4b1f\\n[2021-03-04 15:19:44Z] Completing processing run id ffe7875a-5db6-4cf6-a08f-cce16d2f4b1f.\\n[2021-03-04 15:19:45Z] Submitting 1 runs, first five are: 02634b9d:3926fda0-7b84-431e-b4c4-25719870bc56\\n[2021-03-04 15:20:44Z] Completing processing run id 3926fda0-7b84-431e-b4c4-25719870bc56.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"451f2a6e\": {\"node_id\": \"451f2a6e\", \"name\": \"080bc6dd-580d-4c4d-b66d-a97e51a96442\"}}, \"module_nodes\": {\"8bfdd59f\": {\"node_id\": \"8bfdd59f\", \"name\": \"Train Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"ffe7875a-5db6-4cf6-a08f-cce16d2f4b1f\"}, \"02634b9d\": {\"node_id\": \"02634b9d\", \"name\": \"Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"3926fda0-7b84-431e-b4c4-25719870bc56\"}}, \"edges\": [{\"source_node_id\": \"451f2a6e\", \"source_node_name\": \"080bc6dd-580d-4c4d-b66d-a97e51a96442\", \"source_name\": \"data\", \"target_name\": \"diabetes_train\", \"dst_node_id\": \"8bfdd59f\", \"dst_node_name\": \"Train Model\"}, {\"source_node_id\": \"8bfdd59f\", \"source_node_name\": \"Train Model\", \"source_name\": \"model_folder\", \"target_name\": \"model_folder\", \"dst_node_id\": \"02634b9d\", \"dst_node_name\": \"Register Model\"}], \"child_runs\": [{\"run_id\": \"ffe7875a-5db6-4cf6-a08f-cce16d2f4b1f\", \"name\": \"Train Model\", \"status\": \"Finished\", \"start_time\": \"2021-03-04T15:14:50.147727Z\", \"created_time\": \"2021-03-04T15:10:19.943293Z\", \"end_time\": \"2021-03-04T15:19:29.75336Z\", \"duration\": \"0:09:09\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-03-04T15:10:19.943293Z\", \"is_reused\": \"\"}, {\"run_id\": \"3926fda0-7b84-431e-b4c4-25719870bc56\", \"name\": \"Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-03-04T15:19:55.173839Z\", \"created_time\": \"2021-03-04T15:19:45.721652Z\", \"end_time\": \"2021-03-04T15:20:38.823152Z\", \"duration\": \"0:00:53\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-03-04T15:19:45.721652Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.23.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
    "RunDetails(published_pipeline_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline_run](../../image/howto_automl/pipeline_run.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_automl",
   "language": "python",
   "name": "conda-env-py38_automl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
