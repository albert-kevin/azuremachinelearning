{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Kevin ALBERT  \n",
    "\n",
    "Created: September 2020 (Updated: 24 Mar 2022)  \n",
    "\n",
    "TestRun: 24 Mar 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datareport\n",
    "_**How to generate an interactive and static report.**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install python modules\n",
    "!conda install -y -c conda-forge pandas-profiling dtale seaborn pyarrow fastparquet xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dtale\n",
    "import pandas_profiling as pp\n",
    "from IPython.display import Javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda 4.10.3\n",
      "Python 3.8.12\n",
      "numpy                     1.22.3                   pypi_0    pypi\n",
      "pandas                    1.4.1                    pypi_0    pypi\n",
      "pandas-profiling          3.1.0                    pypi_0    pypi\n",
      "dtale                     2.2.0                    pypi_0    pypi\n"
     ]
    }
   ],
   "source": [
    "# check versions\n",
    "!conda -V\n",
    "!python -V\n",
    "!conda list |grep numpy\n",
    "!conda list |grep pandas\n",
    "!conda list |grep pandas_profiling\n",
    "!conda list |grep dtale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo with clean '*.parquet' data: ../bronze/ -> silver -> gold -> platinum\n",
    "df = pd.read_parquet('../../data/platinum/diabetes.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   PatientID               10000 non-null  int64  \n",
      " 1   Pregnancies             10000 non-null  int64  \n",
      " 2   PlasmaGlucose           10000 non-null  int64  \n",
      " 3   DiastolicBloodPressure  10000 non-null  int64  \n",
      " 4   TricepsThickness        10000 non-null  int64  \n",
      " 5   SerumInsulin            10000 non-null  int64  \n",
      " 6   BMI                     10000 non-null  float64\n",
      " 7   DiabetesPedigree        10000 non-null  float64\n",
      " 8   Age                     10000 non-null  int64  \n",
      " 9   Diabetic                10000 non-null  int64  \n",
      "dtypes: float64(2), int64(8)\n",
      "memory usage: 781.4 KB\n"
     ]
    }
   ],
   "source": [
    "# concise summary (shape, memory use, data types, nan's)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interactive report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start webapp (change IP, port)\n",
    "d = dtale.show(df, host=\"20.223.36.46\", port=\"40000\", ignore_duplicate=True, drop_index=True, reaper_on=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://20.223.36.46:40000/dtale/main/1\n",
      "Executing shutdown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 20:18:31,944 - INFO     - Executing shutdown...\n"
     ]
    }
   ],
   "source": [
    "# show all running instances\n",
    "d.main_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop webapp\n",
    "d.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### static report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reportFile = \"../../data/report/diabetes_report.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick report on 100% records (no correlation matrix stuff)\n",
    "pp.ProfileReport(df=df.sample(frac=1),\n",
    "                 minimal=True,\n",
    "                 progress_bar=False,\n",
    "                 correlations={\"cramers\": {\"calculate\": False}},\n",
    "                 title=\"Report Title\",\n",
    "                 html={\"style\": {\"full_width\": True}}).to_file(reportFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.open(\"../../data/report/diabetes_report.html\");"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open the report (*.html)\n",
    "display(Javascript('window.open(\"{url}\");'.format(url=reportFile)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data loading test\n",
    "```python\n",
    "# check first 2 lines\n",
    "! head -n 2 ../../data/bronze/data.csv \n",
    "```\n",
    "### data loading\n",
    "```python\n",
    "# read dataset, define delimiter, dtypes and encoding (preserve id: '000000')\n",
    "df = pd.read_csv('data.csv',\n",
    "                 delimiter=';',\n",
    "                 encoding='utf-8',\n",
    "                 dtype={\"event_id\":\"str\",\n",
    "                        \"game_id\":\"str\"})\n",
    "```\n",
    "### report\n",
    "```python\n",
    "# generate a data report to get a feel of the data (EDA)\n",
    "d = dtale.show(df, host=\"52.174.238.247\", port=\"40000\", ignore_duplicate=True, drop_index=True, reaper_on=False)\n",
    "```\n",
    "### data selection\n",
    "```python\n",
    "# remove irrelevant usecase columns\n",
    "# drop features with only 1 unique value\n",
    "# drop features that are highly correlated (ex: lat, long == loc_x, loc_y)\n",
    "df = df.drop(['col1', 'col2'], axis=1)\n",
    "# select columns by regular expression [tags_0_name, tags_1_name, ...]\n",
    "df.filter(regex='tags_\\d*_name', axis=1)\n",
    "```\n",
    "```python\n",
    "# remove irrelevant usecase records\n",
    "# remove records that are 2 characters long\n",
    "df = df.drop(df[df[\"col1\"].str.len() == 2].index, axis=0)\n",
    "```\n",
    "```python\n",
    "# drop all columns with all values NA\n",
    "df = df.dropna(axis=1, how='all')\n",
    "# drop all records with all values NA\n",
    "df = df.dropna(axis=0, how='all')\n",
    "```\n",
    "```python\n",
    "# remove similar rows\n",
    "df = df.drop_duplicates()\n",
    "```\n",
    "### replace values\n",
    "```python\n",
    "# careful when using .map() for causing nan\n",
    "# replace values and categorical errors (typos, capitalization, labeling)\n",
    "df = df.replace({'col1':{'Male': 'M', 'Man': 'M'},\n",
    "                 'col2':{'True': 1, 'Yes': 1}})\n",
    "```\n",
    "### variance\n",
    "Remove the red flagged skewed columns, not usable for machine learning\n",
    "![enable low variance flag](../../image/howto_dataclean/dtale_low_variance.png)\n",
    "### outliers\n",
    "Never remove an outlier, they will be normalized or scaled for machine learning\n",
    "![enable outliers flag](../../image/howto_dataclean/dtale_highlight_outliers.png)\n",
    "### missing\n",
    "#### KEEP\n",
    "```python\n",
    "# replace nan\n",
    "df['col1'] = df['col1'].fillna('No Value')\n",
    "```\n",
    "#### DELETE\n",
    "Drop columns with >90% nan\n",
    "![highlight missing](../../image/howto_dataclean/dtale_highlight_missing.png)\n",
    "#### IMPUTE\n",
    "Replace categorical missing with top most frequency value\n",
    "![replace categorical missing values](../../image/howto_dataclean/dtale_replace_missing_with_categorical_top_frequency.png)\n",
    "Replace numerical missing with the calculated median not the mean value  \n",
    "![replace numerical missing values](../../image/howto_dataclean/dtale_replace_missing_with_numerical_median.png)  \n",
    "```python\n",
    "# replace 'age' with median\n",
    "df['age'] = df['age'].replace({np.nan: getattr(df['age'], 'median')()})\n",
    "```\n",
    "### setup dtypes\n",
    "```python\n",
    "# timestamp (format=strftime or autodetect)\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True)\n",
    "```\n",
    "```python\n",
    "# add: year, month, day, hour, part_of_day\n",
    "df['year'] = df['dateTime'].dt.year\n",
    "df['month'] = df['dateTime'].dt.month\n",
    "df['day'] = df['dateTime'].dt.day\n",
    "df['hour'] = df['dateTime'].dt.hour\n",
    "\n",
    "def f(x):\n",
    "    if (x > 4) and (x <= 8):\n",
    "        return 'Early Morning'\n",
    "    elif (x > 8) and (x <= 12 ):\n",
    "        return 'Morning'\n",
    "    elif (x > 12) and (x <= 16):\n",
    "        return'Noon'\n",
    "    elif (x > 16) and (x <= 20) :\n",
    "        return 'Eve'\n",
    "    elif (x > 20) and (x <= 24):\n",
    "        return'Night'\n",
    "    elif (x <= 4):\n",
    "        return'Late Night'\n",
    "\n",
    "df['part_of_day'] = df['hour'].apply(f)\n",
    "```\n",
    "```python\n",
    "# generate dtypes dictionary\n",
    "df.dtypes.apply(lambda x: x.name).to_dict()\n",
    "# float, bool, category, str, int (size: int8, int16, int32, int64)\n",
    "df = df.astype({'col1':'float', 'col2':'bool', 'col3':'category', 'col4':'int', 'col5':'str'})\n",
    "```\n",
    "### setup feature names\n",
    "```python\n",
    "# replace feature names with interpretable naming (others are left as-is) \n",
    "df = df.rename(columns={'col1': 'age', 'col2': 'price'})\n",
    "# rename all the columns\n",
    "df.columns = ['age', 'price', '...']\n",
    "```\n",
    "### feature engineering\n",
    "#### CREATE\n",
    "Transform what you have into the right format, handle text, metrics and units\n",
    "```python\n",
    "# create an aggregation (sum, mean, count) on a group\n",
    "df.groupby(['year','month','day','hour','camera'])['amount'].sum().reset_index()\n",
    "# calculate the time remaining using (#min x 60sec/min) + #sec)\n",
    "df['time_remaining_seconds'] = (df['minutes_remaining'] * 60) + (df['seconds_remaining'])\n",
    "```\n",
    "#### CAPPING\n",
    "replace low values with 5 percentile value and high values with 1 percentile value\n",
    "![winsorize capping](../../image/howto_dataclean/winsorize_capping.png)\n",
    "```python\n",
    "from scipy.stats.mstats import winsorize\n",
    "winsorize(df[\"col1\"], limits=[0.05, 0.01])\n",
    "```\n",
    "#### BINNING\n",
    "Convert numeric data into bins (categorize or discretize)\n",
    "![categorize numeric data](../../image/howto_dataclean/dtale_binning.png)\n",
    "```python\n",
    "# evenly sized\n",
    "pd.qcut(df[\"col1\"], 3)\n",
    "```\n",
    "```python\n",
    "# evenly spaced\n",
    "pd.cut(df[\"col1\"], [0,20,40,60])\n",
    "```\n",
    "### machine learning\n",
    "Distinct ID values are used for database, but removed for ML training data\n",
    "### data saving\n",
    "```python\n",
    "# export without the index, add encoding, delimiter and rounded to two decimals\n",
    "df.to_csv(\"../../data/silver/data.csv\", encoding='utf-8', sep=',', float_format='%.2f', index=False)\n",
    "```\n",
    "```python\n",
    "# parquet preserve the schema with optimal compression\n",
    "df.to_parquet(\"../../data/silver/data.parquet\")\n",
    "```\n",
    "### documentation\n",
    "[framework guide](https://elitedatascience.com/data-cleaning)  \n",
    "[howto dtale youtube](https://www.youtube.com/watch?v=Q2kMNPKgN4g)  \n",
    "[Google Docs - Giant Data Quality List](https://docs.google.com/document/d/19THZHWUQkxHg4t5kToRnEnOb7VKcye6Gs046meXCtng/edit?usp=sharing)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_datareport",
   "language": "python",
   "name": "conda-env-py38_datareport-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
