{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. [Workspace](#Workspace)\n",
    "1. [Import](#Import)\n",
    "1. [Introduction](#Introduction)\n",
    "1. [Setup](#Setup)\n",
    "1. [Compute](#Compute)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Featurization](#Featurization)\n",
    "1. [Evaluate](#Evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import open source Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import os\n",
    "# import random\n",
    "# import re\n",
    "# import lightgbm\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import json\n",
    "# import csv\n",
    "# from matplotlib import pyplot as plt\n",
    "# from matplotlib.pyplot import imshow\n",
    "# from sklearn import datasets\n",
    "# from shutil import copy2\n",
    "# import seaborn as sns\n",
    "# sns.set(color_codes='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Azure Machine Learning Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import azureml.core\n",
    "# from azureml.core import Workspace\n",
    "# from azureml.core.experiment import Experiment\n",
    "# from azureml.core.workspace import Workspace\n",
    "# from azureml.core.compute import AksCompute, ComputeTarget\n",
    "# from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "# from azureml.core.compute_target import ComputeTargetException\n",
    "# from azureml.core.webservice import Webservice, AksWebservice\n",
    "# from azureml.core.image import Image\n",
    "# from azureml.core.model import Model\n",
    "# from azureml.train.automl import AutoMLConfig\n",
    "# from azureml.train.automl.run import AutoMLRun\n",
    "# from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download config.json from machine learning portal\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment & Run  \n",
    "### Interactive inline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experiment variable\n",
    "experiment = Experiment(workspace=ws, name=\"experiment_01\")\n",
    "# start the experiment\n",
    "run = experiment.start_logging()\n",
    "# experiment code goes here\n",
    "# log          Record a single named value\n",
    "# log_list     Record a named list of values\n",
    "# log_row      Record a row with multiple columns\n",
    "# log_table    Record a dictionary as a table\n",
    "# log_image    Record an image file or a plot\n",
    "run.log('Accuracy', 0.50)\n",
    "run.log('Accuracy', 0.55)\n",
    "run.log('Accuracy', 0.60)\n",
    "run.log('Accuracy', 0.65)\n",
    "run.log('Accuracy', 0.77)\n",
    "# end the experiment\n",
    "run.complete()\n",
    "# only for this specific Run we can get the log data:\n",
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook widget to view the progress of model training\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment & Run  \n",
    "### Script method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a script \"experiment.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile experiment.py\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Count the rows and log the result\n",
    "row_count = (len(data))\n",
    "run.log('observations', row_count)\n",
    "\n",
    "# Save a sample of the data\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "data.head(2).to_csv(\"outputs/sample.csv\", index=False, header=True)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating testdata\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"firstName\":[\"bart\",\"koen\",\"karel\"],\n",
    "                   \"lastName\":[\"Vermeers\",\"Aerts\",\"Venbelsteren\"]})\n",
    "df.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RunConfiguration = python environment setup\n",
    "# ScriptRunConfig  = script + environment setup\n",
    "from azureml.core import Experiment, RunConfiguration, ScriptRunConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new RunConfig object\n",
    "# Represents configuration for experiment runs targeting different compute targets in Azure Machine Learning\n",
    "experiment_run_config = RunConfiguration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ScriptRunConfig object\n",
    "# Represents configuration information for submitting a training run in Azure Machine Learning\n",
    "script_config = ScriptRunConfig(source_directory='.',\n",
    "                                script='experiment.py',\n",
    "                                run_config=experiment_run_config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the experiment\n",
    "experiment = Experiment(workspace=ws, name='experiment_02')\n",
    "run = experiment.submit(config=script_config)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment & Run\n",
    "## Estimator (generic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an estimator\n",
    "estimator = Estimator(source_directory='.',\n",
    "                      entry_script='experiment.py',\n",
    "                      compute_target='local',\n",
    "                      conda_packages=['scikit-learn']\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run an experiment\n",
    "experiment = Experiment(workspace=ws, name='experiment_03')\n",
    "run = experiment.submit(config=estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encapsulates a 'Run Configuration' and a 'Script Run Configuration' in a single object !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment & Run\n",
    "## passing arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing titanic.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile titanic.csv\n",
    ",PassengerId,Survived,Pclass,Age,SibSp,Parch,Fare,male,Q,S\n",
    "0,1,0,3,22.0,1,0,7.2500,1.0,0.0,1.0\n",
    "1,2,1,1,38.0,1,0,71.2833,0.0,0.0,0.0\n",
    "2,3,1,3,26.0,0,0,7.9250,0.0,0.0,1.0\n",
    "3,4,1,1,35.0,1,0,53.1000,0.0,0.0,1.0\n",
    "4,5,0,3,35.0,0,0,8.0500,1.0,0.0,1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  \\\n",
       "0           0            1         0       3  22.0      1      0   7.2500   \n",
       "1           1            2         1       1  38.0      1      0  71.2833   \n",
       "2           2            3         1       3  26.0      0      0   7.9250   \n",
       "3           3            4         1       1  35.0      1      0  53.1000   \n",
       "4           4            5         0       3  35.0      0      0   8.0500   \n",
       "\n",
       "   male    Q    S  \n",
       "0   1.0  0.0  1.0  \n",
       "1   0.0  0.0  0.0  \n",
       "2   0.0  0.0  1.0  \n",
       "3   0.0  0.0  1.0  \n",
       "4   1.0  0.0  1.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titan = pd.read_csv(\"titanic.csv\", )\n",
    "titan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp',\n",
       "       'Parch', 'Fare', 'male', 'Q', 'S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titan.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting experiment_argparse.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile experiment_argparse.py\n",
    "from azureml.core import Run\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Set regularization hyperparameter\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--reg_rate', type=float, dest='reg', default=0.01)\n",
    "args = parser.parse_args()\n",
    "reg = args.reg\n",
    "\n",
    "# Prepare the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "titanic = pd.read_csv('titanic.csv')\n",
    "X, y = titanic[['PassengerId','Pclass','Age','SibSp','Parch','Fare','male','Q','S']].values, titanic['Survived'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# Count the rows and log the result and save the argument value\n",
    "row_count = (len(data))\n",
    "run.log('observations', row_count)\n",
    "run.log(\"the given 'reg_rate' parameter:\", reg) # <------------\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# Save a sample of the data\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "data.head(2).to_csv(\"outputs/sample.csv\", index=False, header=True)\n",
    "\n",
    "# Save the trained model\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/titanic_model.pkl')\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use script_params = {'--reg_rate': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an estimator\n",
    "estimator = Estimator(source_directory='.',\n",
    "                      entry_script='experiment_argparse.py',\n",
    "                      script_params = {'--reg_rate': 0.1}, # <-------------\n",
    "                      compute_target='local',\n",
    "                      conda_packages=['scikit-learn', 'joblib'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run an experiment\n",
    "experiment = Experiment(workspace=ws, name='experiment_04')\n",
    "run = experiment.submit(config=estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: experiment_04_1585219254_ef64c469\n",
      "Web View: https://ml.azure.com/experiments/experiment_04/runs/experiment_04_1585219254_ef64c469?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/machine_learning_workspace\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 22426\n",
      "Running: ['/bin/bash', '/tmp/azureml_runs/experiment_04_1585219254_ef64c469/azureml-environment-setup/docker_env_checker.sh']\n",
      "\n",
      "Found materialized image on target: azureml/azureml_586a3ed27470f038ee8054b84967c621\n",
      "\n",
      "\n",
      "Logging experiment running status in history service.\n",
      "Running: ['sudo', 'docker', 'run', '--name', 'experiment_04_1585219254_ef64c469', '--rm', '-v', '/tmp/azureml_runs/experiment_04_1585219254_ef64c469:/azureml-run', '--shm-size', '2g', '-e', 'EXAMPLE_ENV_VAR=EXAMPLE_VALUE', '-e', 'AZUREML_CONTEXT_MANAGER_TRACKUSERERROR=eyJTa2lwSGlzdG9yeUltcG9ydENoZWNrIjoiRmFsc2UifQ==', '-e', 'AZUREML_CONTEXT_MANAGER_RUNHISTORY=eyJPdXRwdXRDb2xsZWN0aW9uIjp0cnVlLCJEaXJlY3Rvcmllc1RvV2F0Y2giOlsibG9ncyJdLCJzbmFwc2hvdFByb2plY3QiOnRydWV9', '-e', 'AZUREML_CONTEXT_MANAGER_PROJECTPYTHONPATH=bnVsbA==', '-e', 'AZUREML_RUN_TOKEN_EXPIRY=1587033656', '-e', 'AZUREML_RUN_TOKEN=eyJhbGciOiJSUzI1NiIsImtpZCI6IjFFQzcxMzQ3QjlFMDRERjRFMDAzRDkyRTZFQUY2QzNBQzRFNjAwNDkiLCJ0eXAiOiJKV1QifQ.eyJyb2xlIjoiQ29udHJpYnV0b3IiLCJzY29wZSI6Ii9zdWJzY3JpcHRpb25zLzQzYzFmOTNhLTkwM2QtNGIyMy1hNGJmLTkyYmQ3YTE1MDYyNy9yZXNvdXJjZUdyb3Vwcy9teVJlc291cmNlR3JvdXAvcHJvdmlkZXJzL01pY3Jvc29mdC5NYWNoaW5lTGVhcm5pbmdTZXJ2aWNlcy93b3Jrc3BhY2VzL21hY2hpbmVfbGVhcm5pbmdfd29ya3NwYWNlIiwiYWNjb3VudGlkIjoiMDAwMDAwMDAtMDAwMC0wMDAwLTAwMDAtMDAwMDAwMDAwMDAwIiwid29ya3NwYWNlSWQiOiI4ZmZkMzhhNC1kNjg4LTQ0ZjYtOWZjNy04NjJkZjkyMGM2NDYiLCJwcm9qZWN0aWQiOiIwMDAwMDAwMC0wMDAwLTAwMDAtMDAwMC0wMDAwMDAwMDAwMDAiLCJkaXNjb3ZlcnkiOiJ1cmk6Ly9kaXNjb3Zlcnl1cmkvIiwidGlkIjoiNzNiNDkxOTEtOGRiMy00NWFiLTg3YjMtYjhmOTU2YWMxMjNiIiwib2lkIjoiOGVlOWNjODctYmIyYS00Y2VhLTgxNDYtOTI1OGExM2VmZjU3IiwicHVpZCI6IjEwMDMyMDAwNDQ0NDhFMTMiLCJpc3MiOiJhenVyZW1sIiwiaWRwIjoibGl2ZS5jb20iLCJhcHBpZCI6IktldmluIGFsYmVydCIsImFsdHNlY2lkIjoiMTpsaXZlLmNvbTowMDAxMTU4NzRDNDE5MUI3IiwiZXhwIjoxNTg3MDMzNjU2LCJhdWQiOiJhenVyZW1sIn0.DiZFJYFbUa9hFkcoVQIfEUhmWeTqvbzYcLy21NutmXUnXTCfy-gwhyrvGERe1W8o24wgvA7TNrj0yckZplj6RQz4a57erzGf7Obk_nVOzbPrSTnXmPhl5Q8XlgGIIOWnlcH_1mHp9u7n6zt7yUqezaFQxaHsxL_uywnJiqNODroa4JuhDfpSiBP--rRQRu8iSjeqx3_Lx9aktx9XhCvCu0hMgqHboK7qDTxEGs1ti-8KM9d7YbCLOq8BfrSvEHC8OFDCnmeoXHanc_t_7Rkg7u7WhHqpHrsJILJN05ioqt-Yt5TN-lXKt6QGKLPIOeCouIrxpYQIakPhZdg-uii8hA', '-e', 'HBI_WORKSPACE_JOB=false', '-e', 'AZUREML_RUN_TOKEN_RAND=c17f5c1e-80f1-4021-ab1e-31085749962f', '-e', 'AZUREML_RUN_TOKEN_PASS=c4fa8f19-22b2-4e48-a951-129380b1fcbd', '-e', 'PYTHONUNBUFFERED=True', '-e', 'AZUREML_COMMUNICATOR=None', '-e', 'AZUREML_FRAMEWORK=Python', '-e', 'AZUREML_ARM_PROJECT_NAME=experiment_04', '-e', 'AZUREML_ARM_WORKSPACE_NAME=machine_learning_workspace', '-e', 'AZUREML_ARM_SUBSCRIPTION=43c1f93a-903d-4b23-a4bf-92bd7a150627', '-e', 'AZUREML_ARM_RESOURCEGROUP=myResourceGroup', '-e', 'AZUREML_EXPERIMENT_SCOPE=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourceGroups/myResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/machine_learning_workspace/experiments/experiment_04', '-e', 'AZUREML_WORKSPACE_ID=8ffd38a4-d688-44f6-9fc7-862df920c646', '-e', 'AZUREML_WORKSPACE_SCOPE=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourceGroups/myResourceGroup/providers/Microsoft.MachineLearningServices/workspaces/machine_learning_workspace', '-e', 'AZUREML_DATA_CONTAINER_ID=dcid.experiment_04_1585219254_ef64c469', '-e', 'AZUREML_DISCOVERY_SERVICE_ENDPOINT=https://westeurope.experiments.azureml.net/discovery', '-e', 'AZUREML_RUN_HISTORY_SERVICE_ENDPOINT=https://westeurope.experiments.azureml.net', '-e', 'AZUREML_SERVICE_ENDPOINT=https://westeurope.experiments.azureml.net', '-e', 'AZUREML_RUN_CONFIGURATION=azureml-setup/mutated_run_configuration.json', '-e', 'AZUREML_INSTRUMENTATION_KEY=fb7e27a4-f865-4147-83ee-ffbf79d1a9f5', '-e', 'AZUREML_DRIVERLOG_PATH=azureml-logs/driver_log.txt', '-e', 'TELEMETRY_LOGS=azureml-logs/telemetry_logs/', '-e', 'FAIRLEARN_LOGS=azureml-logs/telemetry_logs/fairlearn_log.txt', '-e', 'INTERPRET_TEXT_LOGS=azureml-logs/telemetry_logs/interpret_text_log.txt', '-e', 'INTERPRET_C_LOGS=azureml-logs/telemetry_logs/interpret_community_log.txt', '-e', 'AZUREML_JOBRELEASELOG_PATH=azureml-logs/job_release_log.txt', '-e', 'AZUREML_JOBPREPLOG_PATH=azureml-logs/job_prep_log.txt', '-e', 'AZUREML_CONTROLLOG_PATH=azureml-logs/control_log.txt', '-e', 'AZUREML_LOGDIRECTORY_PATH=azureml-logs/', '-e', 'AZUREML_PIDFILE_PATH=azureml-setup/pid.txt', '-e', 'AZUREML_RUN_ID=experiment_04_1585219254_ef64c469', 'azureml/azureml_586a3ed27470f038ee8054b84967c621', '/bin/bash', '-c', 'cd /azureml-run && \"/azureml-envs/azureml_0693bf5a27c007269f994179ddcb4745/bin/python\" \"azureml-setup/run_script.py\" \"/azureml-envs/azureml_0693bf5a27c007269f994179ddcb4745/bin/python\" \"azureml-setup/context_manager_injector.py\" \"-i\" \"ProjectPythonPath:context_managers.ProjectPythonPath\" \"-i\" \"RunHistory:context_managers.RunHistory\" \"-i\" \"TrackUserError:context_managers.TrackUserError\" \"experiment_argparse.py\" \"--reg_rate\" \"0.1\"']\n",
      "/bin/bash: /azureml-envs/azureml_0693bf5a27c007269f994179ddcb4745/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "Streaming log file azureml-logs/70_driver_log.txt\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 8\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ experiment_argparse.py ] with arguments: ['--reg_rate', '0.1']\n",
      "After variable expansion, calling script [ experiment_argparse.py ] with arguments: ['--reg_rate', '0.1']\n",
      "\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 8\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.15246844291687012 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: experiment_04_1585219254_ef64c469\n",
      "Web View: https://ml.azure.com/experiments/experiment_04/runs/experiment_04_1585219254_ef64c469?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/machine_learning_workspace\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'experiment_04_1585219254_ef64c469',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-03-26T10:40:57.797123Z',\n",
       " 'endTimeUtc': '2020-03-26T10:41:06.256736Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '2769b7e8-81cb-4cd4-abf2-3c7eddf947b3',\n",
       "  'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '52678fcbd4c5cd3218a03f1cfd3043f4bdf6d765',\n",
       "  'mlflow.source.git.commit': '52678fcbd4c5cd3218a03f1cfd3043f4bdf6d765',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'runDefinition': {'script': 'experiment_argparse.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--reg_rate', '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment experiment_04 Environment',\n",
       "   'version': 'Autosave_2020-03-26T09:06:53Z_8d69e219',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults']},\n",
       "      'scikit-learn',\n",
       "      'joblib'],\n",
       "     'name': 'azureml_0693bf5a27c007269f994179ddcb4745'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.experiment_04_1585219254_ef64c469/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=Klx5Hfek040cGD6KAgn2aL0kn64llYSel6d6zDLyMcY%3D&st=2020-03-26T10%3A31%3A07Z&se=2020-03-26T18%3A41%3A07Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.experiment_04_1585219254_ef64c469/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=Txd5M8aF1kNXfZSFLjUsawNk%2FNaetqa4C7F2R54dFIY%3D&st=2020-03-26T10%3A31%3A07Z&se=2020-03-26T18%3A41%3A07Z&sp=r',\n",
       "  'logs/azureml/8_azureml.log': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.experiment_04_1585219254_ef64c469/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=wJRqJw6Gz%2BJW2A%2FTkHJ6ohGjQsUVMzgOXj7SerJei7s%3D&st=2020-03-26T10%3A31%3A07Z&se=2020-03-26T18%3A41%3A07Z&sp=r'}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml-logs/60_control_log.txt\n",
      "azureml-logs/70_driver_log.txt\n",
      "logs/azureml/8_azureml.log\n",
      "outputs/sample.csv\n",
      "outputs/titanic_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# \"run\" is a reference to a completed experiment run\n",
    "# List the files generated by the experiment\n",
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a named file\n",
    "#run.download_file(name='outputs/model.pkl', output_file_path='model.pkl')\n",
    "run.download_file(name='outputs/sample.csv', output_file_path='sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ubuntu ubuntu 59 Mar 26 11:44 sample.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l sample.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### option A\n",
    "Fails, because it first need to download the model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register a model from a local file, you can use the register method of the Model object\n",
    "# from azureml.core import Model\n",
    "\n",
    "# model = Model.register(workspace=ws,\n",
    "#                        model_name='titanic_classification_model',\n",
    "#                        model_path='outputs/titanic_model.pkl', # local path\n",
    "#                        description='A classification model Titanic',\n",
    "#                        tags={'testmodel': 'titanic'},\n",
    "#                        model_framework=Model.Framework.SCIKITLEARN,\n",
    "#                        model_framework_version='0.20.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### option B\n",
    "this is better because it grabs the model file from the run !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup'), name=titanic_classification_model, id=titanic_classification_model:1, version=1, tags={'testmodel': 'titanic'}, properties={})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register a model using reference to the Run use its register_model method\n",
    "run.register_model(model_name='titanic_classification_model',\n",
    "                   model_path='outputs/titanic_model.pkl', # run outputs path\n",
    "                   description='A classification model Titanic',\n",
    "                   tags={'testmodel': 'titanic'},\n",
    "                   model_framework=Model.Framework.SCIKITLEARN,\n",
    "                   model_framework_version='0.20.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(workspace=Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup'), name=titanic_classification_model, id=titanic_classification_model:1, version=1, tags={'testmodel': 'titanic'}, properties={})]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view registered models with\n",
    "Model.list(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_lake_gen2': <azureml.data.azure_data_lake_datastore.AzureDataLakeGen2Datastore at 0x7efdd6ef9cc0>,\n",
       " 'workspacefilestore': <azureml.data.azure_storage_datastore.AzureFileDatastore at 0x7efdd6ef9be0>,\n",
       " 'workspaceblobstore': <azureml.data.azure_storage_datastore.AzureBlobDatastore at 0x7efdd6e8dc88>}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all datastores (already registered a few manually)\n",
    "ws.datastores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a reference to ex: data_lake_gen2\n",
    "blob_store = Datastore.get(ws, datastore_name='workspaceblobstore')\n",
    "data_lake_gen2 = Datastore.get(ws, datastore_name='data_lake_gen2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'azureml.data.azure_storage_datastore.AzureBlobDatastore'>\n",
      "<class 'azureml.data.azure_data_lake_datastore.AzureDataLakeGen2Datastore'>\n"
     ]
    }
   ],
   "source": [
    "print(type(blob_store))\n",
    "print(type(data_lake_gen2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy titanic.csv to datalake in /datalake/gold/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### option1: Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### option2: Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### option3: Mount (preferred) - not possible on local compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you must pass \"script_params\" parameter to an experiment script\n",
    "# ex:   script_params = {'--data_folder': data_ref}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile experiment_argparse.py\n",
    "from azureml.core import Run\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Set regularization hyperparameter\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--reg_rate', type=float, dest='reg', default=0.01)\n",
    "args = parser.parse_args()\n",
    "reg = args.reg\n",
    "\n",
    "# set datastore local reference path\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_folder', type=str, dest='data_folder')\n",
    "args = parser.parse_args()\n",
    "data_files = os.listdir(args.data_folder)\n",
    "\n",
    "# Prepare the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "titanic = pd.read_csv('titanic.csv')\n",
    "X, y = titanic[['PassengerId','Pclass','Age','SibSp','Parch','Fare','male','Q','S']].values, titanic['Survived'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# Count the rows and log the result and save the argument value\n",
    "row_count = (len(data))\n",
    "run.log('observations', row_count)\n",
    "run.log(\"the given 'reg_rate' parameter:\", reg) # <------------\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# Save a sample of the data\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "data.head(2).to_csv(\"outputs/sample.csv\", index=False, header=True)\n",
    "\n",
    "# Save the trained model\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/titanic_model.pkl')\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ref = blob_store.path(\"data/files\").as_download(path_on_compute='training_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "listdir: path should be string, bytes, os.PathLike, integer or None, not DataReference",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-644ee567ba9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: listdir: path should be string, bytes, os.PathLike, integer or None, not DataReference"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(data_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ref = blob_ds.path('gold/').as_download(path_on_compute='training_data')\n",
    "estimator = Estimator(source_directory='.',\n",
    "                      entry_script='experiment_argparse.py',\n",
    "                      script_params = {'--reg_rate': 0.1}, # <-------------\n",
    "                      compute_target='local',\n",
    "                      conda_packages=['scikit-learn', 'joblib'],\n",
    "                      pip_packages=['azureml-sdk'],\n",
    "                      script_params = {'--data_folder': data_ref})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "### Retrieving a registered dataset\n",
    "https://nbviewer.jupyter.org/github/MicrosoftDocs/mslearn-aml-labs/blob/master/03-Working_with_Data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we manually created and registered a dataset from the datalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datalake': DatasetRegistration(id='a2af81a9-8e27-429d-8845-489bd371e9ca', name='datalake', version=1, description='', tags={})}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show a list of available datasets\n",
    "ws.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataset from the workspace datasets collection\n",
    "#ds1 = ws.datasets['datalake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataset by name from the datasets class\n",
    "ds2 = Dataset.get_by_name(ws, 'datalake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/bronze/db_v2_csv/_committed_1187318739692831567',\n",
       " '/bronze/db_v2_csv/_started_1187318739692831567',\n",
       " '/bronze/db_v2_csv/part-00000-tid-1187318739692831567-fae6394b-2577-421a-ab58-50e75b7b6889-9-1-c000.csv',\n",
       " '/bronze/db_v2_csv/part-00001-tid-1187318739692831567-fae6394b-2577-421a-ab58-50e75b7b6889-10-1-c000.csv',\n",
       " '/bronze/db_v2_csv/part-00002-tid-1187318739692831567-fae6394b-2577-421a-ab58-50e75b7b6889-11-1-c000.csv',\n",
       " '/bronze/docph/DB_V2.parquet',\n",
       " '/bronze/pharma_ref.xlsx',\n",
       " '/bronze/pharma_ref_csv/_committed_3971660126738673139',\n",
       " '/bronze/pharma_ref_csv/_started_3971660126738673139',\n",
       " '/bronze/pharma_ref_csv/part-00000-tid-3971660126738673139-e84ee614-8706-4e8b-afc5-89e3bd88a7a4-4-1-c000.csv',\n",
       " '/bronze/pharma_ref_csv/part-00001-tid-3971660126738673139-e84ee614-8706-4e8b-afc5-89e3bd88a7a4-5-1-c000.csv',\n",
       " '/bronze/pharma_ref_csv/part-00002-tid-3971660126738673139-e84ee614-8706-4e8b-afc5-89e3bd88a7a4-6-1-c000.csv',\n",
       " '/bronze/pharma_ref_csv/part-00003-tid-3971660126738673139-e84ee614-8706-4e8b-afc5-89e3bd88a7a4-7-1-c000.csv',\n",
       " '/bronze/pharma_ref_parquet/part-00000-tid-7225977555282070365-fe0b57fc-2ebc-4c9a-9bc8-3c3ec4ce3d9c-33-1-c000.snappy.parquet',\n",
       " '/bronze/pharma_ref_parquet/part-00001-tid-7225977555282070365-fe0b57fc-2ebc-4c9a-9bc8-3c3ec4ce3d9c-34-1-c000.snappy.parquet',\n",
       " '/bronze/pharma_ref_parquet/part-00002-tid-7225977555282070365-fe0b57fc-2ebc-4c9a-9bc8-3c3ec4ce3d9c-35-1-c000.snappy.parquet',\n",
       " '/bronze/pharma_ref_parquet/part-00003-tid-7225977555282070365-fe0b57fc-2ebc-4c9a-9bc8-3c3ec4ce3d9c-36-1-c000.snappy.parquet',\n",
       " '/bronze/reimb_category.xlsx',\n",
       " '/bronze/reimb_category_csv/_committed_3468056746057978212',\n",
       " '/bronze/reimb_category_csv/_started_3468056746057978212',\n",
       " '/bronze/reimb_category_csv/part-00000-tid-3468056746057978212-44068129-5d2f-409b-aed3-dc237a793ee9-12-1-c000.csv',\n",
       " '/bronze/reimb_category_csv/part-00001-tid-3468056746057978212-44068129-5d2f-409b-aed3-dc237a793ee9-13-1-c000.csv',\n",
       " '/bronze/reimb_category_csv/part-00002-tid-3468056746057978212-44068129-5d2f-409b-aed3-dc237a793ee9-14-1-c000.csv',\n",
       " '/bronze/reimb_category_csv/part-00003-tid-3468056746057978212-44068129-5d2f-409b-aed3-dc237a793ee9-15-1-c000.csv',\n",
       " '/delta/koalas-DF/_delta_log/00000000000000000000.crc',\n",
       " '/delta/koalas-DF/_delta_log/00000000000000000000.json',\n",
       " '/delta/koalas-DF/_delta_log/00000000000000000001.crc',\n",
       " '/delta/koalas-DF/_delta_log/00000000000000000001.json',\n",
       " '/delta/koalas-DF/_delta_log/00000000000000000002.crc',\n",
       " '/delta/koalas-DF/_delta_log/00000000000000000002.json',\n",
       " '/delta/koalas-DF/_delta_log/00000000000000000003.crc',\n",
       " '/delta/koalas-DF/_delta_log/00000000000000000003.json',\n",
       " '/delta/koalas-DF/_delta_log/00000000000000000004.crc',\n",
       " '/delta/koalas-DF/_delta_log/00000000000000000004.json',\n",
       " '/delta/koalas-DF/part-00000-2c2c1c97-c2bb-47c8-9025-6508f2bbd464-c000.snappy.parquet',\n",
       " '/delta/koalas-DF/part-00000-7379869e-0869-4f19-a1d8-62c46a86747c-c000.snappy.parquet',\n",
       " '/delta/koalas-DF/part-00000-85fc04f7-1dfb-4ded-93f5-d4a04d934ea3-c000.snappy.parquet',\n",
       " '/delta/koalas-DF/part-00000-c3efd631-4d24-4a7c-8a56-6d1cd5a93d49-c000.snappy.parquet',\n",
       " '/delta/koalas-DF/part-00000-e0cceafa-7734-4040-ab43-abe6ef82ab72-c000.snappy.parquet',\n",
       " '/delta/koalas-DF/part-00001-5361a12a-6ffa-48a9-a8dc-09ce747d0018-c000.snappy.parquet',\n",
       " '/delta/koalas-DF/part-00001-70ab77fb-6bd0-458e-8bcb-ca926afe84f8-c000.snappy.parquet',\n",
       " '/delta/koalas-DF/part-00001-80085cc0-1c28-4754-98f3-2093b481bcc4-c000.snappy.parquet',\n",
       " '/delta/koalas-DF/part-00001-9a865a77-2d22-4e54-bdbb-a369d94f8051-c000.snappy.parquet',\n",
       " '/delta/koalas-DF/part-00001-ea728bcb-00b3-4f00-82ba-c19c3f5427ca-c000.snappy.parquet',\n",
       " '/delta/koalas-DF/part-00002-1ba55a93-85d8-406e-84d6-2d3271cb8591-c000.snappy.parquet',\n",
       " '/delta/koalas-DF/part-00002-29cdc731-bdae-4c1b-a287-8ad989e78528-c000.snappy.parquet',\n",
       " '/delta/koalas-DF/part-00002-49688d7b-8118-4915-bd6f-3d6377fcdb55-c000.snappy.parquet',\n",
       " '/delta/koalas-DF/part-00002-4a09f219-7df3-40d1-81a8-7da6d6bd6b4f-c000.snappy.parquet',\n",
       " '/delta/koalas-DF/part-00002-e36f793d-49d1-49e9-bfef-fc11a4191505-c000.snappy.parquet',\n",
       " '/gold/titanic.csv',\n",
       " '/silver/dataforbetterhealth_parquet/_committed_6703812260516560499',\n",
       " '/silver/dataforbetterhealth_parquet/_started_6703812260516560499',\n",
       " '/silver/dataforbetterhealth_parquet/part-00000-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7244-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00001-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7247-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00002-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7241-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00003-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7231-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00004-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7237-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00005-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7251-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00006-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7305-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00007-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7401-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00008-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7310-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00009-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7416-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00010-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7286-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00011-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7335-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00012-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7327-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00013-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7378-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00014-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7428-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00015-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7258-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00016-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7315-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00017-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7373-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00018-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7262-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00019-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7311-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00020-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7423-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00021-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7383-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00022-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7406-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00023-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7332-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00024-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7361-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00025-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7368-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00026-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7294-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00027-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7409-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00028-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7296-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00029-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7357-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00030-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7395-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00031-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7301-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00032-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7398-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00033-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7348-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00034-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7367-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00035-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7270-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00036-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7355-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00037-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7408-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00038-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7396-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00039-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7397-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00040-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7375-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00041-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7280-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00042-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7349-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00043-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7344-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00044-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7324-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00045-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7417-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00046-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7359-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00047-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7343-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00048-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7277-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00049-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7259-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00050-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7281-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00051-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7325-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00052-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7243-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00053-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7300-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00054-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7273-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00055-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7267-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00056-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7313-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00057-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7308-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00058-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7250-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00059-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7264-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00060-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7240-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00061-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7234-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00062-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7238-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00063-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7252-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00064-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7235-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00065-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7246-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00066-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7233-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00067-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7253-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00068-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7232-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00069-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7269-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00070-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7268-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00071-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7429-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00072-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7376-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00073-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7342-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00074-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7379-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00075-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7370-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00076-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7430-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00077-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7338-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00078-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7381-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00079-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7289-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00080-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7248-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00081-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7393-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00082-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7293-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00083-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7288-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00084-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7366-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00085-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7389-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00086-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7422-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00087-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7299-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00088-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7360-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00089-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7407-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00090-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7330-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00091-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7418-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00092-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7388-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00093-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7339-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00094-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7265-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00095-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7321-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00096-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7303-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00097-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7279-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00098-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7285-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00099-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7385-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00100-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7399-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00101-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7309-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00102-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7263-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00103-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7350-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00104-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7306-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00105-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7425-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00106-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7352-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00107-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7405-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00108-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7354-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00109-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7346-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00110-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7326-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00111-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7345-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00112-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7257-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00113-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7427-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00114-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7341-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00115-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7377-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00116-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7364-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00117-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7304-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00118-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7371-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00119-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7386-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00120-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7369-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00121-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7390-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00122-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7411-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00123-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7317-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00124-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7337-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00125-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7365-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00126-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7254-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00127-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7242-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00128-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7239-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00129-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7403-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00130-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7284-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00131-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7318-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00132-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7358-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00133-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7351-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00134-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7415-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00135-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7329-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00136-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7372-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00137-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7302-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00138-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7420-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00139-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7400-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00140-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7362-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00141-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7340-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00142-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7347-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00143-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7312-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00144-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7319-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00145-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7353-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00146-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7419-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00147-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7391-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00148-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7323-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00149-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7260-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00150-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7290-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00151-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7380-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00152-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7424-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00153-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7261-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00154-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7274-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00155-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7404-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00156-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7282-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00157-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7298-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00158-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7333-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00159-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7295-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00160-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7402-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00161-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7245-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00162-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7392-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00163-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7276-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00164-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7314-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00165-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7297-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00166-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7322-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00167-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7336-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00168-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7272-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00169-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7387-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00170-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7410-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00171-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7374-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00172-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7394-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00173-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7292-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00174-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7363-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00175-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7414-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00176-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7384-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00177-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7275-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00178-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7266-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00179-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7412-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00180-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7316-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00181-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7426-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00182-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7382-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00183-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7334-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00184-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7283-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00185-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7278-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00186-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7320-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00187-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7256-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00188-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7331-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00189-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7413-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00190-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7255-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00191-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7287-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00192-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7236-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00193-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7291-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00194-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7307-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00195-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7356-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00196-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7421-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00197-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7328-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00198-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7271-1-c000.snappy.parquet',\n",
       " '/silver/dataforbetterhealth_parquet/part-00199-tid-6703812260516560499-2b1fb5e3-b134-4fd7-8b93-09bcb97d8ce8-7249-1-c000.snappy.parquet',\n",
       " '/silver/pharma_ref_csv/_committed_4868494169037066666',\n",
       " '/silver/pharma_ref_csv/_started_4868494169037066666',\n",
       " '/silver/pharma_ref_csv/part-00000-tid-4868494169037066666-61f7c703-8abe-4261-b6e0-249f9a965057-0-1-c000.csv',\n",
       " '/silver/pharma_ref_csv/part-00001-tid-4868494169037066666-61f7c703-8abe-4261-b6e0-249f9a965057-1-1-c000.csv',\n",
       " '/silver/pharma_ref_csv/part-00002-tid-4868494169037066666-61f7c703-8abe-4261-b6e0-249f9a965057-2-1-c000.csv',\n",
       " '/silver/pharma_ref_csv/part-00003-tid-4868494169037066666-61f7c703-8abe-4261-b6e0-249f9a965057-3-1-c000.csv']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all files in the datalake (incl. directories)\n",
    "ds2.to_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### passing a file dataset, you must specify the access mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the script will need to work with a Dataset object, you must include pip packages:\n",
    "\n",
    "#estimator = Estimator(pip_packages=['azureml-sdk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(source_directory='.',\n",
    "                      entry_script='experiment_argparse.py'\n",
    "                      compute_target='local',\n",
    "                      inputs=[img_ds.as_named_input('img_data').as_download(path_on_compute='data')],\n",
    "                      pip_packages=['azureml-dataprep[pandas]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SKLearn( source_directory='experiment_folder',\n",
    "                     entry_script='training_script.py',\n",
    "                     compute_target='local',\n",
    "                     inputs=[tab_ds.as_named_input('csv_data')],\n",
    "                     pip_packages=['azureml-dataprep[pandas]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ref = blob_ds.path('gold/').as_download(path_on_compute='training_data')\n",
    "estimator = Estimator(source_directory='.',\n",
    "                      entry_script='experiment_argparse.py',\n",
    "                      script_params = {'--reg_rate': 0.1}, # <-------------\n",
    "                      compute_target='local',\n",
    "                      conda_packages=['scikit-learn', 'joblib'],\n",
    "                      pip_packages=['azureml-sdk'],\n",
    "                      script_params = {'--data_folder': data_ref})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Model from a File Dataset (mount mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put 2 files in the ADSL Gen2 data lake\n",
    "# they are in container \"datalake\" and this is registered in ml workspace as \"datalake\" Datastore\n",
    "# in turn the container \"datalake\" is registered as a Dataset in azure ML Workspace\n",
    "# 2 specific files of intrest: \n",
    "# /gold/diabetes.csv\n",
    "# /gold/diabetes2.csv\n",
    "# the goal is to mount these into a run script send to compute nodes to train model on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset input passed to the script represents a mount point containing file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_training_from_file_dataset folder created\n"
     ]
    }
   ],
   "source": [
    "# create A folder named diabetes_training_from_file_dataset here locally\n",
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'diabetes_training_from_file_dataset'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a script that trains a classification model by using a file dataset that is passed to it as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes/*.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"diabetes\" + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting diabetes_training_from_file_dataset/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import glob\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data_path = run.input_datasets['diabetes']  # Get the training data from the estimator input\n",
    "print(\"data_path: \" + str(data_path))         # diabetes_path\n",
    "all_files = glob.glob(data_path + \"/*\")\n",
    "print(\"data_path + '/*.csv': \" + str(data_path + '/*.csv')) # diabetes_path/*.csv\n",
    "print([file for file in all_files])   # ['diabetes_path/diabetes.csv', 'diabetes_path/diabetes2.csv']\n",
    "print(\"type(all_files): \" + str(type(all_files)))\n",
    "print(type(all_files[0]))\n",
    "diabetes = pd.concat((pd.read_csv(f) for f in all_files))\n",
    "print(\"number of records: \" + str(len(diabetes)))\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to change the way we pass the dataset to the estimator - it needs to define a mount point from which the script can read the files. For large volumes of data, you'd generally use the **as_mount** method to stream the files directly from the dataset source; but when running on local compute (as we are in this example), you need to use the **as_download** option to download the dataset files to a local folder.\n",
    "\n",
    "Also, since the **Dataset** class is defined in the **azureml-dataprep** package, we need to include that in the experiment environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Dataset\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the script parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diabetes1': DatasetRegistration(id='ebc21ed2-3f94-494b-8072-2c71d2190200', name='diabetes1', version=1, description='', tags={}), 'datalakegold': DatasetRegistration(id='ad71d877-e111-4bd4-bf8a-8a602709dffd', name='datalakegold', version=1, description='', tags={}), 'datalake': DatasetRegistration(id='a2af81a9-8e27-429d-8845-489bd371e9ca', name='datalake', version=1, description='', tags={})}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"datalakegold\")\n",
    "\n",
    "# Get a dataset from the workspace datasets collection\n",
    "#ds1 = ws.datasets['datalakegold']\n",
    "#-or-\n",
    "# Get a dataset by name from the datasets class\n",
    "#ds2 = Dataset.get_by_name(ws, 'datalakegold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('data_lake_gen2', 'gold/**')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"ad71d877-e111-4bd4-bf8a-8a602709dffd\",\n",
       "    \"name\": \"datalakegold\",\n",
       "    \"version\": 1,\n",
       "    \"workspace\": \"Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\n",
       "   \"source\": [\n",
       "     \"('data_lake_gen2', 'gold/**')\"\n",
       "   ],\n",
       "   \"definition\": [\n",
       "     \"GetDatastoreFiles\"\n",
       "   ],\n",
       "   \"registration\": {\n",
       "     \"id\": \"ad71d877-e111-4bd4-bf8a-8a602709dffd\",\n",
       "     \"name\": \"datalakegold\",\n",
       "     \"version\": 1,\n",
       "     \"workspace\": \"Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup')\"\n",
       "   }\n",
       " }]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[diabetes_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diabetes_ds.as_named_input('diabetes').as_download(path_on_compute='diabetes_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an estimator\n",
    "estimator = SKLearn(source_directory=experiment_folder,\n",
    "                    entry_script='diabetes_training.py',\n",
    "                    script_params=script_params,\n",
    "                    compute_target = 'local',\n",
    "                    inputs=[diabetes_ds.as_named_input('diabetes').as_download(path_on_compute='diabetes_path')], # Pass the Dataset object as an input\n",
    "                    pip_packages=['azureml-dataprep[pandas]'] # so we need the dataprep package\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {\n",
       "   \"source\": [\n",
       "     \"('data_lake_gen2', 'gold/**')\"\n",
       "   ],\n",
       "   \"definition\": [\n",
       "     \"GetDatastoreFiles\"\n",
       "   ],\n",
       "   \"registration\": {\n",
       "     \"id\": \"ad71d877-e111-4bd4-bf8a-8a602709dffd\",\n",
       "     \"name\": \"datalakegold\",\n",
       "     \"version\": 1,\n",
       "     \"workspace\": \"Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup')\"\n",
       "   }\n",
       " },\n",
       " 'name': 'diabetes',\n",
       " 'mode': 'download',\n",
       " 'path_on_compute': 'diabetes_path'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_ds.as_named_input('diabetes').as_download(path_on_compute='diabetes_path').__dict__\n",
    "# notice the mode if set to Download or Mount then \n",
    "# Run.input_datasets will return the base path of the delivered data\n",
    "# ex: Run.input_datasets['diabetes']   ---> \"diabetes_path\" string value\n",
    "# this is probably the path_on_compute where the data should be put...\n",
    "# files are available on  ['diabetes_path/diabetes.csv', 'diabetes_path/diabetes2.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment\n",
    "experiment_name = 'diabetes-training'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0369d659d14fea86c739949fc3df2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-training/runs/diabetes-training_1585308364_a95f99c6?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/machine_learning_workspace\", \"run_id\": \"diabetes-training_1585308364_a95f99c6\", \"run_properties\": {\"run_id\": \"diabetes-training_1585308364_a95f99c6\", \"created_utc\": \"2020-03-27T11:26:05.512458Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"761f2bce-8d30-4c56-9dd5-0be0c7d55ccb\", \"azureml.git.repository_uri\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"mlflow.source.git.repoURL\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"8189bb0610764a3d5583f351f729bdc6cb32fe0e\", \"mlflow.source.git.commit\": \"8189bb0610764a3d5583f351f729bdc6cb32fe0e\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-03-27T11:26:18.822266Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585308364_a95f99c6/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=Srd%2FwP9STjmxiMsb95hVPT2P1U2byv6PXpPHAiECOCo%3D&st=2020-03-27T11%3A16%3A24Z&se=2020-03-27T19%3A26%3A24Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585308364_a95f99c6/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=9ovjZXq2eMZDf3eWi73oGsSWkfEbu1kzZ0OW2EYOXOk%3D&st=2020-03-27T11%3A16%3A24Z&se=2020-03-27T19%3A26%3A24Z&sp=r\", \"logs/azureml/8_azureml.log\": \"https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585308364_a95f99c6/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=Trh%2BdZgXn39bFS2BqLjeJOOu%2BmSXTXp%2ByOBGs69%2Bq7s%3D&st=2020-03-27T11%3A16%3A24Z&se=2020-03-27T19%3A26%3A24Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/8_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:00:13\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"diabetes-training_1585308364_a95f99c6\", \"categories\": [0], \"series\": [{\"data\": [0.1]}]}, {\"name\": \"Accuracy\", \"run_id\": \"diabetes-training_1585308364_a95f99c6\", \"categories\": [0], \"series\": [{\"data\": [0.7893333333333333]}]}, {\"name\": \"AUC\", \"run_id\": \"diabetes-training_1585308364_a95f99c6\", \"categories\": [0], \"series\": [{\"data\": [0.8568655044545174]}]}], \"run_logs\": \"Initialize DatasetContextManager.\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nEnter __enter__ of DatasetContextManager\\nSDK version: azureml-core==1.2.0.post1 azureml-dataprep==1.4.0\\nProcessing 'diabetes'\\nProcessing dataset FileDataset\\n{\\n  \\\"source\\\": [\\n    \\\"('data_lake_gen2', 'gold/**')\\\"\\n  ],\\n  \\\"definition\\\": [\\n    \\\"GetDatastoreFiles\\\"\\n  ],\\n  \\\"registration\\\": {\\n    \\\"id\\\": \\\"ad71d877-e111-4bd4-bf8a-8a602709dffd\\\",\\n    \\\"name\\\": \\\"datalakegold\\\",\\n    \\\"version\\\": 1,\\n    \\\"workspace\\\": \\\"Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup')\\\"\\n  }\\n}\\nDownloading diabetes to diabetes_path\\nDownloaded diabetes to diabetes_path\\nExit __enter__ of DatasetContextManager\\nEntering Run History Context Manager.\\nPreparing to call script [ diabetes_training.py ] with arguments: ['--regularization', '0.1']\\nAfter variable expansion, calling script [ diabetes_training.py ] with arguments: ['--regularization', '0.1']\\n\\nLoading Data...\\ndata_path: diabetes_path\\ndata_path + '/*.csv': diabetes_path/*.csv\\n['diabetes_path/diabetes.csv', 'diabetes_path/diabetes2.csv']\\ntype(all_files): <class 'list'>\\n<class 'str'>\\nnumber of records: 15000\\nTraining a logistic regression model with regularization rate of 0.1\\nAccuracy: 0.7893333333333333\\nAUC: 0.8568655044545174\\n\\n\\nThe experiment completed successfully. Finalizing run...\\nLogging experiment finalizing status in history service.\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.1431584358215332 seconds\\nEnter __exit__ of DatasetContextManager\\nExit __exit__ of DatasetContextManager\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.85\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'diabetes-training_1585308364_a95f99c6',\n",
       " 'target': 'local',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2020-03-27T11:26:06.544218Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '761f2bce-8d30-4c56-9dd5-0be0c7d55ccb',\n",
       "  'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '8189bb0610764a3d5583f351f729bdc6cb32fe0e',\n",
       "  'mlflow.source.git.commit': '8189bb0610764a3d5583f351f729bdc6cb32fe0e',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [{'dataset': {'id': 'ad71d877-e111-4bd4-bf8a-8a602709dffd'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes', 'mechanism': 'Download', 'pathOnCompute': 'diabetes_path'}}],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization', '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'diabetes': {'dataLocation': {'dataset': {'id': 'ad71d877-e111-4bd4-bf8a-8a602709dffd'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Download',\n",
       "    'environmentVariableName': 'diabetes',\n",
       "    'pathOnCompute': 'diabetes_path',\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment diabetes-training Environment',\n",
       "   'version': 'Autosave_2020-03-26T16:12:43Z_51b19fc4',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-dataprep[pandas]',\n",
       "        'azureml-defaults',\n",
       "        'scikit-learn==0.20.3',\n",
       "        'scipy==1.2.1',\n",
       "        'numpy==1.16.2',\n",
       "        'joblib==0.13.2']}],\n",
       "     'name': 'azureml_33c71153666f0570038d765d08eae59e'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585308364_a95f99c6/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=6zUK4O0vHvcNLV9feXO38opwR4mNLwSa2wW5NAtuDK8%3D&st=2020-03-27T11%3A16%3A16Z&se=2020-03-27T19%3A26%3A16Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585308364_a95f99c6/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=f8CKk771U4AHX5TXqc1y8LcdgmxFYU2gAPhygjJLVaw%3D&st=2020-03-27T11%3A16%3A16Z&se=2020-03-27T19%3A26%3A16Z&sp=r',\n",
       "  'logs/azureml/8_azureml.log': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585308364_a95f99c6/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=mrR%2BedNJD40IHNrQHkkEc31VnwJXEF%2FYlQfXK4oA%2B60%3D&st=2020-03-27T11%3A16%3A16Z&se=2020-03-27T19%3A26%3A16Z&sp=r'}}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the experiment has completed, in the widget, view the **azureml-logs/70_driver_log.txt** output log to verify that the file dataset was processed and the data files downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datastore method (mount mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_lake_gen2': <azureml.data.azure_data_lake_datastore.AzureDataLakeGen2Datastore at 0x7f2bd1730668>,\n",
       " 'workspacefilestore': <azureml.data.azure_storage_datastore.AzureFileDatastore at 0x7f2bd17302b0>,\n",
       " 'workspaceblobstore': <azureml.data.azure_storage_datastore.AzureBlobDatastore at 0x7f2bc226ac50>}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available datastore names\n",
    "ws.datastores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Datastore.get(workspace=ws, datastore_name=\"data_lake_gen2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_workspace': Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup'),\n",
       " '_name': 'data_lake_gen2',\n",
       " '_datastore_type': 'AzureDataLakeGen2',\n",
       " 'tenant_id': '73b49191-8db3-45ab-87b3-b8f956ac123b',\n",
       " 'client_id': '38c02221-4a41-4ec8-b8da-a81f16c38e82',\n",
       " 'client_secret': 'l]ABG6@Z/9r/hX7EK0zavK5Nx[MA-J1V',\n",
       " 'resource_url': 'https://storage.azure.com',\n",
       " 'authority_url': 'https://login.microsoftonline.com',\n",
       " 'container_name': 'datalake',\n",
       " 'account_name': 'datalake21032020',\n",
       " 'protocol': 'https',\n",
       " 'endpoint': 'core.windows.net'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diabetes1': DatasetRegistration(id='ebc21ed2-3f94-494b-8072-2c71d2190200', name='diabetes1', version=1, description='', tags={}), 'datalakegold': DatasetRegistration(id='ad71d877-e111-4bd4-bf8a-8a602709dffd', name='datalakegold', version=1, description='', tags={}), 'datalake': DatasetRegistration(id='a2af81a9-8e27-429d-8845-489bd371e9ca', name='datalake', version=1, description='', tags={})}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# available dataset names\n",
    "ws.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.datapath import DataPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and registering file datasets\n",
    "#blob_ds = Dataset.get_by_name(workspace=ws, name=\"datalakegold\")\n",
    "datastore = Datastore.get(workspace=ws, datastore_name=\"data_lake_gen2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_path = [\n",
    "    DataPath(datastore, 'platinum/diabetes.csv'),\n",
    "    DataPath(datastore, 'platinum/folder/*.csv')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<azureml.data.datapath.DataPath at 0x7f2bc225aeb8>,\n",
       " <azureml.data.datapath.DataPath at 0x7f2bc225afd0>]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the files that you need\n",
    "file_dataset = Dataset.File.from_files(path=datastore_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('data_lake_gen2', 'platinum/diabetes.csv')\",\n",
       "    \"('data_lake_gen2', 'platinum/folder/*.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# registering these files\n",
    "file_ds = file_dataset.register(workspace=ws, name='diabetes1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the registered dataset by name from the datasets class\n",
    "ds = Dataset.get_by_name(workspace=ws, name=\"diabetes2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('data_lake_gen2', 'platinum/diabetes.csv')\",\n",
       "    \"('data_lake_gen2', 'platinum/folder/*.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"ebc21ed2-3f94-494b-8072-2c71d2190200\",\n",
       "    \"name\": \"diabetes1\",\n",
       "    \"version\": 1,\n",
       "    \"workspace\": \"Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data_lake_gen2/platinum/diabetes.csv',\n",
       " '/data_lake_gen2/platinum/folder/diabetes2.csv']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all files\n",
    "ds.to_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing a dataset to an experiment script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_training_from_file_dataset folder created\n"
     ]
    }
   ],
   "source": [
    "# create A folder named diabetes_training_from_file_dataset here locally\n",
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'diabetes_training_from_file_dataset'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have created a global variable \"experiment_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting diabetes_training_from_file_dataset/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import glob\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data_path = run.input_datasets['diabetes2'] # Get the training data from the estimator input\n",
    "print(\"data_path: \" + str(data_path))\n",
    "all_files = glob.glob(data_path + \"/folder/*.csv\")\n",
    "#print(\"data_path + '/*.csv': \" + str(data_path + '/*.csv')) # diabetes_path/*.csv\n",
    "print([file for file in all_files])   # ['diabetes_path/diabetes.csv', 'diabetes_path/diabetes2.csv']\n",
    "print(\"type(all_files): \" + str(type(all_files)))\n",
    "print(type(all_files[0]))\n",
    "diabetes = pd.concat((pd.read_csv(f) for f in all_files))\n",
    "print(\"number of records: \" + str(len(diabetes)))\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Dataset\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the registered dataset by name from the datasets class\n",
    "ds = Dataset.get_by_name(workspace=ws, name=\"diabetes2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the script parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {\n",
       "   \"source\": [\n",
       "     \"('data_lake_gen2', 'platinum/**')\"\n",
       "   ],\n",
       "   \"definition\": [\n",
       "     \"GetDatastoreFiles\"\n",
       "   ],\n",
       "   \"registration\": {\n",
       "     \"id\": \"2c81c692-c43c-4f03-9952-45124c0da47c\",\n",
       "     \"name\": \"diabetes2\",\n",
       "     \"version\": 1,\n",
       "     \"workspace\": \"Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup')\"\n",
       "   }\n",
       " },\n",
       " 'name': 'diabetes2',\n",
       " 'mode': 'direct',\n",
       " 'path_on_compute': None}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.as_named_input('diabetes2').__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.data.dataset_consumption_config.DatasetConsumptionConfig at 0x7f2bc2209438>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.as_named_input('diabetes2').as_download(path_on_compute='diabetes_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/diabetes.csv', '/folder/diabetes2.csv']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of all the files\n",
    "ds.to_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an estimator\n",
    "estimator = SKLearn(source_directory=experiment_folder,\n",
    "                    entry_script='diabetes_training.py',\n",
    "                    script_params=script_params,\n",
    "                    compute_target = 'local',\n",
    "                    inputs=[ds.as_named_input('diabetes2').as_download(path_on_compute='diabetes_path')], # Pass the Dataset object as an input\n",
    "                    pip_packages=['azureml-dataprep[pandas]'] # so we need the dataprep package\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment\n",
    "experiment_name = 'diabetes-training'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23265f290984405a870dbfed8fa6ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-training/runs/diabetes-training_1585314547_c0946781?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/machine_learning_workspace\", \"run_id\": \"diabetes-training_1585314547_c0946781\", \"run_properties\": {\"run_id\": \"diabetes-training_1585314547_c0946781\", \"created_utc\": \"2020-03-27T13:09:07.934601Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"a3adee05-57f2-4bdc-903f-8941cc1e936b\", \"azureml.git.repository_uri\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"mlflow.source.git.repoURL\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"8189bb0610764a3d5583f351f729bdc6cb32fe0e\", \"mlflow.source.git.commit\": \"8189bb0610764a3d5583f351f729bdc6cb32fe0e\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-03-27T13:09:21.378383Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585314547_c0946781/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=s6MM3HfyVnaE4jeBHyJqvpAYJn2BKBQNsLF5F4sLCqY%3D&st=2020-03-27T12%3A59%3A26Z&se=2020-03-27T21%3A09%3A26Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585314547_c0946781/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=2Z8HHkVPeCFjrUjNu87IOgp2%2Fa4dngSGwBP7c72Hwwg%3D&st=2020-03-27T12%3A59%3A26Z&se=2020-03-27T21%3A09%3A26Z&sp=r\", \"logs/azureml/8_azureml.log\": \"https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585314547_c0946781/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=dRorvJNrSnNlE%2B81lFjz0JMOEcmt1aVD79pbEcf%2BwxQ%3D&st=2020-03-27T12%3A59%3A26Z&se=2020-03-27T21%3A09%3A26Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/8_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:00:13\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"diabetes-training_1585314547_c0946781\", \"categories\": [0], \"series\": [{\"data\": [0.1]}]}, {\"name\": \"Accuracy\", \"run_id\": \"diabetes-training_1585314547_c0946781\", \"categories\": [0], \"series\": [{\"data\": [0.7906666666666666]}]}, {\"name\": \"AUC\", \"run_id\": \"diabetes-training_1585314547_c0946781\", \"categories\": [0], \"series\": [{\"data\": [0.8535812401883831]}]}], \"run_logs\": \"Initialize DatasetContextManager.\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nEnter __enter__ of DatasetContextManager\\nSDK version: azureml-core==1.2.0.post1 azureml-dataprep==1.4.0\\nProcessing 'diabetes2'\\nProcessing dataset FileDataset\\n{\\n  \\\"source\\\": [\\n    \\\"('data_lake_gen2', 'platinum/**')\\\"\\n  ],\\n  \\\"definition\\\": [\\n    \\\"GetDatastoreFiles\\\"\\n  ],\\n  \\\"registration\\\": {\\n    \\\"id\\\": \\\"2c81c692-c43c-4f03-9952-45124c0da47c\\\",\\n    \\\"name\\\": \\\"diabetes2\\\",\\n    \\\"version\\\": 1,\\n    \\\"workspace\\\": \\\"Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup')\\\"\\n  }\\n}\\nDownloading diabetes2 to diabetes_path\\nDownloaded diabetes2 to diabetes_path\\nExit __enter__ of DatasetContextManager\\nEntering Run History Context Manager.\\nPreparing to call script [ diabetes_training.py ] with arguments: ['--regularization', '0.1']\\nAfter variable expansion, calling script [ diabetes_training.py ] with arguments: ['--regularization', '0.1']\\n\\nLoading Data...\\ndata_path: diabetes_path\\n['diabetes_path/folder/diabetes2.csv']\\ntype(all_files): <class 'list'>\\n<class 'str'>\\nnumber of records: 5000\\nTraining a logistic regression model with regularization rate of 0.1\\nAccuracy: 0.7906666666666666\\nAUC: 0.8535812401883831\\n\\n\\nThe experiment completed successfully. Finalizing run...\\nLogging experiment finalizing status in history service.\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.14887619018554688 seconds\\nEnter __exit__ of DatasetContextManager\\nExit __exit__ of DatasetContextManager\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.85\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'diabetes-training_1585314547_c0946781',\n",
       " 'target': 'local',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2020-03-27T13:09:09.090884Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': 'a3adee05-57f2-4bdc-903f-8941cc1e936b',\n",
       "  'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '8189bb0610764a3d5583f351f729bdc6cb32fe0e',\n",
       "  'mlflow.source.git.commit': '8189bb0610764a3d5583f351f729bdc6cb32fe0e',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [{'dataset': {'id': '2c81c692-c43c-4f03-9952-45124c0da47c'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes2', 'mechanism': 'Download', 'pathOnCompute': 'diabetes_path'}}],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization', '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'diabetes2': {'dataLocation': {'dataset': {'id': '2c81c692-c43c-4f03-9952-45124c0da47c'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Download',\n",
       "    'environmentVariableName': 'diabetes2',\n",
       "    'pathOnCompute': 'diabetes_path',\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment diabetes-training Environment',\n",
       "   'version': 'Autosave_2020-03-26T16:12:43Z_51b19fc4',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-dataprep[pandas]',\n",
       "        'azureml-defaults',\n",
       "        'scikit-learn==0.20.3',\n",
       "        'scipy==1.2.1',\n",
       "        'numpy==1.16.2',\n",
       "        'joblib==0.13.2']}],\n",
       "     'name': 'azureml_33c71153666f0570038d765d08eae59e'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585314547_c0946781/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=9HFKwOZkhcipEVm1lnP6MxttaBza8qX7ErchEpKkw2g%3D&st=2020-03-27T12%3A59%3A19Z&se=2020-03-27T21%3A09%3A19Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585314547_c0946781/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=hJJ%2FBPJaYXYGvefBnINWxS7IgJob9To8hCPAgJerORc%3D&st=2020-03-27T12%3A59%3A19Z&se=2020-03-27T21%3A09%3A19Z&sp=r',\n",
       "  'logs/azureml/8_azureml.log': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585314547_c0946781/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=snt3cdpi9nMBaK71vbwOMf9vP4lN02l2vZ58e5MkZSU%3D&st=2020-03-27T12%3A59%3A19Z&se=2020-03-27T21%3A09%3A19Z&sp=r'}}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's try again with Mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core import Datastore\n",
    "from azureml.core import Dataset\n",
    "\n",
    "#from azureml.train.sklearn import SKLearn\n",
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diabetes2': DatasetRegistration(id='2c81c692-c43c-4f03-9952-45124c0da47c', name='diabetes2', version=1, description='', tags={}), 'diabetes1': DatasetRegistration(id='ebc21ed2-3f94-494b-8072-2c71d2190200', name='diabetes1', version=1, description='', tags={}), 'datalakegold': DatasetRegistration(id='ad71d877-e111-4bd4-bf8a-8a602709dffd', name='datalakegold', version=1, description='', tags={}), 'datalake': DatasetRegistration(id='a2af81a9-8e27-429d-8845-489bd371e9ca', name='datalake', version=1, description='', tags={})}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.get_by_name(workspace=ws, name=\"diabetes2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/diabetes.csv', '/folder/diabetes2.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.to_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_training_from_file_dataset folder created\n"
     ]
    }
   ],
   "source": [
    "# create A folder named diabetes_training_from_file_dataset here locally\n",
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'diabetes_training_from_file_dataset'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the script parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting diabetes_training_from_file_dataset/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import glob\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data_path = run.input_datasets['diabetes2'] # Get the training data from the estimator input\n",
    "print(\"data_path: \" + str(data_path))\n",
    "all_files = glob.glob(data_path + \"/**/*.csv\", recursive=True)\n",
    "print(\"data_path + '/**/*.csv': \" + str(data_path + '/**/*.csv')) # diabetes_path/*.csv\n",
    "print([file for file in all_files])   # ['diabetes_path/diabetes.csv', 'diabetes_path/diabetes2.csv']\n",
    "print(\"type(all_files): \" + str(type(all_files)))\n",
    "print(type(all_files[0]))\n",
    "diabetes = pd.concat((pd.read_csv(f) for f in all_files))\n",
    "print(\"number of records: \" + str(len(diabetes)))\n",
    "print(\"writing outputs/diabetes.parquet:\")\n",
    "diabetes.to_parquet(\"outputs/diabetes.parquet\")\n",
    "print(\"writing logs/out.csv:\")\n",
    "diabetes.to_csv(\"logs/out.csv\", index=False)\n",
    "print(\"crap upload\")\n",
    "#diabetes.to_csv(\"diabetes_path/diabetes.csv\", index=False)\n",
    "#run.output_datasets['diabetes2']\n",
    "# read-only filesystem !!\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {\n",
       "   \"source\": [\n",
       "     \"('data_lake_gen2', 'platinum/**')\"\n",
       "   ],\n",
       "   \"definition\": [\n",
       "     \"GetDatastoreFiles\"\n",
       "   ],\n",
       "   \"registration\": {\n",
       "     \"id\": \"2c81c692-c43c-4f03-9952-45124c0da47c\",\n",
       "     \"name\": \"diabetes2\",\n",
       "     \"version\": 1,\n",
       "     \"workspace\": \"Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup')\"\n",
       "   }\n",
       " },\n",
       " 'name': 'diabetes2',\n",
       " 'mode': 'mount',\n",
       " 'path_on_compute': 'diabetes_path'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mode: download\n",
    "#ds.as_named_input('diabetes2').as_download(path_on_compute='diabetes_path').__dict__\n",
    "# mode: mount\n",
    "ds.as_named_input('diabetes2').as_mount(path_on_compute='diabetes_path').__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an estimator\n",
    "# estimator = SKLearn(source_directory=experiment_folder,\n",
    "#                     entry_script='diabetes_training.py',\n",
    "#                     script_params=script_params,\n",
    "#                     compute_target = 'local',\n",
    "#                     inputs=[ds.as_named_input('diabetes2').as_download(path_on_compute='diabetes_path')], # Pass the Dataset object as an input\n",
    "#                     pip_packages=['azureml-dataprep[pandas]'] # so we need the dataprep package\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an estimator\n",
    "# estimator = Estim(source_directory=experiment_folder,\n",
    "#                     entry_script='diabetes_training.py',\n",
    "#                     script_params=script_params,\n",
    "#                     compute_target = 'local',\n",
    "#                     inputs=[ds.as_named_input('diabetes2').as_mount(path_on_compute='diabetes_path')], # Pass the Dataset object as an input\n",
    "#                     pip_packages=['azureml-dataprep[pandas]', 'azureml-dataprep[fuse]', 'pyarrow', 'fastparquet'] # so we need the dataprep package\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "# Create an estimator\n",
    "#data_ref = blob_ds.path('gold/').as_download(path_on_compute='training_data')\n",
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                      entry_script='diabetes_training.py',\n",
    "                      script_params=script_params,\n",
    "                      compute_target = 'local',\n",
    "                      inputs=[ds.as_named_input('diabetes2').as_mount(path_on_compute='diabetes_path')],\n",
    "                      conda_packages=['scikit-learn', 'joblib'],\n",
    "                      pip_packages=['azureml-dataprep[pandas]', 'azureml-dataprep[fuse]', 'pyarrow', 'fastparquet']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment\n",
    "experiment_name = 'diabetes-training'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d2ebb67d1f49cb9443c0293d40087b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-training/runs/diabetes-training_1585387694_4b338672?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/machine_learning_workspace\", \"run_id\": \"diabetes-training_1585387694_4b338672\", \"run_properties\": {\"run_id\": \"diabetes-training_1585387694_4b338672\", \"created_utc\": \"2020-03-28T09:28:15.122949Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": \"1df106e5-ab5c-43de-8c4b-ee4ed3c1ad43\", \"azureml.git.repository_uri\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"mlflow.source.git.repoURL\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"f0ca49dc4562d42ef37c283476bd7532e5beaac6\", \"mlflow.source.git.commit\": \"f0ca49dc4562d42ef37c283476bd7532e5beaac6\", \"azureml.git.dirty\": \"True\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-03-28T09:29:00.485599Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585387694_4b338672/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=Neb%2BCBuTYLZycATE%2Bd2NSq%2FeVyccAJVDpoQvcfDGaBk%3D&st=2020-03-28T09%3A19%3A04Z&se=2020-03-28T17%3A29%3A04Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585387694_4b338672/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=88%2BKaie2hxX5rMykemQD9gy%2Bn1wULf52DZGL3y%2B41QI%3D&st=2020-03-28T09%3A19%3A04Z&se=2020-03-28T17%3A29%3A04Z&sp=r\", \"logs/azureml/8_azureml.log\": \"https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585387694_4b338672/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=f7Eg3houJqoUGEE9Q4hwRXabx2KT1v4DKWxZcBApFbo%3D&st=2020-03-28T09%3A19%3A04Z&se=2020-03-28T17%3A29%3A04Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/8_azureml.log\"], [\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"]], \"run_duration\": \"0:00:45\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Regularization Rate\", \"run_id\": \"diabetes-training_1585387694_4b338672\", \"categories\": [0], \"series\": [{\"data\": [0.1]}]}, {\"name\": \"Accuracy\", \"run_id\": \"diabetes-training_1585387694_4b338672\", \"categories\": [0], \"series\": [{\"data\": [0.7891111111111111]}]}, {\"name\": \"AUC\", \"run_id\": \"diabetes-training_1585387694_4b338672\", \"categories\": [0], \"series\": [{\"data\": [0.8568579836683917]}]}], \"run_logs\": \"Initialize DatasetContextManager.\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nEnter __enter__ of DatasetContextManager\\nSDK version: azureml-core==1.2.0.post1 azureml-dataprep==1.4.0\\nProcessing 'diabetes2'\\nProcessing dataset FileDataset\\n{\\n  \\\"source\\\": [\\n    \\\"('data_lake_gen2', 'platinum/**')\\\"\\n  ],\\n  \\\"definition\\\": [\\n    \\\"GetDatastoreFiles\\\"\\n  ],\\n  \\\"registration\\\": {\\n    \\\"id\\\": \\\"2c81c692-c43c-4f03-9952-45124c0da47c\\\",\\n    \\\"name\\\": \\\"diabetes2\\\",\\n    \\\"version\\\": 1,\\n    \\\"workspace\\\": \\\"Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup')\\\"\\n  }\\n}\\nMounting diabetes2 to diabetes_path\\nMounted diabetes2 to diabetes_path\\nExit __enter__ of DatasetContextManager\\nEntering Run History Context Manager.\\nPreparing to call script [ diabetes_training.py ] with arguments: ['--regularization', '0.1']\\nAfter variable expansion, calling script [ diabetes_training.py ] with arguments: ['--regularization', '0.1']\\n\\nLoading Data...\\ndata_path: diabetes_path\\ndata_path + '/**/*.csv': diabetes_path/**/*.csv\\n['diabetes_path/diabetes.csv', 'diabetes_path/folder/diabetes2.csv']\\ntype(all_files): <class 'list'>\\n<class 'str'>\\nnumber of records: 15000\\nwriting outputs/diabetes.parquet:\\nwriting logs/out.csv:\\ncrap upload\\nTraining a logistic regression model with regularization rate of 0.1\\nAccuracy: 0.7891111111111111\\nAUC: 0.8568579836683917\\n\\n\\nThe experiment completed successfully. Finalizing run...\\nLogging experiment finalizing status in history service.\\nStarting the daemon thread to refresh tokens in background for process with pid = 8\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\n2 items cleaning up...\\nCleanup took 0.1220850944519043 seconds\\nEnter __exit__ of DatasetContextManager\\nUnmounting /azureml-run/diabetes_path.\\nFinishing unmounting /azureml-run/diabetes_path.\\nExit __exit__ of DatasetContextManager\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.85\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'diabetes-training_1585387694_4b338672',\n",
       " 'target': 'local',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2020-03-28T09:28:18.865017Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '1df106e5-ab5c-43de-8c4b-ee4ed3c1ad43',\n",
       "  'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': 'f0ca49dc4562d42ef37c283476bd7532e5beaac6',\n",
       "  'mlflow.source.git.commit': 'f0ca49dc4562d42ef37c283476bd7532e5beaac6',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [{'dataset': {'id': '2c81c692-c43c-4f03-9952-45124c0da47c'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes2', 'mechanism': 'Mount', 'pathOnCompute': 'diabetes_path'}}],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization', '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {'diabetes2': {'dataLocation': {'dataset': {'id': '2c81c692-c43c-4f03-9952-45124c0da47c'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'diabetes2',\n",
       "    'pathOnCompute': 'diabetes_path',\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment diabetes-training Environment',\n",
       "   'version': 'Autosave_2020-03-27T15:14:33Z_fe5fae28',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'azureml-dataprep[fuse]',\n",
       "        'pyarrow',\n",
       "        'fastparquet']},\n",
       "      'scikit-learn',\n",
       "      'joblib'],\n",
       "     'name': 'azureml_406fd7468ea3a2b76844cc722ed429aa'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585387694_4b338672/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=Hi7bWX8gQimTsCzTu1H1y6LVJdlVBSog%2B%2BqW98O7ebU%3D&st=2020-03-28T09%3A18%3A57Z&se=2020-03-28T17%3A28%3A57Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585387694_4b338672/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=J1Wu%2FmOAnVDiI7OTVAt11%2BS1V3HF7G9SOMmtyWApVJ4%3D&st=2020-03-28T09%3A18%3A57Z&se=2020-03-28T17%3A28%3A57Z&sp=r',\n",
       "  'logs/azureml/8_azureml.log': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585387694_4b338672/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=h6dnmImCmbaHkcC0TKNnaER7d7VmZPJN1JUVbywk85g%3D&st=2020-03-28T09%3A18%3A57Z&se=2020-03-28T17%3A28%3A57Z&sp=r'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()\n",
    "#run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conda.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conda.yml\n",
    "name: py_env\n",
    "dependencies:\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - scikit-learn\n",
    "  - joblib\n",
    "  - pip:\n",
    "    - azureml-defaults\n",
    "    - azureml-dataprep[pandas]\n",
    "    - azureml-dataprep[fuse]\n",
    "    - pyarrow\n",
    "    - fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - No Python version provided, defaulting to \"3.6.2\"\n"
     ]
    }
   ],
   "source": [
    "# create environment from a file\n",
    "env = Environment.from_conda_specification(name='training_environment',\n",
    "                                           file_path='./conda.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: training_environment\n",
      "Name: AzureML-Tutorial\n",
      "Name: AzureML-Minimal\n",
      "Name: AzureML-Chainer-5.1.0-GPU\n",
      "Name: AzureML-PyTorch-1.2-CPU\n",
      "Name: AzureML-TensorFlow-1.12-CPU\n",
      "Name: AzureML-TensorFlow-1.13-CPU\n",
      "Name: AzureML-PyTorch-1.1-CPU\n",
      "Name: AzureML-TensorFlow-1.10-CPU\n",
      "Name: AzureML-PyTorch-1.0-GPU\n",
      "Name: AzureML-TensorFlow-1.12-GPU\n",
      "Name: AzureML-TensorFlow-1.13-GPU\n",
      "Name: AzureML-Chainer-5.1.0-CPU\n",
      "Name: AzureML-PyTorch-1.0-CPU\n",
      "Name: AzureML-Scikit-learn-0.20.3\n",
      "Name: AzureML-PyTorch-1.2-GPU\n",
      "Name: AzureML-PyTorch-1.1-GPU\n",
      "Name: AzureML-TensorFlow-1.10-GPU\n",
      "Name: AzureML-PyTorch-1.3-GPU\n",
      "Name: AzureML-TensorFlow-2.0-CPU\n",
      "Name: AzureML-PyTorch-1.3-CPU\n",
      "Name: AzureML-TensorFlow-2.0-GPU\n",
      "Name: AzureML-PySpark-MmlSpark-0.15\n",
      "Name: AzureML-AutoML\n",
      "Name: AzureML-PyTorch-1.4-GPU\n",
      "Name: AzureML-PyTorch-1.4-CPU\n",
      "Name: AzureML-VowpalWabbit-8.8.0\n",
      "Name: AzureML-Hyperdrive-ForecastDNN\n",
      "Name: AzureML-AutoML-GPU\n",
      "Name: AzureML-AutoML-DNN-GPU\n",
      "Name: AzureML-AutoML-DNN\n",
      "Name: AzureML-Designer-R\n",
      "Name: AzureML-Designer-Recommender\n",
      "Name: AzureML-Designer-Transform\n",
      "Name: AzureML-Designer\n",
      "Name: AzureML-Designer-IO\n",
      "Name: AzureML-Designer-NLP\n",
      "Name: AzureML-Dask-CPU\n",
      "Name: AzureML-Dask-GPU\n"
     ]
    }
   ],
   "source": [
    "env_names = Environment.list(workspace=ws)\n",
    "for env_name in env_names:\n",
    "    print('Name:',env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create environment from the DSVM itself\n",
    "# env = Environment.from_existing_conda_environment(name='training_environment',\n",
    "#                                                   conda_environment_name='azureml_py36_automl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"training_environment\",\n",
       "    \"version\": \"5\",\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"python\": {\n",
       "        \"userManagedDependencies\": false,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"dependencies\": [\n",
       "                \"numpy\",\n",
       "                \"pandas\",\n",
       "                \"scikit-learn\",\n",
       "                \"joblib\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults\",\n",
       "                        \"azureml-dataprep[pandas]\",\n",
       "                        \"azureml-dataprep[fuse]\",\n",
       "                        \"pyarrow\",\n",
       "                        \"fastparquet\"\n",
       "                    ]\n",
       "                },\n",
       "                \"python=3.6.2\"\n",
       "            ],\n",
       "            \"name\": \"azureml_5920f805fa659293f97bedc85ff62dbe\"\n",
       "        }\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"enabled\": false,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\",\n",
       "        \"baseDockerfile\": null,\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null,\n",
       "        \"arguments\": [],\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"username\": null,\n",
       "            \"password\": null\n",
       "        }\n",
       "    },\n",
       "    \"spark\": {\n",
       "        \"repositories\": [],\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true\n",
       "    },\n",
       "    \"databricks\": {\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"eggLibraries\": []\n",
       "    },\n",
       "    \"inferencingStackVersion\": null\n",
       "}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: training_environment\n",
      "Name: AzureML-Tutorial\n",
      "Name: AzureML-Minimal\n",
      "Name: AzureML-Chainer-5.1.0-GPU\n",
      "Name: AzureML-PyTorch-1.2-CPU\n",
      "Name: AzureML-TensorFlow-1.12-CPU\n",
      "Name: AzureML-TensorFlow-1.13-CPU\n",
      "Name: AzureML-PyTorch-1.1-CPU\n",
      "Name: AzureML-TensorFlow-1.10-CPU\n",
      "Name: AzureML-PyTorch-1.0-GPU\n",
      "Name: AzureML-TensorFlow-1.12-GPU\n",
      "Name: AzureML-TensorFlow-1.13-GPU\n",
      "Name: AzureML-Chainer-5.1.0-CPU\n",
      "Name: AzureML-PyTorch-1.0-CPU\n",
      "Name: AzureML-Scikit-learn-0.20.3\n",
      "Name: AzureML-PyTorch-1.2-GPU\n",
      "Name: AzureML-PyTorch-1.1-GPU\n",
      "Name: AzureML-TensorFlow-1.10-GPU\n",
      "Name: AzureML-PyTorch-1.3-GPU\n",
      "Name: AzureML-TensorFlow-2.0-CPU\n",
      "Name: AzureML-PyTorch-1.3-CPU\n",
      "Name: AzureML-TensorFlow-2.0-GPU\n",
      "Name: AzureML-PySpark-MmlSpark-0.15\n",
      "Name: AzureML-AutoML\n",
      "Name: AzureML-PyTorch-1.4-GPU\n",
      "Name: AzureML-PyTorch-1.4-CPU\n",
      "Name: AzureML-VowpalWabbit-8.8.0\n",
      "Name: AzureML-Hyperdrive-ForecastDNN\n",
      "Name: AzureML-AutoML-GPU\n",
      "Name: AzureML-AutoML-DNN-GPU\n",
      "Name: AzureML-AutoML-DNN\n",
      "Name: AzureML-Designer-R\n",
      "Name: AzureML-Designer-Recommender\n",
      "Name: AzureML-Designer-Transform\n",
      "Name: AzureML-Designer\n",
      "Name: AzureML-Designer-IO\n",
      "Name: AzureML-Designer-NLP\n",
      "Name: AzureML-Dask-CPU\n",
      "Name: AzureML-Dask-GPU\n"
     ]
    }
   ],
   "source": [
    "env_names = Environment.list(workspace=ws)\n",
    "for env_name in env_names:\n",
    "    print('Name:',env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve any from the list\n",
    "training_env = Environment.get(workspace=ws, name='training_environment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# later you put it in \"environment_definition=...\":\n",
    "\n",
    "# estimator = Estimator(source_directory='experiment_folder'\n",
    "#                       entry_script='training_script.py',\n",
    "#                       compute_target='local',\n",
    "#                       environment_definition=training_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create compute targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a name for the compute (unique within the workspace)\n",
    "compute_name = 'aml-cluster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define compute configuration\n",
    "# compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS12_V2',\n",
    "#                                                        min_nodes=0, max_nodes=4,\n",
    "#                                                        vm_priority='dedicated')\n",
    "compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS12_V2',\n",
    "                                                       min_nodes=0, max_nodes=4,\n",
    "                                                       vm_priority='lowpriority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "# Create the compute\n",
    "aml_cluster = ComputeTarget.create(ws, compute_name, compute_config)\n",
    "aml_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using attached compute (databricks or DSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using \"unmanaged\" compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I prefer to do this manually in the portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# later you put compute in Estimator, \"compute_target=...\":\n",
    "# estimator = Estimator(source_directory='experiment_folder',\n",
    "#                       entry_script='training_script.py',\n",
    "#                       environment_definition=training_env,\n",
    "#                       compute_target='alm-cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cluster = ComputeTarget(workspace=ws, name='aml-cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve your prepped compute environment from the list\n",
    "training_env = Environment.get(workspace=ws, name='training_environment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"training_environment\",\n",
       "    \"version\": \"5\",\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"python\": {\n",
       "        \"userManagedDependencies\": false,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"dependencies\": [\n",
       "                \"numpy\",\n",
       "                \"pandas\",\n",
       "                \"scikit-learn\",\n",
       "                \"joblib\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults\",\n",
       "                        \"azureml-dataprep[pandas]\",\n",
       "                        \"azureml-dataprep[fuse]\",\n",
       "                        \"pyarrow\",\n",
       "                        \"fastparquet\"\n",
       "                    ]\n",
       "                },\n",
       "                \"python=3.6.2\"\n",
       "            ],\n",
       "            \"name\": \"azureml_5920f805fa659293f97bedc85ff62dbe\"\n",
       "        }\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"enabled\": true,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\",\n",
       "        \"baseDockerfile\": null,\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null,\n",
       "        \"arguments\": [],\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"username\": null,\n",
       "            \"password\": null\n",
       "        }\n",
       "    },\n",
       "    \"spark\": {\n",
       "        \"repositories\": [],\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true\n",
       "    },\n",
       "    \"databricks\": {\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"eggLibraries\": []\n",
       "    },\n",
       "    \"inferencingStackVersion\": null\n",
       "}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator = Estimator(source_directory='experiment_folder',\n",
    "#                       entry_script='training_script.py',\n",
    "#                       environment_definition=training_env,\n",
    "#                       compute_target=training_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - This compute target type doesn't support non-Docker runs; overriding run configuration enable Docker.\n"
     ]
    }
   ],
   "source": [
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                      entry_script='diabetes_training.py',\n",
    "                      script_params=script_params,\n",
    "                      environment_definition=training_env,\n",
    "                      compute_target=training_cluster,\n",
    "                      inputs=[ds.as_named_input('diabetes2').as_mount(path_on_compute='diabetes_path')]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment\n",
    "experiment_name = 'diabetes-training'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1c5f991490413fa09101415195d103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Preparing\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-training/runs/diabetes-training_1585395706_505c3720?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/machine_learning_workspace\", \"run_id\": \"diabetes-training_1585395706_505c3720\", \"run_properties\": {\"run_id\": \"diabetes-training_1585395706_505c3720\", \"created_utc\": \"2020-03-28T11:41:47.686958Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"1df106e5-ab5c-43de-8c4b-ee4ed3c1ad43\", \"azureml.git.repository_uri\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"mlflow.source.git.repoURL\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"f0ca49dc4562d42ef37c283476bd7532e5beaac6\", \"mlflow.source.git.commit\": \"f0ca49dc4562d42ef37c283476bd7532e5beaac6\", \"azureml.git.dirty\": \"True\", \"AzureML.DerivedImageName\": \"azureml/azureml_477bf1d7ade609ed922d77bae8853b03\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Preparing\", \"log_files\": {\"azureml-logs/20_image_build_log.txt\": \"https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585395706_505c3720/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=lKYpXocOUyTtVmus%2Fljgw4tRXlMyysOX%2Bjiu8P%2BaCZ4%3D&st=2020-03-28T11%3A36%3A53Z&se=2020-03-28T19%3A46%3A53Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/20_image_build_log.txt\"]], \"run_duration\": \"0:05:05\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"2020/03/28 11:42:02 Downloading source code...\\r\\n2020/03/28 11:42:03 Finished downloading source code\\r\\n2020/03/28 11:42:04 Creating Docker network: acb_default_network, driver: 'bridge'\\n2020/03/28 11:42:04 Successfully set up Docker network: acb_default_network\\n2020/03/28 11:42:04 Setting up Docker configuration...\\n2020/03/28 11:42:05 Successfully set up Docker configuration\\n2020/03/28 11:42:05 Logging in to registry: machinelearn48d206af.azurecr.io\\n2020/03/28 11:42:06 Successfully logged into machinelearn48d206af.azurecr.io\\n2020/03/28 11:42:06 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\\n2020/03/28 11:42:06 Scanning for dependencies...\\r\\n2020/03/28 11:42:07 Successfully scanned dependencies\\n2020/03/28 11:42:07 Launching container with name: acb_step_0\\nSending build context to Docker daemon  60.93kB\\r\\r\\nStep 1/15 : FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\\nsha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05: Pulling from azureml/base\\nDigest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\\n ---> 93a72e6bd1ce\\nStep 2/15 : USER root\\n ---> Running in 67fd352e77bf\\nRemoving intermediate container 67fd352e77bf\\n ---> 42a7a5bd7a03\\nStep 3/15 : RUN mkdir -p $HOME/.cache\\r\\n ---> Running in c09ca383c488\\nRemoving intermediate container c09ca383c488\\n ---> c081821c09da\\nStep 4/15 : WORKDIR /\\n ---> Running in 445976b64e82\\nRemoving intermediate container 445976b64e82\\n ---> 593ac5f3768a\\nStep 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\\r\\n ---> 192c253b52e0\\nStep 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\\n ---> Running in d74fc305698f\\nRemoving intermediate container d74fc305698f\\n ---> 8c41b3f591e0\\nStep 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\\r\\n ---> 221925379d30\\nStep 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \\\"$HOME/.cache/pip\\\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \\\"$CONDA_ROOT_DIR/pkgs\\\" && find \\\"$CONDA_ROOT_DIR\\\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\\n ---> Running in 7895bbd3b56b\\nSolving environment: ...working... done\\r\\n\\u001b[91m\\n\\n==> WARNING: A newer version of conda exists. <==\\n  current version: 4.5.11\\n  latest version: 4.8.3\\n\\nPlease update conda by running\\n\\n    $ conda update -n base -c defaults conda\\n\\n\\n\\rnumpy-1.18.1         | 5 KB      |            |   0% \\u001b[0m\\u001b[91m\\rnumpy-1.18.1         | 5 KB      | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rlibstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \\u001b[0m\\u001b[91m\\rlibstdcxx-ng-9.1.0   | 4.0 MB    | #######8   |  78% \\u001b[0m\\u001b[91m\\rlibstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rcertifi-2019.11.28   | 157 KB    |            |   0% \\u001b[0m\\u001b[91m\\rcertifi-2019.11.28   | 157 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rmkl-service-2.3.0    | 208 KB    |            |   0% \\u001b[0m\\u001b[91m\\rmkl-service-2.3.0    | 208 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rlibgcc-ng-9.1.0      | 8.1 MB    |            |   0% \\u001b[0m\\u001b[91m\\rlibgcc-ng-9.1.0      | 8.1 MB    | #######5   |  76% \\u001b[0m\\u001b[91m\\rlibgcc-ng-9.1.0      | 8.1 MB    | #########7 |  97% \\u001b[0m\\u001b[91m\\rlibgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rscipy-1.4.1          | 18.9 MB   |            |   0% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 18.9 MB   | ####7      |  47% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 18.9 MB   | #######5   |  75% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 18.9 MB   | #########3 |  94% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 18.9 MB   | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rpython-dateutil-2.8. | 224 KB    |            |   0% \\u001b[0m\\u001b[91m\\rpython-dateutil-2.8. | 224 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rblas-1.0             | 6 KB      |            |   0% \\u001b[0m\\u001b[91m\\rblas-1.0             | 6 KB      | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rsetuptools-46.1.1    | 660 KB    |            |   0% \\u001b[0m\\u001b[91m\\rsetuptools-46.1.1    | 660 KB    | 1          |   2% \\u001b[0m\\u001b[91m\\rsetuptools-46.1.1    | 660 KB    | #########  |  90% \\u001b[0m\\u001b[91m\\rsetuptools-46.1.1    | 660 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rzlib-1.2.11          | 120 KB    |            |   0% \\u001b[0m\\u001b[91m\\rzlib-1.2.11          | 120 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rnumpy-base-1.18.1    | 5.2 MB    |            |   0% \\u001b[0m\\u001b[91m\\rnumpy-base-1.18.1    | 5.2 MB    | #######6   |  76% \\u001b[0m\\u001b[91m\\rnumpy-base-1.18.1    | 5.2 MB    | #########2 |  92% \\u001b[0m\\u001b[91m\\rnumpy-base-1.18.1    | 5.2 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rtk-8.6.8             | 3.1 MB    |            |   0% \\u001b[0m\\u001b[91m\\rtk-8.6.8             | 3.1 MB    | #######6   |  77% \\u001b[0m\\u001b[91m\\rtk-8.6.8             | 3.1 MB    | #########3 |  93% \\u001b[0m\\u001b[91m\\rtk-8.6.8             | 3.1 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rpip-20.0.2           | 1.9 MB    |            |   0% \\u001b[0m\\u001b[91m\\rpip-20.0.2           | 1.9 MB    | #######8   |  78% \\u001b[0m\\u001b[91m\\rpip-20.0.2           | 1.9 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rscikit-learn-0.22.1  | 7.1 MB    |            |   0% \\u001b[0m\\u001b[91m\\rscikit-learn-0.22.1  | 7.1 MB    | #######5   |  76% \\u001b[0m\\u001b[91m\\rscikit-learn-0.22.1  | 7.1 MB    | #########8 |  98% \\u001b[0m\\u001b[91m\\rscikit-learn-0.22.1  | 7.1 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rintel-openmp-2020.0  | 916 KB    |            |   0% \\u001b[0m\\u001b[91m\\rintel-openmp-2020.0  | 916 KB    | #########  |  91% \\u001b[0m\\u001b[91m\\rintel-openmp-2020.0  | 916 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rlibffi-3.2.1         | 43 KB     |            |   0% \\u001b[0m\\u001b[91m\\rlibffi-3.2.1         | 43 KB     | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rreadline-7.0         | 1.1 MB    |            |   0% \\u001b[0m\\u001b[91m\\rreadline-7.0         | 1.1 MB    | ########8  |  88% \\u001b[0m\\u001b[91m\\rreadline-7.0         | 1.1 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rpytz-2019.3          | 231 KB    |            |   0% \\u001b[0m\\u001b[91m\\rpytz-2019.3          | 231 KB    | #########  |  91% \\u001b[0m\\u001b[91m\\rpytz-2019.3          | 231 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rpandas-1.0.3         | 11.1 MB   |            |   0% \\u001b[0m\\u001b[91m\\rpandas-1.0.3         | 11.1 MB   | ######4    |  64% \\u001b[0m\\u001b[91m\\rpandas-1.0.3         | 11.1 MB   | ########3  |  83% \\u001b[0m\\u001b[91m\\rpandas-1.0.3         | 11.1 MB   | #########7 |  97% \\u001b[0m\\u001b[91m\\rpandas-1.0.3         | 11.1 MB   | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rmkl-2020.0           | 202.1 MB  |            |   0% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | 4          |   4% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | 9          |  10% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #3         |  14% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #9         |  19% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ##5        |  25% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ###        |  31% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ###6       |  36% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ####1      |  42% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ####7      |  47% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #####2     |  52% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #####6     |  57% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ######1    |  61% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ######5    |  66% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #######1   |  72% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #######6   |  77% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########   |  80% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########2  |  83% \\u001b[0m\\r\\n\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########4  |  84% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########5  |  86% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########6  |  86% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########7  |  87% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########7  |  88% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########7  |  88% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########8  |  88% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########8  |  88% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########8  |  89% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########8  |  89% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########8  |  89% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########9  |  89% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########9  |  89% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########9  |  89% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########9  |  89% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########9  |  89% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########9  |  90% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########9  |  90% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########9  |  90% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########9  |  90% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########9  |  90% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########  |  90% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########  |  90% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########  |  90% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########  |  90% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########  |  90% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########  |  91% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########  |  91% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########  |  91% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########  |  91% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########  |  91% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########  |  91% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########1 |  91% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########1 |  91% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########1 |  91% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########1 |  91% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########1 |  91% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########1 |  92% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########1 |  92% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########1 |  92% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########1 |  92% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########1 |  92% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########2 |  92% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########2 |  92% \\u001b[0m\\r\\n\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########2 |  92% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########2 |  92% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########2 |  93% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########2 |  93% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########2 |  93% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########2 |  93% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########2 |  93% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########3 |  93% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########3 |  93% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########3 |  93% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########3 |  93% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########3 |  93% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########3 |  94% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########3 |  94% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########3 |  94% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########3 |  94% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########3 |  94% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########4 |  94% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########4 |  94% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########4 |  94% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########4 |  94% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########4 |  94% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########4 |  95% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########4 |  95% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########4 |  95% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########4 |  95% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########4 |  95% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########4 |  95% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########5 |  95% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########5 |  95% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########5 |  95% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########5 |  95% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########5 |  95% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########5 |  96% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########5 |  96% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########5 |  96% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########5 |  96% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########5 |  96% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########6 |  96% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########6 |  96% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########6 |  96% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########6 |  96% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########6 |  96% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########6 |  97% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########6 |  97% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########6 |  97% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########6 |  97% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########6 |  97% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########7 |  97% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########7 |  97% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########7 |  97% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########7 |  97% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########7 |  97% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########7 |  98% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########7 |  98% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########7 |  98% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########7 |  98% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########7 |  98% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########8 |  98% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########8 |  98% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########8 |  98% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########8 |  98% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########8 |  98% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########8 |  99% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########8 |  99% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########8 |  99% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########8 |  99% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########8 |  99% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########8 |  99% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########9 |  99% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########9 |  99% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########9 |  99% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########9 |  99% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########9 |  99% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########9 |  99% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########9 | 100% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########9 | 100% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########9 | 100% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########9 | 100% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########9 | 100% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | #########9 | 100% \\u001b[0m\\u001b[91m\\rmkl-2020.0           | 202.1 MB  | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rlibedit-3.1          | 171 KB    |            |   0% \\u001b[0m\\u001b[91m\\rlibedit-3.1          | 171 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rncurses-6.0          | 920 KB    |            |   0% \\u001b[0m\\u001b[91m\\rncurses-6.0          | 920 KB    | #######9   |  79% \\u001b[0m\\u001b[91m\\rncurses-6.0          | 920 KB    | #########1 |  92% \\u001b[0m\\u001b[91m\\rncurses-6.0          | 920 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rwheel-0.34.2         | 49 KB     |            |   0% \\u001b[0m\\u001b[91m\\rwheel-0.34.2         | 49 KB     | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rsqlite-3.23.1        | 1.5 MB    |            |   0% \\u001b[0m\\u001b[91m\\rsqlite-3.23.1        | 1.5 MB    | ########2  |  83% \\u001b[0m\\u001b[91m\\rsqlite-3.23.1        | 1.5 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rmkl_random-1.1.0     | 369 KB    |            |   0% \\u001b[0m\\u001b[91m\\rmkl_random-1.1.0     | 369 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rmkl_fft-1.0.15       | 173 KB    |            |   0% \\u001b[0m\\u001b[91m\\rmkl_fft-1.0.15       | 173 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rlibgfortran-ng-7.3.0 | 1.3 MB    |            |   0% \\u001b[0m\\u001b[91m\\rlibgfortran-ng-7.3.0 | 1.3 MB    | ########4  |  84% \\u001b[0m\\u001b[91m\\rlibgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rxz-5.2.4             | 366 KB    |            |   0% \\u001b[0m\\u001b[91m\\rxz-5.2.4             | 366 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rjoblib-0.14.1        | 202 KB    |            |   0% \\u001b[0m\\u001b[91m\\rjoblib-0.14.1        | 202 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rsix-1.14.0           | 27 KB     |            |   0% \\u001b[0m\\u001b[91m\\rsix-1.14.0           | 27 KB     | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rca-certificates-2020 | 132 KB    |            |   0% \\u001b[0m\\u001b[91m\\rca-certificates-2020 | 132 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\r_libgcc_mutex-0.1    | 3 KB      |            |   0% \\u001b[0m\\u001b[91m\\r_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rpython-3.6.2         | 27.0 MB   |            |   0% \\u001b[0m\\u001b[91m\\rpython-3.6.2         | 27.0 MB   | ##4        |  25% \\u001b[0m\\u001b[91m\\rpython-3.6.2         | 27.0 MB   | ######2    |  63% \\u001b[0m\\u001b[91m\\rpython-3.6.2         | 27.0 MB   | #######9   |  79% \\u001b[0m\\u001b[91m\\rpython-3.6.2         | 27.0 MB   | #########1 |  91% \\u001b[0m\\u001b[91m\\rpython-3.6.2         | 27.0 MB   | #########9 | 100% \\u001b[0m\\u001b[91m\\rpython-3.6.2         | 27.0 MB   | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\ropenssl-1.0.2u       | 3.1 MB    |            |   0% \\u001b[0m\\u001b[91m\\ropenssl-1.0.2u       | 3.1 MB    | #######6   |  76% \\u001b[0m\\u001b[91m\\ropenssl-1.0.2u       | 3.1 MB    | #########9 |  99% \\u001b[0m\\u001b[91m\\ropenssl-1.0.2u       | 3.1 MB    | ########## | 100% \\u001b[0m\\nDownloading and Extracting Packages\\nPreparing transaction: ...working... done\\nVerifying transaction: ...working... done\\r\\nExecuting transaction: ...working... done\\r\\nCollecting azureml-defaults\\n  Downloading azureml_defaults-1.2.0-py3-none-any.whl (3.0 kB)\\nCollecting azureml-dataprep[pandas]\\n  Downloading azureml_dataprep-1.4.0-py3-none-any.whl (26.7 MB)\\nCollecting pyarrow\\n  Downloading pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1 MB)\\nCollecting fastparquet\\r\\n  Downloading fastparquet-0.3.3.tar.gz (152 kB)\\nCollecting azureml-model-management-sdk==1.0.1b6.post1\\n  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\\nCollecting werkzeug==0.16.1\\n  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\\nCollecting json-logging-py==0.2\\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\\nCollecting azureml-core~=1.2.0\\n  Downloading azureml_core-1.2.0.post1-py3-none-any.whl (1.2 MB)\\nCollecting configparser==3.7.4\\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\\nCollecting flask==1.0.3\\n  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\\nCollecting gunicorn==19.9.0\\n  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\\nCollecting applicationinsights>=0.11.7\\n  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\\nCollecting dotnetcore2>=2.1.13\\n  Downloading dotnetcore2-2.1.13-py3-none-manylinux1_x86_64.whl (29.3 MB)\\nCollecting azure-identity>=1.2.0\\r\\n  Downloading azure_identity-1.3.0-py2.py3-none-any.whl (61 kB)\\nCollecting cloudpickle>=1.1.0\\n  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\\nCollecting azureml-dataprep-native<15.0.0,>=14.1.0\\n  Downloading azureml_dataprep_native-14.1.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\\nRequirement already satisfied: numpy>=1.14.0; extra == \\\"pandas\\\" in /azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages (from azureml-dataprep[pandas]->-r /azureml-environment-setup/condaenv.ncqn4erd.requirements.txt (line 2)) (1.18.1)\\nRequirement already satisfied: pandas>=0.23.4; extra == \\\"pandas\\\" in /azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages (from azureml-dataprep[pandas]->-r /azureml-environment-setup/condaenv.ncqn4erd.requirements.txt (line 2)) (1.0.3)\\nRequirement already satisfied: six>=1.0.0 in /azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages (from pyarrow->-r /azureml-environment-setup/condaenv.ncqn4erd.requirements.txt (line 4)) (1.14.0)\\nCollecting numba>=0.28\\r\\n  Downloading numba-0.48.0-cp36-cp36m-manylinux1_x86_64.whl (2.5 MB)\\nCollecting thrift>=0.11.0\\n  Downloading thrift-0.13.0.tar.gz (59 kB)\\nCollecting liac-arff>=2.1.1\\n  Downloading liac-arff-2.4.0.tar.gz (15 kB)\\nCollecting dill>=0.2.7.1\\n  Downloading dill-0.3.1.1.tar.gz (151 kB)\\nRequirement already satisfied: python-dateutil>=2.5.3 in /azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults->-r /azureml-environment-setup/condaenv.ncqn4erd.requirements.txt (line 1)) (2.8.1)\\nRequirement already satisfied: pytz>=2017.2 in /azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults->-r /azureml-environment-setup/condaenv.ncqn4erd.requirements.txt (line 1)) (2019.3)\\nCollecting adal>=0.4.5\\n  Downloading adal-1.2.2-py2.py3-none-any.whl (53 kB)\\nCollecting requests>=2.17.3\\n  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\\nCollecting backports.tempfile\\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\\nCollecting azure-common>=1.1.12\\n  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\\nCollecting azure-mgmt-keyvault>=0.40.0\\n  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\\nCollecting contextlib2\\n  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\\nCollecting ruamel.yaml<=0.15.89,>=0.15.35\\n  Downloading ruamel.yaml-0.15.89-cp36-cp36m-manylinux1_x86_64.whl (651 kB)\\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\\r\\n  Downloading cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3 MB)\\nCollecting msrestazure>=0.4.33\\n  Downloading msrestazure-0.6.3-py2.py3-none-any.whl (40 kB)\\nCollecting azure-graphrbac>=0.40.0\\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\\nCollecting pathspec\\n  Downloading pathspec-0.7.0-py2.py3-none-any.whl (25 kB)\\nCollecting docker\\n  Downloading docker-4.2.0-py2.py3-none-any.whl (143 kB)\\nCollecting jmespath\\n  Downloading jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\\nCollecting urllib3>=1.23\\n  Downloading urllib3-1.25.8-py2.py3-none-any.whl (125 kB)\\nCollecting SecretStorage\\n  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\\nCollecting azure-mgmt-authorization>=0.40.0\\n  Downloading azure_mgmt_authorization-0.60.0-py2.py3-none-any.whl (82 kB)\\nCollecting pyopenssl\\n  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\\nCollecting ndg-httpsclient\\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\\nCollecting azure-mgmt-storage>=1.5.0\\n  Downloading azure_mgmt_storage-8.0.0-py2.py3-none-any.whl (524 kB)\\nCollecting azure-mgmt-containerregistry>=2.0.0\\n  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\\nCollecting PyJWT\\n  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\\nCollecting jsonpickle\\n  Downloading jsonpickle-1.3-py2.py3-none-any.whl (32 kB)\\nCollecting msrest>=0.5.1\\n  Downloading msrest-0.6.11-py2.py3-none-any.whl (83 kB)\\nCollecting azure-mgmt-resource>=1.2.1\\n  Downloading azure_mgmt_resource-8.0.1-py2.py3-none-any.whl (758 kB)\\nCollecting Jinja2>=2.10\\n  Downloading Jinja2-2.11.1-py2.py3-none-any.whl (126 kB)\\nCollecting itsdangerous>=0.24\\n  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\\nCollecting click>=5.1\\n  Downloading click-7.1.1-py2.py3-none-any.whl (82 kB)\\nCollecting distro>=1.2.0\\n  Downloading distro-1.4.0-py2.py3-none-any.whl (17 kB)\\nCollecting msal-extensions~=0.1.3\\n  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\\nCollecting azure-core<2.0.0,>=1.0.0\\n  Downloading azure_core-1.3.0-py2.py3-none-any.whl (106 kB)\\nCollecting msal<2.0.0,>=1.0.0\\n  Downloading msal-1.1.0-py2.py3-none-any.whl (44 kB)\\nRequirement already satisfied: setuptools in /azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages (from numba>=0.28->fastparquet->-r /azureml-environment-setup/condaenv.ncqn4erd.requirements.txt (line 5)) (46.1.1.post20200323)\\nCollecting llvmlite<0.32.0,>=0.31.0dev0\\n  Downloading llvmlite-0.31.0-cp36-cp36m-manylinux1_x86_64.whl (20.2 MB)\\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages (from requests>=2.17.3->azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults->-r /azureml-environment-setup/condaenv.ncqn4erd.requirements.txt (line 1)) (2019.11.28)\\r\\nCollecting idna<3,>=2.5\\n  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\\nCollecting chardet<4,>=3.0.2\\n  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\\nCollecting backports.weakref\\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\\nCollecting cffi!=1.11.3,>=1.8\\n  Downloading cffi-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (399 kB)\\nCollecting websocket-client>=0.32.0\\n  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\\nCollecting jeepney>=0.4.2\\n  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\\nCollecting pyasn1>=0.1.1\\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\\nCollecting requests-oauthlib>=0.5.0\\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\\nCollecting isodate>=0.6.0\\n  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\\nCollecting MarkupSafe>=0.23\\n  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\\nCollecting portalocker~=1.0\\n  Downloading portalocker-1.6.0-py2.py3-none-any.whl (14 kB)\\nCollecting pycparser\\n  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\\nCollecting oauthlib>=3.0.0\\n  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\\nBuilding wheels for collected packages: fastparquet, json-logging-py, thrift, liac-arff, dill\\n  Building wheel for fastparquet (setup.py): started\\n  Building wheel for fastparquet (setup.py): finished with status 'done'\\r\\n  Created wheel for fastparquet: filename=fastparquet-0.3.3-cp36-cp36m-linux_x86_64.whl size=258164 sha256=b13957e9098b93283258a5914d615bb6407669601d6fc03cb090c04687b35286\\n  Stored in directory: /root/.cache/pip/wheels/17/0b/fe/81b4ce36e4b0abb7220e29ea450ac345efb6219b9ac888e5c9\\n  Building wheel for json-logging-py (setup.py): started\\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3923 sha256=bd5b52f961fb46344046c61ebea7797655baadf41f85adb2fb71480e72684df2\\n  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\\n  Building wheel for thrift (setup.py): started\\n  Building wheel for thrift (setup.py): finished with status 'done'\\r\\n  Created wheel for thrift: filename=thrift-0.13.0-cp36-cp36m-linux_x86_64.whl size=371585 sha256=f39204f4fff1f4324d3ca43168474497506ae94d71b734cbe02bf2be1d23b607\\n  Stored in directory: /root/.cache/pip/wheels/e0/38/fc/472fe18756b177b42096961f8bd3ff2dc5c5620ac399fce52d\\n  Building wheel for liac-arff (setup.py): started\\n  Building wheel for liac-arff (setup.py): finished with status 'done'\\n  Created wheel for liac-arff: filename=liac_arff-2.4.0-py3-none-any.whl size=13333 sha256=6fad5e922ee31a47f2bca3df182953f444a6fc336f062fa6983508b758b8a91d\\n  Stored in directory: /root/.cache/pip/wheels/ba/2a/e1/6f7be2e2ea150e2486bff64fd6f0670f4f35f4c8f31c819fb8\\n  Building wheel for dill (setup.py): started\\n  Building wheel for dill (setup.py): finished with status 'done'\\n  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=1c8a55c5a2270f5c14908bb230391aaaf0eb8e6351bda297b3f11bedd5190ad6\\n  Stored in directory: /root/.cache/pip/wheels/09/84/74/d2b4feb9ac9488bc83c475cb2cbe8e8b7d9cea8320d32f3787\\nSuccessfully built fastparquet json-logging-py thrift liac-arff dill\\n\\u001b[91mERROR: azureml-defaults 1.2.0 has requirement azureml-dataprep[fuse]<1.4.0a,>=1.3.5, but you'll have azureml-dataprep 1.4.0 which is incompatible.\\n\\u001b[0mInstalling collected packages: distro, dotnetcore2, pycparser, cffi, cryptography, portalocker, idna, urllib3, chardet, requests, PyJWT, msal, msal-extensions, azure-core, azure-identity, cloudpickle, azureml-dataprep-native, pyarrow, azureml-dataprep, liac-arff, dill, adal, azureml-model-management-sdk, werkzeug, json-logging-py, backports.weakref, backports.tempfile, azure-common, oauthlib, requests-oauthlib, isodate, msrest, msrestazure, azure-mgmt-keyvault, contextlib2, ruamel.yaml, azure-graphrbac, pathspec, websocket-client, docker, jmespath, jeepney, SecretStorage, azure-mgmt-authorization, pyopenssl, pyasn1, ndg-httpsclient, azure-mgmt-storage, azure-mgmt-containerregistry, jsonpickle, azure-mgmt-resource, azureml-core, configparser, MarkupSafe, Jinja2, itsdangerous, click, flask, gunicorn, applicationinsights, azureml-defaults, llvmlite, numba, thrift, fastparquet\\nSuccessfully installed Jinja2-2.11.1 MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.1.2 adal-1.2.2 applicationinsights-0.11.9 azure-common-1.1.25 azure-core-1.3.0 azure-graphrbac-0.61.1 azure-identity-1.3.0 azure-mgmt-authorization-0.60.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-8.0.1 azure-mgmt-storage-8.0.0 azureml-core-1.2.0.post1 azureml-dataprep-1.4.0 azureml-dataprep-native-14.1.0 azureml-defaults-1.2.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.0 chardet-3.0.4 click-7.1.1 cloudpickle-1.3.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-2.8 dill-0.3.1.1 distro-1.4.0 docker-4.2.0 dotnetcore2-2.1.13 fastparquet-0.3.3 flask-1.0.3 gunicorn-19.9.0 idna-2.9 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.4.3 jmespath-0.9.5 json-logging-py-0.2 jsonpickle-1.3 liac-arff-2.4.0 llvmlite-0.31.0 msal-1.1.0 msal-extensions-0.1.3 msrest-0.6.11 msrestazure-0.6.3 ndg-httpsclient-0.5.1 numba-0.48.0 oauthlib-3.1.0 pathspec-0.7.0 portalocker-1.6.0 pyarrow-0.16.0 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 requests-2.23.0 requests-oauthlib-1.3.0 ruamel.yaml-0.15.89 thrift-0.13.0 urllib3-1.25.8 websocket-client-0.57.0 werkzeug-0.16.1\\r\\n\\u001b[91m\\n\\u001b[0m#\\n# To activate this environment, use:\\n# > source activate /azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe\\n#\\n# To deactivate an active environment, use:\\n# > source deactivate\\n#\\n\\n\\r\\nRemoving intermediate container 7895bbd3b56b\\n ---> fe00c88a325d\\nStep 9/15 : ENV PATH /azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/bin:$PATH\\r\\n ---> Running in 6e4ecfeb6bd6\\nRemoving intermediate container 6e4ecfeb6bd6\\n ---> 573ed0b6c5f4\\nStep 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe\\n ---> Running in 06c51cd2e3a0\\nRemoving intermediate container 06c51cd2e3a0\\n ---> 6f5a4b1542fc\\nStep 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib:$LD_LIBRARY_PATH\\r\\n ---> Running in dbdd4f587811\\nRemoving intermediate container dbdd4f587811\\n ---> 0dac40ff8e36\\nStep 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\\n ---> 2cc108a7b989\\nStep 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\\r\\n ---> Running in add0f83df254\\nRemoving intermediate container add0f83df254\\r\\n ---> 6cc9f34d601e\\nStep 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\\n ---> Running in ed6dee4b253e\\nRemoving intermediate container ed6dee4b253e\\n ---> e39891f1c1b6\\nStep 15/15 : CMD [\\\"bash\\\"]\\n ---> Running in ea3859f54277\\nRemoving intermediate container ea3859f54277\\n ---> 025ba1817534\\r\\nSuccessfully built 025ba1817534\\nSuccessfully tagged machinelearn48d206af.azurecr.io/azureml/azureml_477bf1d7ade609ed922d77bae8853b03:latest\\n2020/03/28 11:44:39 Successfully executed container: acb_step_0\\n2020/03/28 11:44:39 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\\n2020/03/28 11:44:39 Pushing image: machinelearn48d206af.azurecr.io/azureml/azureml_477bf1d7ade609ed922d77bae8853b03:latest, attempt 1\\nThe push refers to repository [machinelearn48d206af.azurecr.io/azureml/azureml_477bf1d7ade609ed922d77bae8853b03]\\n98286d0d00e4: Preparing\\nf2331ff0fd69: Preparing\\nc44696547a45: Preparing\\ne3d3942e35b4: Preparing\\n701242c41cdd: Preparing\\na7fa84aa7fc1: Preparing\\ne1171d4d60ca: Preparing\\n6ef1a8ae63b7: Preparing\\n85389f9ead9e: Preparing\\nf2608f66a0e3: Preparing\\n0e259b09e5f4: Preparing\\n340dc32eb998: Preparing\\ndf18b66efaa6: Preparing\\nccdb13a20bf2: Preparing\\n9513cdf4e497: Preparing\\n7f083f9454c0: Preparing\\n29f36b5893dc: Preparing\\nf2608f66a0e3: Waiting\\n0e259b09e5f4: Waiting\\n340dc32eb998: Waiting\\ndf18b66efaa6: Waiting\\nccdb13a20bf2: Waiting\\n9513cdf4e497: Waiting\\n7f083f9454c0: Waiting\\n29f36b5893dc: Waiting\\na7fa84aa7fc1: Waiting\\ne1171d4d60ca: Waiting\\n6ef1a8ae63b7: Waiting\\n85389f9ead9e: Waiting\\nc44696547a45: Pushed\\r\\n701242c41cdd: Pushed\\ne3d3942e35b4: Pushed\\n98286d0d00e4: Pushed\\na7fa84aa7fc1: Pushed\\r\\n6ef1a8ae63b7: Pushed\\ne1171d4d60ca: Pushed\\n\\r\\n340dc32eb998: Pushed\\r\\n85389f9ead9e: Pushed\\r\\nccdb13a20bf2: Pushed\\r\\n0e259b09e5f4: Pushed\\r\\n9513cdf4e497: Pushed\\r\\n7f083f9454c0: Pushed\\r\\nf2608f66a0e3: Pushed\\r\\n29f36b5893dc: Pushed\\r\\ndf18b66efaa6: Pushed\\r\\nf2331ff0fd69: Pushed\\r\\nlatest: digest: sha256:ad829f96c00c73223ddbee7d7c962fc5e4b87c316dbae235f94d962325e936a1 size: 3883\\r\\n2020/03/28 11:46:42 Successfully pushed image: machinelearn48d206af.azurecr.io/azureml/azureml_477bf1d7ade609ed922d77bae8853b03:latest\\n2020/03/28 11:46:42 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 152.470339)\\n2020/03/28 11:46:42 Populating digests for step ID: acb_step_0...\\n2020/03/28 11:46:43 Successfully populated digests for step ID: acb_step_0\\n2020/03/28 11:46:43 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 122.800423)\\n2020/03/28 11:46:43 The following dependencies were found:\\n2020/03/28 11:46:43 \\n- image:\\n    registry: machinelearn48d206af.azurecr.io\\n    repository: azureml/azureml_477bf1d7ade609ed922d77bae8853b03\\n    tag: latest\\n    digest: sha256:ad829f96c00c73223ddbee7d7c962fc5e4b87c316dbae235f94d962325e936a1\\n  runtime-dependency:\\n    registry: mcr.microsoft.com\\n    repository: azureml/base\\n    tag: intelmpi2018.3-ubuntu16.04\\n    digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\\n  git: {}\\n\\n\\r\\nRun ID: cb3 was successful after 4m42s\\r\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.85\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'diabetes-training_1585395706_505c3720',\n",
       " 'target': 'aml-cluster',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2020-03-28T11:49:38.057787Z',\n",
       " 'error': {'error': {'code': 'ServiceError',\n",
       "   'message': 'Dataset initialization failed: Missing required package \"azureml-dataprep[fuse]\", which can be installed by running: \"/azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/bin/python\" -m pip install azureml-dataprep[fuse] --upgrade.',\n",
       "   'details': [],\n",
       "   'debugInfo': {'type': 'ImportError',\n",
       "    'message': 'Missing required package \"azureml-dataprep[fuse]\", which can be installed by running: \"/azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/bin/python\" -m pip install azureml-dataprep[fuse] --upgrade.',\n",
       "    'stackTrace': '  File \"/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace/azureml/diabetes-training_1585395706_505c3720/mounts/workspaceblobstore/azureml/diabetes-training_1585395706_505c3720/azureml-setup/context_manager_injector.py\", line 44, in __enter__\\n    self.context_manager.__enter__()\\n  File \"/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace/azureml/diabetes-training_1585395706_505c3720/mounts/workspaceblobstore/azureml/diabetes-training_1585395706_505c3720/azureml-setup/context_managers.py\", line 226, in __enter__\\n    self.datasets.__enter__()\\n  File \"/azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages/azureml/data/context_managers.py\", line 133, in __enter__\\n    context_manager = dataset.mount(mount_point=target_path)\\n  File \"/azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages/azureml/data/_loggerfactory.py\", line 106, in wrapper\\n    return func(*args, **kwargs)\\n  File \"/azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages/azureml/data/file_dataset.py\", line 177, in mount\\n    mount = dataprep_fuse().mount\\n  File \"/azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages/azureml/data/_dataprep_helper.py\", line 49, in dataprep_fuse\\n    raise ImportError(get_dataprep_missing_message(extra=\\'[fuse]\\'))\\n'}},\n",
       "  'time': '0001-01-01T00:00:00.000Z'},\n",
       " 'warnings': [{'message': 'ERROR:: Dataset  failed. . Exception Details:Traceback (most recent call last):\\n  File \"/azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages/azureml/data/_dataprep_helper.py\", line 45, in dataprep_fuse\\n    import azureml.dataprep.fuse.dprepfuse as _dprep_fuse\\n  File \"/azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages/azureml/dataprep/fuse/dprepfuse.py\", line 3, in <module>\\n    from ._filecache import FileCache\\n  File \"/azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages/azureml/dataprep/fuse/_filecache.py\", line 10, in <module>\\n    from fuse import FuseOSError\\nModuleNotFoundError: No module named \\'fuse\\'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \"/mnt/batch/tasks/shared/LS_root/jobs/machine_learning_workspace/azureml/diabetes-training_1585395706_505c3720/mounts/workspaceblobstore/azureml/diabetes-training_1585395706_505c3720/azureml-setup/context_managers.py\", line 226, in __enter__\\n    self.datasets.__enter__()\\n  File \"/azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages/azureml/data/context_managers.py\", line 133, in __enter__\\n    context_manager = dataset.mount(mount_point=target_path)\\n  File \"/azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages/azureml/data/_loggerfactory.py\", line 106, in wrapper\\n    return func(*args, **kwargs)\\n  File \"/azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages/azureml/data/file_dataset.py\", line 177, in mount\\n    mount = dataprep_fuse().mount\\n  File \"/azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/lib/python3.6/site-packages/azureml/data/_dataprep_helper.py\", line 49, in dataprep_fuse\\n    raise ImportError(get_dataprep_missing_message(extra=\\'[fuse]\\'))\\nImportError: Missing required package \"azureml-dataprep[fuse]\", which can be installed by running: \"/azureml-envs/azureml_5920f805fa659293f97bedc85ff62dbe/bin/python\" -m pip install azureml-dataprep[fuse] --upgrade.\\n'}],\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '1df106e5-ab5c-43de-8c4b-ee4ed3c1ad43',\n",
       "  'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': 'f0ca49dc4562d42ef37c283476bd7532e5beaac6',\n",
       "  'mlflow.source.git.commit': 'f0ca49dc4562d42ef37c283476bd7532e5beaac6',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'AzureML.DerivedImageName': 'azureml/azureml_477bf1d7ade609ed922d77bae8853b03',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '2c81c692-c43c-4f03-9952-45124c0da47c'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes2', 'mechanism': 'Mount', 'pathOnCompute': 'diabetes_path'}}],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization', '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'aml-cluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {'diabetes2': {'dataLocation': {'dataset': {'id': '2c81c692-c43c-4f03-9952-45124c0da47c'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'diabetes2',\n",
       "    'pathOnCompute': 'diabetes_path',\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'training_environment',\n",
       "   'version': 'Autosave_2020-03-28T11:41:46Z_69dd02bf',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'dependencies': ['numpy',\n",
       "      'pandas',\n",
       "      'scikit-learn',\n",
       "      'joblib',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'azureml-dataprep[pandas]',\n",
       "        'azureml-dataprep[fuse]',\n",
       "        'pyarrow',\n",
       "        'fastparquet']},\n",
       "      'python=3.6.2'],\n",
       "     'name': 'azureml_5920f805fa659293f97bedc85ff62dbe'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585395706_505c3720/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=rQWrNHbfZ%2FuG8bpvY0DVNVxwPfUihgVKvhGUjzcgEDA%3D&st=2020-03-28T11%3A41%3A21Z&se=2020-03-28T19%3A51%3A21Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_7db09eee0a4cee101a57b171575befbf8dedac5675d9291b8b35772e9b4ada74_p.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585395706_505c3720/azureml-logs/55_azureml-execution-tvmps_7db09eee0a4cee101a57b171575befbf8dedac5675d9291b8b35772e9b4ada74_p.txt?sv=2019-02-02&sr=b&sig=9BsgVd0QCP27Sj%2FERHxgL8NTOe1JBve5sWUTmQqO%2Fvw%3D&st=2020-03-28T11%3A41%3A21Z&se=2020-03-28T19%3A51%3A21Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_7db09eee0a4cee101a57b171575befbf8dedac5675d9291b8b35772e9b4ada74_p.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585395706_505c3720/azureml-logs/65_job_prep-tvmps_7db09eee0a4cee101a57b171575befbf8dedac5675d9291b8b35772e9b4ada74_p.txt?sv=2019-02-02&sr=b&sig=nUUXj9r2FvriOeLEZ4nSP1i6O4H%2Bsq1T8%2BpIdYZio8k%3D&st=2020-03-28T11%3A41%3A21Z&se=2020-03-28T19%3A51%3A21Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585395706_505c3720/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=6r%2Bfc4z%2FyBS76SKLY7ZatVeeNxpBU8GW6CprZ79LMY8%3D&st=2020-03-28T11%3A41%3A21Z&se=2020-03-28T19%3A51%3A21Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_7db09eee0a4cee101a57b171575befbf8dedac5675d9291b8b35772e9b4ada74_p.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585395706_505c3720/azureml-logs/75_job_post-tvmps_7db09eee0a4cee101a57b171575befbf8dedac5675d9291b8b35772e9b4ada74_p.txt?sv=2019-02-02&sr=b&sig=zZYfumoOW%2BNpFFkDYzusX7S9%2FjK3tnm5mznHAIt2Jvw%3D&st=2020-03-28T11%3A41%3A21Z&se=2020-03-28T19%3A51%3A21Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585395706_505c3720/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=0o1Do5fnUHvBzjmVUbxwbQvb2RvvSuw6%2F4tRlLGFhmM%3D&st=2020-03-28T11%3A41%3A21Z&se=2020-03-28T19%3A51%3A21Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585395706_505c3720/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=Tem2FolcBL9XtQg7sf4udpLGs9XT%2BiqL3N3ema2i6S4%3D&st=2020-03-28T11%3A41%3A21Z&se=2020-03-28T19%3A51%3A21Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585395706_505c3720/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=8%2FjLBYmHjUvzs2EcRE9g5GIlDfe%2B0O5kQB5SpICVGwM%3D&st=2020-03-28T11%3A41%3A21Z&se=2020-03-28T19%3A51%3A21Z&sp=r'}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()\n",
    "#run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nbviewer.jupyter.org/github/MicrosoftDocs/mslearn-aml-labs/blob/master/04-Working_with_Compute.ipynb  \n",
    "https://nbviewer.jupyter.org/github/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training/using-environments/using-environments.ipynb  \n",
    "https://docs.microsoft.com/en-gb/learn/modules/use-compute-contexts-in-aml/2-environments  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception cannot import name '_DistributedTraining'.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Datastore\n",
    "from azureml.core import Dataset\n",
    "from azureml.core import Environment\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.conda_dependencies import CondaDependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_training_from_file_dataset folder created\n"
     ]
    }
   ],
   "source": [
    "# create A folder named diabetes_training_from_file_dataset here locally\n",
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'diabetes_training_from_file_dataset'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting diabetes_training_from_file_dataset/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "print(\"start custom script...\")\n",
    "import argparse\n",
    "print(\"argparse loaded\")\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run\n",
    "print(\"azureml.core loaded\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import glob\n",
    "print(\"all imports loaded\")\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data_path = run.input_datasets['diabetes2'] # Get the training data from the estimator input\n",
    "print(\"data_path: \" + str(data_path))\n",
    "all_files = glob.glob(data_path + \"/**/*.csv\", recursive=True)\n",
    "print(\"data_path + '/**/*.csv': \" + str(data_path + '/**/*.csv')) # diabetes_path/*.csv\n",
    "print([file for file in all_files])   # ['diabetes_path/diabetes.csv', 'diabetes_path/diabetes2.csv']\n",
    "print(\"type(all_files): \" + str(type(all_files)))\n",
    "print(type(all_files[0]))\n",
    "diabetes = pd.concat((pd.read_csv(f) for f in all_files))\n",
    "print(\"number of records: \" + str(len(diabetes)))\n",
    "print(\"writing outputs/diabetes.parquet:\")\n",
    "diabetes.to_parquet(\"outputs/diabetes.parquet\")\n",
    "print(\"writing logs/out.csv:\")\n",
    "diabetes.to_csv(\"logs/out.csv\", index=False)\n",
    "print(\"crap upload\")\n",
    "#diabetes.to_csv(\"diabetes_path/diabetes.csv\", index=False)\n",
    "#run.output_datasets['diabetes2']\n",
    "# read-only filesystem !!\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conda.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conda.yml\n",
    "name: py_env\n",
    "dependencies:\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - scikit-learn\n",
    "  - joblib\n",
    "  - pip:\n",
    "    - azureml-defaults\n",
    "    - azureml-dataprep[pandas]\n",
    "    - azureml-dataprep[fuse]\n",
    "    - pyarrow\n",
    "    - fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_environment defined.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "env = Environment(\"training_environment\")\n",
    "env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "env.docker.enabled = True # Use a docker container\n",
    "\n",
    "# Create a set of package dependencies (conda or pip as required)\n",
    "env_packages = CondaDependencies.create(conda_packages=['scikit-learn', 'joblib'],\n",
    "                                        pip_packages=['azureml-defaults',\n",
    "                                                      'azureml-dataprep[pandas]',\n",
    "                                                      'azureml-dataprep[fuse]',\n",
    "                                                      'pyarrow',\n",
    "                                                      'fastparquet'])\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "env.python.conda_dependencies = env_packages\n",
    "\n",
    "print(env.name, 'defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create environment from a file\n",
    "#env = Environment.from_conda_specification(name='training_environment', file_path='./conda.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"training_environment\",\n",
       "    \"version\": \"13\",\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"python\": {\n",
       "        \"userManagedDependencies\": false,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults==1.0.85.*\",\n",
       "                        \"azureml-dataprep[fuse]\",\n",
       "                        \"pyarrow\",\n",
       "                        \"fastparquet\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn\",\n",
       "                \"joblib\"\n",
       "            ],\n",
       "            \"name\": \"azureml_cec3c0c2eda4dee5bf29ecf1761c4111\"\n",
       "        }\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"enabled\": true,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\",\n",
       "        \"baseDockerfile\": null,\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null,\n",
       "        \"arguments\": [],\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"username\": null,\n",
       "            \"password\": null\n",
       "        }\n",
       "    },\n",
       "    \"spark\": {\n",
       "        \"repositories\": [],\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true\n",
       "    },\n",
       "    \"databricks\": {\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"eggLibraries\": []\n",
       "    },\n",
       "    \"inferencingStackVersion\": null\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed16078fd792479f88af1b24c5dd2b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Preparing\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-training/runs/diabetes-training_1585418882_2a8f68d2?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/machine_learning_workspace\", \"run_id\": \"diabetes-training_1585418882_2a8f68d2\", \"run_properties\": {\"run_id\": \"diabetes-training_1585418882_2a8f68d2\", \"created_utc\": \"2020-03-28T18:08:03.985094Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"c7dcadc3-228b-40ed-88d5-40fdf5749982\", \"azureml.git.repository_uri\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"mlflow.source.git.repoURL\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"c61c81ddc6083d0223952071edde983513310a58\", \"mlflow.source.git.commit\": \"c61c81ddc6083d0223952071edde983513310a58\", \"azureml.git.dirty\": \"True\", \"AzureML.DerivedImageName\": \"azureml/azureml_07d072b2a196016f8e79e803fe25ad26\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Preparing\", \"log_files\": {\"azureml-logs/20_image_build_log.txt\": \"https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585418882_2a8f68d2/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=So1NQZeEY3E9rZ6rqjlrQF02psTg2vpihpY3B%2F2aKQU%3D&st=2020-03-28T18%3A03%3A07Z&se=2020-03-29T02%3A13%3A07Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/20_image_build_log.txt\"]], \"run_duration\": \"0:05:04\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"2020/03/28 18:08:20 Downloading source code...\\r\\n2020/03/28 18:08:21 Finished downloading source code\\r\\n2020/03/28 18:08:21 Creating Docker network: acb_default_network, driver: 'bridge'\\n2020/03/28 18:08:22 Successfully set up Docker network: acb_default_network\\n2020/03/28 18:08:22 Setting up Docker configuration...\\n2020/03/28 18:08:23 Successfully set up Docker configuration\\n2020/03/28 18:08:23 Logging in to registry: machinelearn48d206af.azurecr.io\\n2020/03/28 18:08:24 Successfully logged into machinelearn48d206af.azurecr.io\\n2020/03/28 18:08:24 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\\n2020/03/28 18:08:24 Scanning for dependencies...\\r\\n2020/03/28 18:08:25 Successfully scanned dependencies\\n2020/03/28 18:08:25 Launching container with name: acb_step_0\\nSending build context to Docker daemon  60.93kB\\r\\r\\nStep 1/15 : FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\\nsha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05: Pulling from azureml/base\\nDigest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\\n ---> 93a72e6bd1ce\\nStep 2/15 : USER root\\n ---> Running in b7015179c347\\nRemoving intermediate container b7015179c347\\n ---> dc2dd317c973\\nStep 3/15 : RUN mkdir -p $HOME/.cache\\r\\n ---> Running in 9ac0dbd08397\\nRemoving intermediate container 9ac0dbd08397\\n ---> a5c71d42d5a0\\nStep 4/15 : WORKDIR /\\n ---> Running in 97bda3ff2010\\nRemoving intermediate container 97bda3ff2010\\n ---> 482d8c2aed6b\\nStep 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\\r\\n ---> dcc79488b466\\nStep 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\\n ---> Running in 04ac41a7d13d\\nRemoving intermediate container 04ac41a7d13d\\n ---> 661534fabe39\\nStep 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\\r\\n ---> c1fc099be059\\nStep 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_cec3c0c2eda4dee5bf29ecf1761c4111 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \\\"$HOME/.cache/pip\\\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \\\"$CONDA_ROOT_DIR/pkgs\\\" && find \\\"$CONDA_ROOT_DIR\\\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\\n ---> Running in ee85b373bd97\\nSolving environment: ...working... \\r\\ndone\\r\\n\\u001b[91m\\n\\n==> WARNING: A newer version of conda exists. <==\\n  current version: 4.5.11\\n  latest version: 4.8.3\\n\\nPlease update conda by running\\n\\n    $ conda update -n base -c defaults conda\\n\\n\\n\\rliblapack-3.8.0      | 10 KB     |            |   0% \\u001b[0m\\u001b[91m\\rliblapack-3.8.0      | 10 KB     | #######5   |  75% \\u001b[0m\\u001b[91m\\rliblapack-3.8.0      | 10 KB     | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rsqlite-3.13.0        | 4.9 MB    |            |   0% \\u001b[0m\\u001b[91m\\rsqlite-3.13.0        | 4.9 MB    | #######5   |  75% \\u001b[0m\\u001b[91m\\rsqlite-3.13.0        | 4.9 MB    | #########7 |  98% \\u001b[0m\\u001b[91m\\rsqlite-3.13.0        | 4.9 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\ropenssl-1.0.2u       | 3.2 MB    |            |   0% \\u001b[0m\\u001b[91m\\ropenssl-1.0.2u       | 3.2 MB    | #######6   |  76% \\u001b[0m\\u001b[91m\\ropenssl-1.0.2u       | 3.2 MB    | #########2 |  93% \\u001b[0m\\u001b[91m\\ropenssl-1.0.2u       | 3.2 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rlibgfortran-ng-7.3.0 | 1.7 MB    |            |   0% \\u001b[0m\\u001b[91m\\rlibgfortran-ng-7.3.0 | 1.7 MB    | #######8   |  78% \\u001b[0m\\u001b[91m\\rlibgfortran-ng-7.3.0 | 1.7 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rreadline-6.2         | 713 KB    |            |   0% \\u001b[0m\\u001b[91m\\rreadline-6.2         | 713 KB    | ########3  |  83% \\u001b[0m\\u001b[91m\\rreadline-6.2         | 713 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rxz-5.2.4             | 375 KB    |            |   0% \\u001b[0m\\u001b[91m\\rxz-5.2.4             | 375 KB    | #########3 |  93% \\u001b[0m\\u001b[91m\\rxz-5.2.4             | 375 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rlibblas-3.8.0        | 10 KB     |            |   0% \\u001b[0m\\u001b[91m\\rlibblas-3.8.0        | 10 KB     | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rllvm-openmp-9.0.1    | 782 KB    |            |   0% \\u001b[0m\\u001b[91m\\rllvm-openmp-9.0.1    | 782 KB    | ########6  |  86% \\u001b[0m\\u001b[91m\\rllvm-openmp-9.0.1    | 782 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rpython-3.6.2         | 19.0 MB   |            |   0% \\u001b[0m\\u001b[91m\\rpython-3.6.2         | 19.0 MB   |            |   0% \\u001b[0m\\u001b[91m\\rpython-3.6.2         | 19.0 MB   | ##1        |  21% \\u001b[0m\\u001b[91m\\rpython-3.6.2         | 19.0 MB   | #######5   |  75% \\u001b[0m\\u001b[91m\\rpython-3.6.2         | 19.0 MB   | #########5 |  96% \\u001b[0m\\u001b[91m\\rpython-3.6.2         | 19.0 MB   | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rnumpy-1.18.1         | 5.2 MB    |            |   0% \\u001b[0m\\u001b[91m\\rnumpy-1.18.1         | 5.2 MB    | ####8      |  49% \\u001b[0m\\u001b[91m\\rnumpy-1.18.1         | 5.2 MB    | #######6   |  77% \\u001b[0m\\u001b[91m\\rnumpy-1.18.1         | 5.2 MB    | #########5 |  96% \\u001b[0m\\u001b[91m\\rnumpy-1.18.1         | 5.2 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rca-certificates-2019 | 145 KB    |            |   0% \\u001b[0m\\u001b[91m\\rca-certificates-2019 | 145 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rzlib-1.2.11          | 105 KB    |            |   0% \\u001b[0m\\u001b[91m\\rzlib-1.2.11          | 105 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rlibgcc-ng-9.2.0      | 8.2 MB    |            |   0% \\u001b[0m\\u001b[91m\\rlibgcc-ng-9.2.0      | 8.2 MB    | #5         |  16% \\u001b[0m\\u001b[91m\\rlibgcc-ng-9.2.0      | 8.2 MB    | #######6   |  76% \\u001b[0m\\u001b[91m\\rlibgcc-ng-9.2.0      | 8.2 MB    | #########7 |  98% \\u001b[0m\\u001b[91m\\rlibgcc-ng-9.2.0      | 8.2 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\r_libgcc_mutex-0.1    | 3 KB      |            |   0% \\u001b[0m\\u001b[91m\\r_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rtk-8.5.19            | 1.9 MB    |            |   0% \\u001b[0m\\u001b[91m\\rtk-8.5.19            | 1.9 MB    | #######7   |  78% \\u001b[0m\\u001b[91m\\rtk-8.5.19            | 1.9 MB    | #########1 |  91% \\u001b[0m\\u001b[91m\\rtk-8.5.19            | 1.9 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rjoblib-0.14.1        | 198 KB    |            |   0% \\u001b[0m\\u001b[91m\\rjoblib-0.14.1        | 198 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rlibopenblas-0.3.9    | 7.8 MB    |            |   0% \\u001b[0m\\u001b[91m\\rlibopenblas-0.3.9    | 7.8 MB    | #####      |  50% \\u001b[0m\\u001b[91m\\rlibopenblas-0.3.9    | 7.8 MB    | #######6   |  77% \\u001b[0m\\u001b[91m\\rlibopenblas-0.3.9    | 7.8 MB    | #########4 |  94% \\u001b[0m\\u001b[91m\\rlibopenblas-0.3.9    | 7.8 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rlibcblas-3.8.0       | 10 KB     |            |   0% \\u001b[0m\\u001b[91m\\rlibcblas-3.8.0       | 10 KB     | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rscikit-learn-0.22.2. | 7.1 MB    |            |   0% \\u001b[0m\\u001b[91m\\rscikit-learn-0.22.2. | 7.1 MB    | ####8      |  48% \\u001b[0m\\u001b[91m\\rscikit-learn-0.22.2. | 7.1 MB    | #######6   |  77% \\u001b[0m\\u001b[91m\\rscikit-learn-0.22.2. | 7.1 MB    | #########5 |  95% \\u001b[0m\\u001b[91m\\rscikit-learn-0.22.2. | 7.1 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rsetuptools-46.1.3    | 653 KB    |            |   0% \\u001b[0m\\u001b[91m\\rsetuptools-46.1.3    | 653 KB    | ########3  |  84% \\u001b[0m\\u001b[91m\\rsetuptools-46.1.3    | 653 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rlibstdcxx-ng-9.2.0   | 4.5 MB    |            |   0% \\u001b[0m\\u001b[91m\\rlibstdcxx-ng-9.2.0   | 4.5 MB    | #######8   |  78% \\u001b[0m\\u001b[91m\\rlibstdcxx-ng-9.2.0   | 4.5 MB    | #########7 |  98% \\u001b[0m\\u001b[91m\\rlibstdcxx-ng-9.2.0   | 4.5 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rpip-20.0.2           | 1.0 MB    |            |   0% \\u001b[0m\\u001b[91m\\rpip-20.0.2           | 1.0 MB    | #######9   |  79% \\u001b[0m\\u001b[91m\\rpip-20.0.2           | 1.0 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rncurses-5.9          | 1.1 MB    |            |   0% \\u001b[0m\\u001b[91m\\rncurses-5.9          | 1.1 MB    | #######7   |  77% \\u001b[0m\\u001b[91m\\rncurses-5.9          | 1.1 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\r_openmp_mutex-4.5    | 5 KB      |            |   0% \\u001b[0m\\u001b[91m\\r_openmp_mutex-4.5    | 5 KB      | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rcertifi-2019.11.28   | 149 KB    |            |   0% \\u001b[0m\\u001b[91m\\rcertifi-2019.11.28   | 149 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rwheel-0.34.2         | 24 KB     |            |   0% \\u001b[0m\\u001b[91m\\rwheel-0.34.2         | 24 KB     | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rscipy-1.4.1          | 18.9 MB   |            |   0% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 18.9 MB   | #3         |  14% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 18.9 MB   | ###2       |  33% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 18.9 MB   | #####8     |  58% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 18.9 MB   | #######5   |  75% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 18.9 MB   | ########9  |  89% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 18.9 MB   | #########9 |  99% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 18.9 MB   | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rpython_abi-3.6       | 4 KB      |            |   0% \\u001b[0m\\u001b[91m\\rpython_abi-3.6       | 4 KB      | ########## | 100% \\u001b[0m\\nDownloading and Extracting Packages\\nPreparing transaction: ...working... done\\nVerifying transaction: ...working... done\\r\\nExecuting transaction: ...working... \\r\\ndone\\r\\nCollecting azureml-defaults==1.0.85.*\\n  Downloading azureml_defaults-1.0.85.1-py2.py3-none-any.whl (3.0 kB)\\nCollecting azureml-dataprep[fuse]\\n  Downloading azureml_dataprep-1.4.0-py3-none-any.whl (26.7 MB)\\nCollecting pyarrow\\r\\n  Downloading pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1 MB)\\nCollecting fastparquet\\r\\n  Downloading fastparquet-0.3.3.tar.gz (152 kB)\\nCollecting configparser==3.7.4\\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\\nCollecting werkzeug==0.16.1\\n  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\\nCollecting flask==1.0.3\\n  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\\nCollecting azureml-core==1.0.85.*\\n  Downloading azureml_core-1.0.85.5-py2.py3-none-any.whl (1.2 MB)\\nCollecting gunicorn==19.9.0\\n  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\\nCollecting azureml-model-management-sdk==1.0.1b6.post1\\n  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\\nCollecting json-logging-py==0.2\\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\\nCollecting applicationinsights>=0.11.7\\r\\n  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\\nCollecting azureml-dataprep-native<15.0.0,>=14.1.0\\n  Downloading azureml_dataprep_native-14.1.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\\nCollecting cloudpickle>=1.1.0\\n  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\\nCollecting dotnetcore2>=2.1.13\\n  Downloading dotnetcore2-2.1.13-py3-none-manylinux1_x86_64.whl (29.3 MB)\\nCollecting azure-identity>=1.2.0\\n  Downloading azure_identity-1.3.0-py2.py3-none-any.whl (61 kB)\\nCollecting fusepy>=3.0.1; extra == \\\"fuse\\\"\\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\\nCollecting six>=1.0.0\\r\\n  Downloading six-1.14.0-py2.py3-none-any.whl (10 kB)\\nRequirement already satisfied: numpy>=1.14 in /azureml-envs/azureml_cec3c0c2eda4dee5bf29ecf1761c4111/lib/python3.6/site-packages (from pyarrow->-r /azureml-environment-setup/condaenv.naqcs2tk.requirements.txt (line 3)) (1.18.1)\\nCollecting pandas>=0.19\\n  Downloading pandas-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (10.0 MB)\\nCollecting numba>=0.28\\n  Downloading numba-0.48.0-cp36-cp36m-manylinux1_x86_64.whl (2.5 MB)\\nCollecting thrift>=0.11.0\\n  Downloading thrift-0.13.0.tar.gz (59 kB)\\nCollecting Jinja2>=2.10\\n  Downloading Jinja2-2.11.1-py2.py3-none-any.whl (126 kB)\\nCollecting click>=5.1\\n  Downloading click-7.1.1-py2.py3-none-any.whl (82 kB)\\nCollecting itsdangerous>=0.24\\n  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\\nCollecting pytz\\r\\n  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)\\nCollecting azure-common>=1.1.12\\n  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\\nCollecting python-dateutil>=2.7.3\\n  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\\nCollecting backports.tempfile\\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\\nCollecting urllib3>=1.23\\n  Downloading urllib3-1.25.8-py2.py3-none-any.whl (125 kB)\\nCollecting contextlib2\\n  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\\nCollecting ruamel.yaml<=0.15.89,>=0.15.35\\n  Downloading ruamel.yaml-0.15.89-cp36-cp36m-manylinux1_x86_64.whl (651 kB)\\nCollecting azure-mgmt-keyvault>=0.40.0\\n  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\\nCollecting azure-graphrbac>=0.40.0\\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\\nCollecting jsonpickle\\n  Downloading jsonpickle-1.3-py2.py3-none-any.whl (32 kB)\\nCollecting azure-mgmt-storage>=1.5.0\\n  Downloading azure_mgmt_storage-8.0.0-py2.py3-none-any.whl (524 kB)\\nCollecting azure-mgmt-resource>=1.2.1\\n  Downloading azure_mgmt_resource-8.0.1-py2.py3-none-any.whl (758 kB)\\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\\r\\n  Downloading cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3 MB)\\nCollecting msrestazure>=0.4.33\\n  Downloading msrestazure-0.6.3-py2.py3-none-any.whl (40 kB)\\nCollecting jmespath\\n  Downloading jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\\nCollecting azure-mgmt-containerregistry>=2.0.0\\n  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\\nCollecting requests>=2.19.1\\n  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\\nCollecting azure-mgmt-authorization>=0.40.0\\n  Downloading azure_mgmt_authorization-0.60.0-py2.py3-none-any.whl (82 kB)\\nCollecting adal>=1.2.0\\n  Downloading adal-1.2.2-py2.py3-none-any.whl (53 kB)\\nCollecting SecretStorage\\n  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\\nCollecting ndg-httpsclient\\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\\nCollecting pyopenssl\\n  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\\nCollecting docker\\n  Downloading docker-4.2.0-py2.py3-none-any.whl (143 kB)\\nCollecting pathspec\\n  Downloading pathspec-0.7.0-py2.py3-none-any.whl (25 kB)\\nCollecting PyJWT\\n  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\\nCollecting msrest>=0.5.1\\n  Downloading msrest-0.6.11-py2.py3-none-any.whl (83 kB)\\nCollecting dill>=0.2.7.1\\n  Downloading dill-0.3.1.1.tar.gz (151 kB)\\nCollecting liac-arff>=2.1.1\\n  Downloading liac-arff-2.4.0.tar.gz (15 kB)\\nCollecting distro>=1.2.0\\r\\n  Downloading distro-1.4.0-py2.py3-none-any.whl (17 kB)\\nCollecting msal<2.0.0,>=1.0.0\\n  Downloading msal-1.1.0-py2.py3-none-any.whl (44 kB)\\nCollecting msal-extensions~=0.1.3\\n  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\\nCollecting azure-core<2.0.0,>=1.0.0\\n  Downloading azure_core-1.3.0-py2.py3-none-any.whl (106 kB)\\nCollecting llvmlite<0.32.0,>=0.31.0dev0\\n  Downloading llvmlite-0.31.0-cp36-cp36m-manylinux1_x86_64.whl (20.2 MB)\\nRequirement already satisfied: setuptools in /azureml-envs/azureml_cec3c0c2eda4dee5bf29ecf1761c4111/lib/python3.6/site-packages (from numba>=0.28->fastparquet->-r /azureml-environment-setup/condaenv.naqcs2tk.requirements.txt (line 4)) (46.1.3.post20200325)\\nCollecting MarkupSafe>=0.23\\n  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\\nCollecting backports.weakref\\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\\nCollecting cffi!=1.11.3,>=1.8\\n  Downloading cffi-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (399 kB)\\nCollecting idna<3,>=2.5\\n  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\\nCollecting chardet<4,>=3.0.2\\r\\n  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_cec3c0c2eda4dee5bf29ecf1761c4111/lib/python3.6/site-packages (from requests>=2.19.1->azureml-core==1.0.85.*->azureml-defaults==1.0.85.*->-r /azureml-environment-setup/condaenv.naqcs2tk.requirements.txt (line 1)) (2019.11.28)\\nCollecting jeepney>=0.4.2\\n  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\\nCollecting pyasn1>=0.1.1\\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\\nCollecting websocket-client>=0.32.0\\n  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\\nCollecting requests-oauthlib>=0.5.0\\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\\nCollecting isodate>=0.6.0\\n  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\\nCollecting portalocker~=1.0\\n  Downloading portalocker-1.6.0-py2.py3-none-any.whl (14 kB)\\nCollecting pycparser\\n  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\\nCollecting oauthlib>=3.0.0\\n  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\\nBuilding wheels for collected packages: fastparquet, json-logging-py, fusepy, thrift, dill, liac-arff\\n  Building wheel for fastparquet (setup.py): started\\n  Building wheel for fastparquet (setup.py): finished with status 'done'\\r\\n  Created wheel for fastparquet: filename=fastparquet-0.3.3-cp36-cp36m-linux_x86_64.whl size=258137 sha256=3a4a5af9b0d433a68670ce9bc56d1f55d499b11a7f224d0c32d4d6ff38ff5906\\n  Stored in directory: /root/.cache/pip/wheels/17/0b/fe/81b4ce36e4b0abb7220e29ea450ac345efb6219b9ac888e5c9\\n  Building wheel for json-logging-py (setup.py): started\\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3923 sha256=73dec929abf175bacb582e1e5f439522ce16c5a57b1828ce574cc2e4c2d5bae4\\n  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\\n  Building wheel for fusepy (setup.py): started\\n  Building wheel for fusepy (setup.py): finished with status 'done'\\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=c6b8a50f4f02ca73c48d07a8a637aba38c71f44f4978fdd190edd2d48f95cd5b\\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\\n  Building wheel for thrift (setup.py): started\\n  Building wheel for thrift (setup.py): finished with status 'done'\\r\\n  Created wheel for thrift: filename=thrift-0.13.0-cp36-cp36m-linux_x86_64.whl size=371616 sha256=365013d7d61f4f90909c5bb4caaa242a292e37fc1ddf612eacd4233977c48d6e\\n  Stored in directory: /root/.cache/pip/wheels/e0/38/fc/472fe18756b177b42096961f8bd3ff2dc5c5620ac399fce52d\\n  Building wheel for dill (setup.py): started\\n  Building wheel for dill (setup.py): finished with status 'done'\\n  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=70ed34e1efff3a7fbade0baea17160bf7b3756230df8667ac8ff1ede3415c4c4\\n  Stored in directory: /root/.cache/pip/wheels/09/84/74/d2b4feb9ac9488bc83c475cb2cbe8e8b7d9cea8320d32f3787\\n  Building wheel for liac-arff (setup.py): started\\n  Building wheel for liac-arff (setup.py): finished with status 'done'\\n  Created wheel for liac-arff: filename=liac_arff-2.4.0-py3-none-any.whl size=13333 sha256=578d6ffdb648716b38136be6fcdc035095181726e5487b534df797da86e38867\\n  Stored in directory: /root/.cache/pip/wheels/ba/2a/e1/6f7be2e2ea150e2486bff64fd6f0670f4f35f4c8f31c819fb8\\nSuccessfully built fastparquet json-logging-py fusepy thrift dill liac-arff\\nInstalling collected packages: configparser, werkzeug, MarkupSafe, Jinja2, click, itsdangerous, flask, pytz, azure-common, six, python-dateutil, backports.weakref, backports.tempfile, urllib3, contextlib2, ruamel.yaml, oauthlib, idna, chardet, requests, requests-oauthlib, isodate, msrest, PyJWT, pycparser, cffi, cryptography, adal, msrestazure, azure-mgmt-keyvault, azure-graphrbac, jsonpickle, azure-mgmt-storage, azure-mgmt-resource, jmespath, azure-mgmt-containerregistry, azure-mgmt-authorization, jeepney, SecretStorage, pyasn1, pyopenssl, ndg-httpsclient, websocket-client, docker, pathspec, azureml-core, gunicorn, pandas, dill, liac-arff, azureml-model-management-sdk, json-logging-py, applicationinsights, azureml-defaults, azureml-dataprep-native, cloudpickle, distro, dotnetcore2, msal, portalocker, msal-extensions, azure-core, azure-identity, fusepy, azureml-dataprep, pyarrow, llvmlite, numba, thrift, fastparquet\\n\\r\\nSuccessfully installed Jinja2-2.11.1 MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.1.2 adal-1.2.2 applicationinsights-0.11.9 azure-common-1.1.25 azure-core-1.3.0 azure-graphrbac-0.61.1 azure-identity-1.3.0 azure-mgmt-authorization-0.60.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-8.0.1 azure-mgmt-storage-8.0.0 azureml-core-1.0.85.5 azureml-dataprep-1.4.0 azureml-dataprep-native-14.1.0 azureml-defaults-1.0.85.1 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.0 chardet-3.0.4 click-7.1.1 cloudpickle-1.3.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-2.8 dill-0.3.1.1 distro-1.4.0 docker-4.2.0 dotnetcore2-2.1.13 fastparquet-0.3.3 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.9 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.4.3 jmespath-0.9.5 json-logging-py-0.2 jsonpickle-1.3 liac-arff-2.4.0 llvmlite-0.31.0 msal-1.1.0 msal-extensions-0.1.3 msrest-0.6.11 msrestazure-0.6.3 ndg-httpsclient-0.5.1 numba-0.48.0 oauthlib-3.1.0 pandas-1.0.3 pathspec-0.7.0 portalocker-1.6.0 pyarrow-0.16.0 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 python-dateutil-2.8.1 pytz-2019.3 requests-2.23.0 requests-oauthlib-1.3.0 ruamel.yaml-0.15.89 six-1.14.0 thrift-0.13.0 urllib3-1.25.8 websocket-client-0.57.0 werkzeug-0.16.1\\r\\n\\u001b[91m\\n\\u001b[0m#\\n# To activate this environment, use:\\n# > source activate /azureml-envs/azureml_cec3c0c2eda4dee5bf29ecf1761c4111\\n#\\n# To deactivate an active environment, use:\\n# > source deactivate\\n#\\n\\n\\r\\nRemoving intermediate container ee85b373bd97\\n ---> e328f62074bc\\nStep 9/15 : ENV PATH /azureml-envs/azureml_cec3c0c2eda4dee5bf29ecf1761c4111/bin:$PATH\\r\\n ---> Running in bcdcba7d3886\\nRemoving intermediate container bcdcba7d3886\\n ---> d2873825faba\\nStep 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_cec3c0c2eda4dee5bf29ecf1761c4111\\r\\n ---> Running in 3a205b17a1e2\\nRemoving intermediate container 3a205b17a1e2\\n ---> 623ff322bb13\\nStep 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_cec3c0c2eda4dee5bf29ecf1761c4111/lib:$LD_LIBRARY_PATH\\r\\n ---> Running in ddc3f25d6fd4\\nRemoving intermediate container ddc3f25d6fd4\\n ---> bd5291a27d8a\\nStep 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\\r\\n ---> b74e0bbadef2\\nStep 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\\r\\n ---> Running in 10182fb097a4\\nRemoving intermediate container 10182fb097a4\\n ---> 16ce0ebd63c8\\nStep 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\\r\\n ---> Running in 91cafc17e36b\\nRemoving intermediate container 91cafc17e36b\\n ---> 0d97431c90b6\\nStep 15/15 : CMD [\\\"bash\\\"]\\r\\n ---> Running in dff02f595a38\\nRemoving intermediate container dff02f595a38\\n ---> 3b5f8cb64932\\nSuccessfully built 3b5f8cb64932\\nSuccessfully tagged machinelearn48d206af.azurecr.io/azureml/azureml_07d072b2a196016f8e79e803fe25ad26:latest\\r\\n2020/03/28 18:11:33 Successfully executed container: acb_step_0\\n2020/03/28 18:11:33 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\\n2020/03/28 18:11:33 Pushing image: machinelearn48d206af.azurecr.io/azureml/azureml_07d072b2a196016f8e79e803fe25ad26:latest, attempt 1\\nThe push refers to repository [machinelearn48d206af.azurecr.io/azureml/azureml_07d072b2a196016f8e79e803fe25ad26]\\n52d0f8ddd87a: Preparing\\n496522595a43: Preparing\\ne564058384f5: Preparing\\n0c4df5d8b04a: Preparing\\n296c09e3c144: Preparing\\ncf852dec5765: Preparing\\ne1171d4d60ca: Preparing\\n6ef1a8ae63b7: Preparing\\n85389f9ead9e: Preparing\\nf2608f66a0e3: Preparing\\n0e259b09e5f4: Preparing\\n340dc32eb998: Preparing\\ndf18b66efaa6: Preparing\\nccdb13a20bf2: Preparing\\n9513cdf4e497: Preparing\\n7f083f9454c0: Preparing\\n29f36b5893dc: Preparing\\ncf852dec5765: Waiting\\ne1171d4d60ca: Waiting\\n6ef1a8ae63b7: Waiting\\n85389f9ead9e: Waiting\\nf2608f66a0e3: Waiting\\n0e259b09e5f4: Waiting\\n340dc32eb998: Waiting\\ndf18b66efaa6: Waiting\\nccdb13a20bf2: Waiting\\n9513cdf4e497: Waiting\\n7f083f9454c0: Waiting\\n29f36b5893dc: Waiting\\n0c4df5d8b04a: Pushed\\r\\n296c09e3c144: Pushed\\n52d0f8ddd87a: Pushed\\ne564058384f5: Pushed\\ncf852dec5765: Pushed\\r\\ne1171d4d60ca: Pushed\\r\\n6ef1a8ae63b7: Pushed\\n\\r\\n340dc32eb998: Pushed\\r\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.85\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'diabetes-training_1585418882_2a8f68d2',\n",
       " 'target': 'aml-cluster',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2020-03-28T18:20:22.04869Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'c7dcadc3-228b-40ed-88d5-40fdf5749982',\n",
       "  'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': 'c61c81ddc6083d0223952071edde983513310a58',\n",
       "  'mlflow.source.git.commit': 'c61c81ddc6083d0223952071edde983513310a58',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'AzureML.DerivedImageName': 'azureml/azureml_07d072b2a196016f8e79e803fe25ad26',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '2c81c692-c43c-4f03-9952-45124c0da47c'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes2', 'mechanism': 'Mount', 'pathOnCompute': 'diabetes_path'}}],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization', '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'aml-cluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {'diabetes2': {'dataLocation': {'dataset': {'id': '2c81c692-c43c-4f03-9952-45124c0da47c'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'diabetes2',\n",
       "    'pathOnCompute': 'diabetes_path',\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'training_environment',\n",
       "   'version': '6',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults==1.0.85.*',\n",
       "        'azureml-dataprep[fuse]',\n",
       "        'pyarrow',\n",
       "        'fastparquet']},\n",
       "      'scikit-learn',\n",
       "      'joblib'],\n",
       "     'name': 'azureml_cec3c0c2eda4dee5bf29ecf1761c4111'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585418882_2a8f68d2/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=PNbvdzfMHyWQbgG5sjwJuZHNzdjBLDCzUNyFrQ1%2FI0I%3D&st=2020-03-28T18%3A12%3A09Z&se=2020-03-29T02%3A22%3A09Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_56fa45a700657d5907a21a061ac0577eb4da69392bb06027b914e9fcdc721ef7_p.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585418882_2a8f68d2/azureml-logs/55_azureml-execution-tvmps_56fa45a700657d5907a21a061ac0577eb4da69392bb06027b914e9fcdc721ef7_p.txt?sv=2019-02-02&sr=b&sig=XRqUNN7IdKV%2B7pvRqZp0eRrW1UPWTut0BF8p8dxJE9s%3D&st=2020-03-28T18%3A12%3A10Z&se=2020-03-29T02%3A22%3A10Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_56fa45a700657d5907a21a061ac0577eb4da69392bb06027b914e9fcdc721ef7_p.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585418882_2a8f68d2/azureml-logs/65_job_prep-tvmps_56fa45a700657d5907a21a061ac0577eb4da69392bb06027b914e9fcdc721ef7_p.txt?sv=2019-02-02&sr=b&sig=spQKcCiZN9u28xMUigtzArtjgenDrDhfRnn%2BTrnUu8I%3D&st=2020-03-28T18%3A12%3A10Z&se=2020-03-29T02%3A22%3A10Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585418882_2a8f68d2/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=xpT7eL1iXCpCbopr5AY8CKHPUp00vkYZqnZM8AdhVk8%3D&st=2020-03-28T18%3A12%3A10Z&se=2020-03-29T02%3A22%3A10Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_56fa45a700657d5907a21a061ac0577eb4da69392bb06027b914e9fcdc721ef7_p.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585418882_2a8f68d2/azureml-logs/75_job_post-tvmps_56fa45a700657d5907a21a061ac0577eb4da69392bb06027b914e9fcdc721ef7_p.txt?sv=2019-02-02&sr=b&sig=rrXhkDrRrclQrXG9ChUVaOATaq5JdrjMazjitMchP%2FE%3D&st=2020-03-28T18%3A12%3A10Z&se=2020-03-29T02%3A22%3A10Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585418882_2a8f68d2/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=MeaA%2BRPwlNjVoC1pLRPAd7bijjN0afhr9pvdyGTh5II%3D&st=2020-03-28T18%3A12%3A10Z&se=2020-03-29T02%3A22%3A10Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585418882_2a8f68d2/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=%2Bm8IZigCtJRLpvrCgBh5xqSceXpJOCYxneHtV72VTog%3D&st=2020-03-28T18%3A12%3A10Z&se=2020-03-29T02%3A22%3A10Z&sp=r',\n",
       "  'logs/azureml/152_azureml.log': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585418882_2a8f68d2/logs/azureml/152_azureml.log?sv=2019-02-02&sr=b&sig=LUVcSom8r0XWix0iNT4dWu6NRFdGU7g8odLwzze9%2BVA%3D&st=2020-03-28T18%3A12%3A09Z&se=2020-03-29T02%3A22%3A09Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585418882_2a8f68d2/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=RCas6jeA56dUyFaQcdnIfvyWZj3W7v%2BqU83gLczXnJ0%3D&st=2020-03-28T18%3A12%3A09Z&se=2020-03-29T02%3A22%3A09Z&sp=r'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the script parameters\n",
    "script_params = {'--regularization': 0.1}\n",
    "\n",
    "ds = Dataset.get_by_name(workspace=ws, name=\"diabetes2\")\n",
    "\n",
    "# Get the environment\n",
    "# retrieve your prepped compute environment from the list\n",
    "training_env = Environment.get(workspace=ws, name='training_environment')\n",
    "\n",
    "training_cluster = ComputeTarget(workspace=ws, name='aml-cluster')\n",
    "\n",
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                      entry_script='diabetes_training.py',\n",
    "                      script_params=script_params,\n",
    "                      environment_definition=training_env,\n",
    "                      compute_target=training_cluster,\n",
    "                      inputs=[ds.as_named_input('diabetes2').as_mount(path_on_compute='diabetes_path')]\n",
    "                     )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'diabetes-training'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()\n",
    "#run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it builds the docker container on this local DSVM,\n",
    "# then pushes it onto ML workspace image register (~500MB/image - 10GB capacity)\n",
    "# - image:\n",
    "#     registry: machinelearn48d206af.azurecr.io\n",
    "#     repository: azureml/azureml_07d072b2a196016f8e79e803fe25ad26\n",
    "#     tag: latest\n",
    "#     digest: sha256:e4b841deabe07ab49b7f142da5e052be741281aaed902c017a0e96ce5925abc1\n",
    "# runtime-dependency:\n",
    "#     registry: mcr.microsoft.com\n",
    "#     repository: azureml/base\n",
    "#     tag: intelmpi2018.3-ubuntu16.04\n",
    "#     digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\n",
    "\n",
    "# then it provisions from your compute an instance (~batch service)\n",
    "# resizing can take 2min and renting costs start...\n",
    "# downloading docker image and then starting and mounting datalake etc and running and then closing off\n",
    "# 120 sec for the server to shutdown again "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final extra test about conda.yml - would be more elegant...\n",
    "I think we can do it if we use False in that auto dependecy thing...\n",
    "Let's try again below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Datastore\n",
    "from azureml.core import Dataset\n",
    "from azureml.core import Environment\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.conda_dependencies import CondaDependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_training_from_file_dataset folder created\n"
     ]
    }
   ],
   "source": [
    "# create A folder named diabetes_training_from_file_dataset here locally\n",
    "import os\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'diabetes_training_from_file_dataset'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting diabetes_training_from_file_dataset/diabetes_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "print(\"start custom script...\")\n",
    "import argparse\n",
    "print(\"argparse loaded\")\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run\n",
    "print(\"azureml.core loaded\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import glob\n",
    "print(\"all imports loaded\")\n",
    "\n",
    "# Set regularization hyperparameter (passed as an argument to the script)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "data_path = run.input_datasets['diabetes2'] # Get the training data from the estimator input\n",
    "print(\"data_path: \" + str(data_path))\n",
    "all_files = glob.glob(data_path + \"/**/*.csv\", recursive=True)\n",
    "print(\"data_path + '/**/*.csv': \" + str(data_path + '/**/*.csv')) # diabetes_path/*.csv\n",
    "print([file for file in all_files])   # ['diabetes_path/diabetes.csv', 'diabetes_path/diabetes2.csv']\n",
    "print(\"type(all_files): \" + str(type(all_files)))\n",
    "print(type(all_files[0]))\n",
    "diabetes = pd.concat((pd.read_csv(f) for f in all_files))\n",
    "print(\"number of records: \" + str(len(diabetes)))\n",
    "print(\"writing outputs/diabetes.parquet:\")\n",
    "diabetes.to_parquet(\"outputs/diabetes.parquet\")\n",
    "print(\"writing logs/out.csv:\")\n",
    "diabetes.to_csv(\"logs/out.csv\", index=False)\n",
    "print(\"crap upload\")\n",
    "#diabetes.to_csv(\"diabetes_path/diabetes.csv\", index=False)\n",
    "#run.output_datasets['diabetes2']\n",
    "# read-only filesystem !!\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conda.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conda.yml\n",
    "name: py_env\n",
    "channels:\n",
    " - conda-forge\n",
    "dependencies:\n",
    " - python=3.8.2\n",
    " - scikit-learn\n",
    " - joblib\n",
    " - pip:\n",
    "    - azureml-defaults\n",
    "    - pyarrow\n",
    "    - fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "#from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# create environment from a file\n",
    "env = Environment.from_conda_specification(name='training_environment', file_path='./conda.yml')\n",
    "#env = Environment(\"training_environment\")  # this would create a new env \n",
    "env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "env.docker.enabled = True # Use a docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"training_environment\",\n",
       "    \"version\": \"18\",\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"python\": {\n",
       "        \"userManagedDependencies\": false,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.8.2\",\n",
       "                \"scikit-learn\",\n",
       "                \"joblib\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults\",\n",
       "                        \"pyarrow\",\n",
       "                        \"fastparquet\"\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"name\": \"azureml_ed6ad1ace64132edbe11676fea09b7be\"\n",
       "        }\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"enabled\": true,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04\",\n",
       "        \"baseDockerfile\": null,\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null,\n",
       "        \"arguments\": [],\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"username\": null,\n",
       "            \"password\": null\n",
       "        }\n",
       "    },\n",
       "    \"spark\": {\n",
       "        \"repositories\": [],\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true\n",
       "    },\n",
       "    \"databricks\": {\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"eggLibraries\": []\n",
       "    },\n",
       "    \"inferencingStackVersion\": null\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a35cccf67574f2ebcfa6321c81b658d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Preparing\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes-training/runs/diabetes-training_1585430064_9b4f0ac2?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/machine_learning_workspace\", \"run_id\": \"diabetes-training_1585430064_9b4f0ac2\", \"run_properties\": {\"run_id\": \"diabetes-training_1585430064_9b4f0ac2\", \"created_utc\": \"2020-03-28T21:14:25.926222Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"c7dcadc3-228b-40ed-88d5-40fdf5749982\", \"azureml.git.repository_uri\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"mlflow.source.git.repoURL\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"0e7102f49f3ae90e172c3b504d5bebc9f50b6446\", \"mlflow.source.git.commit\": \"0e7102f49f3ae90e172c3b504d5bebc9f50b6446\", \"azureml.git.dirty\": \"True\", \"AzureML.DerivedImageName\": \"azureml/azureml_7a273b62f76221b8f2e7d811a9b5a0ed\"}, \"tags\": {}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Preparing\", \"log_files\": {\"azureml-logs/20_image_build_log.txt\": \"https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585430064_9b4f0ac2/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=qK9eAWAP11YYkTt9%2BROXaErSsXp9kpWsLHbo7hi0%2FVs%3D&st=2020-03-28T21%3A09%3A28Z&se=2020-03-29T05%3A19%3A28Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/20_image_build_log.txt\"]], \"run_duration\": \"0:05:03\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"2020/03/28 21:14:42 Downloading source code...\\r\\n2020/03/28 21:14:43 Finished downloading source code\\r\\n2020/03/28 21:14:43 Creating Docker network: acb_default_network, driver: 'bridge'\\n2020/03/28 21:14:44 Successfully set up Docker network: acb_default_network\\n2020/03/28 21:14:44 Setting up Docker configuration...\\n2020/03/28 21:14:44 Successfully set up Docker configuration\\n2020/03/28 21:14:44 Logging in to registry: machinelearn48d206af.azurecr.io\\n2020/03/28 21:14:46 Successfully logged into machinelearn48d206af.azurecr.io\\n2020/03/28 21:14:46 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\\n2020/03/28 21:14:46 Scanning for dependencies...\\r\\n2020/03/28 21:14:46 Successfully scanned dependencies\\n2020/03/28 21:14:46 Launching container with name: acb_step_0\\nSending build context to Docker daemon  60.93kB\\r\\r\\nStep 1/15 : FROM mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\\nsha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05: Pulling from azureml/base\\nDigest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04@sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\\n ---> 93a72e6bd1ce\\nStep 2/15 : USER root\\n ---> Running in bc00e8c3dadf\\nRemoving intermediate container bc00e8c3dadf\\n ---> 3b53f3b86049\\nStep 3/15 : RUN mkdir -p $HOME/.cache\\r\\n ---> Running in 5a516a7f1078\\nRemoving intermediate container 5a516a7f1078\\n ---> 3b88cefb59f2\\nStep 4/15 : WORKDIR /\\n ---> Running in 21a98edda841\\nRemoving intermediate container 21a98edda841\\n ---> 25dee5b9b04b\\nStep 5/15 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\\r\\n ---> 2af5cb101c75\\nStep 6/15 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\\n ---> Running in 13388da93934\\nRemoving intermediate container 13388da93934\\n ---> f63ab3fe7a17\\nStep 7/15 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\\r\\n ---> 850a9da0c7ba\\nStep 8/15 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_ed6ad1ace64132edbe11676fea09b7be -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \\\"$HOME/.cache/pip\\\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \\\"$CONDA_ROOT_DIR/pkgs\\\" && find \\\"$CONDA_ROOT_DIR\\\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\\n ---> Running in 2268ccc9a548\\nSolving environment: ...working... \\r\\ndone\\r\\n\\u001b[91m\\n\\n==> WARNING: A newer version of conda exists. <==\\n  current version: 4.5.11\\n  latest version: 4.8.3\\n\\nPlease update conda by running\\n\\n    $ conda update -n base -c defaults conda\\n\\n\\n\\rcertifi-2019.11.28   | 149 KB    |            |   0% \\u001b[0m\\u001b[91m\\rcertifi-2019.11.28   | 149 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\r_libgcc_mutex-0.1    | 3 KB      |            |   0% \\u001b[0m\\u001b[91m\\r_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \\u001b[0m\\u001b[91m\\n\\ropenssl-1.1.1e       | 2.1 MB    |            |   0% \\u001b[0m\\u001b[91m\\ropenssl-1.1.1e       | 2.1 MB    | #######6   |  77% \\u001b[0m\\u001b[91m\\ropenssl-1.1.1e       | 2.1 MB    | #########7 |  98% \\u001b[0m\\u001b[91m\\ropenssl-1.1.1e       | 2.1 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rscikit-learn-0.22.2. | 7.2 MB    |            |   0% \\u001b[0m\\u001b[91m\\rscikit-learn-0.22.2. | 7.2 MB    | ###6       |  36% \\u001b[0m\\u001b[91m\\rscikit-learn-0.22.2. | 7.2 MB    | #######6   |  76% \\u001b[0m\\u001b[91m\\rscikit-learn-0.22.2. | 7.2 MB    | #########2 |  92% \\u001b[0m\\u001b[91m\\rscikit-learn-0.22.2. | 7.2 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rca-certificates-2019 | 145 KB    |            |   0% \\u001b[0m\\u001b[91m\\rca-certificates-2019 | 145 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rwheel-0.34.2         | 24 KB     |            |   0% \\u001b[0m\\u001b[91m\\rwheel-0.34.2         | 24 KB     | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rreadline-8.0         | 441 KB    |            |   0% \\u001b[0m\\u001b[91m\\rreadline-8.0         | 441 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rlibffi-3.2.1         | 47 KB     |            |   0% \\u001b[0m\\u001b[91m\\rlibffi-3.2.1         | 47 KB     | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rtk-8.6.10            | 3.2 MB    |            |   0% \\u001b[0m\\u001b[91m\\rtk-8.6.10            | 3.2 MB    | #######6   |  77% \\u001b[0m\\u001b[91m\\rtk-8.6.10            | 3.2 MB    | #########4 |  95% \\u001b[0m\\u001b[91m\\rtk-8.6.10            | 3.2 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rliblapack-3.8.0      | 10 KB     |            |   0% \\u001b[0m\\u001b[91m\\rliblapack-3.8.0      | 10 KB     | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rsqlite-3.30.1        | 2.0 MB    |            |   0% \\u001b[0m\\u001b[91m\\rsqlite-3.30.1        | 2.0 MB    | ########   |  80% \\u001b[0m\\u001b[91m\\rsqlite-3.30.1        | 2.0 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rnumpy-1.18.1         | 5.3 MB    |            |   0% \\u001b[0m\\u001b[91m\\rnumpy-1.18.1         | 5.3 MB    | #####4     |  55% \\u001b[0m\\u001b[91m\\rnumpy-1.18.1         | 5.3 MB    | #######6   |  77% \\u001b[0m\\u001b[91m\\rnumpy-1.18.1         | 5.3 MB    | #########5 |  95% \\u001b[0m\\u001b[91m\\rnumpy-1.18.1         | 5.3 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rxz-5.2.4             | 375 KB    |            |   0% \\u001b[0m\\u001b[91m\\rxz-5.2.4             | 375 KB    | #########4 |  94% \\u001b[0m\\u001b[91m\\rxz-5.2.4             | 375 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rlibopenblas-0.3.9    | 7.8 MB    |            |   0% \\u001b[0m\\u001b[91m\\rlibopenblas-0.3.9    | 7.8 MB    | #######5   |  75% \\u001b[0m\\u001b[91m\\rlibopenblas-0.3.9    | 7.8 MB    | #########7 |  98% \\u001b[0m\\u001b[91m\\rlibopenblas-0.3.9    | 7.8 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rlibcblas-3.8.0       | 10 KB     |            |   0% \\u001b[0m\\u001b[91m\\rlibcblas-3.8.0       | 10 KB     | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rlibgcc-ng-9.2.0      | 8.2 MB    |            |   0% \\u001b[0m\\u001b[91m\\rlibgcc-ng-9.2.0      | 8.2 MB    | ###5       |  36% \\u001b[0m\\u001b[91m\\rlibgcc-ng-9.2.0      | 8.2 MB    | #######6   |  77% \\u001b[0m\\u001b[91m\\rlibgcc-ng-9.2.0      | 8.2 MB    | #########6 |  96% \\u001b[0m\\u001b[91m\\rlibgcc-ng-9.2.0      | 8.2 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rzlib-1.2.11          | 105 KB    |            |   0% \\u001b[0m\\u001b[91m\\rzlib-1.2.11          | 105 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rncurses-6.1          | 1.3 MB    |            |   0% \\u001b[0m\\u001b[91m\\rncurses-6.1          | 1.3 MB    | #######7   |  78% \\u001b[0m\\u001b[91m\\rncurses-6.1          | 1.3 MB    | #########9 | 100% \\u001b[0m\\u001b[91m\\rncurses-6.1          | 1.3 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rpython-3.8.2         | 58.2 MB   |            |   0% \\u001b[0m\\u001b[91m\\rpython-3.8.2         | 58.2 MB   | 4          |   5% \\u001b[0m\\u001b[91m\\rpython-3.8.2         | 58.2 MB   | #9         |  19% \\u001b[0m\\u001b[91m\\rpython-3.8.2         | 58.2 MB   | ###4       |  34% \\u001b[0m\\u001b[91m\\rpython-3.8.2         | 58.2 MB   | ####9      |  49% \\u001b[0m\\u001b[91m\\rpython-3.8.2         | 58.2 MB   | ######2    |  62% \\u001b[0m\\u001b[91m\\rpython-3.8.2         | 58.2 MB   | #######5   |  75% \\u001b[0m\\u001b[91m\\rpython-3.8.2         | 58.2 MB   | ########5  |  85% \\u001b[0m\\u001b[91m\\rpython-3.8.2         | 58.2 MB   | #########2 |  93% \\u001b[0m\\u001b[91m\\rpython-3.8.2         | 58.2 MB   | #########7 |  98% \\u001b[0m\\u001b[91m\\rpython-3.8.2         | 58.2 MB   | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rlibgfortran-ng-7.3.0 | 1.7 MB    |            |   0% \\u001b[0m\\u001b[91m\\rlibgfortran-ng-7.3.0 | 1.7 MB    | ########   |  80% \\u001b[0m\\u001b[91m\\rlibgfortran-ng-7.3.0 | 1.7 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\r_openmp_mutex-4.5    | 5 KB      |            |   0% \\u001b[0m\\u001b[91m\\r_openmp_mutex-4.5    | 5 KB      | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rpip-20.0.2           | 1.0 MB    |            |   0% \\u001b[0m\\u001b[91m\\rpip-20.0.2           | 1.0 MB    | #######9   |  80% \\u001b[0m\\u001b[91m\\rpip-20.0.2           | 1.0 MB    | #########6 |  97% \\u001b[0m\\u001b[91m\\rpip-20.0.2           | 1.0 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rscipy-1.4.1          | 19.1 MB   |            |   0% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 19.1 MB   | ##2        |  23% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 19.1 MB   | #####5     |  55% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 19.1 MB   | #######5   |  75% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 19.1 MB   | #########1 |  91% \\u001b[0m\\u001b[91m\\rscipy-1.4.1          | 19.1 MB   | ########## | 100% \\u001b[0m\\u001b[91m\\r\\n\\rlibblas-3.8.0        | 10 KB     |            |   0% \\u001b[0m\\u001b[91m\\rlibblas-3.8.0        | 10 KB     | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rlibstdcxx-ng-9.2.0   | 4.5 MB    |            |   0% \\u001b[0m\\u001b[91m\\rlibstdcxx-ng-9.2.0   | 4.5 MB    | #######8   |  78% \\u001b[0m\\u001b[91m\\rlibstdcxx-ng-9.2.0   | 4.5 MB    | #########9 |  99% \\u001b[0m\\u001b[91m\\rlibstdcxx-ng-9.2.0   | 4.5 MB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rjoblib-0.14.1        | 198 KB    |            |   0% \\u001b[0m\\u001b[91m\\rjoblib-0.14.1        | 198 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rpython_abi-3.8       | 4 KB      |            |   0% \\u001b[0m\\u001b[91m\\rpython_abi-3.8       | 4 KB      | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rllvm-openmp-9.0.1    | 782 KB    |            |   0% \\u001b[0m\\u001b[91m\\rllvm-openmp-9.0.1    | 782 KB    | #########4 |  94% \\u001b[0m\\u001b[91m\\rllvm-openmp-9.0.1    | 782 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rsetuptools-46.1.3    | 635 KB    |            |   0% \\u001b[0m\\u001b[91m\\rsetuptools-46.1.3    | 635 KB    | ########3  |  84% \\u001b[0m\\u001b[91m\\rsetuptools-46.1.3    | 635 KB    | ########## | 100% \\u001b[0m\\u001b[91m\\n\\rld_impl_linux-64-2.3 | 616 KB    |            |   0% \\u001b[0m\\u001b[91m\\rld_impl_linux-64-2.3 | 616 KB    | #########3 |  94% \\u001b[0m\\u001b[91m\\rld_impl_linux-64-2.3 | 616 KB    | ########## | 100% \\u001b[0m\\nDownloading and Extracting Packages\\nPreparing transaction: ...working... done\\nVerifying transaction: ...working... done\\r\\nExecuting transaction: ...working... \\r\\ndone\\r\\nCollecting azureml-defaults\\n  Downloading azureml_defaults-1.2.0-py3-none-any.whl (3.0 kB)\\nCollecting pyarrow\\n  Downloading pyarrow-0.16.0-cp38-cp38-manylinux2014_x86_64.whl (63.2 MB)\\nCollecting fastparquet\\r\\n  Downloading fastparquet-0.3.3.tar.gz (152 kB)\\nCollecting configparser==3.7.4\\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\\nCollecting applicationinsights>=0.11.7\\n  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\\nCollecting flask==1.0.3\\n  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\\nCollecting azureml-model-management-sdk==1.0.1b6.post1\\n  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\\nCollecting json-logging-py==0.2\\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\\nCollecting azureml-core~=1.2.0\\n  Downloading azureml_core-1.2.0.post1-py3-none-any.whl (1.2 MB)\\nCollecting gunicorn==19.9.0\\n  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\\nCollecting werkzeug==0.16.1\\n  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\\nCollecting azureml-dataprep[fuse]<1.4.0a,>=1.3.5\\n  Downloading azureml_dataprep-1.3.5-py3-none-any.whl (26.6 MB)\\nCollecting six>=1.0.0\\r\\n  Downloading six-1.14.0-py2.py3-none-any.whl (10 kB)\\nRequirement already satisfied: numpy>=1.14 in /azureml-envs/azureml_ed6ad1ace64132edbe11676fea09b7be/lib/python3.8/site-packages (from pyarrow->-r /azureml-environment-setup/condaenv.u6mr0r1b.requirements.txt (line 2)) (1.18.1)\\nCollecting pandas>=0.19\\n  Downloading pandas-1.0.3-cp38-cp38-manylinux1_x86_64.whl (10.0 MB)\\nCollecting numba>=0.28\\n  Downloading numba-0.48.0-cp38-cp38-manylinux1_x86_64.whl (2.5 MB)\\nCollecting thrift>=0.11.0\\n  Downloading thrift-0.13.0.tar.gz (59 kB)\\nCollecting Jinja2>=2.10\\n  Downloading Jinja2-2.11.1-py2.py3-none-any.whl (126 kB)\\nCollecting click>=5.1\\n  Downloading click-7.1.1-py2.py3-none-any.whl (82 kB)\\nCollecting itsdangerous>=0.24\\n  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\\nCollecting dill>=0.2.7.1\\n  Downloading dill-0.3.1.1.tar.gz (151 kB)\\nCollecting adal>=0.4.5\\n  Downloading adal-1.2.2-py2.py3-none-any.whl (53 kB)\\nCollecting python-dateutil>=2.5.3\\n  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\\nCollecting pytz>=2017.2\\n  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)\\nCollecting requests>=2.17.3\\r\\n  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\\nCollecting liac-arff>=2.1.1\\n  Downloading liac-arff-2.4.0.tar.gz (15 kB)\\nCollecting pathspec\\n  Downloading pathspec-0.7.0-py2.py3-none-any.whl (25 kB)\\nCollecting azure-graphrbac>=0.40.0\\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\\nCollecting azure-mgmt-authorization>=0.40.0\\n  Downloading azure_mgmt_authorization-0.60.0-py2.py3-none-any.whl (82 kB)\\nCollecting azure-mgmt-containerregistry>=2.0.0\\n  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\\nCollecting msrest>=0.5.1\\n  Downloading msrest-0.6.11-py2.py3-none-any.whl (83 kB)\\nCollecting docker\\n  Downloading docker-4.2.0-py2.py3-none-any.whl (143 kB)\\nCollecting jmespath\\n  Downloading jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\\nCollecting urllib3>=1.23\\n  Downloading urllib3-1.25.8-py2.py3-none-any.whl (125 kB)\\nCollecting ruamel.yaml<=0.15.89,>=0.15.35\\n  Downloading ruamel.yaml-0.15.89.tar.gz (306 kB)\\nCollecting azure-mgmt-storage>=1.5.0\\n  Downloading azure_mgmt_storage-8.0.0-py2.py3-none-any.whl (524 kB)\\nCollecting pyopenssl\\n  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\\r\\n  Downloading cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3 MB)\\nCollecting SecretStorage\\n  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\\nCollecting backports.tempfile\\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\\nCollecting contextlib2\\n  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\\nCollecting jsonpickle\\n  Downloading jsonpickle-1.3-py2.py3-none-any.whl (32 kB)\\nCollecting msrestazure>=0.4.33\\n  Downloading msrestazure-0.6.3-py2.py3-none-any.whl (40 kB)\\nCollecting azure-mgmt-keyvault>=0.40.0\\n  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\\nCollecting PyJWT\\n  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\\nCollecting ndg-httpsclient\\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\\nCollecting azure-common>=1.1.12\\n  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\\nCollecting azure-mgmt-resource>=1.2.1\\n  Downloading azure_mgmt_resource-8.0.1-py2.py3-none-any.whl (758 kB)\\nCollecting azureml-dataprep-native<15.0.0,>=14.1.0\\n  Downloading azureml_dataprep_native-14.1.0-cp38-cp38-manylinux1_x86_64.whl (1.4 MB)\\nCollecting dotnetcore2>=2.1.13\\n  Downloading dotnetcore2-2.1.13-py3-none-manylinux1_x86_64.whl (29.3 MB)\\nCollecting azure-identity>=1.2.0\\r\\n  Downloading azure_identity-1.3.0-py2.py3-none-any.whl (61 kB)\\nCollecting cloudpickle>=1.1.0\\n  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\\nCollecting fusepy>=3.0.1; extra == \\\"fuse\\\"\\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\\nCollecting llvmlite<0.32.0,>=0.31.0dev0\\n  Downloading llvmlite-0.31.0-cp38-cp38-manylinux1_x86_64.whl (20.2 MB)\\nRequirement already satisfied: setuptools in /azureml-envs/azureml_ed6ad1ace64132edbe11676fea09b7be/lib/python3.8/site-packages (from numba>=0.28->fastparquet->-r /azureml-environment-setup/condaenv.u6mr0r1b.requirements.txt (line 3)) (46.1.3.post20200325)\\r\\nCollecting MarkupSafe>=0.23\\n  Downloading MarkupSafe-1.1.1-cp38-cp38-manylinux1_x86_64.whl (32 kB)\\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_ed6ad1ace64132edbe11676fea09b7be/lib/python3.8/site-packages (from requests>=2.17.3->azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults->-r /azureml-environment-setup/condaenv.u6mr0r1b.requirements.txt (line 1)) (2019.11.28)\\nCollecting idna<3,>=2.5\\n  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\\nCollecting chardet<4,>=3.0.2\\n  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\\nCollecting requests-oauthlib>=0.5.0\\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\\nCollecting isodate>=0.6.0\\n  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\\nCollecting websocket-client>=0.32.0\\n  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\\nCollecting cffi!=1.11.3,>=1.8\\n  Downloading cffi-1.14.0-cp38-cp38-manylinux1_x86_64.whl (409 kB)\\nCollecting jeepney>=0.4.2\\n  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\\nCollecting backports.weakref\\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\\nCollecting pyasn1>=0.1.1\\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\\nCollecting distro>=1.2.0\\n  Downloading distro-1.4.0-py2.py3-none-any.whl (17 kB)\\nCollecting msal<2.0.0,>=1.0.0\\n  Downloading msal-1.1.0-py2.py3-none-any.whl (44 kB)\\nCollecting azure-core<2.0.0,>=1.0.0\\n  Downloading azure_core-1.3.0-py2.py3-none-any.whl (106 kB)\\nCollecting msal-extensions~=0.1.3\\n  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\\nCollecting oauthlib>=3.0.0\\n  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\\nCollecting pycparser\\n  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\\nCollecting portalocker~=1.0\\n  Downloading portalocker-1.6.0-py2.py3-none-any.whl (14 kB)\\nBuilding wheels for collected packages: fastparquet, json-logging-py, thrift, dill, liac-arff, ruamel.yaml, fusepy\\n  Building wheel for fastparquet (setup.py): started\\n  Building wheel for fastparquet (setup.py): finished with status 'done'\\r\\n  Created wheel for fastparquet: filename=fastparquet-0.3.3-cp38-cp38-linux_x86_64.whl size=265240 sha256=e2de9368c730a03f13e24c224889c207cb85ea6b94914a5d164154102b7e7dcc\\n  Stored in directory: /root/.cache/pip/wheels/ab/e4/8a/5bf9e2dfbe90b06d3aa6f0fba3cf2f5e9514ce20d7f73acdd4\\n  Building wheel for json-logging-py (setup.py): started\\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3923 sha256=65e84c8841787fdb31189f530d2cd9b7d35bf0c2815e43f79449fe0251fb532e\\n  Stored in directory: /root/.cache/pip/wheels/e9/d6/70/7491901d808e74dd9238e4a91658ba108e4b5939b55327e6fb\\n  Building wheel for thrift (setup.py): started\\n  Building wheel for thrift (setup.py): finished with status 'done'\\r\\n  Created wheel for thrift: filename=thrift-0.13.0-cp38-cp38-linux_x86_64.whl size=388173 sha256=a065c46fcf85122fd00947b69ea442cd4d2005afce2401d53cfa732e2876142f\\n  Stored in directory: /root/.cache/pip/wheels/0a/52/7e/8054b57725b8f2b9ddbaacb81b271b939681cc03f8231e6ebc\\n  Building wheel for dill (setup.py): started\\n  Building wheel for dill (setup.py): finished with status 'done'\\n  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=3e9b36877e8cb7a7b6f4222f26e2581f84f2a9a74e89ed378dde6b1fe34fdac4\\n  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\\n  Building wheel for liac-arff (setup.py): started\\n  Building wheel for liac-arff (setup.py): finished with status 'done'\\n  Created wheel for liac-arff: filename=liac_arff-2.4.0-py3-none-any.whl size=13333 sha256=3faaa3a073192a8227b3db6e7d3ab392a9de58837f107bc76455beb218703ae3\\n  Stored in directory: /root/.cache/pip/wheels/b1/a5/a6/e2fcffce8959ffa92c16d8ca4ab632299d73c18470b112263c\\n  Building wheel for ruamel.yaml (setup.py): started\\n  Building wheel for ruamel.yaml (setup.py): finished with status 'done'\\r\\n  Created wheel for ruamel.yaml: filename=ruamel.yaml-0.15.89-cp38-cp38-linux_x86_64.whl size=675503 sha256=56eb756ce32301e0467b80af9c799240c131568a1679ff8431e47fc3d7cea6a7\\n  Stored in directory: /root/.cache/pip/wheels/ff/6d/69/6a3ed44734986d96f09da482c41ecdce74a40fbe10d605bc9f\\n  Building wheel for fusepy (setup.py): started\\n  Building wheel for fusepy (setup.py): finished with status 'done'\\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=69171f2dda9f98df99ed364585e3195efaf8689d02a1e668862366e7ce1da9fb\\n  Stored in directory: /root/.cache/pip/wheels/7f/41/10/f70b83a1164fdb95e7bc37bace13114a024227e56c2fee02bb\\nSuccessfully built fastparquet json-logging-py thrift dill liac-arff ruamel.yaml fusepy\\nInstalling collected packages: configparser, applicationinsights, MarkupSafe, Jinja2, werkzeug, click, itsdangerous, flask, dill, six, pycparser, cffi, cryptography, PyJWT, urllib3, idna, chardet, requests, python-dateutil, adal, pytz, pandas, liac-arff, azureml-model-management-sdk, json-logging-py, pathspec, oauthlib, requests-oauthlib, isodate, msrest, msrestazure, azure-common, azure-graphrbac, azure-mgmt-authorization, azure-mgmt-containerregistry, websocket-client, docker, jmespath, ruamel.yaml, azure-mgmt-storage, pyopenssl, jeepney, SecretStorage, backports.weakref, backports.tempfile, contextlib2, jsonpickle, azure-mgmt-keyvault, pyasn1, ndg-httpsclient, azure-mgmt-resource, azureml-core, gunicorn, azureml-dataprep-native, distro, dotnetcore2, msal, azure-core, portalocker, msal-extensions, azure-identity, cloudpickle, fusepy, azureml-dataprep, azureml-defaults, pyarrow, llvmlite, numba, thrift, fastparquet\\n\\r\\nSuccessfully installed Jinja2-2.11.1 MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.1.2 adal-1.2.2 applicationinsights-0.11.9 azure-common-1.1.25 azure-core-1.3.0 azure-graphrbac-0.61.1 azure-identity-1.3.0 azure-mgmt-authorization-0.60.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-8.0.1 azure-mgmt-storage-8.0.0 azureml-core-1.2.0.post1 azureml-dataprep-1.3.5 azureml-dataprep-native-14.1.0 azureml-defaults-1.2.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.0 chardet-3.0.4 click-7.1.1 cloudpickle-1.3.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-2.8 dill-0.3.1.1 distro-1.4.0 docker-4.2.0 dotnetcore2-2.1.13 fastparquet-0.3.3 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.9 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.4.3 jmespath-0.9.5 json-logging-py-0.2 jsonpickle-1.3 liac-arff-2.4.0 llvmlite-0.31.0 msal-1.1.0 msal-extensions-0.1.3 msrest-0.6.11 msrestazure-0.6.3 ndg-httpsclient-0.5.1 numba-0.48.0 oauthlib-3.1.0 pandas-1.0.3 pathspec-0.7.0 portalocker-1.6.0 pyarrow-0.16.0 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 python-dateutil-2.8.1 pytz-2019.3 requests-2.23.0 requests-oauthlib-1.3.0 ruamel.yaml-0.15.89 six-1.14.0 thrift-0.13.0 urllib3-1.25.8 websocket-client-0.57.0 werkzeug-0.16.1\\n\\u001b[91m\\n\\u001b[0m#\\n# To activate this environment, use:\\n# > source activate /azureml-envs/azureml_ed6ad1ace64132edbe11676fea09b7be\\n#\\n# To deactivate an active environment, use:\\n# > source deactivate\\n#\\n\\n\\r\\nRemoving intermediate container 2268ccc9a548\\n ---> e4b6af661aca\\nStep 9/15 : ENV PATH /azureml-envs/azureml_ed6ad1ace64132edbe11676fea09b7be/bin:$PATH\\r\\n ---> Running in 34c807e29e57\\nRemoving intermediate container 34c807e29e57\\n ---> ae82dfbbef64\\nStep 10/15 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_ed6ad1ace64132edbe11676fea09b7be\\n ---> Running in d12cbc1a399e\\nRemoving intermediate container d12cbc1a399e\\n ---> dda0b1587ca3\\nStep 11/15 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_ed6ad1ace64132edbe11676fea09b7be/lib:$LD_LIBRARY_PATH\\r\\n ---> Running in 51e6c776cf1a\\nRemoving intermediate container 51e6c776cf1a\\n ---> 1728f7f79101\\nStep 12/15 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\\n ---> 87bcd3232968\\nStep 13/15 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\\r\\n ---> Running in 9a07a23b5c93\\nRemoving intermediate container 9a07a23b5c93\\n ---> b601faf2e158\\nStep 14/15 : ENV AZUREML_ENVIRONMENT_IMAGE True\\r\\n ---> Running in 4d366d366970\\nRemoving intermediate container 4d366d366970\\n ---> a26edca6297c\\nStep 15/15 : CMD [\\\"bash\\\"]\\n ---> Running in e6a8f49deba5\\nRemoving intermediate container e6a8f49deba5\\n ---> c37a0b7f118f\\nSuccessfully built c37a0b7f118f\\nSuccessfully tagged machinelearn48d206af.azurecr.io/azureml/azureml_7a273b62f76221b8f2e7d811a9b5a0ed:latest\\r\\n2020/03/28 21:17:38 Successfully executed container: acb_step_0\\n2020/03/28 21:17:38 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\\n2020/03/28 21:17:38 Pushing image: machinelearn48d206af.azurecr.io/azureml/azureml_7a273b62f76221b8f2e7d811a9b5a0ed:latest, attempt 1\\nThe push refers to repository [machinelearn48d206af.azurecr.io/azureml/azureml_7a273b62f76221b8f2e7d811a9b5a0ed]\\n406d48e0f206: Preparing\\nd008af43d94e: Preparing\\n46840a882def: Preparing\\n1a41f41452c5: Preparing\\n666d98b91512: Preparing\\ncd7db104aaa6: Preparing\\ne1171d4d60ca: Preparing\\n6ef1a8ae63b7: Preparing\\n85389f9ead9e: Preparing\\nf2608f66a0e3: Preparing\\n0e259b09e5f4: Preparing\\n340dc32eb998: Preparing\\ndf18b66efaa6: Preparing\\nccdb13a20bf2: Preparing\\n9513cdf4e497: Preparing\\n7f083f9454c0: Preparing\\n29f36b5893dc: Preparing\\ncd7db104aaa6: Waiting\\ne1171d4d60ca: Waiting\\n6ef1a8ae63b7: Waiting\\n85389f9ead9e: Waiting\\nf2608f66a0e3: Waiting\\n0e259b09e5f4: Waiting\\n340dc32eb998: Waiting\\ndf18b66efaa6: Waiting\\nccdb13a20bf2: Waiting\\n9513cdf4e497: Waiting\\n7f083f9454c0: Waiting\\n29f36b5893dc: Waiting\\n666d98b91512: Pushed\\r\\n406d48e0f206: Pushed\\n46840a882def: Pushed\\n1a41f41452c5: Pushed\\ncd7db104aaa6: Pushed\\ne1171d4d60ca: Pushed\\r\\n6ef1a8ae63b7: Pushed\\n\\r\\n85389f9ead9e: Pushed\\r\\n340dc32eb998: Pushed\\nccdb13a20bf2: Pushed\\r\\n9513cdf4e497: Pushed\\r\\n0e259b09e5f4: Pushed\\n7f083f9454c0: Pushed\\r\\nf2608f66a0e3: Pushed\\r\\n29f36b5893dc: Pushed\\r\\ndf18b66efaa6: Pushed\\r\\nd008af43d94e: Pushed\\r\\nlatest: digest: sha256:59ba91aa6449891fc4f00c935347c0bea211681adca39c2337c71e520783c484 size: 3883\\r\\n2020/03/28 21:19:21 Successfully pushed image: machinelearn48d206af.azurecr.io/azureml/azureml_7a273b62f76221b8f2e7d811a9b5a0ed:latest\\n2020/03/28 21:19:21 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 172.457286)\\n2020/03/28 21:19:21 Populating digests for step ID: acb_step_0...\\n2020/03/28 21:19:23 Successfully populated digests for step ID: acb_step_0\\n2020/03/28 21:19:23 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 103.500177)\\n2020/03/28 21:19:23 The following dependencies were found:\\n2020/03/28 21:19:23 \\n- image:\\n    registry: machinelearn48d206af.azurecr.io\\n    repository: azureml/azureml_7a273b62f76221b8f2e7d811a9b5a0ed\\n    tag: latest\\n    digest: sha256:59ba91aa6449891fc4f00c935347c0bea211681adca39c2337c71e520783c484\\n  runtime-dependency:\\n    registry: mcr.microsoft.com\\n    repository: azureml/base\\n    tag: intelmpi2018.3-ubuntu16.04\\n    digest: sha256:a1b514f3ba884b9a7695cbba5638933ddaf222e8ce3e8c81e8cdf861679abb05\\n  git: {}\\n\\r\\nRun ID: cbb was successful after 4m42s\\r\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.85\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'diabetes-training_1585430064_9b4f0ac2',\n",
       " 'target': 'aml-cluster',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2020-03-28T21:23:41.133957Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'c7dcadc3-228b-40ed-88d5-40fdf5749982',\n",
       "  'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '0e7102f49f3ae90e172c3b504d5bebc9f50b6446',\n",
       "  'mlflow.source.git.commit': '0e7102f49f3ae90e172c3b504d5bebc9f50b6446',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'AzureML.DerivedImageName': 'azureml/azureml_7a273b62f76221b8f2e7d811a9b5a0ed',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '2c81c692-c43c-4f03-9952-45124c0da47c'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes2', 'mechanism': 'Mount', 'pathOnCompute': 'diabetes_path'}}],\n",
       " 'runDefinition': {'script': 'diabetes_training.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization', '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'aml-cluster',\n",
       "  'dataReferences': {},\n",
       "  'data': {'diabetes2': {'dataLocation': {'dataset': {'id': '2c81c692-c43c-4f03-9952-45124c0da47c'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'diabetes2',\n",
       "    'pathOnCompute': 'diabetes_path',\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'training_environment',\n",
       "   'version': '18',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.8.2',\n",
       "      'scikit-learn',\n",
       "      'joblib',\n",
       "      {'pip': ['azureml-defaults', 'pyarrow', 'fastparquet']}],\n",
       "     'name': 'azureml_ed6ad1ace64132edbe11676fea09b7be'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585430064_9b4f0ac2/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=z9UPsUJZKW41rMB%2Bf8fhNQ%2BHFTgRvsNFO5NtecBIq20%3D&st=2020-03-28T21%3A15%3A26Z&se=2020-03-29T05%3A25%3A26Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_a0cd726ed715e4eb3fe203cea2262d09dcb8dfa8493913c3d1915b71c3da0f2b_p.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585430064_9b4f0ac2/azureml-logs/55_azureml-execution-tvmps_a0cd726ed715e4eb3fe203cea2262d09dcb8dfa8493913c3d1915b71c3da0f2b_p.txt?sv=2019-02-02&sr=b&sig=KyDJUHYf%2Fz%2Faucq750YdtSJH7xQgny1ZAhqSLWxVcXc%3D&st=2020-03-28T21%3A15%3A26Z&se=2020-03-29T05%3A25%3A26Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_a0cd726ed715e4eb3fe203cea2262d09dcb8dfa8493913c3d1915b71c3da0f2b_p.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585430064_9b4f0ac2/azureml-logs/65_job_prep-tvmps_a0cd726ed715e4eb3fe203cea2262d09dcb8dfa8493913c3d1915b71c3da0f2b_p.txt?sv=2019-02-02&sr=b&sig=Z0mc13IWkrdCiXkbCHnXKN%2BBGswFtzHAdiIGwa9rEB4%3D&st=2020-03-28T21%3A15%3A26Z&se=2020-03-29T05%3A25%3A26Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585430064_9b4f0ac2/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=0ILCG8lVXtflZBE43KuEyIQsiG0UcBuiz9Njwr15Lzg%3D&st=2020-03-28T21%3A15%3A26Z&se=2020-03-29T05%3A25%3A26Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_a0cd726ed715e4eb3fe203cea2262d09dcb8dfa8493913c3d1915b71c3da0f2b_p.txt': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585430064_9b4f0ac2/azureml-logs/75_job_post-tvmps_a0cd726ed715e4eb3fe203cea2262d09dcb8dfa8493913c3d1915b71c3da0f2b_p.txt?sv=2019-02-02&sr=b&sig=LjOoAGet%2Fg3pyp8rj%2B6DOLCIVA%2BzApC2B8VuZVSuRjM%3D&st=2020-03-28T21%3A15%3A26Z&se=2020-03-29T05%3A25%3A26Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585430064_9b4f0ac2/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=4ecMgeqDb%2F6CddzPI8lo2sd3eL5GTIocyUcVcuPewSQ%3D&st=2020-03-28T21%3A15%3A26Z&se=2020-03-29T05%3A25%3A26Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585430064_9b4f0ac2/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=uORs2pA1vq317NuhUGS1tWX5aOPPuSghcf1UWB%2FQbG4%3D&st=2020-03-28T21%3A15%3A26Z&se=2020-03-29T05%3A25%3A26Z&sp=r',\n",
       "  'logs/azureml/150_azureml.log': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585430064_9b4f0ac2/logs/azureml/150_azureml.log?sv=2019-02-02&sr=b&sig=oqCJQShB%2BsmBRCrGTxIsUak3y4ohTEe8U%2Foly4tDalA%3D&st=2020-03-28T21%3A15%3A26Z&se=2020-03-29T05%3A25%3A26Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://machinelstorage071578f15.blob.core.windows.net/azureml/ExperimentRun/dcid.diabetes-training_1585430064_9b4f0ac2/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=5RoPkYP%2F4LaJ9z7RKFdcCDFiOOMu7WAIwY2z%2BbEb%2Bdk%3D&st=2020-03-28T21%3A15%3A26Z&se=2020-03-29T05%3A25%3A26Z&sp=r'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the script parameters\n",
    "script_params = {'--regularization': 0.1}\n",
    "\n",
    "ds = Dataset.get_by_name(workspace=ws, name=\"diabetes2\")\n",
    "\n",
    "# Get the environment\n",
    "# retrieve your prepped compute environment from the list\n",
    "training_env = Environment.get(workspace=ws, name='training_environment')\n",
    "\n",
    "training_cluster = ComputeTarget(workspace=ws, name='aml-cluster')\n",
    "\n",
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                      entry_script='diabetes_training.py',\n",
    "                      script_params=script_params,\n",
    "                      environment_definition=training_env,\n",
    "                      compute_target=training_cluster,\n",
    "                      inputs=[ds.as_named_input('diabetes2').as_mount(path_on_compute='diabetes_path')]\n",
    "                     )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'diabetes-training'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()\n",
    "#run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. algorithms\n",
    "### 2. preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automl_run_config = RunConfiguration(framework='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automl_config = AutoMLConfig(name='Automated ML Experiment',\n",
    "#                              task='classification',\n",
    "#                              primary_metric = 'AUC_weighted',\n",
    "#                              compute_target=aml_compute,\n",
    "#                              training_data = train_dataset,\n",
    "#                              validation_data = test_dataset,\n",
    "#                              label_column_name='Label',\n",
    "#                              featurization='auto',\n",
    "#                              iterations=12,\n",
    "#                              max_concurrent_iterations=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['norm_macro_recall',\n",
       " 'AUC_weighted',\n",
       " 'average_precision_score_weighted',\n",
       " 'precision_score_weighted',\n",
       " 'accuracy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.automl.utilities import get_primary_metrics\n",
    "\n",
    "get_primary_metrics('classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spearman_correlation',\n",
       " 'normalized_root_mean_squared_error',\n",
       " 'r2_score',\n",
       " 'normalized_mean_absolute_error']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.automl.utilities import get_primary_metrics\n",
    "\n",
    "get_primary_metrics('regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core.experiment import Experiment\n",
    "\n",
    "# automl_experiment = Experiment(ws, 'automl_experiment')\n",
    "# automl_run = automl_experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show the run details while running\n",
    "# RunDetails(run).show()\n",
    "# run.wait_for_completion()\n",
    "# #run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the best run\n",
    "# best_run, fitted_model = automl_run.get_output()\n",
    "# best_run_metrics = best_run.get_metrics()\n",
    "# for metric_name in best_run_metrics:\n",
    "#     metric = best_run_metrics[metric_name]\n",
    "#     print(metric_name, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view preprocessing steps\n",
    "# for step_ in fitted_model.named_steps:\n",
    "#     print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try to autoML make it Work ! (using a local dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nbviewer.jupyter.org/github/MicrosoftDocs/mslearn-aml-labs/blob/master/07-Automated_ML.ipynb\n",
    "# https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/automated-machine-learning#samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try many combinations of algorithms and preprocessing transformations\n",
    "# automate the comparison of models trained using different algorithms and preprocessing options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azureml-sdk[automl,explain]\n",
      "  Downloading azureml_sdk-1.2.0-py3-none-any.whl (4.6 kB)\n",
      "Collecting azureml-train-automl-client~=1.2.0\n",
      "  Using cached azureml_train_automl_client-1.2.0-py3-none-any.whl (78 kB)\n",
      "Collecting azureml-dataprep[fuse]<1.4.0a,>=1.3.5\n",
      "  Using cached azureml_dataprep-1.3.5-py3-none-any.whl (26.6 MB)\n",
      "Collecting azureml-pipeline~=1.2.0\n",
      "  Downloading azureml_pipeline-1.2.0-py3-none-any.whl (3.7 kB)\n",
      "Collecting azureml-core~=1.2.0\n",
      "  Using cached azureml_core-1.2.0.post1-py3-none-any.whl (1.2 MB)\n",
      "Collecting azureml-train~=1.2.0\n",
      "  Downloading azureml_train-1.2.0-py3-none-any.whl (3.2 kB)\n",
      "Collecting azureml-train-automl~=1.2.0; extra == \"automl\"\n",
      "  Downloading azureml_train_automl-1.2.0-py3-none-any.whl (3.4 kB)\n",
      "Collecting azureml-explain-model~=1.2.0; extra == \"explain\"\n",
      "  Using cached azureml_explain_model-1.2.0-py3-none-any.whl (22 kB)\n",
      "Collecting azureml-automl-core~=1.2.0\n",
      "  Using cached azureml_automl_core-1.2.0-py3-none-any.whl (113 kB)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-train-automl-client~=1.2.0->azureml-sdk[automl,explain]) (2019.3)\n",
      "Collecting azureml-telemetry~=1.2.0\n",
      "  Using cached azureml_telemetry-1.2.0-py3-none-any.whl (29 kB)\n",
      "Collecting azure-identity>=1.2.0\n",
      "  Using cached azure_identity-1.3.0-py2.py3-none-any.whl (61 kB)\n",
      "Collecting dotnetcore2>=2.1.13\n",
      "  Using cached dotnetcore2-2.1.13-py3-none-manylinux1_x86_64.whl (29.3 MB)\n",
      "Collecting azureml-dataprep-native<15.0.0,>=14.1.0\n",
      "  Downloading azureml_dataprep_native-14.1.0-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 12.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: cloudpickle>=1.1.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-dataprep[fuse]<1.4.0a,>=1.3.5->azureml-sdk[automl,explain]) (1.2.2)\n",
      "Collecting fusepy>=3.0.1; extra == \"fuse\"\n",
      "  Using cached fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting azureml-pipeline-core~=1.2.0\n",
      "  Using cached azureml_pipeline_core-1.2.0-py3-none-any.whl (271 kB)\n",
      "Collecting azureml-pipeline-steps~=1.2.0\n",
      "  Downloading azureml_pipeline_steps-1.2.0-py3-none-any.whl (48 kB)\n",
      "\u001b[K     |████████████████████████████████| 48 kB 2.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting SecretStorage\n",
      "  Using cached SecretStorage-3.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting contextlib2\n",
      "  Using cached contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting backports.tempfile\n",
      "  Using cached backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied, skipping upgrade: jmespath in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3>=1.23 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (1.25.8)\n",
      "Collecting jsonpickle\n",
      "  Using cached jsonpickle-1.3-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied, skipping upgrade: azure-graphrbac>=0.40.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (0.40.0)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-containerregistry>=2.0.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: adal>=1.2.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-authorization>=0.40.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (0.50.0)\n",
      "Requirement already satisfied, skipping upgrade: PyJWT in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-keyvault>=0.40.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (1.1.0)\n",
      "Collecting pyopenssl\n",
      "  Using cached pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
      "Collecting ruamel.yaml<=0.15.89,>=0.15.35\n",
      "  Downloading ruamel.yaml-0.15.89-cp37-cp37m-manylinux1_x86_64.whl (647 kB)\n",
      "\u001b[K     |████████████████████████████████| 647 kB 31.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests>=2.19.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: msrestazure>=0.4.33 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: azure-common>=1.1.12 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (1.1.24)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-storage>=1.5.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (2.0.0)\n",
      "Collecting ndg-httpsclient\n",
      "  Using cached ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting pathspec\n",
      "  Using cached pathspec-0.7.0-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-resource>=1.2.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (2.2.0)\n",
      "Collecting docker\n",
      "  Using cached docker-4.2.0-py2.py3-none-any.whl (143 kB)\n",
      "Requirement already satisfied, skipping upgrade: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: msrest>=0.5.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-sdk[automl,explain]) (0.6.11)\n",
      "Collecting azureml-train-core~=1.2.0\n",
      "  Downloading azureml_train_core-1.2.0-py3-none-any.whl (8.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.6 MB 49.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azureml-automl-runtime~=1.2.0\n",
      "  Using cached azureml_automl_runtime-1.2.0-py3-none-any.whl (1.9 MB)\n",
      "Collecting azureml-train-automl-runtime~=1.2.0\n",
      "  Using cached azureml_train_automl_runtime-1.2.0-py3-none-any.whl (82 kB)\n",
      "Collecting azureml-interpret~=1.2.0\n",
      "  Using cached azureml_interpret-1.2.0-py3-none-any.whl (43 kB)\n",
      "Collecting applicationinsights\n",
      "  Using cached applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.6 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azure-identity>=1.2.0->azureml-dataprep[fuse]<1.4.0a,>=1.3.5->azureml-sdk[automl,explain]) (1.14.0)\n",
      "Collecting msal<2.0.0,>=1.0.0\n",
      "  Using cached msal-1.1.0-py2.py3-none-any.whl (44 kB)\n",
      "Collecting msal-extensions~=0.1.3\n",
      "  Using cached msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Using cached azure_core-1.3.0-py2.py3-none-any.whl (106 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Using cached distro-1.4.0-py2.py3-none-any.whl (17 kB)\n",
      "Collecting jeepney>=0.4.2\n",
      "  Using cached jeepney-0.4.3-py3-none-any.whl (21 kB)\n",
      "Collecting backports.weakref\n",
      "  Using cached backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Requirement already satisfied, skipping upgrade: azure-nspkg>=2.0.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azure-graphrbac>=0.40.0->azureml-core~=1.2.0->azureml-sdk[automl,explain]) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-nspkg>=2.0.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azure-mgmt-authorization>=0.40.0->azureml-core~=1.2.0->azureml-sdk[automl,explain]) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from requests>=2.19.1->azureml-core~=1.2.0->azureml-sdk[automl,explain]) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from requests>=2.19.1->azureml-core~=1.2.0->azureml-sdk[automl,explain]) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from requests>=2.19.1->azureml-core~=1.2.0->azureml-sdk[automl,explain]) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ndg-httpsclient->azureml-core~=1.2.0->azureml-sdk[automl,explain]) (0.4.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting websocket-client>=0.32.0\n",
      "  Using cached websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core~=1.2.0->azureml-sdk[automl,explain]) (1.13.2)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.5.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from msrest>=0.5.1->azureml-core~=1.2.0->azureml-sdk[automl,explain]) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: isodate>=0.6.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from msrest>=0.5.1->azureml-core~=1.2.0->azureml-sdk[automl,explain]) (0.6.0)\n",
      "Collecting flake8<=3.7.9,>=3.1.0; python_version >= \"3.6\"\n",
      "  Downloading flake8-3.7.9-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 3.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting azureml-train-restclients-hyperdrive~=1.2.0\n",
      "  Downloading azureml_train_restclients_hyperdrive-1.2.0-py3-none-any.whl (18 kB)\n",
      "Collecting pandas<=0.23.4,>=0.21.0\n",
      "  Downloading pandas-0.23.4-cp37-cp37m-manylinux1_x86_64.whl (8.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.8 MB 39.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting onnxconverter-common<=1.6.0,>=1.4.2\n",
      "  Using cached onnxconverter_common-1.6.0-py2.py3-none-any.whl (43 kB)\n",
      "Collecting pmdarima==1.1.1\n",
      "  Downloading pmdarima-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (696 kB)\n",
      "\u001b[K     |████████████████████████████████| 696 kB 41.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sklearn-pandas<=1.7.0,>=1.4.0\n",
      "  Downloading sklearn_pandas-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py-cpuinfo-5.0.0.tar.gz (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 124 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: lightgbm<=2.3.0,>=2.0.11 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (2.3.0)\n",
      "Collecting resource>=0.1.8\n",
      "  Downloading Resource-0.2.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting numpy<=1.16.2,>=1.16.0\n",
      "  Downloading numpy-1.16.2-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 20 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting patsy>=0.5.1\n",
      "  Downloading patsy-0.5.1-py2.py3-none-any.whl (231 kB)\n",
      "\u001b[K     |████████████████████████████████| 231 kB 36.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting skl2onnx==1.4.9\n",
      "  Downloading skl2onnx-1.4.9-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 53.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting statsmodels<=0.10.2,>=0.9.0\n",
      "  Downloading statsmodels-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (8.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.1 MB 41.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn<=0.20.3,>=0.19.0\n",
      "  Downloading scikit_learn-0.20.3-cp37-cp37m-manylinux1_x86_64.whl (5.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.4 MB 16.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting psutil<6.0.0,>=5.2.2\n",
      "  Downloading psutil-5.7.0.tar.gz (449 kB)\n",
      "\u001b[K     |████████████████████████████████| 449 kB 44.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting onnxmltools==1.4.1\n",
      "  Downloading onnxmltools-1.4.1-py2.py3-none-any.whl (371 kB)\n",
      "\u001b[K     |████████████████████████████████| 371 kB 50.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill>=0.2.8\n",
      "  Using cached dill-0.3.1.1.tar.gz (151 kB)\n",
      "Collecting scipy<=1.1.0,>=1.0.0\n",
      "  Downloading scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.2 MB 41 kB/s s eta 0:00:01     |███████████████▎                | 14.9 MB 33.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: gensim in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (3.8.1)\n",
      "Requirement already satisfied, skipping upgrade: onnx>=1.5.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (1.6.0)\n",
      "Collecting wheel==0.30.0\n",
      "  Using cached wheel-0.30.0-py2.py3-none-any.whl (49 kB)\n",
      "Collecting nimbusml>=1.5.0\n",
      "  Downloading nimbusml-1.7.0-cp37-none-manylinux1_x86_64.whl (116.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 116.2 MB 7.1 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting azureml-defaults~=1.2.0\n",
      "  Using cached azureml_defaults-1.2.0-py3-none-any.whl (3.0 kB)\n",
      "Collecting interpret-community==0.7.*\n",
      "  Using cached interpret_community-0.7.0-py3-none-any.whl (5.4 MB)\n",
      "Collecting portalocker~=1.0\n",
      "  Using cached portalocker-1.6.0-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /anaconda/envs/py37_default/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core~=1.2.0->azureml-sdk[automl,explain]) (2.19)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core~=1.2.0->azureml-sdk[automl,explain]) (3.1.0)\n",
      "Collecting pyflakes<2.2.0,>=2.1.0\n",
      "  Downloading pyflakes-2.1.1-py2.py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 3.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pycodestyle<2.6.0,>=2.5.0\n",
      "  Downloading pycodestyle-2.5.0-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 2.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: mccabe<0.7.0,>=0.6.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from flake8<=3.7.9,>=3.1.0; python_version >= \"3.6\"->azureml-train-core~=1.2.0->azureml-train~=1.2.0->azureml-sdk[automl,explain]) (0.6.1)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints<0.4.0,>=0.3.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from flake8<=3.7.9,>=3.1.0; python_version >= \"3.6\"->azureml-train-core~=1.2.0->azureml-train~=1.2.0->azureml-sdk[automl,explain]) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: protobuf in /anaconda/envs/py37_default/lib/python3.7/site-packages (from onnxconverter-common<=1.6.0,>=1.4.2->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (3.11.2)\n",
      "Requirement already satisfied, skipping upgrade: Cython>=0.29 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from pmdarima==1.1.1->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (0.29.14)\n",
      "Collecting JsonSir>=0.0.2\n",
      "  Downloading JsonSir-0.0.2.tar.gz (2.2 kB)\n",
      "Collecting JsonForm>=0.0.2\n",
      "  Downloading JsonForm-0.0.2.tar.gz (2.4 kB)\n",
      "Collecting python-easyconfig>=0.1.0\n",
      "  Downloading Python_EasyConfig-0.1.7-py2.py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied, skipping upgrade: keras2onnx in /anaconda/envs/py37_default/lib/python3.7/site-packages (from onnxmltools==1.4.1->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (1.6.5)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from gensim->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.2.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from onnx>=1.5.0->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (3.7.4.1)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Using cached azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Using cached Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Using cached configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Using cached json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting gunicorn==19.9.0\n",
      "  Using cached gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug==0.16.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-defaults~=1.2.0->azureml-train-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (0.16.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packaging\n",
      "  Downloading packaging-20.3-py2.py3-none-any.whl (37 kB)\n",
      "Collecting shap<=0.34.0,>=0.20.0\n",
      "  Downloading shap-0.34.0.tar.gz (264 kB)\n",
      "\u001b[K     |████████████████████████████████| 264 kB 47.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting interpret-core[required]==0.1.20\n",
      "  Using cached interpret_core-0.1.20-py3-none-any.whl (7.9 MB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /anaconda/envs/py37_default/lib/python3.7/site-packages (from protobuf->onnxconverter-common<=1.6.0,>=1.4.2->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (45.1.0.post20200127)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema in /anaconda/envs/py37_default/lib/python3.7/site-packages (from JsonForm>=0.0.2->resource>=0.1.8->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (3.2.0)\n",
      "Collecting PyYAML\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "\u001b[K     |████████████████████████████████| 269 kB 44.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: fire in /anaconda/envs/py37_default/lib/python3.7/site-packages (from keras2onnx->onnxmltools==1.4.1->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (1.11.9)\n",
      "Requirement already satisfied, skipping upgrade: boto>=2.32 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (2.49.0)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Using cached liac-arff-2.4.0.tar.gz (15 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Using cached itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied, skipping upgrade: click>=5.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from flask==1.0.3->azureml-defaults~=1.2.0->azureml-train-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: Jinja2>=2.10 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from flask==1.0.3->azureml-defaults~=1.2.0->azureml-train-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (2.10.3)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from packaging->interpret-community==0.7.*->azureml-interpret~=1.2.0->azureml-explain-model~=1.2.0; extra == \"explain\"->azureml-sdk[automl,explain]) (2.4.6)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>4.25.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from shap<=0.34.0,>=0.20.0->interpret-community==0.7.*->azureml-interpret~=1.2.0->azureml-explain-model~=1.2.0; extra == \"explain\"->azureml-sdk[automl,explain]) (4.42.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11; extra == \"required\" in /anaconda/envs/py37_default/lib/python3.7/site-packages (from interpret-core[required]==0.1.20->interpret-community==0.7.*->azureml-interpret~=1.2.0->azureml-explain-model~=1.2.0; extra == \"explain\"->azureml-sdk[automl,explain]) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /anaconda/envs/py37_default/lib/python3.7/site-packages (from jsonschema->JsonForm>=0.0.2->resource>=0.1.8->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from jsonschema->JsonForm>=0.0.2->resource>=0.1.8->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (0.15.7)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from jsonschema->JsonForm>=0.0.2->resource>=0.1.8->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor in /anaconda/envs/py37_default/lib/python3.7/site-packages (from fire->keras2onnx->onnxmltools==1.4.1->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (0.3.2)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.15.0,>=1.14.9 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (1.14.9)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from Jinja2>=2.10->flask==1.0.3->azureml-defaults~=1.2.0->azureml-train-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->JsonForm>=0.0.2->resource>=0.1.8->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from botocore<1.15.0,>=1.14.9->boto3->smart-open>=1.8.1->gensim->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (0.15.2)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /anaconda/envs/py37_default/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->jsonschema->JsonForm>=0.0.2->resource>=0.1.8->azureml-automl-runtime~=1.2.0->azureml-train-automl~=1.2.0; extra == \"automl\"->azureml-sdk[automl,explain]) (8.0.2)\n",
      "Building wheels for collected packages: fusepy, py-cpuinfo, psutil, dill, JsonSir, JsonForm, json-logging-py, shap, PyYAML, liac-arff\n",
      "  Building wheel for fusepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10502 sha256=651f70c09ed429bcc645dc74582d39e85acae1018962fb98f73c81582e311b95\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/89/07/84/a5ebfafeefbbc56ceda9d6935a54a8be7a4eccf4ea7e9bf980\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-5.0.0-py3-none-any.whl size=18684 sha256=2015a163fa343e0c14886628325ab7f85b8a74f2781e73de4374647ed3e32966\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/e7/3b/8e/2b1f0f6cc651cd381bb5806e5005820c6986867c46f3536101\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psutil: filename=psutil-5.7.0-cp37-cp37m-linux_x86_64.whl size=276506 sha256=ca231407bc138ad28b868ad21097c8ca9a63331566ee3cc7c5b1ca2c1095ad77\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/b6/e7/50/aee9cc966163d74430f13f208171dee22f11efa4a4a826661c\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78530 sha256=1081aacc10629d2ea21b4d568ce2f16366c5207109e843be4846bd9d160ef3bd\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
      "  Building wheel for JsonSir (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for JsonSir: filename=JsonSir-0.0.2-py3-none-any.whl size=4773 sha256=075bc0ab032bd01b517ec8c0528cd26f88ebb9e473bfe6ae9297456205aa6088\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/92/e7/84/a8d4911b522bbb5f666473d8078021b526aae31b049b53c902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for JsonForm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for JsonForm: filename=JsonForm-0.0.2-py3-none-any.whl size=3326 sha256=3569bb90a24a22ebafc27ea808a1a00779b42e6734c97c179cf818d0e1a7cef4\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/cb/e2/4e/2e3c9500e5e695f31fa97ad873d5565bbd985cc484cba4a265\n",
      "  Building wheel for json-logging-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=85dc098889f1ff86a61778c782180accd3ae7dda50d17c25c6cb0e72c01cadae\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/2b/2c/0b/56aba27cc60071c52f66346a1abc22ee9db8c7376549aa4910\n",
      "  Building wheel for shap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shap: filename=shap-0.34.0-cp37-cp37m-linux_x86_64.whl size=388179 sha256=eda9e70a07b8f229381bc9b0fe0ad4c3f51cfd8766f3f0a7b44998730197c90c\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/05/86/23/2c22a86fb2ba700382f20e1dbe536e211b3b1578aecc8adfac\n",
      "  Building wheel for PyYAML (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44620 sha256=aed170d1bf8eab05541f9e4074960f039cc62471531f95d2f41771f41eb2af08\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n",
      "  Building wheel for liac-arff (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for liac-arff: filename=liac_arff-2.4.0-py3-none-any.whl size=13333 sha256=31664eb5a75e3ea96cc541e7e2cc22e18b30af8e7f02df8842f4a29b19e5cb33\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/db/b2/8d/8737daed1b77ee2e9e834da36b2213d6e439bf42d82ce5e911\n",
      "Successfully built fusepy py-cpuinfo psutil dill JsonSir JsonForm json-logging-py shap PyYAML liac-arff\n",
      "\u001b[31mERROR: keras2onnx 1.6.5 has requirement onnxconverter-common>=1.6.5, but you'll have onnxconverter-common 1.6.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: catboost 0.18 has requirement pandas>=0.24.0, but you'll have pandas 0.23.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: msal, portalocker, msal-extensions, azure-core, azure-identity, distro, dotnetcore2, azureml-dataprep-native, fusepy, azureml-dataprep, azureml-automl-core, jeepney, SecretStorage, contextlib2, backports.weakref, backports.tempfile, jsonpickle, pyopenssl, ruamel.yaml, ndg-httpsclient, pathspec, websocket-client, docker, azureml-core, applicationinsights, azureml-telemetry, azureml-train-automl-client, azureml-pipeline-core, pyflakes, pycodestyle, flake8, azureml-train-restclients-hyperdrive, azureml-train-core, azureml-pipeline-steps, azureml-pipeline, azureml-train, numpy, pandas, onnxconverter-common, scipy, scikit-learn, patsy, statsmodels, pmdarima, sklearn-pandas, py-cpuinfo, JsonSir, JsonForm, PyYAML, python-easyconfig, resource, skl2onnx, psutil, onnxmltools, dill, wheel, nimbusml, azureml-automl-runtime, liac-arff, azureml-model-management-sdk, itsdangerous, flask, configparser, json-logging-py, gunicorn, azureml-defaults, packaging, shap, interpret-core, interpret-community, azureml-interpret, azureml-explain-model, azureml-train-automl-runtime, azureml-train-automl, azureml-sdk\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.1\n",
      "    Uninstalling numpy-1.18.1:\n",
      "      Successfully uninstalled numpy-1.18.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.0.0\n",
      "    Uninstalling pandas-1.0.0:\n",
      "      Successfully uninstalled pandas-1.0.0\n",
      "  Attempting uninstall: onnxconverter-common\n",
      "    Found existing installation: onnxconverter-common 1.6.5\n",
      "    Uninstalling onnxconverter-common-1.6.5:\n",
      "      Successfully uninstalled onnxconverter-common-1.6.5\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.3.2\n",
      "    Uninstalling scipy-1.3.2:\n",
      "      Successfully uninstalled scipy-1.3.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "  Attempting uninstall: skl2onnx\n",
      "    Found existing installation: skl2onnx 1.6.0\n",
      "    Uninstalling skl2onnx-1.6.0:\n",
      "      Successfully uninstalled skl2onnx-1.6.0\n",
      "  Attempting uninstall: onnxmltools\n",
      "    Found existing installation: onnxmltools 1.6.5\n",
      "    Uninstalling onnxmltools-1.6.5:\n",
      "      Successfully uninstalled onnxmltools-1.6.5\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.1\n",
      "    Uninstalling wheel-0.34.1:\n",
      "      Successfully uninstalled wheel-0.34.1\n",
      "  Attempting uninstall: configparser\n",
      "    Found existing installation: configparser 4.0.2\n",
      "    Uninstalling configparser-4.0.2:\n",
      "      Successfully uninstalled configparser-4.0.2\n",
      "Successfully installed JsonForm-0.0.2 JsonSir-0.0.2 PyYAML-5.3.1 SecretStorage-3.1.2 applicationinsights-0.11.9 azure-core-1.3.0 azure-identity-1.3.0 azureml-automl-core-1.2.0 azureml-automl-runtime-1.2.0 azureml-core-1.2.0.post1 azureml-dataprep-1.3.5 azureml-dataprep-native-14.1.0 azureml-defaults-1.2.0 azureml-explain-model-1.2.0 azureml-interpret-1.2.0 azureml-model-management-sdk-1.0.1b6.post1 azureml-pipeline-1.2.0 azureml-pipeline-core-1.2.0 azureml-pipeline-steps-1.2.0 azureml-sdk-1.2.0 azureml-telemetry-1.2.0 azureml-train-1.2.0 azureml-train-automl-1.2.0 azureml-train-automl-client-1.2.0 azureml-train-automl-runtime-1.2.0 azureml-train-core-1.2.0 azureml-train-restclients-hyperdrive-1.2.0 backports.tempfile-1.0 backports.weakref-1.0.post1 configparser-3.7.4 contextlib2-0.6.0.post1 dill-0.3.1.1 distro-1.4.0 docker-4.2.0 dotnetcore2-2.1.13 flake8-3.7.9 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 interpret-community-0.7.0 interpret-core-0.1.20 itsdangerous-1.1.0 jeepney-0.4.3 json-logging-py-0.2 jsonpickle-1.3 liac-arff-2.4.0 msal-1.1.0 msal-extensions-0.1.3 ndg-httpsclient-0.5.1 nimbusml-1.7.0 numpy-1.16.2 onnxconverter-common-1.6.0 onnxmltools-1.4.1 packaging-20.3 pandas-0.23.4 pathspec-0.7.0 patsy-0.5.1 pmdarima-1.1.1 portalocker-1.6.0 psutil-5.7.0 py-cpuinfo-5.0.0 pycodestyle-2.5.0 pyflakes-2.1.1 pyopenssl-19.1.0 python-easyconfig-0.1.7 resource-0.2.1 ruamel.yaml-0.15.89 scikit-learn-0.20.3 scipy-1.1.0 shap-0.34.0 skl2onnx-1.4.9 sklearn-pandas-1.7.0 statsmodels-0.10.2 websocket-client-0.57.0 wheel-0.30.0\n"
     ]
    }
   ],
   "source": [
    "# make sure you install this on the \"py_37default\" evironment !\n",
    "# this is when we compute 'local' it uses this default environment !\n",
    "! pip install --upgrade azureml-sdk[explain,automl]\n",
    "! pip install --upgrade azureml-widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azureml-widgets\n",
      "  Downloading azureml_widgets-1.2.0-py3-none-any.whl (14.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.3 MB 12.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: ipywidgets>=7.0.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-widgets) (7.5.1)\n",
      "Requirement already satisfied, skipping upgrade: azureml-telemetry~=1.2.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-widgets) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: azureml-core~=1.2.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-widgets) (1.2.0.post1)\n",
      "Requirement already satisfied, skipping upgrade: ipython>=4.0.0; python_version >= \"3.3\" in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipywidgets>=7.0.0->azureml-widgets) (7.11.1)\n",
      "Requirement already satisfied, skipping upgrade: ipykernel>=4.5.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipywidgets>=7.0.0->azureml-widgets) (5.1.4)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.3.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipywidgets>=7.0.0->azureml-widgets) (4.3.3)\n",
      "Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipywidgets>=7.0.0->azureml-widgets) (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: nbformat>=4.2.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipywidgets>=7.0.0->azureml-widgets) (5.0.4)\n",
      "Requirement already satisfied, skipping upgrade: applicationinsights in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-telemetry~=1.2.0->azureml-widgets) (0.11.9)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-containerregistry>=2.0.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: backports.tempfile in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (1.0)\n",
      "Requirement already satisfied, skipping upgrade: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: PyJWT in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: msrest>=0.5.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (0.6.11)\n",
      "Requirement already satisfied, skipping upgrade: urllib3>=1.23 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: SecretStorage in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (3.1.2)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-storage>=1.5.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: jmespath in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: azure-common>=1.1.12 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (1.1.24)\n",
      "Requirement already satisfied, skipping upgrade: msrestazure>=0.4.33 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-keyvault>=0.40.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: docker in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (4.2.0)\n",
      "Requirement already satisfied, skipping upgrade: ndg-httpsclient in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: ruamel.yaml<=0.15.89,>=0.15.35 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (0.15.89)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-authorization>=0.40.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (0.50.0)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-resource>=1.2.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pathspec in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonpickle in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (1.3)\n",
      "Requirement already satisfied, skipping upgrade: adal>=1.2.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: pyopenssl in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (19.1.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.19.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: azure-graphrbac>=0.40.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (0.40.0)\n",
      "Requirement already satisfied, skipping upgrade: contextlib2 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azureml-core~=1.2.0->azureml-widgets) (0.6.0.post1)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets) (4.4.1)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets) (3.0.3)\n",
      "Requirement already satisfied, skipping upgrade: pygments in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets) (2.5.2)\n",
      "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets) (4.8.0)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets) (45.1.0.post20200127)\n",
      "Requirement already satisfied, skipping upgrade: backcall in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets) (0.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=4.2 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->azureml-widgets) (6.0.3)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-client in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->azureml-widgets) (5.3.4)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in /anaconda/envs/py37_default/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets>=7.0.0->azureml-widgets) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: six in /anaconda/envs/py37_default/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets>=7.0.0->azureml-widgets) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: notebook>=4.4.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets) (6.0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: jupyter-core in /anaconda/envs/py37_default/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets) (4.6.1)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: backports.weakref in /anaconda/envs/py37_default/lib/python3.7/site-packages (from backports.tempfile->azureml-core~=1.2.0->azureml-widgets) (1.0.post1)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core~=1.2.0->azureml-widgets) (1.13.2)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.5.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from msrest>=0.5.1->azureml-core~=1.2.0->azureml-widgets) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: isodate>=0.6.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from msrest>=0.5.1->azureml-core~=1.2.0->azureml-widgets) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from msrest>=0.5.1->azureml-core~=1.2.0->azureml-widgets) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: jeepney>=0.4.2 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from SecretStorage->azureml-core~=1.2.0->azureml-widgets) (0.4.3)\n",
      "Requirement already satisfied, skipping upgrade: azure-mgmt-nspkg>=2.0.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azure-mgmt-storage>=1.5.0->azureml-core~=1.2.0->azureml-widgets) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client>=0.32.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from docker->azureml-core~=1.2.0->azureml-widgets) (0.57.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from ndg-httpsclient->azureml-core~=1.2.0->azureml-widgets) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from requests>=2.19.1->azureml-core~=1.2.0->azureml-widgets) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from requests>=2.19.1->azureml-core~=1.2.0->azureml-widgets) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: azure-nspkg>=2.0.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from azure-graphrbac>=0.40.0->azureml-core~=1.2.0->azureml-widgets) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /anaconda/envs/py37_default/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets) (0.1.7)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: parso>=0.5.2 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->azureml-widgets) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: pyzmq>=13 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0->azureml-widgets) (18.1.0)\n",
      "Requirement already satisfied, skipping upgrade: nbconvert in /anaconda/envs/py37_default/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets) (5.6.1)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets) (2.10.3)\n",
      "Requirement already satisfied, skipping upgrade: prometheus-client in /anaconda/envs/py37_default/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: Send2Trash in /anaconda/envs/py37_default/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets) (0.15.7)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /anaconda/envs/py37_default/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /anaconda/envs/py37_default/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core~=1.2.0->azureml-widgets) (2.19)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core~=1.2.0->azureml-widgets) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets) (0.3)\n",
      "Requirement already satisfied, skipping upgrade: bleach in /anaconda/envs/py37_default/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: defusedxml in /anaconda/envs/py37_default/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets) (1.4.2)\n",
      "Requirement already satisfied, skipping upgrade: testpath in /anaconda/envs/py37_default/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets) (0.4.4)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /anaconda/envs/py37_default/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: webencodings in /anaconda/envs/py37_default/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets) (0.5.1)\n",
      "Requirement already satisfied, skipping upgrade: more-itertools in /anaconda/envs/py37_default/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets) (8.0.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: azureml-widgets\n",
      "Successfully installed azureml-widgets-1.2.0\n"
     ]
    }
   ],
   "source": [
    "#! pip install --upgrade azureml-widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you can use the \"azureml_py36_automl\" kernel again...\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Datastore\n",
    "from azureml.core import Dataset\n",
    "from azureml.core import Environment\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "import pandas as pd\n",
    "from azureml.train.automl import AutoMLConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Your Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Automated Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('data/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>PlasmaGlucose</th>\n",
       "      <th>DiastolicBloodPressure</th>\n",
       "      <th>TricepsThickness</th>\n",
       "      <th>SerumInsulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>1638800</td>\n",
       "      <td>6</td>\n",
       "      <td>172</td>\n",
       "      <td>60</td>\n",
       "      <td>41</td>\n",
       "      <td>63</td>\n",
       "      <td>28.26</td>\n",
       "      <td>0.29</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5185</th>\n",
       "      <td>1236992</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>80</td>\n",
       "      <td>45</td>\n",
       "      <td>71</td>\n",
       "      <td>37.23</td>\n",
       "      <td>0.28</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6773</th>\n",
       "      <td>1786417</td>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>85</td>\n",
       "      <td>43</td>\n",
       "      <td>33</td>\n",
       "      <td>40.28</td>\n",
       "      <td>0.69</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PatientID  Pregnancies  PlasmaGlucose  DiastolicBloodPressure  \\\n",
       "4118    1638800            6            172                      60   \n",
       "5185    1236992            0            138                      80   \n",
       "6773    1786417            3            106                      85   \n",
       "\n",
       "      TricepsThickness  SerumInsulin   BMI  DiabetesPedigree  Age  Diabetic  \n",
       "4118                41            63 28.26              0.29   30         1  \n",
       "5185                45            71 37.23              0.28   22         0  \n",
       "6773                43            33 40.28              0.69   53         1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PatientID', 'Pregnancies', 'PlasmaGlucose', 'DiastolicBloodPressure',\n",
       "       'TricepsThickness', 'SerumInsulin', 'BMI', 'DiabetesPedigree', 'Age',\n",
       "       'Diabetic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_config = AutoMLConfig(name='Automated ML Experiment',\n",
    "                             task='classification',\n",
    "                             compute_target='local',\n",
    "                             training_data = train_data,\n",
    "                             n_cross_validations = 2,\n",
    "                             label_column_name = 'Diabetic',\n",
    "                             iterations=6,\n",
    "                             primary_metric = 'AUC_weighted',\n",
    "                             max_concurrent_iterations=3,\n",
    "                             featurization='auto'\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run an Automated Machine Learning Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U azureml-train-automl-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8606b652e3314b94a3281ffd0955bdd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/diabetes_automl/runs/AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/machine_learning_workspace\", \"run_id\": \"AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c\", \"run_properties\": {\"run_id\": \"AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c\", \"created_utc\": \"2020-03-30T14:29:35.749836Z\", \"properties\": {\"num_iterations\": \"6\", \"training_type\": \"TrainFull\", \"acquisition_function\": \"EI\", \"primary_metric\": \"AUC_weighted\", \"train_split\": \"0\", \"acquisition_parameter\": \"0\", \"num_cross_validation\": \"2\", \"target\": \"local\", \"RawAMLSettingsString\": \"{'name': 'Automated ML Experiment', 'path': '.', 'subscription_id': '43c1f93a-903d-4b23-a4bf-92bd7a150627', 'resource_group': 'myResourceGroup', 'workspace_name': 'machine_learning_workspace', 'region': 'westeurope', 'compute_target': 'local', 'spark_service': None, 'azure_service': 'local', 'iterations': 6, 'primary_metric': 'AUC_weighted', 'task_type': 'classification', 'data_script': None, 'validation_size': 0.0, 'n_cross_validations': 2, 'y_min': None, 'y_max': None, 'num_classes': 2, 'featurization': 'auto', 'lag_length': 0, 'is_timeseries': False, 'max_cores_per_iteration': 1, 'max_concurrent_iterations': 3, 'iteration_timeout_minutes': None, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'experiment_timeout_minutes': 10080, 'experiment_exit_score': None, 'whitelist_models': None, 'blacklist_algos': ['XGBoostClassifier', 'KNN', 'SVM'], 'supported_models': ['SGD', 'KNN', 'MultinomialNaiveBayes', 'TensorFlowDNN', 'ExtremeRandomTrees', 'DecisionTree', 'AveragedPerceptronClassifier', 'TensorFlowLinearClassifier', 'LinearSVM', 'GradientBoosting', 'RandomForest', 'XGBoostClassifier', 'LogisticRegression', 'SVM', 'BernoulliNaiveBayes', 'LightGBM'], 'auto_blacklist': True, 'blacklist_samples_reached': True, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'automl.log', 'show_warnings': False, 'model_explainability': True, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'enable_onnx_compatible_models': False, 'enable_split_onnx_featurizer_estimator_models': False, 'vm_type': None, 'telemetry_verbosity': 'INFO', 'send_telemetry': True, 'enable_dnn': False, 'force_text_dnn': False, 'enable_feature_sweeping': True, 'enable_early_stopping': False, 'early_stopping_n_iters': 10, 'metrics': None, 'enable_ensembling': True, 'enable_stack_ensembling': True, 'ensemble_iterations': 6, 'enable_tf': False, 'enable_cache': True, 'enable_subsampling': False, 'subsample_seed': None, 'enable_nimbusml': False, 'enable_streaming': False, 'force_streaming': False, 'label_column_name': 'Diabetic', 'weight_column_name': None, 'cost_mode': 1, 'metric_operation': 'maximize', 'preprocess': True, 'scenario': 'SDK'}\", \"AMLSettingsJsonString\": \"{\\\"name\\\": \\\"Automated ML Experiment\\\", \\\"path\\\": \\\".\\\", \\\"subscription_id\\\": \\\"43c1f93a-903d-4b23-a4bf-92bd7a150627\\\", \\\"resource_group\\\": \\\"myResourceGroup\\\", \\\"workspace_name\\\": \\\"machine_learning_workspace\\\", \\\"region\\\": \\\"westeurope\\\", \\\"compute_target\\\": \\\"local\\\", \\\"spark_service\\\": null, \\\"azure_service\\\": \\\"local\\\", \\\"iterations\\\": 6, \\\"primary_metric\\\": \\\"AUC_weighted\\\", \\\"task_type\\\": \\\"classification\\\", \\\"data_script\\\": null, \\\"validation_size\\\": 0.0, \\\"n_cross_validations\\\": 2, \\\"y_min\\\": null, \\\"y_max\\\": null, \\\"num_classes\\\": 2, \\\"featurization\\\": \\\"auto\\\", \\\"lag_length\\\": 0, \\\"is_timeseries\\\": false, \\\"max_cores_per_iteration\\\": 1, \\\"max_concurrent_iterations\\\": 3, \\\"iteration_timeout_minutes\\\": null, \\\"mem_in_mb\\\": null, \\\"enforce_time_on_windows\\\": false, \\\"experiment_timeout_minutes\\\": 10080, \\\"experiment_exit_score\\\": null, \\\"whitelist_models\\\": null, \\\"blacklist_algos\\\": [\\\"XGBoostClassifier\\\", \\\"KNN\\\", \\\"SVM\\\"], \\\"supported_models\\\": [\\\"SGD\\\", \\\"KNN\\\", \\\"MultinomialNaiveBayes\\\", \\\"TensorFlowDNN\\\", \\\"ExtremeRandomTrees\\\", \\\"DecisionTree\\\", \\\"AveragedPerceptronClassifier\\\", \\\"TensorFlowLinearClassifier\\\", \\\"LinearSVM\\\", \\\"GradientBoosting\\\", \\\"RandomForest\\\", \\\"XGBoostClassifier\\\", \\\"LogisticRegression\\\", \\\"SVM\\\", \\\"BernoulliNaiveBayes\\\", \\\"LightGBM\\\"], \\\"auto_blacklist\\\": true, \\\"blacklist_samples_reached\\\": true, \\\"exclude_nan_labels\\\": true, \\\"verbosity\\\": 20, \\\"debug_log\\\": \\\"automl.log\\\", \\\"show_warnings\\\": false, \\\"model_explainability\\\": true, \\\"service_url\\\": null, \\\"sdk_url\\\": null, \\\"sdk_packages\\\": null, \\\"enable_onnx_compatible_models\\\": false, \\\"enable_split_onnx_featurizer_estimator_models\\\": false, \\\"vm_type\\\": null, \\\"telemetry_verbosity\\\": \\\"INFO\\\", \\\"send_telemetry\\\": true, \\\"enable_dnn\\\": false, \\\"force_text_dnn\\\": false, \\\"enable_feature_sweeping\\\": true, \\\"enable_early_stopping\\\": false, \\\"early_stopping_n_iters\\\": 10, \\\"metrics\\\": null, \\\"enable_ensembling\\\": true, \\\"enable_stack_ensembling\\\": true, \\\"ensemble_iterations\\\": 6, \\\"enable_tf\\\": false, \\\"enable_cache\\\": true, \\\"enable_subsampling\\\": false, \\\"subsample_seed\\\": null, \\\"enable_nimbusml\\\": false, \\\"enable_streaming\\\": false, \\\"force_streaming\\\": false, \\\"label_column_name\\\": \\\"Diabetic\\\", \\\"weight_column_name\\\": null, \\\"cost_mode\\\": 1, \\\"metric_operation\\\": \\\"maximize\\\", \\\"preprocess\\\": true, \\\"scenario\\\": \\\"SDK\\\"}\", \"DataPrepJsonString\": null, \"EnableSubsampling\": \"False\", \"runTemplate\": \"AutoML\", \"azureml.runsource\": \"automl\", \"display_task_type\": \"classification\", \"dependencies_versions\": \"{\\\"azureml-widgets\\\": \\\"1.0.85\\\", \\\"azureml-train\\\": \\\"1.0.85\\\", \\\"azureml-train-restclients-hyperdrive\\\": \\\"1.0.85\\\", \\\"azureml-train-core\\\": \\\"1.0.85\\\", \\\"azureml-train-automl\\\": \\\"1.0.85\\\", \\\"azureml-train-automl-runtime\\\": \\\"1.2.0\\\", \\\"azureml-train-automl-client\\\": \\\"1.2.0\\\", \\\"azureml-tensorboard\\\": \\\"1.0.85\\\", \\\"azureml-telemetry\\\": \\\"1.2.0\\\", \\\"azureml-sdk\\\": \\\"1.0.85\\\", \\\"azureml-pipeline\\\": \\\"1.0.85\\\", \\\"azureml-pipeline-steps\\\": \\\"1.0.85\\\", \\\"azureml-pipeline-core\\\": \\\"1.2.0\\\", \\\"azureml-opendatasets\\\": \\\"1.0.85\\\", \\\"azureml-model-management-sdk\\\": \\\"1.0.1b6.post1\\\", \\\"azureml-interpret\\\": \\\"1.2.0\\\", \\\"azureml-explain-model\\\": \\\"1.2.0\\\", \\\"azureml-defaults\\\": \\\"1.2.0\\\", \\\"azureml-dataprep\\\": \\\"1.3.5\\\", \\\"azureml-dataprep-native\\\": \\\"14.1.0\\\", \\\"azureml-datadrift\\\": \\\"1.0.85\\\", \\\"azureml-core\\\": \\\"1.2.0.post1\\\", \\\"azureml-contrib-reinforcementlearning\\\": \\\"0.1.0.5919674\\\", \\\"azureml-contrib-notebook\\\": \\\"1.0.85\\\", \\\"azureml-contrib-interpret\\\": \\\"1.0.85\\\", \\\"azureml-automl-runtime\\\": \\\"1.2.0\\\", \\\"azureml-automl-core\\\": \\\"1.2.0\\\"}\", \"ClientType\": \"SDK\", \"ClientSdkVersion\": \"1.2.0\", \"environment_cpu_name\": \"\", \"environment_cpu_version\": \"\", \"environment_gpu_name\": \"\", \"environment_gpu_version\": \"\", \"ProblemInfoJsonString\": \"{\\\"dataset_num_categorical\\\": 0, \\\"is_sparse\\\": true, \\\"subsampling\\\": false, \\\"dataset_classes\\\": 2, \\\"dataset_features\\\": 23, \\\"dataset_samples\\\": 10000, \\\"single_frequency_class_detected\\\": false}\", \"feature_skus\": \"automatedml_sdk_guardrails\", \"azureml.git.repository_uri\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"mlflow.source.git.repoURL\": \"https://github.com/albert-kevin/azuremachinelearning.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"0e7102f49f3ae90e172c3b504d5bebc9f50b6446\", \"mlflow.source.git.commit\": \"0e7102f49f3ae90e172c3b504d5bebc9f50b6446\", \"azureml.git.dirty\": \"True\"}, \"tags\": {\"model_explain_run\": \"best_run\", \"model_explain_best_run_child_id\": \"AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c_0\", \"best_score\": \"0.9887307944471648\", \"best_pipeline\": \"LightGBM\"}, \"end_time_utc\": \"2020-03-30T14:32:07.766982Z\", \"status\": \"Completed\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:02:32\"}, \"child_runs\": [{\"run_id\": \"AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c_0\", \"run_number\": 9, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-03-30T14:30:14.909687Z\", \"end_time\": \"2020-03-30T14:30:30.412912Z\", \"created_time\": \"2020-03-30T14:30:14.729187Z\", \"created_time_dt\": \"2020-03-30T14:30:14.729187Z\", \"duration\": \"0:00:15\", \"iteration\": \"0\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, LightGBM\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.98873079, \"best_metric\": 0.98873079}, {\"run_id\": \"AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c_1\", \"run_number\": 10, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-03-30T14:30:32.004443Z\", \"end_time\": \"2020-03-30T14:30:46.810809Z\", \"created_time\": \"2020-03-30T14:30:31.705939Z\", \"created_time_dt\": \"2020-03-30T14:30:31.705939Z\", \"duration\": \"0:00:15\", \"iteration\": \"1\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, LightGBM\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.97994864, \"best_metric\": 0.98873079}, {\"run_id\": \"AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c_2\", \"run_number\": 11, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-03-30T14:30:50.636146Z\", \"end_time\": \"2020-03-30T14:31:08.54478Z\", \"created_time\": \"2020-03-30T14:30:50.471551Z\", \"created_time_dt\": \"2020-03-30T14:30:50.471551Z\", \"duration\": \"0:00:18\", \"iteration\": \"2\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"MaxAbsScaler, SGD\", \"run_properties\": \"copy=True\", \"primary_metric\": 0.93058648, \"best_metric\": 0.98873079}, {\"run_id\": \"AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c_3\", \"run_number\": 12, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-03-30T14:31:14.092986Z\", \"end_time\": \"2020-03-30T14:31:29.140271Z\", \"created_time\": \"2020-03-30T14:31:12.226046Z\", \"created_time_dt\": \"2020-03-30T14:31:12.226046Z\", \"duration\": \"0:00:16\", \"iteration\": \"3\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"StandardScalerWrapper, LightGBM\", \"run_properties\": \"<azureml.automl.runtime.shared.model_wrappers.StandardScalerWrapper object at 0x7f81ccfc6f60\", \"primary_metric\": 0.97979666, \"best_metric\": 0.98873079}, {\"run_id\": \"AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c_4\", \"run_number\": 13, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-03-30T14:31:30.617324Z\", \"end_time\": \"2020-03-30T14:31:41.713348Z\", \"created_time\": \"2020-03-30T14:31:30.391193Z\", \"created_time_dt\": \"2020-03-30T14:31:30.391193Z\", \"duration\": \"0:00:11\", \"iteration\": \"4\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"VotingEnsemble\", \"run_properties\": \"classification_labels=None,\\n               estimators=[('0', Pipeline(memory=None,\\n     steps=[('maxabsscaler', MaxAbsScaler(copy=True\", \"primary_metric\": 0.98801063, \"best_metric\": 0.98873079}, {\"run_id\": \"AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c_5\", \"run_number\": 14, \"metric\": null, \"status\": \"Completed\", \"run_type\": null, \"training_percent\": \"100\", \"start_time\": \"2020-03-30T14:31:42.706081Z\", \"end_time\": \"2020-03-30T14:31:55.730578Z\", \"created_time\": \"2020-03-30T14:31:42.598Z\", \"created_time_dt\": \"2020-03-30T14:31:42.598Z\", \"duration\": \"0:00:13\", \"iteration\": \"5\", \"goal\": \"AUC_weighted_max\", \"run_name\": \"StackEnsemble\", \"run_properties\": \"base_learners=[('0', Pipeline(memory=None,\\n     steps=[('maxabsscaler', MaxAbsScaler(copy=True\", \"primary_metric\": 0.9877102, \"best_metric\": 0.98873079}], \"children_metrics\": {\"categories\": [0], \"series\": {\"recall_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"recall_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9480999999999999, 0.9289000000000001, 0.8454999999999999, 0.929, 0.9469000000000001, 0.9466]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"recall_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999]}], \"log_loss\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"log_loss\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.12762078769027035, 0.2000891619771948, 0.3403121551492563, 0.22306624019148447, 0.14487672520068218, 0.14366222784780563]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"log_loss_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.12762078769027035, 0.12762078769027035, 0.12762078769027035, 0.12762078769027035, 0.12762078769027035, 0.12762078769027035]}], \"f1_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"f1_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9414766222109543, 0.9193508852777282, 0.8348793692289799, 0.9195705548896618, 0.9401089586436306, 0.9398028824877868]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"f1_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9414766222109543, 0.9414766222109543, 0.9414766222109543, 0.9414766222109543, 0.9414766222109543, 0.9414766222109543]}], \"precision_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"precision_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9479516256433123, 0.9285607586263296, 0.8624877613804638, 0.9286592580604958, 0.9467426997155217, 0.9464545871143822]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"precision_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9479516256433123, 0.9479516256433123, 0.9479516256433123, 0.9479516256433123, 0.9479516256433123, 0.9479516256433123]}], \"precision_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"precision_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9480999999999999, 0.9289000000000001, 0.8454999999999999, 0.929, 0.9469000000000001, 0.9466]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"precision_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999]}], \"average_precision_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"average_precision_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9902351771273721, 0.9824473401888254, 0.9301647923602414, 0.9822048643862759, 0.9894496216632422, 0.9893183493299778]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"average_precision_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9902351771273721, 0.9902351771273721, 0.9902351771273721, 0.9902351771273721, 0.9902351771273721, 0.9902351771273721]}], \"norm_macro_recall\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"norm_macro_recall\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.8794903988906442, 0.8311691167711547, 0.7110218845456984, 0.8324716322550819, 0.8766276871452363, 0.8764574845280225]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"norm_macro_recall_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.8794903988906442, 0.8794903988906442, 0.8794903988906442, 0.8794903988906442, 0.8794903988906442, 0.8794903988906442]}], \"average_precision_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"average_precision_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9868730917793174, 0.9756705163698761, 0.9139777334329997, 0.9758380749287371, 0.9858679123662012, 0.9855117069282353]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"average_precision_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9868730917793174, 0.9868730917793174, 0.9868730917793174, 0.9868730917793174, 0.9868730917793174, 0.9868730917793174]}], \"AUC_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"AUC_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9887307944471648, 0.9799486433677634, 0.9305864811404911, 0.9797966606955508, 0.988010625346702, 0.9877101993997712]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"AUC_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9887307944471648, 0.9887307944471648, 0.9887307944471648, 0.9887307944471648, 0.9887307944471648, 0.9887307944471648]}], \"balanced_accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"balanced_accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9397451994453221, 0.9155845583855773, 0.8555109422728492, 0.916235816127541, 0.9383138435726182, 0.9382287422640112]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"balanced_accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9397451994453221, 0.9397451994453221, 0.9397451994453221, 0.9397451994453221, 0.9397451994453221, 0.9397451994453221]}], \"AUC_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"AUC_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9900371800000001, 0.98204182, 0.92900578, 0.9818132800000001, 0.98930498, 0.98915084]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"AUC_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9900371800000001, 0.9900371800000001, 0.9900371800000001, 0.9900371800000001, 0.9900371800000001, 0.9900371800000001]}], \"accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9480999999999999, 0.9289000000000001, 0.8454999999999999, 0.929, 0.9469000000000001, 0.9466]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999]}], \"recall_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"recall_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9480999999999999, 0.9289000000000001, 0.8454999999999999, 0.929, 0.9469000000000001, 0.9466]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"recall_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999]}], \"average_precision_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"average_precision_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9893133642855426, 0.9804112558618829, 0.9306553836659186, 0.9804763493071854, 0.9885116882648552, 0.9882214882179323]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"average_precision_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9893133642855426, 0.9893133642855426, 0.9893133642855426, 0.9893133642855426, 0.9893133642855426, 0.9893133642855426]}], \"AUC_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"AUC_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9887307944471648, 0.9799486433677633, 0.9305864811404911, 0.9797966606955508, 0.9880106253467019, 0.9877101993997712]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"AUC_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9887307944471648, 0.9887307944471648, 0.9887307944471648, 0.9887307944471648, 0.9887307944471648, 0.9887307944471648]}], \"f1_score_micro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"f1_score_micro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9480999999999999, 0.9289000000000001, 0.8454999999999999, 0.929, 0.9469000000000001, 0.9466]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"f1_score_micro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999, 0.9480999999999999]}], \"precision_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"precision_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9432823058330543, 0.9235474386933737, 0.8264723624189616, 0.9232132794354657, 0.9419836553034111, 0.9414378035698407]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"precision_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9432823058330543, 0.9432823058330543, 0.9432823058330543, 0.9432823058330543, 0.9432823058330543, 0.9432823058330543]}], \"matthews_correlation\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"matthews_correlation\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.8830204071800469, 0.8390870250766345, 0.6813594955770772, 0.8394196618593631, 0.8802898493370254, 0.8796606402176703]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"matthews_correlation_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.8830204071800469, 0.8830204071800469, 0.8830204071800469, 0.8830204071800469, 0.8830204071800469, 0.8830204071800469]}], \"recall_score_macro\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"recall_score_macro\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9397451994453221, 0.9155845583855773, 0.8555109422728492, 0.916235816127541, 0.9383138435726182, 0.9382287422640112]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"recall_score_macro_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9397451994453221, 0.9397451994453221, 0.9397451994453221, 0.9397451994453221, 0.9397451994453221, 0.9397451994453221]}], \"weighted_accuracy\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"weighted_accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.954797070446216, 0.9395374642083159, 0.837479084866092, 0.939231885466908, 0.953780506619579, 0.9533056718372056]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"weighted_accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.954797070446216, 0.954797070446216, 0.954797070446216, 0.954797070446216, 0.954797070446216, 0.954797070446216]}], \"f1_score_weighted\": [{\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"markers\", \"name\": \"f1_score_weighted\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9479958722755598, 0.9285601563852723, 0.8487780057256524, 0.9287052790536583, 0.9467893095007495, 0.9465028996534353]}, {\"categories\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"], \"mode\": \"lines\", \"name\": \"f1_score_weighted_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9479958722755598, 0.9479958722755598, 0.9479958722755598, 0.9479958722755598, 0.9479958722755598, 0.9479958722755598]}]}, \"metricName\": null, \"primaryMetricName\": \"AUC_weighted\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"experiment_status\", \"run_id\": \"AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"series\": [{\"data\": [\"DatasetEvaluation\", \"FeaturesGeneration\", \"DatasetFeaturization\", \"DatasetFeaturizationCompleted\", \"DatasetCrossValidationSplit\", \"ModelSelection\", \"BestRunExplainModel\", \"ModelExplanationDataSetSetup\", \"EngineeredFeatureExplanations\", \"EngineeredFeatureExplanations\", \"BestRunExplainModel\"]}]}, {\"name\": \"experiment_status_description\", \"run_id\": \"AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"series\": [{\"data\": [\"Gathering dataset statistics.\", \"Generating features for the dataset.\", \"Beginning to fit featurizers and featurize the dataset.\", \"Completed fit featurizers and featurizing the dataset.\", \"Generating individually featurized CV splits.\", \"Beginning model selection.\", \"Best run model explanations started\", \"Model explanations data setup completed\", \"Computation of engineered features started\", \"Computation of engineered features completed\", \"Best run model explanations completed\"]}]}], \"run_logs\": \"\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.2.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-03-30T14:30:12.659269Z',\n",
       " 'endTimeUtc': '2020-03-30T14:32:07.766982Z',\n",
       " 'properties': {'num_iterations': '6',\n",
       "  'training_type': 'TrainFull',\n",
       "  'acquisition_function': 'EI',\n",
       "  'primary_metric': 'AUC_weighted',\n",
       "  'train_split': '0',\n",
       "  'acquisition_parameter': '0',\n",
       "  'num_cross_validation': '2',\n",
       "  'target': 'local',\n",
       "  'RawAMLSettingsString': \"{'name': 'Automated ML Experiment', 'path': '.', 'subscription_id': '43c1f93a-903d-4b23-a4bf-92bd7a150627', 'resource_group': 'myResourceGroup', 'workspace_name': 'machine_learning_workspace', 'region': 'westeurope', 'compute_target': 'local', 'spark_service': None, 'azure_service': 'local', 'iterations': 6, 'primary_metric': 'AUC_weighted', 'task_type': 'classification', 'data_script': None, 'validation_size': 0.0, 'n_cross_validations': 2, 'y_min': None, 'y_max': None, 'num_classes': 2, 'featurization': 'auto', 'lag_length': 0, 'is_timeseries': False, 'max_cores_per_iteration': 1, 'max_concurrent_iterations': 3, 'iteration_timeout_minutes': None, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'experiment_timeout_minutes': 10080, 'experiment_exit_score': None, 'whitelist_models': None, 'blacklist_algos': ['XGBoostClassifier', 'KNN', 'SVM'], 'supported_models': ['SGD', 'KNN', 'MultinomialNaiveBayes', 'TensorFlowDNN', 'ExtremeRandomTrees', 'DecisionTree', 'AveragedPerceptronClassifier', 'TensorFlowLinearClassifier', 'LinearSVM', 'GradientBoosting', 'RandomForest', 'XGBoostClassifier', 'LogisticRegression', 'SVM', 'BernoulliNaiveBayes', 'LightGBM'], 'auto_blacklist': True, 'blacklist_samples_reached': True, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'automl.log', 'show_warnings': False, 'model_explainability': True, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'enable_onnx_compatible_models': False, 'enable_split_onnx_featurizer_estimator_models': False, 'vm_type': None, 'telemetry_verbosity': 'INFO', 'send_telemetry': True, 'enable_dnn': False, 'force_text_dnn': False, 'enable_feature_sweeping': True, 'enable_early_stopping': False, 'early_stopping_n_iters': 10, 'metrics': None, 'enable_ensembling': True, 'enable_stack_ensembling': True, 'ensemble_iterations': 6, 'enable_tf': False, 'enable_cache': True, 'enable_subsampling': False, 'subsample_seed': None, 'enable_nimbusml': False, 'enable_streaming': False, 'force_streaming': False, 'label_column_name': 'Diabetic', 'weight_column_name': None, 'cost_mode': 1, 'metric_operation': 'maximize', 'preprocess': True, 'scenario': 'SDK'}\",\n",
       "  'AMLSettingsJsonString': '{\"name\": \"Automated ML Experiment\", \"path\": \".\", \"subscription_id\": \"43c1f93a-903d-4b23-a4bf-92bd7a150627\", \"resource_group\": \"myResourceGroup\", \"workspace_name\": \"machine_learning_workspace\", \"region\": \"westeurope\", \"compute_target\": \"local\", \"spark_service\": null, \"azure_service\": \"local\", \"iterations\": 6, \"primary_metric\": \"AUC_weighted\", \"task_type\": \"classification\", \"data_script\": null, \"validation_size\": 0.0, \"n_cross_validations\": 2, \"y_min\": null, \"y_max\": null, \"num_classes\": 2, \"featurization\": \"auto\", \"lag_length\": 0, \"is_timeseries\": false, \"max_cores_per_iteration\": 1, \"max_concurrent_iterations\": 3, \"iteration_timeout_minutes\": null, \"mem_in_mb\": null, \"enforce_time_on_windows\": false, \"experiment_timeout_minutes\": 10080, \"experiment_exit_score\": null, \"whitelist_models\": null, \"blacklist_algos\": [\"XGBoostClassifier\", \"KNN\", \"SVM\"], \"supported_models\": [\"SGD\", \"KNN\", \"MultinomialNaiveBayes\", \"TensorFlowDNN\", \"ExtremeRandomTrees\", \"DecisionTree\", \"AveragedPerceptronClassifier\", \"TensorFlowLinearClassifier\", \"LinearSVM\", \"GradientBoosting\", \"RandomForest\", \"XGBoostClassifier\", \"LogisticRegression\", \"SVM\", \"BernoulliNaiveBayes\", \"LightGBM\"], \"auto_blacklist\": true, \"blacklist_samples_reached\": true, \"exclude_nan_labels\": true, \"verbosity\": 20, \"debug_log\": \"automl.log\", \"show_warnings\": false, \"model_explainability\": true, \"service_url\": null, \"sdk_url\": null, \"sdk_packages\": null, \"enable_onnx_compatible_models\": false, \"enable_split_onnx_featurizer_estimator_models\": false, \"vm_type\": null, \"telemetry_verbosity\": \"INFO\", \"send_telemetry\": true, \"enable_dnn\": false, \"force_text_dnn\": false, \"enable_feature_sweeping\": true, \"enable_early_stopping\": false, \"early_stopping_n_iters\": 10, \"metrics\": null, \"enable_ensembling\": true, \"enable_stack_ensembling\": true, \"ensemble_iterations\": 6, \"enable_tf\": false, \"enable_cache\": true, \"enable_subsampling\": false, \"subsample_seed\": null, \"enable_nimbusml\": false, \"enable_streaming\": false, \"force_streaming\": false, \"label_column_name\": \"Diabetic\", \"weight_column_name\": null, \"cost_mode\": 1, \"metric_operation\": \"maximize\", \"preprocess\": true, \"scenario\": \"SDK\"}',\n",
       "  'DataPrepJsonString': None,\n",
       "  'EnableSubsampling': 'False',\n",
       "  'runTemplate': 'AutoML',\n",
       "  'azureml.runsource': 'automl',\n",
       "  'display_task_type': 'classification',\n",
       "  'dependencies_versions': '{\"azureml-widgets\": \"1.0.85\", \"azureml-train\": \"1.0.85\", \"azureml-train-restclients-hyperdrive\": \"1.0.85\", \"azureml-train-core\": \"1.0.85\", \"azureml-train-automl\": \"1.0.85\", \"azureml-train-automl-runtime\": \"1.2.0\", \"azureml-train-automl-client\": \"1.2.0\", \"azureml-tensorboard\": \"1.0.85\", \"azureml-telemetry\": \"1.2.0\", \"azureml-sdk\": \"1.0.85\", \"azureml-pipeline\": \"1.0.85\", \"azureml-pipeline-steps\": \"1.0.85\", \"azureml-pipeline-core\": \"1.2.0\", \"azureml-opendatasets\": \"1.0.85\", \"azureml-model-management-sdk\": \"1.0.1b6.post1\", \"azureml-interpret\": \"1.2.0\", \"azureml-explain-model\": \"1.2.0\", \"azureml-defaults\": \"1.2.0\", \"azureml-dataprep\": \"1.3.5\", \"azureml-dataprep-native\": \"14.1.0\", \"azureml-datadrift\": \"1.0.85\", \"azureml-core\": \"1.2.0.post1\", \"azureml-contrib-reinforcementlearning\": \"0.1.0.5919674\", \"azureml-contrib-notebook\": \"1.0.85\", \"azureml-contrib-interpret\": \"1.0.85\", \"azureml-automl-runtime\": \"1.2.0\", \"azureml-automl-core\": \"1.2.0\"}',\n",
       "  'ClientType': 'SDK',\n",
       "  'ClientSdkVersion': '1.2.0',\n",
       "  'environment_cpu_name': '',\n",
       "  'environment_cpu_version': '',\n",
       "  'environment_gpu_name': '',\n",
       "  'environment_gpu_version': '',\n",
       "  'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": true, \"subsampling\": false, \"dataset_classes\": 2, \"dataset_features\": 23, \"dataset_samples\": 10000, \"single_frequency_class_detected\": false}',\n",
       "  'feature_skus': 'automatedml_sdk_guardrails',\n",
       "  'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '0e7102f49f3ae90e172c3b504d5bebc9f50b6446',\n",
       "  'mlflow.source.git.commit': '0e7102f49f3ae90e172c3b504d5bebc9f50b6446',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'logFiles': {}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_experiment = Experiment(ws, 'diabetes_automl')\n",
    "automl_run = automl_experiment.submit(automl_config)\n",
    "RunDetails(automl_run).show()\n",
    "automl_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: diabetes_automl,\n",
      "Id: AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c_0,\n",
      "Type: None,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('datatransformer', DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
      "        feature_sweeping_config=None, feature_sweeping_timeout=None,\n",
      "        featurization_config=None, force_text_dnn=None,\n",
      "        is_cross_validation=None, is_onnx_compatible=None, logger=None,\n",
      "        obser...    silent=True, subsample=1.0, subsample_for_bin=200000,\n",
      "          subsample_freq=0, verbose=-10))])\n",
      "recall_score_micro 0.9480999999999999\n",
      "accuracy_table aml://artifactId/ExperimentRun/dcid.AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c_0/accuracy_table\n",
      "log_loss 0.12762078769027035\n",
      "f1_score_macro 0.9414766222109543\n",
      "precision_score_weighted 0.9479516256433123\n",
      "precision_score_micro 0.9480999999999999\n",
      "average_precision_score_micro 0.9902351771273721\n",
      "norm_macro_recall 0.8794903988906442\n",
      "average_precision_score_macro 0.9868730917793174\n",
      "AUC_weighted 0.9887307944471648\n",
      "balanced_accuracy 0.9397451994453221\n",
      "AUC_micro 0.9900371800000001\n",
      "accuracy 0.9480999999999999\n",
      "recall_score_weighted 0.9480999999999999\n",
      "average_precision_score_weighted 0.9893133642855426\n",
      "AUC_macro 0.9887307944471648\n",
      "f1_score_micro 0.9480999999999999\n",
      "precision_score_macro 0.9432823058330543\n",
      "matthews_correlation 0.8830204071800469\n",
      "confusion_matrix aml://artifactId/ExperimentRun/dcid.AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c_0/confusion_matrix\n",
      "recall_score_macro 0.9397451994453221\n",
      "weighted_accuracy 0.954797070446216\n",
      "f1_score_weighted 0.9479958722755598\n"
     ]
    }
   ],
   "source": [
    "# Determine the Best Performing Model\n",
    "# Notice: it uses sklearn transformation pipelines !\n",
    "best_run, fitted_model = automl_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "for metric_name in best_run_metrics:\n",
    "    metric = best_run_metrics[metric_name]\n",
    "    print(metric_name, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>diabetes_automl</td><td>AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c</td><td>automl</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/diabetes_automl/runs/AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/machine_learning_workspace\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: diabetes_automl,\n",
       "Id: AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c,\n",
       "Type: automl,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatransformer\n",
      "MaxAbsScaler\n",
      "LightGBMClassifier\n"
     ]
    }
   ],
   "source": [
    "for step in fitted_model.named_steps:\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Run(Experiment: diabetes_automl,\n",
       " Id: AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c_0,\n",
       " Type: None,\n",
       " Status: Completed),\n",
       " Pipeline(memory=None,\n",
       "      steps=[('datatransformer', DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
       "         feature_sweeping_config=None, feature_sweeping_timeout=None,\n",
       "         featurization_config=None, force_text_dnn=None,\n",
       "         is_cross_validation=None, is_onnx_compatible=None, logger=None,\n",
       "         obser...    silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "           subsample_freq=0, verbose=-10))]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_run.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_jasmine_client': <azureml._restclient.jasmine_client.JasmineClient at 0x7f81ceadae48>,\n",
       " '_experiment': Experiment(Name: diabetes_automl,\n",
       " Workspace: machine_learning_workspace),\n",
       " '_run_id': 'AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c',\n",
       " '_identity': 'AutoMLRun#AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c',\n",
       " '_logger': <Logger azureml.AutoMLRun#AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c (WARNING)>,\n",
       " '_portal_url': 'https://ml.azure.com',\n",
       " '_workspace_url': 'https://ml.azure.com?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/machine_learning_workspace',\n",
       " '_experiment_url': 'https://ml.azure.com/experiments/diabetes_automl?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/machine_learning_workspace',\n",
       " '_run_details_url': 'https://ml.azure.com/experiments/diabetes_automl/runs/AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c?wsid=/subscriptions/43c1f93a-903d-4b23-a4bf-92bd7a150627/resourcegroups/myResourceGroup/workspaces/machine_learning_workspace',\n",
       " '_client': <azureml._run_impl.run_history_facade.RunHistoryFacade at 0x7f81ceadae10>,\n",
       " '_root_run_id': 'AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c',\n",
       " '_outputs': None,\n",
       " '_run_number': 8,\n",
       " '_run_source': 'automl',\n",
       " '_runtype': 'automl',\n",
       " '_run_name': 'AutoML_735a99da-69ae-4cba-a0ea-039fcd8a112c',\n",
       " '_context_manager': <azureml._run_impl.run_context_manager.RunContextManager at 0x7f81cea54e10>,\n",
       " '_input_datasets': None,\n",
       " 'model_id': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_run.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoML using remote compute (with a local dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "# from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# # Choose a name for your CPU cluster\n",
    "# cpu_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "# # Verify that cluster does not exist already\n",
    "# try:\n",
    "#     compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "#     print('Found existing cluster, use it.')\n",
    "# except ComputeTargetException:\n",
    "#     compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "#                                                            max_nodes=4)\n",
    "#     compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "# compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we already have a compute instance, or we can make it manually in the portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "compute_target = ComputeTarget(workspace=ws, name='aml-cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "# choose a name for experiment\n",
    "experiment_name = 'automl-classification-bmarketing-all'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>PlasmaGlucose</th>\n",
       "      <th>DiastolicBloodPressure</th>\n",
       "      <th>TricepsThickness</th>\n",
       "      <th>SerumInsulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>1669671</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>21.928172</td>\n",
       "      <td>0.177577</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>1245444</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>91</td>\n",
       "      <td>43</td>\n",
       "      <td>140</td>\n",
       "      <td>48.002186</td>\n",
       "      <td>0.087448</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PatientID  Pregnancies  PlasmaGlucose  DiastolicBloodPressure  \\\n",
       "1152    1669671            0             67                      55   \n",
       "830     1245444            1            116                      91   \n",
       "\n",
       "      TricepsThickness  SerumInsulin        BMI  DiabetesPedigree  Age  \\\n",
       "1152                10            38  21.928172          0.177577   34   \n",
       "830                 43           140  48.002186          0.087448   32   \n",
       "\n",
       "      Diabetic  \n",
       "1152         0  \n",
       "830          0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"data/diabetes.csv\")\n",
    "data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet(\"data/diabetes.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AzureDataLakeGen2Datastore' object has no attribute 'upload_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-a9691d631875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This fails not compatible with data lake gen2 or something...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdatastore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatastore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_lake_gen2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdatastore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data/diabetes.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/diabetes.parquet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"target_path/tabular/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'AzureDataLakeGen2Datastore' object has no attribute 'upload_files'"
     ]
    }
   ],
   "source": [
    "# This fails not compatible with data lake gen2 or something...\n",
    "datastore = Datastore.get(ws, 'data_lake_gen2')\n",
    "datastore.upload_files(files=['data/diabetes.csv', 'data/diabetes.parquet'], target_path=\"target_path/tabular/\", overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading data/diabetes.csv\n",
      "Uploading data/diabetes.parquet\n",
      "Uploaded data/diabetes.csv, 1 files out of an estimated total of 2\n",
      "Uploaded data/diabetes.parquet, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_aa7f65b44dde4c2a85eec7d3fb8dd469"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we use default blob storage, it works fine\n",
    "datastore = Datastore.get(ws, 'workspaceblobstore')\n",
    "datastore.upload_files(files=['data/diabetes.csv', 'data/diabetes.parquet'], target_path=\"target_path/tabular/\", overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is needs is a dataset...\n",
    "from azureml.core import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"name\": \"workspaceblobstore\",\n",
       "  \"container_name\": \"azureml-blobstore-8ffd38a4-d688-44f6-9fc7-862df920c646\",\n",
       "  \"account_name\": \"machinelstorage071578f15\",\n",
       "  \"protocol\": \"https\",\n",
       "  \"endpoint\": \"core.windows.net\"\n",
       "}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Datastore.get(ws, 'workspaceblobstore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('workspaceblobstore', 'target_path/tabular/diabetes.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can it work from blob storage ?\n",
    "train_dataset = Dataset.Tabular.from_delimited_files(path=[(Datastore.get(ws, 'workspaceblobstore'), 'target_path/tabular/diabetes.csv')])\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('data_lake_gen2', 'platinum/diabetes.csv')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can it do it from data lake gen 2 ?\n",
    "train_dataset_2 = Dataset.Tabular.from_delimited_files(path=[(Datastore.get(ws, 'data_lake_gen2'), 'platinum/diabetes.csv')])\n",
    "train_dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you normally split the data up in training, validation and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define autoML settings:\n",
    "import logging\n",
    "\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_hours\" : 0.3,\n",
    "    \"enable_early_stopping\" : True,\n",
    "    \"iteration_timeout_minutes\": 5,\n",
    "    \"max_concurrent_iterations\": 4,\n",
    "    \"max_cores_per_iteration\": -1,\n",
    "    #\"n_cross_validations\": 2,\n",
    "    \"primary_metric\": 'AUC_weighted',\n",
    "    \"featurization\": 'auto',\n",
    "    \"verbosity\": logging.INFO,\n",
    "}\n",
    "\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             compute_target=compute_target,\n",
    "                             #experiment_exit_score = 0.9984,\n",
    "                             blacklist_models = ['KNN','LinearSVM'],\n",
    "                             enable_onnx_compatible_models=True,\n",
    "                             training_data = train_dataset,\n",
    "                             label_column_name = \"Diabetic\",\n",
    "                             #validation_data = validation_dataset,\n",
    "                             **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the submit method on the experiment object and pass the run configuration. Execution of local runs is synchronous.\n",
    "# Depending on the data and the number of iterations this can run for a while.\n",
    "remote_run = experiment.submit(automl_config, show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define autoML settings:\n",
    "import logging\n",
    "\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_hours\" : 0.3,\n",
    "    \"enable_early_stopping\" : True,\n",
    "    \"iteration_timeout_minutes\": 5,\n",
    "    \"max_concurrent_iterations\": 4,\n",
    "    \"max_cores_per_iteration\": -1,\n",
    "    #\"n_cross_validations\": 2,\n",
    "    \"primary_metric\": 'AUC_weighted',\n",
    "    \"featurization\": 'auto',\n",
    "    \"verbosity\": logging.INFO,\n",
    "}\n",
    "\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             compute_target=compute_target,\n",
    "                             #experiment_exit_score = 0.9984,\n",
    "                             blacklist_models = ['KNN','LinearSVM'],\n",
    "                             enable_onnx_compatible_models=True,\n",
    "                             training_data = train_dataset_2,\n",
    "                             label_column_name = \"Diabetic\",\n",
    "                             #validation_data = validation_dataset,\n",
    "                             **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the submit method on the experiment object and pass the run configuration. Execution of local runs is synchronous.\n",
    "# Depending on the data and the number of iterations this can run for a while.\n",
    "remote_run = experiment.submit(automl_config, show_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing some new parquet data loading from data lake "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.data.dataset_factory.tabulardatasetfactory?view=azure-ml-py#from-parquet-files-path--validate-true--include-path-false--set-column-types-none-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/work-with-data/dataset-api-change-notice.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset, Datastore\n",
    "from azureml.data.datapath import DataPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is the RIGHT way to register data !!!!  1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register first\n",
    "from azureml.core import Datastore\n",
    "ds = Datastore.register_azure_blob_container(workspace=ws,\n",
    "                                             datastore_name=\"datalakestoragegen2\",\n",
    "                                             container_name=\"datalake\",\n",
    "                                             account_name=\"datalake21032020\",\n",
    "                                             account_key=\"Ck/4hMq3Zrzq5toZ96zE6cDncjbw2VdkR9ny1xXA3GLBwQXIv7V1ycSc/KpqyNRcoPWKtzKljjpcZVqjWOu+3Q==\",\n",
    "                                             create_if_not_exists=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datalakestoragegen2': {\n",
       "   \"name\": \"datalakestoragegen2\",\n",
       "   \"container_name\": \"datalake\",\n",
       "   \"account_name\": \"datalake21032020\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " },\n",
       " 'data_lake_gen2': <azureml.data.azure_data_lake_datastore.AzureDataLakeGen2Datastore at 0x7fbbeab5f5f8>,\n",
       " 'workspacefilestore': {\n",
       "   \"name\": \"workspacefilestore\",\n",
       "   \"container_name\": \"azureml-filestore-8ffd38a4-d688-44f6-9fc7-862df920c646\",\n",
       "   \"account_name\": \"machinelstorage071578f15\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " },\n",
       " 'workspaceblobstore': {\n",
       "   \"name\": \"workspaceblobstore\",\n",
       "   \"container_name\": \"azureml-blobstore-8ffd38a4-d688-44f6-9fc7-862df920c646\",\n",
       "   \"account_name\": \"machinelstorage071578f15\",\n",
       "   \"protocol\": \"https\",\n",
       "   \"endpoint\": \"core.windows.net\"\n",
       " }}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.datastores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# registering parquet files now work !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core.compute import ComputeTarget\n",
    "# compute_target = ComputeTarget(workspace=ws, name='aml-cluster-fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "# choose a name for experiment\n",
    "experiment_name = 'automl-classification-2'\n",
    "experiment = Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual registration works on portal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see below if you want to do it code based manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset, Datastore\n",
    "from azureml.data.datapath import DataPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is the right way to register dataset !!!! 2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tabular dataset from Parquet files in datastore\n",
    "datastore = Datastore.get(ws, 'data_lake_gen2')\n",
    "datastore_path = [DataPath(datastore, 'platinum/diabetes.parquet')]\n",
    "tabular = Dataset.Tabular.from_parquet_files(path=datastore_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"('data_lake_gen2', 'platinum/diabetes.parquet')\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetDatastoreFiles\",\n",
       "    \"ReadParquetFile\",\n",
       "    \"DropColumns\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! now, run autoML using the \"tabular\" dataset (loaded from parquet file from data lake gen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "# from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# # Choose a name for your CPU cluster\n",
    "# cpu_cluster_name = \"aml-cluster-fast\"\n",
    "\n",
    "# # Verify that cluster does not exist already\n",
    "# try:\n",
    "#     compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "#     print('Found existing cluster, use it.')\n",
    "# except ComputeTargetException:\n",
    "#     compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D1',\n",
    "#                                                            max_nodes=4)\n",
    "#     compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "# compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "compute_target = ComputeTarget(workspace=ws, name='aml-cluster-fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define autoML settings:\n",
    "import logging\n",
    "\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_hours\" : 0.3,\n",
    "    \"enable_early_stopping\" : True,\n",
    "    \"iteration_timeout_minutes\": 5,\n",
    "    \"max_concurrent_iterations\": 4,\n",
    "    \"max_cores_per_iteration\": -1,\n",
    "    #\"n_cross_validations\": 2,\n",
    "    \"primary_metric\": 'AUC_weighted',\n",
    "    \"featurization\": 'auto',\n",
    "    \"verbosity\": logging.INFO,\n",
    "}\n",
    "\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             compute_target=compute_target,\n",
    "                             #experiment_exit_score = 0.9984,\n",
    "                             blacklist_models = ['KNN','LinearSVM'],\n",
    "                             enable_onnx_compatible_models=True,\n",
    "                             training_data = tabular,\n",
    "                             label_column_name = \"Diabetic\",\n",
    "                             #validation_data = validation_dataset,\n",
    "                             **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the submit method on the experiment object and pass the run configuration. Execution of local runs is synchronous.\n",
    "# Depending on the data and the number of iterations this can run for a while.\n",
    "remote_run = experiment.submit(automl_config, show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or you can do it from the DSVM local compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define autoML settings:\n",
    "import logging\n",
    "\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_hours\" : 0.3,\n",
    "    \"enable_early_stopping\" : True,\n",
    "    \"iteration_timeout_minutes\": 5,\n",
    "    \"max_concurrent_iterations\": 4,\n",
    "    \"max_cores_per_iteration\": -1,\n",
    "    #\"n_cross_validations\": 2,\n",
    "    \"primary_metric\": 'AUC_weighted',\n",
    "    \"featurization\": 'auto',\n",
    "    \"verbosity\": logging.INFO,\n",
    "}\n",
    "\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automl_errors.log',\n",
    "                             compute_target='local',\n",
    "                             #experiment_exit_score = 0.9984,\n",
    "                             blacklist_models = ['KNN','LinearSVM'],\n",
    "                             enable_onnx_compatible_models=True,\n",
    "                             training_data = tabular,\n",
    "                             label_column_name = \"Diabetic\",\n",
    "                             #validation_data = validation_dataset,\n",
    "                             **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_bda3cdce-2a48-47e2-8630-0b54114e0c1a\n",
      "\n",
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Cross validation\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  Each iteration of the trained model was validated through cross-validation.\n",
      "PARAMETERS:   Number of folds : 3\n",
      "              \n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Classes are balanced in the training data.\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:00:20       0.9900    0.9900\n",
      "         1   MaxAbsScaler LightGBM                          0:00:17       0.9800    0.9900\n",
      "         2   MaxAbsScaler SGD                               0:00:16       0.9318    0.9900\n",
      "         3   StandardScalerWrapper LightGBM                 0:00:17       0.9795    0.9900\n",
      "         4   MaxAbsScaler RandomForest                      0:00:18       0.9647    0.9900\n",
      "         5   MaxAbsScaler SGD                               0:00:17       0.9357    0.9900\n",
      "         6   MaxAbsScaler ExtremeRandomTrees                0:00:17       0.9347    0.9900\n",
      "         7   MaxAbsScaler SGD                               0:00:17       0.9316    0.9900\n",
      "         8   StandardScalerWrapper ExtremeRandomTrees       0:00:18       0.9309    0.9900\n",
      "         9   MaxAbsScaler RandomForest                      0:00:13       0.9595    0.9900\n",
      "        10   MaxAbsScaler LightGBM                          0:00:17       0.9647    0.9900\n",
      "        11   MaxAbsScaler BernoulliNaiveBayes               0:00:16       0.9150    0.9900\n",
      "        12   MaxAbsScaler SGD                               0:00:18       0.9238    0.9900\n",
      "        13   MaxAbsScaler LightGBM                          0:00:17       0.9855    0.9900\n",
      "        14   MaxAbsScaler ExtremeRandomTrees                0:00:18       0.9413    0.9900\n",
      "        15   MaxAbsScaler ExtremeRandomTrees                0:00:20       0.9319    0.9900\n",
      "        16   MaxAbsScaler SGD                               0:00:17       0.9378    0.9900\n",
      "        17   MaxAbsScaler LightGBM                          0:00:17       0.9669    0.9900\n",
      "        18   StandardScalerWrapper BernoulliNaiveBayes      0:00:15       0.9094    0.9900\n",
      "        19   MaxAbsScaler RandomForest                      0:00:19       0.9384    0.9900\n",
      "        20   MaxAbsScaler LightGBM                          0:00:18       0.9911    0.9911\n",
      "        21   MaxAbsScaler LightGBM                          0:00:19       0.9904    0.9911\n",
      "        22   StandardScalerWrapper LightGBM                 0:00:29       0.9894    0.9911\n",
      "        23   MaxAbsScaler LightGBM                          0:00:20       0.9905    0.9911\n",
      "        24   StandardScalerWrapper LightGBM                 0:00:24       0.9904    0.9911\n",
      "        25   MaxAbsScaler LightGBM                          0:00:20       0.9912    0.9912\n",
      "        26   MaxAbsScaler LightGBM                          0:00:21       0.9844    0.9912\n",
      "        27   MaxAbsScaler LightGBM                          0:00:21       0.9896    0.9912\n",
      "        28   StandardScalerWrapper LogisticRegression       0:00:21       0.9397    0.9912\n",
      "        29   MaxAbsScaler LightGBM                          0:00:22       0.9922    0.9922\n",
      "        30   StandardScalerWrapper LightGBM                 0:00:20       0.9737    0.9922\n",
      "        31   MaxAbsScaler LightGBM                          0:00:31       0.9895    0.9922\n",
      "        32   SparseNormalizer LightGBM                      0:00:19       0.9099    0.9922\n",
      "        33   MaxAbsScaler LightGBM                          0:00:24       0.9905    0.9922\n",
      "        34   StandardScalerWrapper LightGBM                 0:00:21       0.9896    0.9922\n",
      "        35   MaxAbsScaler LightGBM                          0:00:21       0.9911    0.9922\n",
      "        36   MaxAbsScaler LightGBM                          0:00:24       0.9891    0.9922\n",
      "        37   MaxAbsScaler LightGBM                          0:00:22       0.9912    0.9922\n",
      "        38   MaxAbsScaler LightGBM                          0:00:19       0.9844    0.9922\n",
      "        39   MaxAbsScaler LightGBM                          0:00:22       0.9863    0.9922\n",
      "        40   VotingEnsemble                                 0:00:41       0.9921    0.9922\n",
      "Stopping criteria reached at iteration 41. Ending experiment.\n",
      "****************************************************************************************************\n",
      "Current status: BestRunExplainModel. Best run model explanations started\n",
      "Current status: ModelExplanationDataSetSetup. Model explanations data setup completed\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features started\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features completed\n",
      "Current status: BestRunExplainModel. Best run model explanations completed\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Call the submit method on the experiment object and pass the run configuration. Execution of local runs is synchronous.\n",
    "# Depending on the data and the number of iterations this can run for a while.\n",
    "remote_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It both worked, it took 1h for the nodes to run, not sure why it is not using 4 nodes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# putting model into production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: diabetes-training\n",
      "Loading Data...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8893333333333333\n",
      "AUC: 0.8780635852529977\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace=ws, name=\"diabetes-training\")\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "run.upload_file(name='outputs/' + model_file,\n",
    "                path_or_stream='./' + model_file)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and registered.\n"
     ]
    }
   ],
   "source": [
    "run.register_model(model_path='outputs/diabetes_model.pkl',\n",
    "                   model_name='diabetes_model',\n",
    "                   tags={'Training context':'Inline Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'],\n",
    "                               'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "print('Model trained and registered.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(workspace=Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup'), name=diabetes_model, id=diabetes_model:1, version=1, tags={'Training context': 'Inline Training'}, properties={'AUC': '0.8780635852529977', 'Accuracy': '0.8893333333333333'}),\n",
       " Model(workspace=Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup'), name=titanic_classification_model, id=titanic_classification_model:1, version=1, tags={'testmodel': 'titanic'}, properties={})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see all registered models:\n",
    "from azureml.core import Model\n",
    "Model.list(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = ws.models['diabetes_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_service folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_name = 'diabetes_service'\n",
    "\n",
    "# Create a folder for the web service files\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "print(folder_name, 'folder created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - init() is called when the service is loaded, to load a registered model\n",
    "# - run(raw_data) is called when a prediction request is received, to predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_service/score_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $folder_name/score_diabetes.py\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = Model.get_model_path('diabetes_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-diabetic', 'diabetic']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependency info in diabetes_service/diabetes_env.yml\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = folder_name + \"/diabetes_env.yml\"\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running............................................................................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   source_directory = folder_name,\n",
    "                                   entry_script=\"score_diabetes.py\",\n",
    "                                   conda_file=\"diabetes_env.yml\")\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service_name = \"diabetes-service\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n",
      "2020-04-01T12:54:26,548604474+00:00 - iot-server/run \n",
      "2020-04-01T12:54:26,549049671+00:00 - rsyslog/run \n",
      "2020-04-01T12:54:26,552403047+00:00 - gunicorn/run \n",
      "2020-04-01T12:54:26,555699824+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-04-01T12:54:26,648832676+00:00 - iot-server/finish 1 0\n",
      "2020-04-01T12:54:26,651539057+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (14)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "Users's init has completed successfully\n",
      "Scoring timeout is found from os.environ: 60000 ms\n",
      "/azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/python3.6/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.20.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.state)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diabetes-service': AciWebservice(workspace=Workspace.create(name='machine_learning_workspace', subscription_id='43c1f93a-903d-4b23-a4bf-92bd7a150627', resource_group='myResourceGroup'), name=diabetes-service, image_id=None, compute_type=None, state=ACI, scoring_uri=None, tags=http://e611bf6a-1020-495d-8275-acfe095ecbdd.westeurope.azurecontainer.io/score, properties={}, created_by={'azureml.git.repository_uri': 'https://github.com/albert-kevin/azuremachinelearning.git', 'mlflow.source.git.repoURL': 'https://github.com/albert-kevin/azuremachinelearning.git', 'azureml.git.branch': 'master', 'mlflow.source.git.branch': 'master', 'azureml.git.commit': '591e0ae11867b48aaf248645cebf031e33dd9790', 'mlflow.source.git.commit': '591e0ae11867b48aaf248645cebf031e33dd9790', 'azureml.git.dirty': 'True'})}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list webservices\n",
    "ws.webservices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Web Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://e611bf6a-1020-495d-8275-acfe095ecbdd.westeurope.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "# HTTP requests to the web service\n",
    "# determine the URL to which these applications must submit their requests\n",
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22] diabetic\n",
      "Patient [0, 148, 58, 11, 179, 39.19207553, 0.160829008, 45] not-diabetic\n"
     ]
    }
   ],
   "source": [
    "# sending the patient data in JSON (or binary) format, and receive back the predicted class(es)\n",
    "import requests\n",
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "predicted_classes = json.loads(predictions.json())\n",
    "\n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete\n",
    "#service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py36_automl",
   "language": "python",
   "name": "conda-env-azureml_py36_automl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
